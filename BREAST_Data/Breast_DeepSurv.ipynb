{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sjquill/MSc_diss/blob/main/BREAST_Data/Breast_DeepSurv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq5yJvIVFRdv",
        "outputId": "5ed731c3-005e-46b9-9bfe-e6a10bc4dbee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lifelines\n",
            "  Downloading lifelines-0.27.7-py3-none-any.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.4/409.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.10.1)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (3.7.1)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.6.2)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines)\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting formulaic>=0.2.2 (from lifelines)\n",
            "  Downloading formulaic-0.6.4-py3-none-any.whl (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.9/88.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd>=1.5->lifelines) (0.18.3)\n",
            "Collecting astor>=0.8 (from formulaic>=0.2.2->lifelines)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines) (4.7.1)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines) (1.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->lifelines) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.16.0)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=e6dbe956a7905e92ed126a484d58a19197a106849330682e47a894b90eb0cd98\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/cc/e0/ef2969164144c899fedb22b338f6703e2b9cf46eeebf254991\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: interface-meta, astor, autograd-gamma, formulaic, lifelines\n",
            "Successfully installed astor-0.8.1 autograd-gamma-0.5.0 formulaic-0.6.4 interface-meta-1.3.0 lifelines-0.27.7\n",
            "Collecting pycox\n",
            "  Downloading pycox-0.2.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtuples>=0.2.0 (from pycox)\n",
            "  Downloading torchtuples-0.2.2-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting feather-format>=0.4.0 (from pycox)\n",
            "  Downloading feather-format-0.4.1.tar.gz (3.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from pycox) (3.9.0)\n",
            "Requirement already satisfied: numba>=0.44 in /usr/local/lib/python3.10/dist-packages (from pycox) (0.56.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from pycox) (1.2.2)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pycox) (2.31.0)\n",
            "Collecting py7zr>=0.11.3 (from pycox)\n",
            "  Downloading py7zr-0.20.6-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from feather-format>=0.4.0->pycox) (9.0.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py>=2.9.0->pycox) (1.23.5)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.44->pycox) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.44->pycox) (67.7.2)\n",
            "Collecting texttable (from py7zr>=0.11.3->pycox)\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pycryptodomex>=3.6.6 (from py7zr>=0.11.3->pycox)\n",
            "  Downloading pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzstd>=0.14.4 (from py7zr>=0.11.3->pycox)\n",
            "  Downloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyppmd<1.1.0,>=0.18.1 (from py7zr>=0.11.3->pycox)\n",
            "  Downloading pyppmd-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybcj>=0.6.0 (from py7zr>=0.11.3->pycox)\n",
            "  Downloading pybcj-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3 (from py7zr>=0.11.3->pycox)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting brotli>=1.0.9 (from py7zr>=0.11.3->pycox)\n",
            "  Downloading Brotli-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting inflate64>=0.3.1 (from py7zr>=0.11.3->pycox)\n",
            "  Downloading inflate64-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from py7zr>=0.11.3->pycox) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pycox) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pycox) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pycox) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pycox) (2023.7.22)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.2->pycox) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.2->pycox) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.2->pycox) (3.2.0)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from torchtuples>=0.2.0->pycox) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from torchtuples>=0.2.0->pycox) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->torchtuples>=0.2.0->pycox) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (1.16.0)\n",
            "Building wheels for collected packages: feather-format\n",
            "  Building wheel for feather-format (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feather-format: filename=feather_format-0.4.1-py3-none-any.whl size=2436 sha256=9d24a26900600b9f536fdfa2d589753b23e7c9d99c2f73e9b634b65fa056cc9a\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/ff/5d/4f10de26fe5ddef243c97f13c6cf579d7353d659e41a05c3a6\n",
            "Successfully built feather-format\n",
            "Installing collected packages: texttable, brotli, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, py7zr, feather-format, torchtuples, pycox\n",
            "Successfully installed brotli-1.0.9 feather-format-0.4.1 inflate64-0.3.1 multivolumefile-0.2.3 py7zr-0.20.6 pybcj-1.0.1 pycox-0.2.3 pycryptodomex-3.18.0 pyppmd-1.0.0 pyzstd-0.15.9 texttable-1.6.7 torchtuples-0.2.2\n",
            "Requirement already satisfied: torchtuples in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from torchtuples) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from torchtuples) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from torchtuples) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->torchtuples) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.3->torchtuples) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install lifelines\n",
        "!pip install pycox\n",
        "!pip install torchtuples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIKYA62DFXvp"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import lifelines\n",
        "import numpy as np\n",
        "from pycox.models import CoxPH\n",
        "from pycox.evaluation import EvalSurv\n",
        "\n",
        "import torch\n",
        "import torchtuples as tt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Y-aSrczFaaI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "breast_train_data_imputed1 = pd.read_csv(\"/content/drive/MyDrive/MSc_summer_project/Clinical_trial_data/Breast/breast_train_data_imputed1.csv\")\n",
        "breast_test_data_imputed1 = pd.read_csv(\"/content/drive/MyDrive/MSc_summer_project/Clinical_trial_data/Breast/breast_test_data_imputed1.csv\")\n",
        "train_data = breast_train_data_imputed1.copy()\n",
        "test_data = breast_test_data_imputed1.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XalHHJYFrvS"
      },
      "outputs": [],
      "source": [
        "column_names = [\n",
        "    'mask_id',\n",
        "    'disease_free_survival_status',\n",
        "    'disease_free_survival_months',\n",
        "    'race_asian',\n",
        "    'race_black',\n",
        "    'race_other',\n",
        "    'Treatment_CA_6',\n",
        "    'Treatment_T_4',\n",
        "    'Treatment_T_6',\n",
        "    'post_menopausal',\n",
        "    'tumor_side_right',\n",
        "    'tumor_side_bilateral',\n",
        "    'receptor_status_er_pos',\n",
        "    'receptor_status_pgrn_pos',\n",
        "    'histologic_grade_inter',\n",
        "    'histologic_grade_high',\n",
        "    'her2_status_pos',\n",
        "    'prior_hormonal_therapy_yes',\n",
        "    'most_extensive_primary_surgery_mast_NOS',\n",
        "    'tumor_size_2_to_5cm',\n",
        "    'tumor_size_over_5cm',\n",
        "    'num_pos_nodes_1',\n",
        "    'num_pos_nodes_2+',\n",
        "    'age_over_fifty'\n",
        "]\n",
        "# Set the new column names\n",
        "train_data.columns = column_names\n",
        "test_data.columns = column_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCZBhUbYINj2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "y_train = np.empty(len(train_data), dtype=[('disease_free_survival_status', bool), ('disease_free_survival_months', float)])\n",
        "y_train['disease_free_survival_status'] = train_data['disease_free_survival_status'].astype(bool)\n",
        "y_train['disease_free_survival_months'] = train_data['disease_free_survival_months']\n",
        "\n",
        "x_train = train_data.drop(columns=['disease_free_survival_status', 'disease_free_survival_months', 'mask_id'])\n",
        "\n",
        "# Repeat for test data.\n",
        "\n",
        "y_test = np.empty(len(test_data), dtype=[('disease_free_survival_status', bool), ('disease_free_survival_months', float)])\n",
        "y_test['disease_free_survival_status'] = test_data['disease_free_survival_status'].astype(bool)\n",
        "y_test['disease_free_survival_months'] = test_data['disease_free_survival_months']\n",
        "\n",
        "x_test = test_data.drop(columns=['disease_free_survival_status', 'disease_free_survival_months', 'mask_id'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgJhaRopHxc4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    x_train, y_train, test_size=0.2, stratify=y_train['disease_free_survival_status'], random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mk4A3jm9Hs2L",
        "outputId": "b860933e-a628-4dbd-94db-cced45b4a0d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 2000\n",
            "Validation set size: 500\n",
            "Test set size: 624\n"
          ]
        }
      ],
      "source": [
        "# Print the sizes of each set\n",
        "print(\"Train set size:\", len(x_train))\n",
        "print(\"Validation set size:\", len(x_val))\n",
        "print(\"Test set size:\", len(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UtyzkzjJE1s"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_val = x_val.astype('float32')\n",
        "x_test = x_test.astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLokh9mxJM2F",
        "outputId": "1c8ec275-4120-42a4-9cd5-3f8071ce1f9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "# Convert y_train to a 2D numpy array\n",
        "\n",
        "\n",
        "# Convert structured array to a 2D numpy array\n",
        "y_train_2d = np.array(y_train.tolist())\n",
        "\n",
        "# Convert boolean indicators to binary integers\n",
        "y_train_2d[:, 0] = y_train_2d[:, 0].astype(int)\n",
        "\n",
        "# Ensure time of events is float\n",
        "y_train_2d[:, 1] = y_train_2d[:, 1].astype(float)\n",
        "\n",
        "x_train = x_train.astype(np.float32)\n",
        "\n",
        "\n",
        "# Validation set\n",
        "# Convert structured array to a 2D numpy array\n",
        "y_val_2d = np.array(y_val.tolist())\n",
        "\n",
        "# Convert boolean indicators to binary integers\n",
        "y_val_2d[:, 0] = y_val_2d[:, 0].astype(int)\n",
        "\n",
        "# Ensure time of events is float\n",
        "y_val_2d[:, 1] = y_val_2d[:, 1].astype(float)\n",
        "\n",
        "\n",
        "## testing set\n",
        "# Convert structured array to a 2D numpy array\n",
        "y_test_2d = np.array(y_test.tolist())\n",
        "\n",
        "# Convert boolean indicators to binary integers\n",
        "y_test_2d[:, 0] = y_test_2d[:, 0].astype(int)\n",
        "\n",
        "# Ensure time of events is float\n",
        "y_test_2d[:, 1] = y_test_2d[:, 1].astype(float)\n",
        "\n",
        "x_test = x_test.astype(np.float32)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "x_train = x_train.values\n",
        "print(type(x_train))\n",
        "\n",
        "\n",
        "x_test = x_test.values\n",
        "print(type(x_test))\n",
        "\n",
        "\n",
        "x_val = x_val.values\n",
        "print(type(x_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BDikGSKJW0f",
        "outputId": "fab95345-6cd7-479f-a4e1-fa1b0d66495e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "(2000, 2)\n",
            "(2000, 21)\n",
            "(500, 2)\n",
            "(500, 21)\n",
            "(624, 2)\n",
            "(624, 21)\n"
          ]
        }
      ],
      "source": [
        "print(type(y_train_2d))\n",
        "print(type(x_train))\n",
        "\n",
        "print(type(y_val_2d))\n",
        "print(type(x_val))\n",
        "\n",
        "print(type(y_test_2d))\n",
        "print(type(x_test))\n",
        "\n",
        "print(y_train_2d.shape)\n",
        "print(x_train.shape)\n",
        "\n",
        "print(y_val_2d.shape)\n",
        "print(x_val.shape)\n",
        "\n",
        "print(y_test_2d.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0j1SVFA0JZP0"
      },
      "outputs": [],
      "source": [
        "y_train_event = y_train['disease_free_survival_status'].astype(np.float32)  # Convert Boolean to float for consistency\n",
        "y_train_surv = y_train['disease_free_survival_months'].astype(np.float32)\n",
        "\n",
        "y_train = (y_train_surv,y_train_event)\n",
        "\n",
        "y_val_event = y_val['disease_free_survival_status'].astype(np.float32)  # Convert Boolean to float for consistency\n",
        "y_val_surv = y_val['disease_free_survival_months'].astype(np.float32)\n",
        "\n",
        "\n",
        "y_test_event = y_test['disease_free_survival_status'].astype(np.float32)  # Convert Boolean to float for consistency\n",
        "y_test_surv = y_test['disease_free_survival_months'].astype(np.float32)\n",
        "\n",
        "y_val = (y_val_surv,y_val_event)\n",
        "\n",
        "val = (x_val,y_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3MvQZjOJfgT"
      },
      "outputs": [],
      "source": [
        "in_features = x_train.shape[1]\n",
        "num_nodes = [32, 32]\n",
        "out_features = 1\n",
        "batch_norm = True\n",
        "dropout = 0.1\n",
        "output_bias = False\n",
        "\n",
        "\n",
        "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm,\n",
        "                              dropout, output_bias=output_bias)\n",
        "\n",
        "model = CoxPH(net, tt.optim.Adam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "56oxULGtJq0n",
        "outputId": "70af602b-edcb-481e-9d06-778e947242f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.10722672220103299"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "batch_size = 256\n",
        "\n",
        "lrfinder = model.lr_finder(x_train, (y_train_event,y_train_surv), batch_size, tolerance=10)\n",
        "_ = lrfinder.plot()\n",
        "\n",
        "lrfinder.get_best_lr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GD3fC0bAJtR_"
      },
      "outputs": [],
      "source": [
        "model.optimizer.set_lr(0.01)\n",
        "epochs = 200\n",
        "callbacks = [tt.callbacks.EarlyStopping(patience = 50)]\n",
        "verbose = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R0bax5VNJxO7",
        "outputId": "c6a93cdb-c479-485f-b137-567c72784fd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 5.3034,\tval_loss: 4.9580\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 5.1008,\tval_loss: 4.9332\n",
            "2:\t[1s / 2s],\t\ttrain_loss: 5.0373,\tval_loss: 4.9185\n",
            "3:\t[0s / 2s],\t\ttrain_loss: 5.0087,\tval_loss: 4.9598\n",
            "4:\t[0s / 3s],\t\ttrain_loss: 4.9808,\tval_loss: 4.9947\n",
            "5:\t[0s / 3s],\t\ttrain_loss: 4.9455,\tval_loss: 5.1012\n",
            "6:\t[0s / 3s],\t\ttrain_loss: 4.8629,\tval_loss: 5.1964\n",
            "7:\t[0s / 3s],\t\ttrain_loss: 4.8035,\tval_loss: 5.3212\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 4.7658,\tval_loss: 5.4159\n",
            "9:\t[0s / 4s],\t\ttrain_loss: 4.7574,\tval_loss: 5.3970\n",
            "10:\t[0s / 4s],\t\ttrain_loss: 4.6748,\tval_loss: 5.4657\n",
            "11:\t[0s / 4s],\t\ttrain_loss: 4.5828,\tval_loss: 5.5726\n",
            "12:\t[0s / 4s],\t\ttrain_loss: 4.5880,\tval_loss: 5.6736\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 4.5714,\tval_loss: 5.9246\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 4.6903,\tval_loss: 5.9431\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 4.5410,\tval_loss: 5.9134\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 4.5154,\tval_loss: 5.9357\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 4.4775,\tval_loss: 5.9611\n",
            "18:\t[0s / 4s],\t\ttrain_loss: 4.5202,\tval_loss: 6.0695\n",
            "19:\t[0s / 4s],\t\ttrain_loss: 4.4161,\tval_loss: 6.0652\n",
            "20:\t[0s / 4s],\t\ttrain_loss: 4.4004,\tval_loss: 6.0919\n",
            "21:\t[0s / 4s],\t\ttrain_loss: 4.3803,\tval_loss: 6.3689\n",
            "22:\t[0s / 4s],\t\ttrain_loss: 4.3219,\tval_loss: 6.2137\n",
            "23:\t[0s / 4s],\t\ttrain_loss: 4.3659,\tval_loss: 6.0979\n",
            "24:\t[0s / 4s],\t\ttrain_loss: 4.3692,\tval_loss: 6.4827\n",
            "25:\t[0s / 4s],\t\ttrain_loss: 4.3572,\tval_loss: 6.4844\n",
            "26:\t[0s / 4s],\t\ttrain_loss: 4.3081,\tval_loss: 6.5363\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 4.3107,\tval_loss: 6.3561\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 4.3153,\tval_loss: 6.5004\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 4.2052,\tval_loss: 6.5765\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 4.2972,\tval_loss: 6.2773\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 4.2843,\tval_loss: 6.0821\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 4.3366,\tval_loss: 6.4082\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 4.1609,\tval_loss: 6.7189\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 4.1685,\tval_loss: 6.6609\n",
            "35:\t[0s / 5s],\t\ttrain_loss: 4.2077,\tval_loss: 6.9349\n",
            "36:\t[0s / 5s],\t\ttrain_loss: 4.3000,\tval_loss: 6.8839\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 4.2158,\tval_loss: 6.7891\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 4.1518,\tval_loss: 6.8731\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 4.1173,\tval_loss: 6.9110\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 4.1604,\tval_loss: 7.1173\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 4.1197,\tval_loss: 6.7222\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 4.0863,\tval_loss: 6.4705\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 4.1839,\tval_loss: 6.5816\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 4.2310,\tval_loss: 6.8120\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 4.1774,\tval_loss: 6.7250\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 4.1028,\tval_loss: 6.8688\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 4.0593,\tval_loss: 6.9558\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 4.1082,\tval_loss: 6.8934\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 3.9651,\tval_loss: 6.8039\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 4.0124,\tval_loss: 6.9452\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 3.9906,\tval_loss: 7.1484\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 4.0382,\tval_loss: 6.9813\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Then use these in your fit call:\n",
        "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose, val_data=val, val_batch_size=batch_size)\n",
        "_ = log.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "-e_ceb66JzCi",
        "outputId": "ff4c5ade-c85a-42d1-c2a2-21055ebb5177"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.partial_log_likelihood(*val).mean()\n",
        "\n",
        "_ = model.compute_baseline_hazards()\n",
        "surv = model.predict_surv_df(x_test)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "surv.iloc[:, :5].plot()\n",
        "plt.ylabel('S(t | x)')\n",
        "_ = plt.xlabel('Time')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_rwbUjSJ44H",
        "outputId": "2080f545-4c77-4992-8a75-9bf9e13326c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.6226428370391218"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pycox.evaluation import EvalSurv\n",
        "ev = EvalSurv(surv, y_test_surv, y_test_event, censor_surv='km')\n",
        "ev.concordance_td()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qoEweZm7hzwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8rAbGtHPhzoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BhDFrFbIYok",
        "outputId": "68dbdfbd-f72e-46fb-e9f7-dcc97fe1c8e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "5 fits failed out of a total of 500.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"<ipython-input-21-2138614a6197>\", line 51, in fit\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pycox/models/cox.py\", line 51, in fit\n",
            "    return super().fit(input, target, batch_size, epochs, callbacks, verbose,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchtuples/base.py\", line 294, in fit\n",
            "    log = self.fit_dataloader(dataloader, epochs, callbacks, verbose, metrics, val_dataloader)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchtuples/base.py\", line 236, in fit_dataloader\n",
            "    self.batch_metrics = self.compute_metrics(data, self.metrics)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchtuples/base.py\", line 180, in compute_metrics\n",
            "    out = self.net(*input)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchtuples/practical.py\", line 84, in forward\n",
            "    return self.net(input)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\", line 217, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchtuples/practical.py\", line 61, in forward\n",
            "    input = self.batch_norm(input)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\", line 171, in forward\n",
            "    return F.batch_norm(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 2448, in batch_norm\n",
            "    _verify_batch_size(input.size())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 2416, in _verify_batch_size\n",
            "    raise ValueError(\"Expected more than 1 value per channel when training, got input size {}\".format(size))\n",
            "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 37])\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.5837463         nan 0.65939469 0.74781998 0.50464092 0.58113806\n",
            " 0.50272351 0.75104722 0.74749046 0.66684843 0.51000847 0.75682746\n",
            " 0.58791857 0.50318057 0.75083312 0.5862965  0.50628707 0.58755366\n",
            " 0.50227811 0.49644118 0.66329804 0.50021488 0.82777827 0.58302873\n",
            " 0.50298203 0.64561404 0.58937082 0.5042068  0.50459258 0.6670956\n",
            " 0.58196983 0.50132935 0.66477025 0.74828977 0.52476107 0.76434118\n",
            " 0.83088657 0.66497179 0.50192005 0.66618879 0.67793983 0.50274176\n",
            " 0.74656954 0.50264222 0.6708081  0.66766577 0.66386247 0.76330592\n",
            " 0.58736289 0.91224409 0.58415591 0.66590456 0.91224409 0.66592038\n",
            " 0.83107593 0.83130653 0.83006513 0.75008381 0.91224409 0.58596634\n",
            " 0.83103572 0.83194657 0.66853571 0.66668523 0.66590818 0.74899509\n",
            " 0.51620201 0.6671769  0.74805976 0.74911362 0.66838243 0.66848734\n",
            " 0.58319754 0.50273463 0.50471639 0.5034063  0.74728552 0.75238583\n",
            " 0.50108988 0.6670796  0.66278232 0.82982583 0.74565238 0.6204741\n",
            " 0.50396314 0.7483465  0.91224409 0.67635577 0.50287497 0.50515145\n",
            " 0.50143417 0.75058574 0.67061328 0.50456642 0.75161373 0.8285183\n",
            " 0.5834442  0.504016   0.50277828 0.83112124]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Estimator learned through RandomizedSearch\n",
            "DeepSURVSklearnAdapter(batch_norm=False, batch_size=113,\n",
            "                       dropout=0.11714902934577448, epochs=100,\n",
            "                       learning_rate=0.004940957296838224,\n",
            "                       num_nodes_per_layer=16, patience=67,\n",
            "                       weight_decay=0.045113108680127245)\n"
          ]
        }
      ],
      "source": [
        "#### Randomised search attempt 3\n",
        "\n",
        "\n",
        "from sklearn.base import BaseEstimator\n",
        "from scipy.stats import randint, uniform\n",
        "import torchtuples as tt\n",
        "from pycox.models import CoxPH\n",
        "from pycox.evaluation import EvalSurv\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "class DeepSURVSklearnAdapter(BaseEstimator):\n",
        "    def __init__(\n",
        "        self,\n",
        "        learning_rate=1e-4,\n",
        "        batch_norm=True,\n",
        "        dropout=0.0,\n",
        "        num_nodes=[32, 32],\n",
        "        batch_size=128,\n",
        "        epochs=10,\n",
        "        weight_decay=0.0,\n",
        "        patience=50,\n",
        "        num_layers=2,\n",
        "        num_nodes_per_layer=20\n",
        "    ):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_norm = batch_norm\n",
        "        self.dropout = dropout\n",
        "        self.num_nodes = num_nodes\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.weight_decay = weight_decay\n",
        "        self.patience = patience\n",
        "        self.num_layers = num_layers\n",
        "        self.num_nodes_per_layer = num_nodes_per_layer\n",
        "\n",
        "    def fit(self, X, y, validation_data=None):\n",
        "      num_nodes = [self.num_nodes_per_layer] * self.num_layers\n",
        "      self.net_ = tt.practical.MLPVanilla(\n",
        "            X.shape[1],\n",
        "            num_nodes,\n",
        "            1,\n",
        "            self.batch_norm,\n",
        "            self.dropout,\n",
        "            output_bias=True,\n",
        "        )\n",
        "      self.deepsurv_ = CoxPH(self.net_, tt.optim.Adam(self.learning_rate, weight_decay=self.weight_decay))\n",
        "      y_ = (y[:, 0], y[:, 1])\n",
        "\n",
        "      callbacks = [tt.callbacks.EarlyStopping(patience=self.patience)]\n",
        "      log = self.deepsurv_.fit(\n",
        "            X,\n",
        "            y_,\n",
        "            batch_size=self.batch_size,\n",
        "            epochs=self.epochs,\n",
        "            callbacks=callbacks,\n",
        "            val_data=validation_data,\n",
        "            verbose=False,\n",
        "        )\n",
        "\n",
        "      return self\n",
        "\n",
        "    def score(self, X, y):\n",
        "        _ = self.deepsurv_.compute_baseline_hazards()\n",
        "        surv = self.deepsurv_.predict_surv_df(X)\n",
        "\n",
        "        ev = EvalSurv(\n",
        "            surv,\n",
        "            y[:, 0],\n",
        "            y[:, 1],\n",
        "            censor_surv=\"km\",\n",
        "        )\n",
        "\n",
        "        return ev.concordance_td()\n",
        "\n",
        "\n",
        "def DeepSURV(param_distributions, n_jobs, n_iter=100):\n",
        "\n",
        "    estimator = DeepSURVSklearnAdapter()\n",
        "\n",
        "    surv = RandomizedSearchCV(estimator=estimator, cv=None, param_distributions=param_distributions,\n",
        "                              n_jobs=n_jobs, n_iter=n_iter)\n",
        "\n",
        "    surv.fit(x_train, y_train_2d, validation_data=(x_val, y_val))\n",
        "\n",
        "    print(\"Best Estimator learned through RandomizedSearch\")\n",
        "    print(surv.best_estimator_)\n",
        "\n",
        "    return surv.best_estimator_\n",
        "\n",
        "param_distributions = {\n",
        "    'learning_rate': uniform(0.001, 0.01),\n",
        "    'num_layers': randint(1, 4),\n",
        "    'num_nodes_per_layer': randint(5, 40),\n",
        "    'batch_norm': [True, False],\n",
        "    'dropout': uniform(0, 0.5),\n",
        "    'batch_size': randint(32, 264),\n",
        "    'epochs': [100],\n",
        "    'patience': randint(25,100),\n",
        "    'weight_decay': uniform(0, 0.5)\n",
        "}\n",
        "\n",
        "n_jobs = -1\n",
        "\n",
        "best_est = DeepSURV(param_distributions, n_jobs)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ei8ckRMYIYkn",
        "outputId": "d4cf4ed4-b238-48e0-eb5c-3391ab52f4d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3895,\tval_loss: 4.0425\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3384,\tval_loss: 4.0408\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3332,\tval_loss: 4.0362\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2894,\tval_loss: 4.0360\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2912,\tval_loss: 4.0338\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2824,\tval_loss: 4.0383\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2614,\tval_loss: 4.0432\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2846,\tval_loss: 4.0337\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.2435,\tval_loss: 4.0382\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.2550,\tval_loss: 4.0336\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.2485,\tval_loss: 4.0545\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.2414,\tval_loss: 4.0437\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.2752,\tval_loss: 4.0381\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.2602,\tval_loss: 4.0436\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.2421,\tval_loss: 4.0309\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.2268,\tval_loss: 4.0273\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.2302,\tval_loss: 4.0239\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.2367,\tval_loss: 4.0438\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.2442,\tval_loss: 4.0319\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 4.1875,\tval_loss: 4.0589\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 4.1841,\tval_loss: 4.0446\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 4.1753,\tval_loss: 4.0763\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 4.2052,\tval_loss: 4.0419\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 4.1970,\tval_loss: 4.0513\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 4.2031,\tval_loss: 4.0608\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 4.1844,\tval_loss: 4.0331\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 4.1843,\tval_loss: 4.0513\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 4.1758,\tval_loss: 4.0487\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 4.1778,\tval_loss: 4.0783\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 4.1684,\tval_loss: 4.0545\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 4.2403,\tval_loss: 4.0591\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 4.2116,\tval_loss: 4.0334\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 4.1738,\tval_loss: 4.0444\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 4.1433,\tval_loss: 4.1065\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 4.1800,\tval_loss: 4.0305\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 4.1399,\tval_loss: 4.0546\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 4.1730,\tval_loss: 4.0699\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 4.1674,\tval_loss: 4.0867\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 4.1454,\tval_loss: 4.0822\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 4.1675,\tval_loss: 4.0998\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 4.1216,\tval_loss: 4.0725\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 4.1296,\tval_loss: 4.0417\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 4.1113,\tval_loss: 4.0789\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 4.1633,\tval_loss: 4.0872\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 4.1761,\tval_loss: 4.0945\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 4.1560,\tval_loss: 4.0797\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 4.1316,\tval_loss: 4.0710\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 4.1736,\tval_loss: 4.0793\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 4.1048,\tval_loss: 4.0774\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 4.1043,\tval_loss: 4.0723\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 4.1433,\tval_loss: 4.0853\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 4.0980,\tval_loss: 4.0924\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 4.1290,\tval_loss: 4.0761\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 4.1249,\tval_loss: 4.0777\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 4.0995,\tval_loss: 4.1107\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 4.1506,\tval_loss: 4.1037\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 4.1018,\tval_loss: 4.1057\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 4.1299,\tval_loss: 4.1057\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 4.1378,\tval_loss: 4.0703\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 4.1347,\tval_loss: 4.0581\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 4.1025,\tval_loss: 4.1185\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 4.0794,\tval_loss: 4.0404\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 4.0871,\tval_loss: 4.0427\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 4.1348,\tval_loss: 4.0603\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 4.1178,\tval_loss: 4.1125\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 4.0802,\tval_loss: 4.0673\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 4.0909,\tval_loss: 4.1101\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 4.0907,\tval_loss: 4.0625\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 4.0544,\tval_loss: 4.1196\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 4.0900,\tval_loss: 4.1017\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 4.1250,\tval_loss: 4.1053\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 4.0632,\tval_loss: 4.1160\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 4.1083,\tval_loss: 4.1135\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 4.0908,\tval_loss: 4.1206\n",
            "74:\t[0s / 3s],\t\ttrain_loss: 4.0926,\tval_loss: 4.0790\n",
            "75:\t[0s / 3s],\t\ttrain_loss: 4.1434,\tval_loss: 4.0813\n",
            "76:\t[0s / 3s],\t\ttrain_loss: 4.0904,\tval_loss: 4.1239\n",
            "77:\t[0s / 3s],\t\ttrain_loss: 4.0959,\tval_loss: 4.1266\n",
            "78:\t[0s / 3s],\t\ttrain_loss: 4.0814,\tval_loss: 4.0957\n",
            "79:\t[0s / 3s],\t\ttrain_loss: 4.0530,\tval_loss: 4.1201\n",
            "80:\t[0s / 3s],\t\ttrain_loss: 4.0838,\tval_loss: 4.1029\n",
            "81:\t[0s / 3s],\t\ttrain_loss: 4.0823,\tval_loss: 4.1177\n",
            "82:\t[0s / 3s],\t\ttrain_loss: 4.0390,\tval_loss: 4.1150\n",
            "83:\t[0s / 3s],\t\ttrain_loss: 4.0772,\tval_loss: 4.1373\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "learning_rate = best_est.learning_rate\n",
        "num_nodes = best_est.num_nodes\n",
        "batch_norm = best_est.batch_norm\n",
        "dropout = best_est.dropout\n",
        "batch_size = best_est.batch_size\n",
        "epochs = best_est.epochs\n",
        "patience = best_est.patience\n",
        "weight_decay = best_est.weight_decay\n",
        "\n",
        "\n",
        "# Define the network architecture and the model\n",
        "in_features = x_train.shape[1]\n",
        "out_features = 1\n",
        "output_bias = False\n",
        "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout, output_bias=output_bias)\n",
        "model = CoxPH(net, tt.optim.Adam(learning_rate, weight_decay = weight_decay))\n",
        "\n",
        "# Set up the training parameters and train the model\n",
        "model.optimizer.set_lr(learning_rate)\n",
        "callbacks = [tt.callbacks.EarlyStopping(patience=patience)]\n",
        "verbose = True\n",
        "\n",
        "# Train the model and plot the training performance\n",
        "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose, val_data=val, val_batch_size=batch_size)\n",
        "_ = log.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSjjbnzeyAru",
        "outputId": "56afdca7-9a51-49d8-e982-d410071eaa9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6487897551365044"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "\n",
        "from pycox.evaluation import EvalSurv\n",
        "\n",
        "model.partial_log_likelihood(*val).mean()\n",
        "\n",
        "_ = model.compute_baseline_hazards()\n",
        "surv = model.predict_surv_df(x_test)\n",
        "\n",
        "ev = EvalSurv(surv, y_test_surv, y_test_event, censor_surv='km')\n",
        "ev.concordance_td()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahahdIZsyAhC",
        "outputId": "cdee8ed8-4a14-4bfa-8de1-8273ac393d3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4232,\tval_loss: 4.0456\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2723,\tval_loss: 4.0504\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2454,\tval_loss: 4.0823\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2161,\tval_loss: 4.0780\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1676,\tval_loss: 4.0920\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1741,\tval_loss: 4.0874\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1492,\tval_loss: 4.1204\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 4.1210,\tval_loss: 4.1284\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 4.0610,\tval_loss: 4.1436\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 4.1010,\tval_loss: 4.1236\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 4.0847,\tval_loss: 4.1129\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 4.0793,\tval_loss: 4.1196\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 4.0343,\tval_loss: 4.1731\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 4.0147,\tval_loss: 4.1977\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.9437,\tval_loss: 4.2299\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9531,\tval_loss: 4.2410\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9425,\tval_loss: 4.2607\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9962,\tval_loss: 4.2979\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.8750,\tval_loss: 4.3101\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8720,\tval_loss: 4.3378\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9024,\tval_loss: 4.2793\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 3.8892,\tval_loss: 4.3356\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 3.8330,\tval_loss: 4.3669\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 3.9023,\tval_loss: 4.2931\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 3.8130,\tval_loss: 4.3212\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 3.8014,\tval_loss: 4.5261\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 3.7846,\tval_loss: 4.3637\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 3.8546,\tval_loss: 4.3547\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 3.8154,\tval_loss: 4.3271\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.8204,\tval_loss: 4.3558\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.7590,\tval_loss: 4.3845\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 3.8064,\tval_loss: 4.3193\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 3.7002,\tval_loss: 4.3851\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 3.6950,\tval_loss: 4.4652\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 3.6692,\tval_loss: 4.4170\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 3.7086,\tval_loss: 4.3764\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 3.8047,\tval_loss: 4.3645\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 3.7072,\tval_loss: 4.4389\n",
            "38:\t[0s / 3s],\t\ttrain_loss: 3.6250,\tval_loss: 4.3917\n",
            "39:\t[0s / 3s],\t\ttrain_loss: 3.6532,\tval_loss: 4.5489\n",
            "40:\t[0s / 3s],\t\ttrain_loss: 3.7027,\tval_loss: 4.3411\n",
            "41:\t[0s / 3s],\t\ttrain_loss: 3.6956,\tval_loss: 4.4974\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 3.6053,\tval_loss: 4.3917\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 3.6627,\tval_loss: 4.4397\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 3.6434,\tval_loss: 4.4205\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 3.6820,\tval_loss: 4.4415\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 3.6060,\tval_loss: 4.4584\n",
            "47:\t[0s / 4s],\t\ttrain_loss: 3.6528,\tval_loss: 4.3819\n",
            "48:\t[0s / 4s],\t\ttrain_loss: 3.6527,\tval_loss: 4.4502\n",
            "49:\t[0s / 4s],\t\ttrain_loss: 3.6354,\tval_loss: 4.3790\n",
            "50:\t[0s / 4s],\t\ttrain_loss: 3.5754,\tval_loss: 4.4428\n",
            "51:\t[0s / 4s],\t\ttrain_loss: 3.6027,\tval_loss: 4.4018\n",
            "52:\t[0s / 4s],\t\ttrain_loss: 3.6477,\tval_loss: 4.5044\n",
            "53:\t[0s / 4s],\t\ttrain_loss: 3.6401,\tval_loss: 4.4080\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 3.5946,\tval_loss: 4.4538\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 3.5670,\tval_loss: 4.4528\n",
            "56:\t[0s / 5s],\t\ttrain_loss: 3.5798,\tval_loss: 4.4316\n",
            "57:\t[0s / 5s],\t\ttrain_loss: 3.5378,\tval_loss: 4.5172\n",
            "58:\t[0s / 5s],\t\ttrain_loss: 3.6204,\tval_loss: 4.4664\n",
            "59:\t[0s / 5s],\t\ttrain_loss: 3.5309,\tval_loss: 4.4536\n",
            "60:\t[0s / 5s],\t\ttrain_loss: 3.5774,\tval_loss: 4.4341\n",
            "61:\t[0s / 5s],\t\ttrain_loss: 3.6001,\tval_loss: 4.4981\n",
            "62:\t[0s / 5s],\t\ttrain_loss: 3.5627,\tval_loss: 4.4891\n",
            "63:\t[0s / 5s],\t\ttrain_loss: 3.6402,\tval_loss: 4.5319\n",
            "64:\t[0s / 5s],\t\ttrain_loss: 3.5997,\tval_loss: 4.4286\n",
            "65:\t[0s / 5s],\t\ttrain_loss: 3.6272,\tval_loss: 4.3982\n",
            "66:\t[0s / 5s],\t\ttrain_loss: 3.5434,\tval_loss: 4.5006\n",
            "67:\t[0s / 6s],\t\ttrain_loss: 3.4988,\tval_loss: 4.5241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4263,\tval_loss: 4.0695\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3016,\tval_loss: 4.0711\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2386,\tval_loss: 4.0755\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2200,\tval_loss: 4.0829\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2129,\tval_loss: 4.1019\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1843,\tval_loss: 4.1162\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1591,\tval_loss: 4.1274\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1278,\tval_loss: 4.1299\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1448,\tval_loss: 4.1526\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1007,\tval_loss: 4.1643\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1384,\tval_loss: 4.1308\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0775,\tval_loss: 4.1824\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0551,\tval_loss: 4.2145\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0232,\tval_loss: 4.2215\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9888,\tval_loss: 4.2504\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9929,\tval_loss: 4.2087\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9170,\tval_loss: 4.3714\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9837,\tval_loss: 4.2312\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0229,\tval_loss: 4.2963\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9636,\tval_loss: 4.3658\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9368,\tval_loss: 4.2506\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8930,\tval_loss: 4.3733\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8492,\tval_loss: 4.4126\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8213,\tval_loss: 4.4304\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7929,\tval_loss: 4.5218\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8079,\tval_loss: 4.3641\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8166,\tval_loss: 4.3684\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7653,\tval_loss: 4.4365\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8292,\tval_loss: 4.3023\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7311,\tval_loss: 4.4363\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7202,\tval_loss: 4.3582\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7674,\tval_loss: 4.3659\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6536,\tval_loss: 4.4511\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6887,\tval_loss: 4.5336\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6922,\tval_loss: 4.6649\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7178,\tval_loss: 4.4956\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7594,\tval_loss: 4.4203\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7045,\tval_loss: 4.4621\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6296,\tval_loss: 4.4055\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6714,\tval_loss: 4.5186\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6009,\tval_loss: 4.5886\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5924,\tval_loss: 4.4651\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6774,\tval_loss: 4.3917\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5247,\tval_loss: 4.5005\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6494,\tval_loss: 4.4015\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6395,\tval_loss: 4.5615\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5649,\tval_loss: 4.4081\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5607,\tval_loss: 4.5454\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6656,\tval_loss: 4.4637\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6017,\tval_loss: 4.4643\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5910,\tval_loss: 4.5470\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6299,\tval_loss: 4.5235\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6474,\tval_loss: 4.3420\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5393,\tval_loss: 4.4932\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5817,\tval_loss: 4.5296\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5045,\tval_loss: 4.5896\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5099,\tval_loss: 4.4664\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.4426,\tval_loss: 4.4757\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5528,\tval_loss: 4.5085\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5641,\tval_loss: 4.5614\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5223,\tval_loss: 4.5514\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5826,\tval_loss: 4.3632\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5559,\tval_loss: 4.5333\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.4954,\tval_loss: 4.4069\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5172,\tval_loss: 4.3335\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5235,\tval_loss: 4.5969\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4943,\tval_loss: 4.5533\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5437,\tval_loss: 4.4752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4199,\tval_loss: 3.9758\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2973,\tval_loss: 3.9848\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2481,\tval_loss: 4.0021\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2472,\tval_loss: 3.9957\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1927,\tval_loss: 4.0073\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1622,\tval_loss: 4.0613\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1316,\tval_loss: 4.0837\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1412,\tval_loss: 4.1067\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1139,\tval_loss: 4.1201\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0989,\tval_loss: 4.1617\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0650,\tval_loss: 4.1860\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0405,\tval_loss: 4.2284\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0472,\tval_loss: 4.1964\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0067,\tval_loss: 4.2628\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9755,\tval_loss: 4.2967\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9840,\tval_loss: 4.3110\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9200,\tval_loss: 4.2763\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9630,\tval_loss: 4.2718\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9089,\tval_loss: 4.3399\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8853,\tval_loss: 4.4409\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.8818,\tval_loss: 4.3103\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8833,\tval_loss: 4.3656\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8204,\tval_loss: 4.4385\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7958,\tval_loss: 4.4143\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8654,\tval_loss: 4.4297\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8471,\tval_loss: 4.3740\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8150,\tval_loss: 4.4542\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7949,\tval_loss: 4.4420\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7548,\tval_loss: 4.4319\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8146,\tval_loss: 4.4599\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7173,\tval_loss: 4.4887\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7921,\tval_loss: 4.4082\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7478,\tval_loss: 4.4725\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7429,\tval_loss: 4.4032\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7253,\tval_loss: 4.4741\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7298,\tval_loss: 4.4452\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7393,\tval_loss: 4.4933\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7556,\tval_loss: 4.3827\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7099,\tval_loss: 4.3835\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7417,\tval_loss: 4.4660\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7308,\tval_loss: 4.5021\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6363,\tval_loss: 4.5250\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.7224,\tval_loss: 4.4788\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6479,\tval_loss: 4.4850\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6929,\tval_loss: 4.5758\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6875,\tval_loss: 4.4974\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6862,\tval_loss: 4.4859\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6171,\tval_loss: 4.5721\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6153,\tval_loss: 4.4900\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5919,\tval_loss: 4.5196\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6376,\tval_loss: 4.5002\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6568,\tval_loss: 4.4703\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7007,\tval_loss: 4.4749\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6321,\tval_loss: 4.4449\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6240,\tval_loss: 4.6174\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6482,\tval_loss: 4.5701\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6134,\tval_loss: 4.5663\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6933,\tval_loss: 4.4403\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6532,\tval_loss: 4.5423\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6111,\tval_loss: 4.4870\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6169,\tval_loss: 4.5202\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6025,\tval_loss: 4.5593\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6447,\tval_loss: 4.5128\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.6314,\tval_loss: 4.4375\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.5998,\tval_loss: 4.4839\n",
            "65:\t[0s / 2s],\t\ttrain_loss: 3.6375,\tval_loss: 4.4527\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6642,\tval_loss: 4.4776\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6338,\tval_loss: 4.4209\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4096,\tval_loss: 4.0628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3099,\tval_loss: 4.0858\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2766,\tval_loss: 4.0919\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2274,\tval_loss: 4.0613\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1916,\tval_loss: 4.0595\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2464,\tval_loss: 4.0337\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1926,\tval_loss: 4.0197\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1674,\tval_loss: 4.0296\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1508,\tval_loss: 4.0266\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1566,\tval_loss: 4.0403\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1135,\tval_loss: 4.0463\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0452,\tval_loss: 4.0809\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0853,\tval_loss: 4.0490\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9731,\tval_loss: 4.0962\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0249,\tval_loss: 4.1081\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0043,\tval_loss: 4.0975\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0137,\tval_loss: 4.1620\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0018,\tval_loss: 4.1473\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9298,\tval_loss: 4.1856\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 4.0071,\tval_loss: 4.1852\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.9235,\tval_loss: 4.2115\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9601,\tval_loss: 4.1949\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9644,\tval_loss: 4.2267\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8985,\tval_loss: 4.2421\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9869,\tval_loss: 4.1702\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8826,\tval_loss: 4.2402\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9059,\tval_loss: 4.2317\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8879,\tval_loss: 4.3301\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8392,\tval_loss: 4.2643\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.9336,\tval_loss: 4.2542\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8949,\tval_loss: 4.2345\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8685,\tval_loss: 4.2274\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.9182,\tval_loss: 4.1848\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8587,\tval_loss: 4.2601\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8222,\tval_loss: 4.2312\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7874,\tval_loss: 4.2295\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.8060,\tval_loss: 4.3191\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7588,\tval_loss: 4.2360\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.8009,\tval_loss: 4.3345\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7688,\tval_loss: 4.3042\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7769,\tval_loss: 4.2735\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7624,\tval_loss: 4.2437\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.6992,\tval_loss: 4.2795\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7479,\tval_loss: 4.2838\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.8042,\tval_loss: 4.1998\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.8236,\tval_loss: 4.2310\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6838,\tval_loss: 4.3051\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7129,\tval_loss: 4.2757\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6795,\tval_loss: 4.2285\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7263,\tval_loss: 4.2309\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7316,\tval_loss: 4.2752\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7736,\tval_loss: 4.2288\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6902,\tval_loss: 4.2556\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6187,\tval_loss: 4.2677\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6981,\tval_loss: 4.3046\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6758,\tval_loss: 4.3276\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6697,\tval_loss: 4.2384\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6246,\tval_loss: 4.2705\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.7198,\tval_loss: 4.3007\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6329,\tval_loss: 4.3425\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6996,\tval_loss: 4.2672\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6739,\tval_loss: 4.2974\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6688,\tval_loss: 4.2739\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.6460,\tval_loss: 4.3296\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.6471,\tval_loss: 4.2938\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6235,\tval_loss: 4.2927\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6412,\tval_loss: 4.3037\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6686,\tval_loss: 4.3061\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6764,\tval_loss: 4.2666\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6644,\tval_loss: 4.2563\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6540,\tval_loss: 4.2549\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.6447,\tval_loss: 4.2956\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.6194,\tval_loss: 4.2298\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.5739,\tval_loss: 4.3119\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3576,\tval_loss: 4.1076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2451,\tval_loss: 4.1023\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2472,\tval_loss: 4.0904\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2054,\tval_loss: 4.1070\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1902,\tval_loss: 4.0953\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1561,\tval_loss: 4.0749\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1707,\tval_loss: 4.1303\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1758,\tval_loss: 4.0908\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1602,\tval_loss: 4.0981\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1332,\tval_loss: 4.1003\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1169,\tval_loss: 4.1034\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1140,\tval_loss: 4.1048\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0535,\tval_loss: 4.1144\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0741,\tval_loss: 4.1107\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0208,\tval_loss: 4.1458\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0485,\tval_loss: 4.1198\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0031,\tval_loss: 4.1604\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9893,\tval_loss: 4.1403\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9751,\tval_loss: 4.1426\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 4.0130,\tval_loss: 4.1514\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9880,\tval_loss: 4.0854\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9168,\tval_loss: 4.1328\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8955,\tval_loss: 4.2043\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8937,\tval_loss: 4.1361\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9145,\tval_loss: 4.1291\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8816,\tval_loss: 4.1340\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8564,\tval_loss: 4.1896\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8926,\tval_loss: 4.1001\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8932,\tval_loss: 4.1934\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8592,\tval_loss: 4.1316\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.9051,\tval_loss: 4.1220\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.9092,\tval_loss: 4.1995\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8637,\tval_loss: 4.1716\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.8658,\tval_loss: 4.1211\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.8528,\tval_loss: 4.2151\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.8416,\tval_loss: 4.1473\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.8947,\tval_loss: 4.1496\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.8674,\tval_loss: 4.1039\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.8822,\tval_loss: 4.1998\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.8729,\tval_loss: 4.0959\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.8357,\tval_loss: 4.1842\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.8014,\tval_loss: 4.1857\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7880,\tval_loss: 4.1379\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.8427,\tval_loss: 4.2029\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.9024,\tval_loss: 4.1509\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.8446,\tval_loss: 4.1213\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.8712,\tval_loss: 4.1983\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.8664,\tval_loss: 4.2387\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.8356,\tval_loss: 4.1857\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.8771,\tval_loss: 4.1607\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.8817,\tval_loss: 4.2071\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.8820,\tval_loss: 4.1267\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.8288,\tval_loss: 4.2024\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.8208,\tval_loss: 4.1769\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.7515,\tval_loss: 4.2364\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.8061,\tval_loss: 4.1805\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.8725,\tval_loss: 4.2057\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.8729,\tval_loss: 4.1446\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.8620,\tval_loss: 4.1510\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.7738,\tval_loss: 4.1641\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.8543,\tval_loss: 4.1796\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.8190,\tval_loss: 4.2325\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.8139,\tval_loss: 4.2429\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.7193,\tval_loss: 4.1908\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.7757,\tval_loss: 4.1981\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.7624,\tval_loss: 4.2980\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.7379,\tval_loss: 4.2011\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.8109,\tval_loss: 4.2275\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.7493,\tval_loss: 4.2352\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.6996,\tval_loss: 4.2319\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.8222,\tval_loss: 4.2244\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.7511,\tval_loss: 4.2084\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.8003,\tval_loss: 4.2513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4495,\tval_loss: 4.0650\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3308,\tval_loss: 4.0656\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3386,\tval_loss: 4.0699\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.3029,\tval_loss: 4.0669\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2791,\tval_loss: 4.0623\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2890,\tval_loss: 4.0645\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2473,\tval_loss: 4.0754\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2128,\tval_loss: 4.0606\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.2118,\tval_loss: 4.0727\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1626,\tval_loss: 4.0757\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1727,\tval_loss: 4.0717\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1465,\tval_loss: 4.1053\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1036,\tval_loss: 4.0871\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1057,\tval_loss: 4.1462\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0410,\tval_loss: 4.1068\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0462,\tval_loss: 4.1576\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 4.0226,\tval_loss: 4.2055\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 4.0624,\tval_loss: 4.1870\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9638,\tval_loss: 4.1989\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9507,\tval_loss: 4.1959\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9511,\tval_loss: 4.2502\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9209,\tval_loss: 4.2494\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8980,\tval_loss: 4.2694\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8583,\tval_loss: 4.2934\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8202,\tval_loss: 4.2162\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7442,\tval_loss: 4.2852\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7898,\tval_loss: 4.3893\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8186,\tval_loss: 4.3881\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8676,\tval_loss: 4.2613\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7714,\tval_loss: 4.3287\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8415,\tval_loss: 4.2981\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7686,\tval_loss: 4.2698\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7159,\tval_loss: 4.2643\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7539,\tval_loss: 4.3517\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7962,\tval_loss: 4.3136\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7808,\tval_loss: 4.2496\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7300,\tval_loss: 4.3039\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7837,\tval_loss: 4.2361\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7554,\tval_loss: 4.3202\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7229,\tval_loss: 4.3395\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7649,\tval_loss: 4.3543\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7789,\tval_loss: 4.2326\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6809,\tval_loss: 4.2730\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7415,\tval_loss: 4.3399\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7489,\tval_loss: 4.2479\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7060,\tval_loss: 4.3215\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6694,\tval_loss: 4.2946\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6930,\tval_loss: 4.2748\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6502,\tval_loss: 4.3901\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6764,\tval_loss: 4.3281\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6764,\tval_loss: 4.3339\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6168,\tval_loss: 4.2731\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6397,\tval_loss: 4.3516\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6976,\tval_loss: 4.3108\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6617,\tval_loss: 4.3154\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5677,\tval_loss: 4.3576\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5793,\tval_loss: 4.3871\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6593,\tval_loss: 4.2872\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.7333,\tval_loss: 4.3422\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.7475,\tval_loss: 4.2831\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6504,\tval_loss: 4.3506\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5629,\tval_loss: 4.3312\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5868,\tval_loss: 4.4690\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5526,\tval_loss: 4.4073\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5542,\tval_loss: 4.3836\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5394,\tval_loss: 4.3902\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5013,\tval_loss: 4.3556\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5578,\tval_loss: 4.4426\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5865,\tval_loss: 4.3266\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5679,\tval_loss: 4.3512\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5358,\tval_loss: 4.3946\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.5516,\tval_loss: 4.4300\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.5657,\tval_loss: 4.3544\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.5084,\tval_loss: 4.3749\n",
            "74:\t[0s / 3s],\t\ttrain_loss: 3.4911,\tval_loss: 4.3977\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3687,\tval_loss: 4.1402\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2680,\tval_loss: 4.1247\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2460,\tval_loss: 4.1178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2115,\tval_loss: 4.1330\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1842,\tval_loss: 4.1445\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1763,\tval_loss: 4.1272\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1822,\tval_loss: 4.1528\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1101,\tval_loss: 4.1517\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0885,\tval_loss: 4.2008\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0949,\tval_loss: 4.1997\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0516,\tval_loss: 4.1781\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0284,\tval_loss: 4.1774\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0268,\tval_loss: 4.2403\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9808,\tval_loss: 4.2712\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9701,\tval_loss: 4.2811\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9279,\tval_loss: 4.3365\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8964,\tval_loss: 4.3561\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9373,\tval_loss: 4.3424\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9011,\tval_loss: 4.3347\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8446,\tval_loss: 4.3885\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.8894,\tval_loss: 4.3592\n",
            "21:\t[0s / 0s],\t\ttrain_loss: 3.8222,\tval_loss: 4.4027\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8324,\tval_loss: 4.4009\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8648,\tval_loss: 4.3788\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7500,\tval_loss: 4.4000\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8191,\tval_loss: 4.4606\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7105,\tval_loss: 4.3989\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7569,\tval_loss: 4.4808\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7844,\tval_loss: 4.4711\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7129,\tval_loss: 4.4401\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7269,\tval_loss: 4.4909\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6575,\tval_loss: 4.5296\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6610,\tval_loss: 4.6051\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6943,\tval_loss: 4.5316\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8162,\tval_loss: 4.3589\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7009,\tval_loss: 4.5630\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6650,\tval_loss: 4.4944\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6635,\tval_loss: 4.5688\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.5973,\tval_loss: 4.5799\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7101,\tval_loss: 4.4582\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.5497,\tval_loss: 4.5645\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6066,\tval_loss: 4.6262\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.5626,\tval_loss: 4.5150\n",
            "43:\t[0s / 1s],\t\ttrain_loss: 3.5392,\tval_loss: 4.5770\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5456,\tval_loss: 4.5472\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6554,\tval_loss: 4.5648\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5376,\tval_loss: 4.5799\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5861,\tval_loss: 4.5798\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5925,\tval_loss: 4.5289\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5408,\tval_loss: 4.5806\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5432,\tval_loss: 4.5896\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5572,\tval_loss: 4.5995\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5813,\tval_loss: 4.6157\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5273,\tval_loss: 4.7076\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.4918,\tval_loss: 4.6917\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5065,\tval_loss: 4.6279\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6595,\tval_loss: 4.3590\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6125,\tval_loss: 4.4243\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6203,\tval_loss: 4.5998\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5766,\tval_loss: 4.5159\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.4544,\tval_loss: 4.5194\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5980,\tval_loss: 4.5449\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5154,\tval_loss: 4.5194\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.4851,\tval_loss: 4.6215\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.5275,\tval_loss: 4.4824\n",
            "65:\t[0s / 2s],\t\ttrain_loss: 3.5832,\tval_loss: 4.5512\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5498,\tval_loss: 4.5956\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4881,\tval_loss: 4.5616\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5524,\tval_loss: 4.5237\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.4151,\tval_loss: 4.6094\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4109,\tval_loss: 4.0938\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2853,\tval_loss: 4.0757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2399,\tval_loss: 4.0777\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2239,\tval_loss: 4.0707\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2388,\tval_loss: 4.0872\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2127,\tval_loss: 4.0780\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1835,\tval_loss: 4.0568\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1285,\tval_loss: 4.0792\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1860,\tval_loss: 4.0633\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0789,\tval_loss: 4.1015\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0805,\tval_loss: 4.0956\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0170,\tval_loss: 4.1446\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9953,\tval_loss: 4.1441\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9683,\tval_loss: 4.1906\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9626,\tval_loss: 4.1491\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9449,\tval_loss: 4.1918\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9705,\tval_loss: 4.2318\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9052,\tval_loss: 4.2608\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8490,\tval_loss: 4.3351\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8891,\tval_loss: 4.2880\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.8907,\tval_loss: 4.2664\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9287,\tval_loss: 4.2644\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8190,\tval_loss: 4.2719\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8127,\tval_loss: 4.2898\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8007,\tval_loss: 4.3536\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8308,\tval_loss: 4.2908\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8196,\tval_loss: 4.3141\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7615,\tval_loss: 4.3698\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7549,\tval_loss: 4.4007\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7318,\tval_loss: 4.3483\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8292,\tval_loss: 4.4386\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7602,\tval_loss: 4.3113\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7139,\tval_loss: 4.3218\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7296,\tval_loss: 4.3708\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6727,\tval_loss: 4.3799\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7093,\tval_loss: 4.2887\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7034,\tval_loss: 4.3763\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6645,\tval_loss: 4.3485\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6979,\tval_loss: 4.3669\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7115,\tval_loss: 4.4292\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6377,\tval_loss: 4.3979\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7160,\tval_loss: 4.3825\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7014,\tval_loss: 4.3364\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7311,\tval_loss: 4.3530\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7085,\tval_loss: 4.3449\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6527,\tval_loss: 4.3676\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6306,\tval_loss: 4.4179\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6430,\tval_loss: 4.4282\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6224,\tval_loss: 4.3982\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6202,\tval_loss: 4.4355\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6001,\tval_loss: 4.4161\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6272,\tval_loss: 4.4108\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6295,\tval_loss: 4.4274\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7002,\tval_loss: 4.4367\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5995,\tval_loss: 4.3413\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5880,\tval_loss: 4.4308\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5432,\tval_loss: 4.4635\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5910,\tval_loss: 4.4233\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5894,\tval_loss: 4.4251\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5973,\tval_loss: 4.4360\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5887,\tval_loss: 4.5126\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5755,\tval_loss: 4.4170\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5363,\tval_loss: 4.5188\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5914,\tval_loss: 4.4089\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5438,\tval_loss: 4.5053\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5758,\tval_loss: 4.4619\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5901,\tval_loss: 4.4849\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5903,\tval_loss: 4.3952\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6108,\tval_loss: 4.4641\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5800,\tval_loss: 4.4257\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5544,\tval_loss: 4.4259\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.5230,\tval_loss: 4.4829\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.5205,\tval_loss: 4.5212\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.5127,\tval_loss: 4.5742\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3183,\tval_loss: 4.0708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2305,\tval_loss: 4.0683\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1021,\tval_loss: 4.0867\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1337,\tval_loss: 4.0828\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1035,\tval_loss: 4.0931\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.0816,\tval_loss: 4.0958\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0452,\tval_loss: 4.1242\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0570,\tval_loss: 4.1134\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0502,\tval_loss: 4.1322\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0115,\tval_loss: 4.1339\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 3.9534,\tval_loss: 4.1687\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9994,\tval_loss: 4.1517\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9756,\tval_loss: 4.1627\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9369,\tval_loss: 4.1939\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.8735,\tval_loss: 4.2246\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.8925,\tval_loss: 4.2458\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.7918,\tval_loss: 4.2035\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.7865,\tval_loss: 4.2824\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.7880,\tval_loss: 4.2558\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.7380,\tval_loss: 4.2792\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.7775,\tval_loss: 4.1947\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7467,\tval_loss: 4.2879\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7420,\tval_loss: 4.2955\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7326,\tval_loss: 4.2746\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7325,\tval_loss: 4.3428\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6422,\tval_loss: 4.3266\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7285,\tval_loss: 4.3192\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6554,\tval_loss: 4.3631\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6972,\tval_loss: 4.3241\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.6872,\tval_loss: 4.3443\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6672,\tval_loss: 4.3042\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6282,\tval_loss: 4.2520\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6406,\tval_loss: 4.3019\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.6407,\tval_loss: 4.3696\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.6394,\tval_loss: 4.3749\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.5569,\tval_loss: 4.4517\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.5295,\tval_loss: 4.4468\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.5748,\tval_loss: 4.3923\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.5863,\tval_loss: 4.3164\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.5580,\tval_loss: 4.3607\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5344,\tval_loss: 4.3357\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5505,\tval_loss: 4.4139\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5422,\tval_loss: 4.3912\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5063,\tval_loss: 4.4144\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5483,\tval_loss: 4.3733\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5451,\tval_loss: 4.4194\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5364,\tval_loss: 4.4062\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.5962,\tval_loss: 4.4295\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.4899,\tval_loss: 4.3430\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.5078,\tval_loss: 4.4757\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.5479,\tval_loss: 4.3539\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.5665,\tval_loss: 4.3522\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6082,\tval_loss: 4.3105\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.5007,\tval_loss: 4.3840\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.4773,\tval_loss: 4.3835\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.4492,\tval_loss: 4.4380\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5170,\tval_loss: 4.3503\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.4227,\tval_loss: 4.4568\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.4898,\tval_loss: 4.3921\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.4438,\tval_loss: 4.3721\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.4503,\tval_loss: 4.4421\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.4870,\tval_loss: 4.3668\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.4493,\tval_loss: 4.4139\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.4487,\tval_loss: 4.4343\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.5161,\tval_loss: 4.5011\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.4274,\tval_loss: 4.2869\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.5114,\tval_loss: 4.2876\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.4311,\tval_loss: 4.3976\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.5027,\tval_loss: 4.4216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3449,\tval_loss: 4.0392\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2069,\tval_loss: 4.0778\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1778,\tval_loss: 4.0862\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1357,\tval_loss: 4.0715\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1387,\tval_loss: 4.0822\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1207,\tval_loss: 4.0684\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0702,\tval_loss: 4.0972\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1098,\tval_loss: 4.0895\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0820,\tval_loss: 4.1091\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0288,\tval_loss: 4.0890\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0268,\tval_loss: 4.0819\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0307,\tval_loss: 4.0813\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0006,\tval_loss: 4.0971\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 3.9707,\tval_loss: 4.1262\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.9047,\tval_loss: 4.1207\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9169,\tval_loss: 4.1898\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9113,\tval_loss: 4.1336\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8915,\tval_loss: 4.1464\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.8753,\tval_loss: 4.1867\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.7996,\tval_loss: 4.2158\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.7863,\tval_loss: 4.2186\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7964,\tval_loss: 4.1633\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7662,\tval_loss: 4.2366\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7920,\tval_loss: 4.1600\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7270,\tval_loss: 4.1995\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7410,\tval_loss: 4.1433\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 3.7468,\tval_loss: 4.2059\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 3.7297,\tval_loss: 4.1616\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 3.7272,\tval_loss: 4.2219\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.7267,\tval_loss: 4.1624\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.6505,\tval_loss: 4.3049\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.5841,\tval_loss: 4.2285\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.6489,\tval_loss: 4.2916\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.6259,\tval_loss: 4.2456\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.5747,\tval_loss: 4.2118\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.6124,\tval_loss: 4.2440\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.5941,\tval_loss: 4.2598\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.5935,\tval_loss: 4.3145\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6321,\tval_loss: 4.2498\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.5882,\tval_loss: 4.2736\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5512,\tval_loss: 4.2911\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5466,\tval_loss: 4.2807\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 3.5485,\tval_loss: 4.3388\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 3.5611,\tval_loss: 4.3267\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.5569,\tval_loss: 4.3374\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.5218,\tval_loss: 4.2865\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.5278,\tval_loss: 4.3439\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.5078,\tval_loss: 4.3785\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.5420,\tval_loss: 4.3324\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.5465,\tval_loss: 4.2458\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.5218,\tval_loss: 4.3025\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.5207,\tval_loss: 4.3846\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.5698,\tval_loss: 4.2851\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.5252,\tval_loss: 4.3162\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.5750,\tval_loss: 4.2317\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.5813,\tval_loss: 4.3287\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5981,\tval_loss: 4.3646\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5896,\tval_loss: 4.2214\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 3.5246,\tval_loss: 4.3752\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 3.4905,\tval_loss: 4.3232\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 3.4628,\tval_loss: 4.3809\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.4949,\tval_loss: 4.3461\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.5528,\tval_loss: 4.3277\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.4638,\tval_loss: 4.3182\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.5231,\tval_loss: 4.4129\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.4905,\tval_loss: 4.2911\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.4782,\tval_loss: 4.3441\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.4659,\tval_loss: 4.3458\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4901,\tval_loss: 4.0816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3820,\tval_loss: 4.0614\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3403,\tval_loss: 4.0652\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.3009,\tval_loss: 4.0614\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.3035,\tval_loss: 4.0391\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2389,\tval_loss: 4.0607\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2442,\tval_loss: 4.0640\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1746,\tval_loss: 4.0704\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.2131,\tval_loss: 4.0907\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.2161,\tval_loss: 4.0754\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1921,\tval_loss: 4.0600\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1941,\tval_loss: 4.1171\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1553,\tval_loss: 4.0440\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1480,\tval_loss: 4.1109\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.1754,\tval_loss: 4.1153\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.1564,\tval_loss: 4.0734\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 4.1393,\tval_loss: 4.1240\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 4.1289,\tval_loss: 4.0884\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 4.1159,\tval_loss: 4.1137\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 4.0895,\tval_loss: 4.1288\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 4.0837,\tval_loss: 4.1325\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9952,\tval_loss: 4.1739\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 4.0551,\tval_loss: 4.1092\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 4.0398,\tval_loss: 4.2161\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 4.0059,\tval_loss: 4.1516\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 4.0192,\tval_loss: 4.1756\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9956,\tval_loss: 4.1521\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9853,\tval_loss: 4.1571\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.9405,\tval_loss: 4.1819\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.9471,\tval_loss: 4.2100\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.9708,\tval_loss: 4.1571\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.9192,\tval_loss: 4.2547\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.9418,\tval_loss: 4.1517\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8749,\tval_loss: 4.1834\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.8713,\tval_loss: 4.2011\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.9068,\tval_loss: 4.2254\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.8588,\tval_loss: 4.2110\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.8654,\tval_loss: 4.2284\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.8561,\tval_loss: 4.1790\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7860,\tval_loss: 4.2144\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.8225,\tval_loss: 4.1841\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7727,\tval_loss: 4.2244\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7968,\tval_loss: 4.2563\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.8030,\tval_loss: 4.1540\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.8128,\tval_loss: 4.2292\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7897,\tval_loss: 4.2162\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7860,\tval_loss: 4.2570\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.8172,\tval_loss: 4.1765\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7911,\tval_loss: 4.1488\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7389,\tval_loss: 4.2406\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7695,\tval_loss: 4.2558\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6901,\tval_loss: 4.2691\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7996,\tval_loss: 4.2398\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7486,\tval_loss: 4.2730\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7559,\tval_loss: 4.2470\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.7238,\tval_loss: 4.2410\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.7932,\tval_loss: 4.2121\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.7444,\tval_loss: 4.2113\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6900,\tval_loss: 4.2476\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6656,\tval_loss: 4.2591\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6925,\tval_loss: 4.2585\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6841,\tval_loss: 4.3307\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6276,\tval_loss: 4.3162\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6743,\tval_loss: 4.2746\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.7055,\tval_loss: 4.2341\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.7430,\tval_loss: 4.2763\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6646,\tval_loss: 4.2278\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.7359,\tval_loss: 4.2072\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6892,\tval_loss: 4.1996\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.7059,\tval_loss: 4.2131\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6826,\tval_loss: 4.2489\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.7284,\tval_loss: 4.2272\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3599,\tval_loss: 4.0758\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2760,\tval_loss: 4.0608\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2347,\tval_loss: 4.0596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2540,\tval_loss: 4.0457\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2169,\tval_loss: 4.0623\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2069,\tval_loss: 4.0662\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1978,\tval_loss: 4.0789\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1756,\tval_loss: 4.0787\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1850,\tval_loss: 4.0737\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1109,\tval_loss: 4.0931\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0819,\tval_loss: 4.0608\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0960,\tval_loss: 4.1122\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0401,\tval_loss: 4.1048\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0405,\tval_loss: 4.0774\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9723,\tval_loss: 4.1535\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0015,\tval_loss: 4.1354\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9197,\tval_loss: 4.2011\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8879,\tval_loss: 4.1634\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8482,\tval_loss: 4.2324\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8705,\tval_loss: 4.2082\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.7675,\tval_loss: 4.2946\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8047,\tval_loss: 4.2485\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8342,\tval_loss: 4.2830\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7756,\tval_loss: 4.2800\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7474,\tval_loss: 4.2981\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7463,\tval_loss: 4.4111\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7116,\tval_loss: 4.3662\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6749,\tval_loss: 4.3974\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6688,\tval_loss: 4.3792\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.6669,\tval_loss: 4.5305\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6588,\tval_loss: 4.4286\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7090,\tval_loss: 4.4502\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.5948,\tval_loss: 4.5492\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.5909,\tval_loss: 4.5394\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6049,\tval_loss: 4.5295\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.5945,\tval_loss: 4.5679\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.5183,\tval_loss: 4.4957\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.4904,\tval_loss: 4.5353\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.5461,\tval_loss: 4.5992\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.5186,\tval_loss: 4.5201\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.4587,\tval_loss: 4.6181\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6368,\tval_loss: 4.4431\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.5140,\tval_loss: 4.5093\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.4880,\tval_loss: 4.5181\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.4160,\tval_loss: 4.5826\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5880,\tval_loss: 4.4722\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.4796,\tval_loss: 4.5189\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.4795,\tval_loss: 4.5177\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.4586,\tval_loss: 4.5316\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.4612,\tval_loss: 4.4720\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.4341,\tval_loss: 4.5734\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.3667,\tval_loss: 4.6506\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.4617,\tval_loss: 4.5253\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.4600,\tval_loss: 4.5210\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.4691,\tval_loss: 4.5733\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.4029,\tval_loss: 4.5794\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.3816,\tval_loss: 4.6012\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.3972,\tval_loss: 4.6188\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.3599,\tval_loss: 4.5996\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.3331,\tval_loss: 4.7091\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.3484,\tval_loss: 4.7897\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.3949,\tval_loss: 4.6770\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.3400,\tval_loss: 4.7470\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.3851,\tval_loss: 4.7544\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.4170,\tval_loss: 4.5438\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.3529,\tval_loss: 4.7253\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4302,\tval_loss: 4.7275\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.3886,\tval_loss: 4.6460\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.4755,\tval_loss: 4.6454\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.4575,\tval_loss: 4.6605\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.2784,\tval_loss: 4.6738\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.5155,\tval_loss: 4.0052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3976,\tval_loss: 4.0005\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3861,\tval_loss: 3.9965\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.3331,\tval_loss: 4.0086\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.3043,\tval_loss: 4.0106\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.3022,\tval_loss: 4.0100\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2960,\tval_loss: 4.0188\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2943,\tval_loss: 4.0147\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.2578,\tval_loss: 4.0260\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.2489,\tval_loss: 4.0294\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.2124,\tval_loss: 4.0492\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1465,\tval_loss: 4.0492\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1617,\tval_loss: 4.0527\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1407,\tval_loss: 4.1129\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.1295,\tval_loss: 4.1164\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0769,\tval_loss: 4.0924\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 4.0703,\tval_loss: 4.0988\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 4.0482,\tval_loss: 4.1530\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 4.0454,\tval_loss: 4.1503\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 4.0260,\tval_loss: 4.1540\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 4.0229,\tval_loss: 4.1768\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 4.0092,\tval_loss: 4.1111\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 4.0565,\tval_loss: 4.1020\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9780,\tval_loss: 4.1652\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9125,\tval_loss: 4.2434\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9323,\tval_loss: 4.2235\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8854,\tval_loss: 4.1862\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9709,\tval_loss: 4.2323\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.9091,\tval_loss: 4.2145\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.9241,\tval_loss: 4.1555\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.8531,\tval_loss: 4.2472\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.8055,\tval_loss: 4.2782\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.8496,\tval_loss: 4.2162\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.8589,\tval_loss: 4.3258\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.9152,\tval_loss: 4.1616\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.8485,\tval_loss: 4.1972\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.8027,\tval_loss: 4.2283\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.9216,\tval_loss: 4.2194\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.8845,\tval_loss: 4.2293\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.8175,\tval_loss: 4.1982\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.8056,\tval_loss: 4.2825\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.8258,\tval_loss: 4.1758\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7652,\tval_loss: 4.2596\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7063,\tval_loss: 4.2480\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7128,\tval_loss: 4.4214\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.8081,\tval_loss: 4.2142\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.7311,\tval_loss: 4.2312\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.7558,\tval_loss: 4.3047\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.7747,\tval_loss: 4.3242\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.7588,\tval_loss: 4.2085\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.7307,\tval_loss: 4.3453\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.7880,\tval_loss: 4.2814\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.8156,\tval_loss: 4.2038\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.7478,\tval_loss: 4.2865\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.7780,\tval_loss: 4.2663\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.7497,\tval_loss: 4.2637\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.7055,\tval_loss: 4.2792\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.7127,\tval_loss: 4.2616\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.7202,\tval_loss: 4.2914\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.7117,\tval_loss: 4.3393\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.7216,\tval_loss: 4.2930\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.7438,\tval_loss: 4.2951\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.8173,\tval_loss: 4.2597\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.7877,\tval_loss: 4.2777\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.7218,\tval_loss: 4.2935\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.6598,\tval_loss: 4.2715\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.7263,\tval_loss: 4.3555\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.7087,\tval_loss: 4.3032\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.7511,\tval_loss: 4.3476\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.6280,\tval_loss: 4.2898\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4426,\tval_loss: 4.1377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3261,\tval_loss: 4.0578\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3202,\tval_loss: 4.0587\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2493,\tval_loss: 4.0439\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2433,\tval_loss: 4.0430\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2235,\tval_loss: 4.0282\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2134,\tval_loss: 4.0209\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2005,\tval_loss: 4.0163\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1798,\tval_loss: 4.0564\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1443,\tval_loss: 4.0464\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1440,\tval_loss: 4.0177\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1190,\tval_loss: 4.0657\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1377,\tval_loss: 4.0511\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1201,\tval_loss: 4.0304\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0926,\tval_loss: 4.0453\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0594,\tval_loss: 4.0768\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 4.0466,\tval_loss: 4.0513\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 4.0075,\tval_loss: 4.0924\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9655,\tval_loss: 4.1327\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9738,\tval_loss: 4.0637\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9883,\tval_loss: 4.1200\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9311,\tval_loss: 4.1591\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9479,\tval_loss: 4.1386\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9000,\tval_loss: 4.1412\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9247,\tval_loss: 4.1771\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9466,\tval_loss: 4.1290\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8999,\tval_loss: 4.1622\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8698,\tval_loss: 4.2289\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8898,\tval_loss: 4.1515\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8387,\tval_loss: 4.1825\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8433,\tval_loss: 4.2313\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8527,\tval_loss: 4.2494\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8684,\tval_loss: 4.1668\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8611,\tval_loss: 4.1587\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7810,\tval_loss: 4.1943\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8271,\tval_loss: 4.2154\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.8577,\tval_loss: 4.2635\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.8314,\tval_loss: 4.1979\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.8336,\tval_loss: 4.1963\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7842,\tval_loss: 4.2545\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.8082,\tval_loss: 4.1565\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7796,\tval_loss: 4.1740\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7172,\tval_loss: 4.1970\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7612,\tval_loss: 4.2316\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7411,\tval_loss: 4.2435\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7382,\tval_loss: 4.2398\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7111,\tval_loss: 4.2329\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7540,\tval_loss: 4.2358\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7395,\tval_loss: 4.1625\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7930,\tval_loss: 4.2460\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7788,\tval_loss: 4.1649\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7832,\tval_loss: 4.1425\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7680,\tval_loss: 4.2165\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7005,\tval_loss: 4.2055\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6864,\tval_loss: 4.2152\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.7384,\tval_loss: 4.2526\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6839,\tval_loss: 4.2474\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6974,\tval_loss: 4.2185\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6997,\tval_loss: 4.2212\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.7049,\tval_loss: 4.1707\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.7679,\tval_loss: 4.1620\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.7060,\tval_loss: 4.2017\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.7130,\tval_loss: 4.1924\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.7078,\tval_loss: 4.2591\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.7377,\tval_loss: 4.1262\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6209,\tval_loss: 4.1911\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6722,\tval_loss: 4.2194\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6275,\tval_loss: 4.2370\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6259,\tval_loss: 4.2696\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6361,\tval_loss: 4.2349\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5995,\tval_loss: 4.2765\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.6856,\tval_loss: 4.1828\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.6620,\tval_loss: 4.2717\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.7211,\tval_loss: 4.1856\n",
            "74:\t[0s / 3s],\t\ttrain_loss: 3.6773,\tval_loss: 4.2448\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4649,\tval_loss: 4.0892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3316,\tval_loss: 4.0729\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2630,\tval_loss: 4.0659\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2462,\tval_loss: 4.0845\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2355,\tval_loss: 4.1241\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1672,\tval_loss: 4.1288\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1493,\tval_loss: 4.1619\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1017,\tval_loss: 4.1514\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0905,\tval_loss: 4.2109\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0598,\tval_loss: 4.2400\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0505,\tval_loss: 4.2152\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9430,\tval_loss: 4.2936\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9327,\tval_loss: 4.3518\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9030,\tval_loss: 4.3485\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9321,\tval_loss: 4.4274\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.8859,\tval_loss: 4.3487\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8322,\tval_loss: 4.3848\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8621,\tval_loss: 4.4066\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8590,\tval_loss: 4.3866\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8124,\tval_loss: 4.4240\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.7523,\tval_loss: 4.4685\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7981,\tval_loss: 4.4169\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7760,\tval_loss: 4.3959\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8172,\tval_loss: 4.3694\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7342,\tval_loss: 4.4806\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7033,\tval_loss: 4.3718\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7225,\tval_loss: 4.4115\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7193,\tval_loss: 4.4760\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7057,\tval_loss: 4.4817\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7353,\tval_loss: 4.5146\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7115,\tval_loss: 4.4751\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6742,\tval_loss: 4.4464\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7150,\tval_loss: 4.4665\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6403,\tval_loss: 4.5931\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7187,\tval_loss: 4.4309\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6849,\tval_loss: 4.5577\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6719,\tval_loss: 4.4658\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7482,\tval_loss: 4.4708\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6860,\tval_loss: 4.4490\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6266,\tval_loss: 4.4858\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6660,\tval_loss: 4.6186\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6324,\tval_loss: 4.5175\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.6811,\tval_loss: 4.5129\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6074,\tval_loss: 4.5659\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5734,\tval_loss: 4.5906\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6248,\tval_loss: 4.4431\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5862,\tval_loss: 4.5425\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6028,\tval_loss: 4.5409\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5972,\tval_loss: 4.6221\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6068,\tval_loss: 4.5062\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5042,\tval_loss: 4.6457\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5774,\tval_loss: 4.6089\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5246,\tval_loss: 4.6009\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5770,\tval_loss: 4.6654\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6158,\tval_loss: 4.5695\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5243,\tval_loss: 4.6095\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5466,\tval_loss: 4.6607\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5573,\tval_loss: 4.6926\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5199,\tval_loss: 4.5227\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6098,\tval_loss: 4.4954\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5367,\tval_loss: 4.5834\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5491,\tval_loss: 4.5716\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5248,\tval_loss: 4.6132\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5306,\tval_loss: 4.6851\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.5490,\tval_loss: 4.7183\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5013,\tval_loss: 4.5952\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4978,\tval_loss: 4.6836\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5282,\tval_loss: 4.6577\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5591,\tval_loss: 4.5308\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.4873,\tval_loss: 4.8446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4716,\tval_loss: 4.0859\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3341,\tval_loss: 4.0583\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3208,\tval_loss: 4.0494\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2884,\tval_loss: 4.0663\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2873,\tval_loss: 4.0469\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2440,\tval_loss: 4.0548\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2533,\tval_loss: 4.0552\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2537,\tval_loss: 4.0659\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1742,\tval_loss: 4.0393\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1862,\tval_loss: 4.0731\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1836,\tval_loss: 4.0742\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1467,\tval_loss: 4.0625\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1282,\tval_loss: 4.1102\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1134,\tval_loss: 4.1086\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0424,\tval_loss: 4.1399\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0948,\tval_loss: 4.1239\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0659,\tval_loss: 4.1920\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 4.0481,\tval_loss: 4.1295\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9989,\tval_loss: 4.1281\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 4.0088,\tval_loss: 4.1092\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 4.0266,\tval_loss: 4.1647\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9811,\tval_loss: 4.1034\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9576,\tval_loss: 4.1388\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9281,\tval_loss: 4.2159\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8922,\tval_loss: 4.1992\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8647,\tval_loss: 4.2088\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8888,\tval_loss: 4.1760\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7732,\tval_loss: 4.2891\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8596,\tval_loss: 4.2460\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8711,\tval_loss: 4.1315\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8024,\tval_loss: 4.2651\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8016,\tval_loss: 4.1754\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.8489,\tval_loss: 4.1681\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.8196,\tval_loss: 4.2059\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.8106,\tval_loss: 4.2701\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7848,\tval_loss: 4.1133\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.8279,\tval_loss: 4.2390\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.8897,\tval_loss: 4.1606\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.8245,\tval_loss: 4.1664\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7504,\tval_loss: 4.2454\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7099,\tval_loss: 4.2530\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7977,\tval_loss: 4.2036\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7473,\tval_loss: 4.2143\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7391,\tval_loss: 4.1732\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.8286,\tval_loss: 4.1670\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6726,\tval_loss: 4.1664\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6586,\tval_loss: 4.2262\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.7235,\tval_loss: 4.2672\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.6805,\tval_loss: 4.2302\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.7397,\tval_loss: 4.2223\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.7545,\tval_loss: 4.2424\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.7153,\tval_loss: 4.2763\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6830,\tval_loss: 4.2370\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.7226,\tval_loss: 4.1790\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6304,\tval_loss: 4.2875\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.5902,\tval_loss: 4.3108\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.7248,\tval_loss: 4.2046\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.7496,\tval_loss: 4.2943\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6245,\tval_loss: 4.3002\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6228,\tval_loss: 4.2855\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5983,\tval_loss: 4.2947\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.6448,\tval_loss: 4.2787\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.7098,\tval_loss: 4.3165\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.5948,\tval_loss: 4.3030\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.7198,\tval_loss: 4.2787\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.6162,\tval_loss: 4.3815\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.6204,\tval_loss: 4.3707\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.6597,\tval_loss: 4.3300\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.6050,\tval_loss: 4.4289\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.6285,\tval_loss: 4.4617\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.6449,\tval_loss: 4.2785\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.6146,\tval_loss: 4.2916\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.6361,\tval_loss: 4.2667\n",
            "73:\t[0s / 5s],\t\ttrain_loss: 3.6042,\tval_loss: 4.3677\n",
            "74:\t[0s / 5s],\t\ttrain_loss: 3.5998,\tval_loss: 4.3039\n",
            "75:\t[0s / 5s],\t\ttrain_loss: 3.5900,\tval_loss: 4.3078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3994,\tval_loss: 4.0542\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3145,\tval_loss: 4.0641\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2916,\tval_loss: 4.0693\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2289,\tval_loss: 4.0857\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2005,\tval_loss: 4.0918\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1801,\tval_loss: 4.0784\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1380,\tval_loss: 4.0923\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1170,\tval_loss: 4.0767\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1068,\tval_loss: 4.0465\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 4.0473,\tval_loss: 4.1250\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 4.0675,\tval_loss: 4.0711\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 3.9836,\tval_loss: 4.0979\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 3.9426,\tval_loss: 4.1642\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 3.9175,\tval_loss: 4.1527\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 3.9069,\tval_loss: 4.1091\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 3.8506,\tval_loss: 4.2239\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 3.9058,\tval_loss: 4.1015\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 3.8314,\tval_loss: 4.2428\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 3.8873,\tval_loss: 4.1581\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 3.7824,\tval_loss: 4.2005\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 3.7112,\tval_loss: 4.2525\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 3.7466,\tval_loss: 4.2643\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 3.7834,\tval_loss: 4.2258\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 3.7399,\tval_loss: 4.2311\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 3.7197,\tval_loss: 4.2850\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 3.6357,\tval_loss: 4.2362\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 3.7542,\tval_loss: 4.1940\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 3.6727,\tval_loss: 4.1814\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 3.7379,\tval_loss: 4.2665\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 3.6719,\tval_loss: 4.2424\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 3.6634,\tval_loss: 4.2754\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 3.6129,\tval_loss: 4.2341\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 3.7094,\tval_loss: 4.2156\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 3.7359,\tval_loss: 4.1443\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 3.7172,\tval_loss: 4.2052\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 3.6721,\tval_loss: 4.3046\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 3.6206,\tval_loss: 4.1960\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 3.5969,\tval_loss: 4.3326\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 3.6003,\tval_loss: 4.2858\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 3.6069,\tval_loss: 4.3023\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 3.6561,\tval_loss: 4.2382\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 3.5983,\tval_loss: 4.2666\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 3.5607,\tval_loss: 4.2635\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 3.5566,\tval_loss: 4.2461\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 3.4889,\tval_loss: 4.3266\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 3.5240,\tval_loss: 4.2938\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 3.5680,\tval_loss: 4.3778\n",
            "47:\t[0s / 4s],\t\ttrain_loss: 3.6317,\tval_loss: 4.2751\n",
            "48:\t[0s / 4s],\t\ttrain_loss: 3.5834,\tval_loss: 4.1767\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 3.5491,\tval_loss: 4.3817\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 3.5497,\tval_loss: 4.2713\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 3.5037,\tval_loss: 4.2781\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 3.4682,\tval_loss: 4.2644\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 3.4891,\tval_loss: 4.2705\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 3.4241,\tval_loss: 4.3863\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 3.4848,\tval_loss: 4.3677\n",
            "56:\t[0s / 5s],\t\ttrain_loss: 3.5623,\tval_loss: 4.2784\n",
            "57:\t[0s / 5s],\t\ttrain_loss: 3.4568,\tval_loss: 4.2556\n",
            "58:\t[0s / 5s],\t\ttrain_loss: 3.4539,\tval_loss: 4.3055\n",
            "59:\t[0s / 5s],\t\ttrain_loss: 3.5889,\tval_loss: 4.2685\n",
            "60:\t[0s / 5s],\t\ttrain_loss: 3.4896,\tval_loss: 4.3334\n",
            "61:\t[0s / 5s],\t\ttrain_loss: 3.4521,\tval_loss: 4.3496\n",
            "62:\t[0s / 5s],\t\ttrain_loss: 3.5256,\tval_loss: 4.2853\n",
            "63:\t[0s / 5s],\t\ttrain_loss: 3.4533,\tval_loss: 4.3569\n",
            "64:\t[0s / 5s],\t\ttrain_loss: 3.3791,\tval_loss: 4.3299\n",
            "65:\t[0s / 5s],\t\ttrain_loss: 3.4499,\tval_loss: 4.2807\n",
            "66:\t[0s / 5s],\t\ttrain_loss: 3.4837,\tval_loss: 4.3210\n",
            "67:\t[0s / 5s],\t\ttrain_loss: 3.4786,\tval_loss: 4.2971\n",
            "68:\t[0s / 5s],\t\ttrain_loss: 3.4698,\tval_loss: 4.3254\n",
            "69:\t[0s / 6s],\t\ttrain_loss: 3.4392,\tval_loss: 4.3575\n",
            "70:\t[0s / 6s],\t\ttrain_loss: 3.4984,\tval_loss: 4.4040\n",
            "71:\t[0s / 6s],\t\ttrain_loss: 3.4240,\tval_loss: 4.4483\n",
            "72:\t[0s / 6s],\t\ttrain_loss: 3.5324,\tval_loss: 4.2750\n",
            "73:\t[0s / 6s],\t\ttrain_loss: 3.3779,\tval_loss: 4.3900\n",
            "74:\t[0s / 6s],\t\ttrain_loss: 3.4925,\tval_loss: 4.3528\n",
            "75:\t[0s / 6s],\t\ttrain_loss: 3.4478,\tval_loss: 4.3768\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3022,\tval_loss: 3.9889\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2409,\tval_loss: 3.9861\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1667,\tval_loss: 3.9915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1703,\tval_loss: 4.0090\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1315,\tval_loss: 4.0045\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1081,\tval_loss: 4.0233\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0823,\tval_loss: 4.0085\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0517,\tval_loss: 4.0560\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0714,\tval_loss: 4.0340\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0369,\tval_loss: 4.0669\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0437,\tval_loss: 4.0760\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0316,\tval_loss: 4.0567\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9890,\tval_loss: 4.0653\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9432,\tval_loss: 4.1405\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9431,\tval_loss: 4.1227\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9691,\tval_loss: 4.1356\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9143,\tval_loss: 4.1441\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8805,\tval_loss: 4.1328\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8314,\tval_loss: 4.1728\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8345,\tval_loss: 4.1633\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.7961,\tval_loss: 4.1860\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7997,\tval_loss: 4.1857\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8242,\tval_loss: 4.1925\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8137,\tval_loss: 4.1838\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7105,\tval_loss: 4.1691\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7122,\tval_loss: 4.1953\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7284,\tval_loss: 4.1993\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6941,\tval_loss: 4.1896\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6983,\tval_loss: 4.2502\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.6169,\tval_loss: 4.2718\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6868,\tval_loss: 4.2690\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7043,\tval_loss: 4.3197\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6936,\tval_loss: 4.2009\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7023,\tval_loss: 4.1903\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7004,\tval_loss: 4.2166\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6488,\tval_loss: 4.3388\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6405,\tval_loss: 4.2915\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6639,\tval_loss: 4.2214\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.5949,\tval_loss: 4.2797\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.5744,\tval_loss: 4.2599\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6469,\tval_loss: 4.2462\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6445,\tval_loss: 4.2542\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.5874,\tval_loss: 4.3202\n",
            "43:\t[0s / 1s],\t\ttrain_loss: 3.6100,\tval_loss: 4.1934\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5812,\tval_loss: 4.2758\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6183,\tval_loss: 4.2676\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6253,\tval_loss: 4.1753\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6058,\tval_loss: 4.2842\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5648,\tval_loss: 4.2728\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5318,\tval_loss: 4.2878\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6033,\tval_loss: 4.1864\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5407,\tval_loss: 4.2865\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6083,\tval_loss: 4.2120\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5502,\tval_loss: 4.3069\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6123,\tval_loss: 4.3365\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5243,\tval_loss: 4.3110\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5587,\tval_loss: 4.2886\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.4795,\tval_loss: 4.2905\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5447,\tval_loss: 4.2254\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5028,\tval_loss: 4.2993\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5233,\tval_loss: 4.3453\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5421,\tval_loss: 4.2661\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5440,\tval_loss: 4.3399\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.4881,\tval_loss: 4.2831\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.4753,\tval_loss: 4.2579\n",
            "65:\t[0s / 2s],\t\ttrain_loss: 3.4582,\tval_loss: 4.3656\n",
            "66:\t[0s / 2s],\t\ttrain_loss: 3.5400,\tval_loss: 4.3334\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5495,\tval_loss: 4.3195\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.4889,\tval_loss: 4.2879\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3705,\tval_loss: 4.0360\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2662,\tval_loss: 4.0290\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2544,\tval_loss: 4.0365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2783,\tval_loss: 4.0380\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2145,\tval_loss: 4.0346\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1821,\tval_loss: 4.0416\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1889,\tval_loss: 4.0320\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1892,\tval_loss: 4.0468\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1382,\tval_loss: 4.0488\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1459,\tval_loss: 4.0332\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1695,\tval_loss: 4.0502\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1009,\tval_loss: 4.0444\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0656,\tval_loss: 4.0507\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0578,\tval_loss: 4.0699\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0272,\tval_loss: 4.0776\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9666,\tval_loss: 4.0961\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9683,\tval_loss: 4.1478\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9664,\tval_loss: 4.1107\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9563,\tval_loss: 4.1441\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9714,\tval_loss: 4.1708\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.8968,\tval_loss: 4.1875\n",
            "21:\t[0s / 0s],\t\ttrain_loss: 3.8429,\tval_loss: 4.1639\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8301,\tval_loss: 4.2984\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8716,\tval_loss: 4.2477\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8402,\tval_loss: 4.1681\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8551,\tval_loss: 4.2655\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8484,\tval_loss: 4.1690\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7722,\tval_loss: 4.2734\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7924,\tval_loss: 4.2169\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7958,\tval_loss: 4.2442\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7331,\tval_loss: 4.2841\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7003,\tval_loss: 4.3007\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7957,\tval_loss: 4.2833\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6834,\tval_loss: 4.2859\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7457,\tval_loss: 4.2643\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7420,\tval_loss: 4.2936\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6663,\tval_loss: 4.2627\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6520,\tval_loss: 4.2522\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6373,\tval_loss: 4.3312\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6537,\tval_loss: 4.3360\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7056,\tval_loss: 4.3093\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.5358,\tval_loss: 4.3922\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.6709,\tval_loss: 4.3941\n",
            "43:\t[0s / 1s],\t\ttrain_loss: 3.5966,\tval_loss: 4.3580\n",
            "44:\t[0s / 1s],\t\ttrain_loss: 3.5772,\tval_loss: 4.4525\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6347,\tval_loss: 4.3070\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5905,\tval_loss: 4.3769\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5807,\tval_loss: 4.3330\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6146,\tval_loss: 4.4105\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5150,\tval_loss: 4.4466\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5439,\tval_loss: 4.3437\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5105,\tval_loss: 4.4306\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.4768,\tval_loss: 4.5095\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5108,\tval_loss: 4.4174\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5045,\tval_loss: 4.5109\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5487,\tval_loss: 4.4127\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5921,\tval_loss: 4.4008\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5440,\tval_loss: 4.4209\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5106,\tval_loss: 4.4511\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5022,\tval_loss: 4.4347\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5410,\tval_loss: 4.4583\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.4428,\tval_loss: 4.4818\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.4845,\tval_loss: 4.5028\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.4138,\tval_loss: 4.5126\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.4890,\tval_loss: 4.5790\n",
            "65:\t[0s / 2s],\t\ttrain_loss: 3.4988,\tval_loss: 4.3852\n",
            "66:\t[0s / 2s],\t\ttrain_loss: 3.4321,\tval_loss: 4.4788\n",
            "67:\t[0s / 2s],\t\ttrain_loss: 3.3949,\tval_loss: 4.5008\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5109,\tval_loss: 4.4467\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4801,\tval_loss: 4.0669\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2351,\tval_loss: 4.0822\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2028,\tval_loss: 4.0713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1759,\tval_loss: 4.0860\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1380,\tval_loss: 4.1080\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1167,\tval_loss: 4.0985\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0648,\tval_loss: 4.1203\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0681,\tval_loss: 4.1592\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0418,\tval_loss: 4.1434\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0163,\tval_loss: 4.1440\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 3.9924,\tval_loss: 4.1999\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0029,\tval_loss: 4.1842\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9577,\tval_loss: 4.1891\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9450,\tval_loss: 4.1957\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9238,\tval_loss: 4.1804\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9205,\tval_loss: 4.2398\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8971,\tval_loss: 4.2270\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8683,\tval_loss: 4.2669\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8330,\tval_loss: 4.2125\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8478,\tval_loss: 4.2162\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.7850,\tval_loss: 4.2464\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7841,\tval_loss: 4.3176\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7742,\tval_loss: 4.3097\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8041,\tval_loss: 4.2299\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7397,\tval_loss: 4.2855\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6981,\tval_loss: 4.4321\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7796,\tval_loss: 4.2414\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6780,\tval_loss: 4.3195\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7457,\tval_loss: 4.2990\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7214,\tval_loss: 4.3101\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7153,\tval_loss: 4.3884\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6293,\tval_loss: 4.2835\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6984,\tval_loss: 4.3353\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6333,\tval_loss: 4.4236\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6582,\tval_loss: 4.3040\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6119,\tval_loss: 4.4209\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6302,\tval_loss: 4.3832\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.5530,\tval_loss: 4.3521\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6420,\tval_loss: 4.3280\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6214,\tval_loss: 4.3611\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.5643,\tval_loss: 4.4709\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6077,\tval_loss: 4.3067\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.5706,\tval_loss: 4.4940\n",
            "43:\t[0s / 1s],\t\ttrain_loss: 3.6091,\tval_loss: 4.2407\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6012,\tval_loss: 4.5224\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6020,\tval_loss: 4.4401\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5594,\tval_loss: 4.3636\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5723,\tval_loss: 4.4454\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5344,\tval_loss: 4.4923\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5505,\tval_loss: 4.5727\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5178,\tval_loss: 4.4563\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5966,\tval_loss: 4.4398\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5700,\tval_loss: 4.4221\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5620,\tval_loss: 4.3827\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5172,\tval_loss: 4.4249\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5529,\tval_loss: 4.3887\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5574,\tval_loss: 4.3559\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5269,\tval_loss: 4.5271\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.4795,\tval_loss: 4.4165\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5481,\tval_loss: 4.5109\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6033,\tval_loss: 4.3383\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6336,\tval_loss: 4.4340\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.4852,\tval_loss: 4.4239\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.4796,\tval_loss: 4.4025\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5348,\tval_loss: 4.3721\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.4884,\tval_loss: 4.4918\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5059,\tval_loss: 4.5006\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5054,\tval_loss: 4.4100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3964,\tval_loss: 4.0842\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2517,\tval_loss: 4.1338\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2079,\tval_loss: 4.1220\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1793,\tval_loss: 4.1599\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2019,\tval_loss: 4.1231\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1746,\tval_loss: 4.1304\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1751,\tval_loss: 4.1943\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1620,\tval_loss: 4.1681\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1299,\tval_loss: 4.2097\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1584,\tval_loss: 4.2069\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0925,\tval_loss: 4.2230\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0736,\tval_loss: 4.2544\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0671,\tval_loss: 4.2839\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0559,\tval_loss: 4.2492\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0239,\tval_loss: 4.2688\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0794,\tval_loss: 4.2582\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 4.0052,\tval_loss: 4.2668\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9664,\tval_loss: 4.2802\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9656,\tval_loss: 4.3312\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9081,\tval_loss: 4.4243\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9970,\tval_loss: 4.3055\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9314,\tval_loss: 4.3769\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9633,\tval_loss: 4.2734\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9170,\tval_loss: 4.4253\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9521,\tval_loss: 4.2609\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9544,\tval_loss: 4.3248\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8500,\tval_loss: 4.4061\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9245,\tval_loss: 4.2602\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8516,\tval_loss: 4.4520\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.8116,\tval_loss: 4.4134\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.8803,\tval_loss: 4.3695\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.8215,\tval_loss: 4.3837\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.8799,\tval_loss: 4.3631\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.8087,\tval_loss: 4.3808\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7941,\tval_loss: 4.4568\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.8021,\tval_loss: 4.4494\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7684,\tval_loss: 4.3985\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7776,\tval_loss: 4.5056\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7874,\tval_loss: 4.3425\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.8247,\tval_loss: 4.4507\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.8093,\tval_loss: 4.4633\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7266,\tval_loss: 4.5409\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7130,\tval_loss: 4.4786\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7266,\tval_loss: 4.4152\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7080,\tval_loss: 4.5547\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.7059,\tval_loss: 4.5226\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.6576,\tval_loss: 4.5156\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.6975,\tval_loss: 4.5488\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.7254,\tval_loss: 4.4583\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.7147,\tval_loss: 4.4521\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.7102,\tval_loss: 4.5001\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.7272,\tval_loss: 4.4460\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6912,\tval_loss: 4.4751\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.7466,\tval_loss: 4.4404\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.7804,\tval_loss: 4.4186\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6911,\tval_loss: 4.5362\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6296,\tval_loss: 4.4987\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6392,\tval_loss: 4.5461\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.7125,\tval_loss: 4.4825\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 3.6991,\tval_loss: 4.5283\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 3.6037,\tval_loss: 4.5456\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.6640,\tval_loss: 4.5453\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.6564,\tval_loss: 4.4423\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.6294,\tval_loss: 4.4333\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.6414,\tval_loss: 4.5222\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.5786,\tval_loss: 4.5250\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.6293,\tval_loss: 4.6051\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.6759,\tval_loss: 4.4483\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3839,\tval_loss: 4.1119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2576,\tval_loss: 4.0914\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2266,\tval_loss: 4.0980\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2070,\tval_loss: 4.0875\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1863,\tval_loss: 4.0692\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1421,\tval_loss: 4.0836\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1133,\tval_loss: 4.2053\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1828,\tval_loss: 4.0745\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0911,\tval_loss: 4.1346\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0477,\tval_loss: 4.1209\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0737,\tval_loss: 4.1151\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0705,\tval_loss: 4.1176\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9822,\tval_loss: 4.1951\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9950,\tval_loss: 4.1799\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0291,\tval_loss: 4.2255\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9728,\tval_loss: 4.2365\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9819,\tval_loss: 4.2820\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9440,\tval_loss: 4.2448\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8589,\tval_loss: 4.3374\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8840,\tval_loss: 4.3178\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.8647,\tval_loss: 4.3647\n",
            "21:\t[0s / 0s],\t\ttrain_loss: 3.8615,\tval_loss: 4.4136\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8646,\tval_loss: 4.3986\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7822,\tval_loss: 4.4135\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7770,\tval_loss: 4.5032\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6763,\tval_loss: 4.5393\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7569,\tval_loss: 4.4080\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7664,\tval_loss: 4.4792\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7117,\tval_loss: 4.5462\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.6809,\tval_loss: 4.4639\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6618,\tval_loss: 4.5566\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6877,\tval_loss: 4.5114\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6706,\tval_loss: 4.5590\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6396,\tval_loss: 4.5426\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7052,\tval_loss: 4.5229\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6241,\tval_loss: 4.5133\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.5876,\tval_loss: 4.5327\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6284,\tval_loss: 4.5571\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6677,\tval_loss: 4.5038\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.5852,\tval_loss: 4.5978\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6061,\tval_loss: 4.4684\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6477,\tval_loss: 4.6769\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.6457,\tval_loss: 4.5033\n",
            "43:\t[0s / 1s],\t\ttrain_loss: 3.6255,\tval_loss: 4.5277\n",
            "44:\t[0s / 1s],\t\ttrain_loss: 3.6372,\tval_loss: 4.5455\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6447,\tval_loss: 4.5416\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5862,\tval_loss: 4.5227\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5503,\tval_loss: 4.6377\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5392,\tval_loss: 4.5955\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5925,\tval_loss: 4.6509\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5276,\tval_loss: 4.6935\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.4122,\tval_loss: 4.6805\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5248,\tval_loss: 4.6973\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.4779,\tval_loss: 4.6793\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5889,\tval_loss: 4.6349\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5024,\tval_loss: 4.6367\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.4923,\tval_loss: 4.6488\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.4976,\tval_loss: 4.7450\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.4968,\tval_loss: 4.7390\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6159,\tval_loss: 4.6409\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5748,\tval_loss: 4.5394\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5527,\tval_loss: 4.6119\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5295,\tval_loss: 4.6749\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5837,\tval_loss: 4.6567\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.4670,\tval_loss: 4.7325\n",
            "65:\t[0s / 2s],\t\ttrain_loss: 3.5231,\tval_loss: 4.7109\n",
            "66:\t[0s / 2s],\t\ttrain_loss: 3.4579,\tval_loss: 4.7208\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5136,\tval_loss: 4.6861\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5750,\tval_loss: 4.5856\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5402,\tval_loss: 4.7037\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5324,\tval_loss: 4.5886\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.4977,\tval_loss: 4.6719\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4469,\tval_loss: 4.1035\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2838,\tval_loss: 4.0789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1964,\tval_loss: 4.0756\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1879,\tval_loss: 4.0769\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1687,\tval_loss: 4.0705\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1449,\tval_loss: 4.0759\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1311,\tval_loss: 4.0700\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0867,\tval_loss: 4.0758\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1004,\tval_loss: 4.1068\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0438,\tval_loss: 4.1351\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0683,\tval_loss: 4.1267\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0218,\tval_loss: 4.1080\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9630,\tval_loss: 4.1245\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9433,\tval_loss: 4.1756\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9014,\tval_loss: 4.1724\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9005,\tval_loss: 4.1681\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8958,\tval_loss: 4.1951\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8476,\tval_loss: 4.2306\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8512,\tval_loss: 4.1855\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8688,\tval_loss: 4.2375\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.7664,\tval_loss: 4.3076\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8369,\tval_loss: 4.2632\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7626,\tval_loss: 4.2815\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8018,\tval_loss: 4.2497\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7619,\tval_loss: 4.2595\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7339,\tval_loss: 4.3368\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7801,\tval_loss: 4.2756\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7589,\tval_loss: 4.2729\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6886,\tval_loss: 4.2769\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7183,\tval_loss: 4.3470\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6927,\tval_loss: 4.3894\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6763,\tval_loss: 4.3050\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6885,\tval_loss: 4.2967\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6573,\tval_loss: 4.3542\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6373,\tval_loss: 4.3421\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6866,\tval_loss: 4.2977\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7006,\tval_loss: 4.3114\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7448,\tval_loss: 4.2548\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6801,\tval_loss: 4.2667\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6587,\tval_loss: 4.3873\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7073,\tval_loss: 4.3994\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6040,\tval_loss: 4.3647\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.6998,\tval_loss: 4.2895\n",
            "43:\t[0s / 1s],\t\ttrain_loss: 3.7093,\tval_loss: 4.3083\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6593,\tval_loss: 4.3425\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5915,\tval_loss: 4.3796\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5567,\tval_loss: 4.3965\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5540,\tval_loss: 4.4067\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5948,\tval_loss: 4.4038\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5903,\tval_loss: 4.3926\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6405,\tval_loss: 4.3727\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5918,\tval_loss: 4.3402\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6668,\tval_loss: 4.3207\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6164,\tval_loss: 4.3216\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6282,\tval_loss: 4.3993\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5991,\tval_loss: 4.3415\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6283,\tval_loss: 4.3501\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5776,\tval_loss: 4.3989\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5635,\tval_loss: 4.4820\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5216,\tval_loss: 4.4749\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6000,\tval_loss: 4.3495\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5930,\tval_loss: 4.3560\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5692,\tval_loss: 4.4140\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5600,\tval_loss: 4.4717\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.5824,\tval_loss: 4.4248\n",
            "65:\t[0s / 2s],\t\ttrain_loss: 3.6193,\tval_loss: 4.4421\n",
            "66:\t[0s / 2s],\t\ttrain_loss: 3.5534,\tval_loss: 4.3451\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5811,\tval_loss: 4.4130\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5822,\tval_loss: 4.3897\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5973,\tval_loss: 4.3771\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5801,\tval_loss: 4.3575\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.6203,\tval_loss: 4.2994\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.5785,\tval_loss: 4.4523\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.5530,\tval_loss: 4.4072\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3713,\tval_loss: 4.0280\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2405,\tval_loss: 4.0660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2012,\tval_loss: 4.0427\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1818,\tval_loss: 4.0618\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1346,\tval_loss: 4.0787\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1192,\tval_loss: 4.0783\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1133,\tval_loss: 4.0841\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1105,\tval_loss: 4.1132\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0843,\tval_loss: 4.1024\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0688,\tval_loss: 4.1043\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0551,\tval_loss: 4.1276\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9900,\tval_loss: 4.1504\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0766,\tval_loss: 4.1675\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0167,\tval_loss: 4.1048\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9959,\tval_loss: 4.2128\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0209,\tval_loss: 4.1791\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9894,\tval_loss: 4.2465\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9600,\tval_loss: 4.2312\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9410,\tval_loss: 4.2157\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9484,\tval_loss: 4.2123\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.8556,\tval_loss: 4.2890\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9342,\tval_loss: 4.3050\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9377,\tval_loss: 4.2766\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8782,\tval_loss: 4.3068\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9267,\tval_loss: 4.3280\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8201,\tval_loss: 4.3218\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8980,\tval_loss: 4.3964\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8511,\tval_loss: 4.3205\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8595,\tval_loss: 4.2975\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8173,\tval_loss: 4.3144\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8393,\tval_loss: 4.3293\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7676,\tval_loss: 4.3281\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.9176,\tval_loss: 4.3079\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7889,\tval_loss: 4.3181\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8241,\tval_loss: 4.3598\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8184,\tval_loss: 4.3318\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7930,\tval_loss: 4.2841\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7318,\tval_loss: 4.3821\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6823,\tval_loss: 4.4839\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7996,\tval_loss: 4.3965\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7378,\tval_loss: 4.4298\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7666,\tval_loss: 4.3030\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.7705,\tval_loss: 4.3371\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7100,\tval_loss: 4.4128\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6205,\tval_loss: 4.4843\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7372,\tval_loss: 4.3275\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7623,\tval_loss: 4.3461\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6911,\tval_loss: 4.3474\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7775,\tval_loss: 4.3714\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7225,\tval_loss: 4.3606\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6999,\tval_loss: 4.4258\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7010,\tval_loss: 4.4242\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6270,\tval_loss: 4.4058\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7527,\tval_loss: 4.4167\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6782,\tval_loss: 4.3550\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6855,\tval_loss: 4.3650\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.7624,\tval_loss: 4.2946\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6829,\tval_loss: 4.3692\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6642,\tval_loss: 4.4577\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.7238,\tval_loss: 4.4013\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6145,\tval_loss: 4.3808\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5647,\tval_loss: 4.3684\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6280,\tval_loss: 4.4520\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.6281,\tval_loss: 4.3966\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.6194,\tval_loss: 4.4659\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6129,\tval_loss: 4.3522\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6309,\tval_loss: 4.4008\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5929,\tval_loss: 4.4096\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3815,\tval_loss: 4.0925\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2580,\tval_loss: 4.0834\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2370,\tval_loss: 4.0760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2153,\tval_loss: 4.0720\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1863,\tval_loss: 4.0782\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1682,\tval_loss: 4.0809\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1393,\tval_loss: 4.1079\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1319,\tval_loss: 4.0869\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0880,\tval_loss: 4.0873\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0770,\tval_loss: 4.0998\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0557,\tval_loss: 4.0839\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9668,\tval_loss: 4.1227\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0223,\tval_loss: 4.1053\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9726,\tval_loss: 4.1628\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0129,\tval_loss: 4.1047\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9400,\tval_loss: 4.1116\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9118,\tval_loss: 4.1392\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8926,\tval_loss: 4.1870\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.8179,\tval_loss: 4.2235\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.7905,\tval_loss: 4.1150\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8014,\tval_loss: 4.1465\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7538,\tval_loss: 4.1735\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7528,\tval_loss: 4.2175\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7411,\tval_loss: 4.2305\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7462,\tval_loss: 4.1345\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7838,\tval_loss: 4.1946\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7254,\tval_loss: 4.1774\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6799,\tval_loss: 4.2741\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6427,\tval_loss: 4.3179\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.6869,\tval_loss: 4.2663\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6237,\tval_loss: 4.3073\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.6669,\tval_loss: 4.2945\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.6696,\tval_loss: 4.3375\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.6186,\tval_loss: 4.3763\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.6906,\tval_loss: 4.3401\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.5999,\tval_loss: 4.3770\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.5548,\tval_loss: 4.3116\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6190,\tval_loss: 4.3177\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.5926,\tval_loss: 4.3141\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.5944,\tval_loss: 4.3250\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.4618,\tval_loss: 4.4143\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5057,\tval_loss: 4.3286\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5729,\tval_loss: 4.3797\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5528,\tval_loss: 4.2835\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5659,\tval_loss: 4.4296\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5202,\tval_loss: 4.3512\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.5570,\tval_loss: 4.3595\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.5173,\tval_loss: 4.3799\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.4796,\tval_loss: 4.3795\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.5354,\tval_loss: 4.3610\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.5468,\tval_loss: 4.3331\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.6099,\tval_loss: 4.3174\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.4943,\tval_loss: 4.3416\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.4835,\tval_loss: 4.3567\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.4858,\tval_loss: 4.4599\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.4717,\tval_loss: 4.4482\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5117,\tval_loss: 4.4575\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.4729,\tval_loss: 4.3951\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.4691,\tval_loss: 4.4742\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5077,\tval_loss: 4.3919\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.4323,\tval_loss: 4.4937\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.4927,\tval_loss: 4.4403\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.4545,\tval_loss: 4.4023\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.4625,\tval_loss: 4.4019\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.4153,\tval_loss: 4.4540\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.4030,\tval_loss: 4.3689\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.5146,\tval_loss: 4.3069\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.4662,\tval_loss: 4.4304\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.4374,\tval_loss: 4.4429\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.4601,\tval_loss: 4.3949\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.4803,\tval_loss: 4.3998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4756,\tval_loss: 4.0158\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3594,\tval_loss: 4.0210\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2926,\tval_loss: 4.0332\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2694,\tval_loss: 4.0229\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2163,\tval_loss: 4.0229\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2119,\tval_loss: 4.0395\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2169,\tval_loss: 4.0233\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1775,\tval_loss: 4.0516\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1885,\tval_loss: 4.0166\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1558,\tval_loss: 4.0459\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1556,\tval_loss: 4.0549\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1333,\tval_loss: 4.0152\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0352,\tval_loss: 4.0930\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0397,\tval_loss: 4.1124\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9949,\tval_loss: 4.0732\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9884,\tval_loss: 4.0968\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9554,\tval_loss: 4.1168\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8567,\tval_loss: 4.0933\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9078,\tval_loss: 4.1952\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8856,\tval_loss: 4.1502\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8413,\tval_loss: 4.1718\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8167,\tval_loss: 4.1577\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8146,\tval_loss: 4.1321\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7684,\tval_loss: 4.1684\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7548,\tval_loss: 4.1978\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7872,\tval_loss: 4.1808\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7415,\tval_loss: 4.1065\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6579,\tval_loss: 4.1919\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6877,\tval_loss: 4.1667\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.6599,\tval_loss: 4.1436\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6209,\tval_loss: 4.1991\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6562,\tval_loss: 4.1847\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6483,\tval_loss: 4.1931\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6945,\tval_loss: 4.1641\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6650,\tval_loss: 4.2212\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6897,\tval_loss: 4.1547\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6226,\tval_loss: 4.2213\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.5785,\tval_loss: 4.2685\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.5674,\tval_loss: 4.2710\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6220,\tval_loss: 4.2881\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5688,\tval_loss: 4.2316\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5342,\tval_loss: 4.2484\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5397,\tval_loss: 4.3522\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.4683,\tval_loss: 4.2211\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5733,\tval_loss: 4.3491\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5562,\tval_loss: 4.2648\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5162,\tval_loss: 4.2657\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.4256,\tval_loss: 4.2918\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5974,\tval_loss: 4.2524\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5012,\tval_loss: 4.2187\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.4896,\tval_loss: 4.2602\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.4918,\tval_loss: 4.2878\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5065,\tval_loss: 4.2897\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.4350,\tval_loss: 4.3197\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.4387,\tval_loss: 4.2934\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.4679,\tval_loss: 4.2909\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.4580,\tval_loss: 4.3033\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.4562,\tval_loss: 4.3479\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.4744,\tval_loss: 4.3942\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.4621,\tval_loss: 4.2936\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.4582,\tval_loss: 4.3291\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.4595,\tval_loss: 4.2514\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.4216,\tval_loss: 4.3160\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.4709,\tval_loss: 4.4292\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.4549,\tval_loss: 4.2590\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.4087,\tval_loss: 4.3550\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4336,\tval_loss: 4.2854\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4126,\tval_loss: 4.3392\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.4773,\tval_loss: 4.2712\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.4609,\tval_loss: 4.4060\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.3976,\tval_loss: 4.3905\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.4252,\tval_loss: 4.3159\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.4071,\tval_loss: 4.3255\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.3561,\tval_loss: 4.3812\n",
            "74:\t[0s / 3s],\t\ttrain_loss: 3.3397,\tval_loss: 4.3770\n",
            "75:\t[0s / 3s],\t\ttrain_loss: 3.4350,\tval_loss: 4.3883\n",
            "76:\t[0s / 3s],\t\ttrain_loss: 3.4377,\tval_loss: 4.3417\n",
            "77:\t[0s / 3s],\t\ttrain_loss: 3.4397,\tval_loss: 4.3002\n",
            "78:\t[0s / 3s],\t\ttrain_loss: 3.3930,\tval_loss: 4.3303\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.6412,\tval_loss: 4.0927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2974,\tval_loss: 4.0718\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2842,\tval_loss: 4.1102\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2372,\tval_loss: 4.1018\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1985,\tval_loss: 4.1141\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1913,\tval_loss: 4.0927\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1830,\tval_loss: 4.1087\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1546,\tval_loss: 4.1252\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0843,\tval_loss: 4.1524\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0691,\tval_loss: 4.1744\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0771,\tval_loss: 4.1929\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0144,\tval_loss: 4.2411\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9920,\tval_loss: 4.2615\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9577,\tval_loss: 4.2686\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.8940,\tval_loss: 4.2853\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9343,\tval_loss: 4.3412\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8104,\tval_loss: 4.3224\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9228,\tval_loss: 4.3958\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8450,\tval_loss: 4.4806\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.7967,\tval_loss: 4.4348\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.8009,\tval_loss: 4.4794\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7347,\tval_loss: 4.5150\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7515,\tval_loss: 4.4938\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7678,\tval_loss: 4.5146\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7488,\tval_loss: 4.4580\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7310,\tval_loss: 4.4796\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6529,\tval_loss: 4.5666\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6639,\tval_loss: 4.5531\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6948,\tval_loss: 4.5658\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.6916,\tval_loss: 4.5123\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7531,\tval_loss: 4.5216\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6512,\tval_loss: 4.5257\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6499,\tval_loss: 4.4771\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6320,\tval_loss: 4.5054\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7238,\tval_loss: 4.5064\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6543,\tval_loss: 4.5527\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6171,\tval_loss: 4.5636\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.5825,\tval_loss: 4.5477\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.5644,\tval_loss: 4.6057\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6193,\tval_loss: 4.5632\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.5188,\tval_loss: 4.6025\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6202,\tval_loss: 4.5729\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.6152,\tval_loss: 4.5340\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5513,\tval_loss: 4.5823\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5189,\tval_loss: 4.5784\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5919,\tval_loss: 4.5472\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5575,\tval_loss: 4.5632\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5805,\tval_loss: 4.6219\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5745,\tval_loss: 4.5149\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5601,\tval_loss: 4.5264\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.4768,\tval_loss: 4.5752\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5538,\tval_loss: 4.6126\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6259,\tval_loss: 4.5181\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5270,\tval_loss: 4.6626\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5023,\tval_loss: 4.5801\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5331,\tval_loss: 4.5217\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.4731,\tval_loss: 4.5795\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5000,\tval_loss: 4.6703\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.4641,\tval_loss: 4.5944\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5053,\tval_loss: 4.6193\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.4730,\tval_loss: 4.6084\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.4409,\tval_loss: 4.6789\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.4930,\tval_loss: 4.5764\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5159,\tval_loss: 4.6010\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.4896,\tval_loss: 4.5822\n",
            "65:\t[0s / 2s],\t\ttrain_loss: 3.5351,\tval_loss: 4.5131\n",
            "66:\t[0s / 2s],\t\ttrain_loss: 3.4805,\tval_loss: 4.6666\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5066,\tval_loss: 4.5136\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.4084,\tval_loss: 4.5627\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4958,\tval_loss: 4.0794\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3252,\tval_loss: 4.0696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2783,\tval_loss: 4.0682\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2530,\tval_loss: 4.0731\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2416,\tval_loss: 4.0849\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2306,\tval_loss: 4.0908\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2338,\tval_loss: 4.0962\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2146,\tval_loss: 4.0760\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1958,\tval_loss: 4.0925\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1438,\tval_loss: 4.1011\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1435,\tval_loss: 4.0945\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1236,\tval_loss: 4.1029\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1374,\tval_loss: 4.1062\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0935,\tval_loss: 4.1639\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.1712,\tval_loss: 4.1145\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.1116,\tval_loss: 4.1143\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0889,\tval_loss: 4.1107\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0399,\tval_loss: 4.1406\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0366,\tval_loss: 4.1525\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 4.0440,\tval_loss: 4.1562\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 4.0788,\tval_loss: 4.1591\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9971,\tval_loss: 4.2011\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9394,\tval_loss: 4.1878\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9501,\tval_loss: 4.2047\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9349,\tval_loss: 4.2218\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9040,\tval_loss: 4.2417\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9360,\tval_loss: 4.1855\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9043,\tval_loss: 4.2176\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8352,\tval_loss: 4.2581\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8135,\tval_loss: 4.2876\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8780,\tval_loss: 4.2759\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8200,\tval_loss: 4.2066\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8544,\tval_loss: 4.2637\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8614,\tval_loss: 4.2404\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8140,\tval_loss: 4.2688\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7762,\tval_loss: 4.2913\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7562,\tval_loss: 4.3899\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7752,\tval_loss: 4.3096\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7573,\tval_loss: 4.3195\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7441,\tval_loss: 4.2561\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7916,\tval_loss: 4.3016\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7867,\tval_loss: 4.2870\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.8019,\tval_loss: 4.2935\n",
            "43:\t[0s / 1s],\t\ttrain_loss: 3.7971,\tval_loss: 4.2727\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7928,\tval_loss: 4.3604\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7236,\tval_loss: 4.2761\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7757,\tval_loss: 4.2802\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7804,\tval_loss: 4.3018\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7279,\tval_loss: 4.3571\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7418,\tval_loss: 4.3609\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7480,\tval_loss: 4.2776\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6865,\tval_loss: 4.3574\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7186,\tval_loss: 4.2771\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7023,\tval_loss: 4.3162\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6540,\tval_loss: 4.2873\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6886,\tval_loss: 4.3293\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6014,\tval_loss: 4.4459\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6573,\tval_loss: 4.3357\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6229,\tval_loss: 4.3421\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6506,\tval_loss: 4.3166\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6485,\tval_loss: 4.3200\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5933,\tval_loss: 4.3961\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6325,\tval_loss: 4.3622\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.6660,\tval_loss: 4.3339\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.6869,\tval_loss: 4.2906\n",
            "65:\t[0s / 2s],\t\ttrain_loss: 3.6599,\tval_loss: 4.2777\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6489,\tval_loss: 4.3588\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5719,\tval_loss: 4.3536\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6132,\tval_loss: 4.4068\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5681,\tval_loss: 4.4067\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4115,\tval_loss: 4.1074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2747,\tval_loss: 4.0929\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2723,\tval_loss: 4.0697\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2208,\tval_loss: 4.1220\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1857,\tval_loss: 4.1059\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1661,\tval_loss: 4.0837\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1520,\tval_loss: 4.1192\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1141,\tval_loss: 4.1327\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1116,\tval_loss: 4.1483\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1151,\tval_loss: 4.2185\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0274,\tval_loss: 4.2128\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0062,\tval_loss: 4.2282\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0221,\tval_loss: 4.2278\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0068,\tval_loss: 4.2616\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9588,\tval_loss: 4.2275\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0018,\tval_loss: 4.2921\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9547,\tval_loss: 4.2162\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8971,\tval_loss: 4.3215\n",
            "18:\t[0s / 1s],\t\n",
            "19:\t[0s / 1s],\t\n",
            "20:\t[0s / 1s],\t\n",
            "21:\t[0s / 1s],\t\n",
            "22:\t[0s / 1s],\t\n",
            "23:\t[0s / 1s],\t\n",
            "24:\t[0s / 1s],\t\n",
            "25:\t[0s / 1s],\t\n",
            "26:\t[0s / 1s],\t\n",
            "27:\t[0s / 1s],\t\n",
            "28:\t[0s / 1s],\t\n",
            "29:\t[0s / 1s],\t\n",
            "30:\t[0s / 1s],\t\n",
            "31:\t[0s / 1s],\t\n",
            "32:\t[0s / 2s],\t\n",
            "33:\t[0s / 2s],\t\n",
            "34:\t[0s / 2s],\t\n",
            "35:\t[0s / 2s],\t\n",
            "36:\t[0s / 2s],\t\n",
            "37:\t[0s / 2s],\t\n",
            "38:\t[0s / 2s],\t\n",
            "39:\t[0s / 2s],\t\n",
            "40:\t[0s / 2s],\t\n",
            "41:\t[0s / 2s],\t\n",
            "42:\t[0s / 2s],\t\n",
            "43:\t[0s / 2s],\t\n",
            "44:\t[0s / 2s],\t\n",
            "45:\t[0s / 2s],\t\n",
            "46:\t[0s / 2s],\t\n",
            "47:\t[0s / 3s],\t\n",
            "48:\t[0s / 3s],\t\n",
            "49:\t[0s / 3s],\t\n",
            "50:\t[0s / 3s],\t\n",
            "51:\t[0s / 3s],\t\n",
            "52:\t[0s / 3s],\t\n",
            "53:\t[0s / 3s],\t\n",
            "54:\t[0s / 3s],\t\n",
            "55:\t[0s / 3s],\t\n",
            "56:\t[0s / 3s],\t\n",
            "57:\t[0s / 3s],\t\n",
            "58:\t[0s / 3s],\t\n",
            "59:\t[0s / 3s],\t\n",
            "60:\t[0s / 3s],\t\n",
            "61:\t[0s / 3s],\t\n",
            "62:\t[0s / 4s],\t\n",
            "63:\t[0s / 4s],\t\n",
            "64:\t[0s / 4s],\t\n",
            "65:\t[0s / 4s],\t\n",
            "66:\t[0s / 4s],\t\n",
            "67:\t[0s / 4s],\t\n",
            "68:\t[0s / 4s],\t\n",
            "69:\t[0s / 4s],\t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3839,\tval_loss: 4.0338\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2344,\tval_loss: 4.0568\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1972,\tval_loss: 4.0803\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1918,\tval_loss: 4.0924\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1511,\tval_loss: 4.0949\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1237,\tval_loss: 4.1208\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1531,\tval_loss: 4.1128\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0922,\tval_loss: 4.1289\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1101,\tval_loss: 4.1412\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0957,\tval_loss: 4.1349\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0316,\tval_loss: 4.1816\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0277,\tval_loss: 4.2221\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9574,\tval_loss: 4.2024\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0456,\tval_loss: 4.1982\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0062,\tval_loss: 4.1530\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9903,\tval_loss: 4.1764\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.8569,\tval_loss: 4.3067\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8809,\tval_loss: 4.2496\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.8782,\tval_loss: 4.1974\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.7729,\tval_loss: 4.3070\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8542,\tval_loss: 4.2385\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7426,\tval_loss: 4.2567\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7939,\tval_loss: 4.2359\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7449,\tval_loss: 4.2505\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7642,\tval_loss: 4.2525\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7139,\tval_loss: 4.2937\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7306,\tval_loss: 4.2292\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7326,\tval_loss: 4.2211\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7142,\tval_loss: 4.2623\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7210,\tval_loss: 4.2497\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6539,\tval_loss: 4.2875\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6440,\tval_loss: 4.2188\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6086,\tval_loss: 4.3457\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.5666,\tval_loss: 4.3211\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6256,\tval_loss: 4.3492\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7655,\tval_loss: 4.1608\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.6634,\tval_loss: 4.2429\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6595,\tval_loss: 4.2794\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.5770,\tval_loss: 4.4380\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6413,\tval_loss: 4.2647\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5813,\tval_loss: 4.3673\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5991,\tval_loss: 4.3960\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5951,\tval_loss: 4.2901\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6121,\tval_loss: 4.3339\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5798,\tval_loss: 4.3403\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.4404,\tval_loss: 4.3175\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5447,\tval_loss: 4.2873\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5978,\tval_loss: 4.3311\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6191,\tval_loss: 4.2205\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6232,\tval_loss: 4.2636\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5867,\tval_loss: 4.2936\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5426,\tval_loss: 4.3707\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.4483,\tval_loss: 4.3732\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5350,\tval_loss: 4.3443\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5549,\tval_loss: 4.4269\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5425,\tval_loss: 4.3261\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5071,\tval_loss: 4.4191\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5226,\tval_loss: 4.3543\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5268,\tval_loss: 4.3171\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5245,\tval_loss: 4.3625\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5142,\tval_loss: 4.3609\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5366,\tval_loss: 4.2627\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.4811,\tval_loss: 4.3225\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.4688,\tval_loss: 4.4212\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.4634,\tval_loss: 4.2764\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5868,\tval_loss: 4.3001\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5388,\tval_loss: 4.2917\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4963,\tval_loss: 4.3316\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3371,\tval_loss: 4.0292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2396,\tval_loss: 4.0191\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2345,\tval_loss: 4.0226\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1923,\tval_loss: 4.0296\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1905,\tval_loss: 4.0161\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1737,\tval_loss: 4.0244\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1635,\tval_loss: 4.0382\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1459,\tval_loss: 4.0270\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0875,\tval_loss: 4.0652\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0998,\tval_loss: 4.0605\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0786,\tval_loss: 4.0773\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0808,\tval_loss: 4.1081\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0108,\tval_loss: 4.0732\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0384,\tval_loss: 4.1298\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0095,\tval_loss: 4.1060\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0268,\tval_loss: 4.0890\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9236,\tval_loss: 4.1260\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9370,\tval_loss: 4.0523\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9121,\tval_loss: 4.1205\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9225,\tval_loss: 4.1189\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8915,\tval_loss: 4.0718\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9201,\tval_loss: 4.0775\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8077,\tval_loss: 4.1707\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9135,\tval_loss: 4.0846\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8417,\tval_loss: 4.0690\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8586,\tval_loss: 4.1391\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8027,\tval_loss: 4.1736\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8759,\tval_loss: 4.0824\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7625,\tval_loss: 4.1405\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7631,\tval_loss: 4.1323\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7939,\tval_loss: 4.2046\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8013,\tval_loss: 4.1603\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8097,\tval_loss: 4.1628\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7863,\tval_loss: 4.1837\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7020,\tval_loss: 4.2181\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7750,\tval_loss: 4.1482\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7322,\tval_loss: 4.1818\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7496,\tval_loss: 4.2275\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7779,\tval_loss: 4.1707\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.8101,\tval_loss: 4.1986\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7464,\tval_loss: 4.1961\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6749,\tval_loss: 4.2626\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6944,\tval_loss: 4.2113\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7372,\tval_loss: 4.1772\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7251,\tval_loss: 4.2229\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7315,\tval_loss: 4.2310\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6890,\tval_loss: 4.1736\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7271,\tval_loss: 4.2074\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7141,\tval_loss: 4.1963\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6464,\tval_loss: 4.2758\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6955,\tval_loss: 4.2070\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7156,\tval_loss: 4.1970\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7094,\tval_loss: 4.2085\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6859,\tval_loss: 4.3165\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6716,\tval_loss: 4.1684\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6809,\tval_loss: 4.2093\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.7030,\tval_loss: 4.1867\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6504,\tval_loss: 4.2244\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.7230,\tval_loss: 4.2202\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5823,\tval_loss: 4.2171\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.7008,\tval_loss: 4.2338\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5918,\tval_loss: 4.2599\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6156,\tval_loss: 4.2375\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.6077,\tval_loss: 4.2203\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.5597,\tval_loss: 4.2031\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6660,\tval_loss: 4.2754\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6809,\tval_loss: 4.2340\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.7026,\tval_loss: 4.2277\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6691,\tval_loss: 4.1954\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6840,\tval_loss: 4.2105\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6588,\tval_loss: 4.2087\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.6975,\tval_loss: 4.1996\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4182,\tval_loss: 4.0927\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.1925,\tval_loss: 4.0641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1722,\tval_loss: 4.0727\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1723,\tval_loss: 4.0666\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1062,\tval_loss: 4.0479\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1501,\tval_loss: 4.0480\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1042,\tval_loss: 4.0578\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0479,\tval_loss: 4.0904\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0771,\tval_loss: 4.0733\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0295,\tval_loss: 4.1254\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 3.9990,\tval_loss: 4.1391\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9242,\tval_loss: 4.1371\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9560,\tval_loss: 4.1332\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9984,\tval_loss: 4.1374\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9100,\tval_loss: 4.1364\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.8756,\tval_loss: 4.2176\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9303,\tval_loss: 4.1662\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8648,\tval_loss: 4.1751\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8164,\tval_loss: 4.2322\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.7715,\tval_loss: 4.2446\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.7452,\tval_loss: 4.2570\n",
            "21:\t[0s / 0s],\t\ttrain_loss: 3.6733,\tval_loss: 4.3843\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7653,\tval_loss: 4.3183\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7059,\tval_loss: 4.3841\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.6846,\tval_loss: 4.2776\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7236,\tval_loss: 4.3301\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6132,\tval_loss: 4.3610\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6460,\tval_loss: 4.3824\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6128,\tval_loss: 4.4960\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.5842,\tval_loss: 4.3959\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.5416,\tval_loss: 4.4657\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6703,\tval_loss: 4.3643\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6427,\tval_loss: 4.4388\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6095,\tval_loss: 4.4345\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.5631,\tval_loss: 4.4133\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6634,\tval_loss: 4.3712\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.5874,\tval_loss: 4.3771\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6037,\tval_loss: 4.5104\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.5422,\tval_loss: 4.3872\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.5038,\tval_loss: 4.4280\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.5515,\tval_loss: 4.4848\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.4113,\tval_loss: 4.6135\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.5404,\tval_loss: 4.4655\n",
            "43:\t[0s / 1s],\t\ttrain_loss: 3.5399,\tval_loss: 4.3989\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.4467,\tval_loss: 4.5670\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5420,\tval_loss: 4.4050\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.3947,\tval_loss: 4.4666\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.4155,\tval_loss: 4.5352\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.4649,\tval_loss: 4.4159\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.4656,\tval_loss: 4.5420\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.4432,\tval_loss: 4.5520\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.4430,\tval_loss: 4.4845\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.4422,\tval_loss: 4.4978\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.4564,\tval_loss: 4.6098\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.4246,\tval_loss: 4.5023\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5174,\tval_loss: 4.4596\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.4119,\tval_loss: 4.5816\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.4241,\tval_loss: 4.4952\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.4554,\tval_loss: 4.5685\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.4044,\tval_loss: 4.4715\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.4203,\tval_loss: 4.4363\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.4572,\tval_loss: 4.3664\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.4221,\tval_loss: 4.5364\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.3248,\tval_loss: 4.5377\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.4012,\tval_loss: 4.5460\n",
            "65:\t[0s / 2s],\t\ttrain_loss: 3.4405,\tval_loss: 4.5098\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4657,\tval_loss: 4.4598\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4200,\tval_loss: 4.4678\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.4465,\tval_loss: 4.4806\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.4333,\tval_loss: 4.4895\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.4422,\tval_loss: 4.5071\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.3546,\tval_loss: 4.5213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3769,\tval_loss: 4.0722\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3056,\tval_loss: 4.0538\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2366,\tval_loss: 4.0668\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2378,\tval_loss: 4.0596\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2031,\tval_loss: 4.0782\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2017,\tval_loss: 4.0750\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1680,\tval_loss: 4.1006\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1414,\tval_loss: 4.1090\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1688,\tval_loss: 4.1037\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1294,\tval_loss: 4.0881\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1150,\tval_loss: 4.1055\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1125,\tval_loss: 4.1127\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0777,\tval_loss: 4.1462\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0053,\tval_loss: 4.1902\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9756,\tval_loss: 4.2688\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0202,\tval_loss: 4.1397\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0235,\tval_loss: 4.1538\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9328,\tval_loss: 4.2655\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9779,\tval_loss: 4.3696\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9639,\tval_loss: 4.2597\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8955,\tval_loss: 4.3085\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8743,\tval_loss: 4.2547\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9124,\tval_loss: 4.2770\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8332,\tval_loss: 4.3219\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7774,\tval_loss: 4.3449\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8073,\tval_loss: 4.4257\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8392,\tval_loss: 4.3665\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7554,\tval_loss: 4.4551\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7878,\tval_loss: 4.3766\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7453,\tval_loss: 4.4128\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7194,\tval_loss: 4.4370\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7794,\tval_loss: 4.3414\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7394,\tval_loss: 4.4529\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6572,\tval_loss: 4.4230\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6491,\tval_loss: 4.5039\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6486,\tval_loss: 4.5019\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7168,\tval_loss: 4.4037\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6470,\tval_loss: 4.4881\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6935,\tval_loss: 4.3729\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6558,\tval_loss: 4.4154\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6310,\tval_loss: 4.4117\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7559,\tval_loss: 4.4714\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7050,\tval_loss: 4.3311\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6589,\tval_loss: 4.4108\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6385,\tval_loss: 4.4203\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6618,\tval_loss: 4.4852\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5945,\tval_loss: 4.4040\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5727,\tval_loss: 4.4229\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5631,\tval_loss: 4.5179\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6211,\tval_loss: 4.4569\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5733,\tval_loss: 4.5978\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.5516,\tval_loss: 4.5398\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.5853,\tval_loss: 4.4373\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6182,\tval_loss: 4.5146\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.5792,\tval_loss: 4.4586\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6151,\tval_loss: 4.4817\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6036,\tval_loss: 4.4720\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5458,\tval_loss: 4.6060\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5547,\tval_loss: 4.4907\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5639,\tval_loss: 4.4988\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5102,\tval_loss: 4.5520\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5987,\tval_loss: 4.4891\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5548,\tval_loss: 4.5155\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5810,\tval_loss: 4.4354\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5598,\tval_loss: 4.5880\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5584,\tval_loss: 4.5226\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5061,\tval_loss: 4.5947\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.4953,\tval_loss: 4.6112\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.5031,\tval_loss: 4.5626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4150,\tval_loss: 4.1078\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3310,\tval_loss: 4.1074\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2729,\tval_loss: 4.0760\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2428,\tval_loss: 4.1040\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2597,\tval_loss: 4.0845\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2619,\tval_loss: 4.0767\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2017,\tval_loss: 4.0929\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2130,\tval_loss: 4.1186\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1807,\tval_loss: 4.1107\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1625,\tval_loss: 4.1167\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1773,\tval_loss: 4.1510\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1435,\tval_loss: 4.1257\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0471,\tval_loss: 4.1919\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 4.1305,\tval_loss: 4.1598\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0775,\tval_loss: 4.2047\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0925,\tval_loss: 4.2235\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 4.0671,\tval_loss: 4.2204\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9553,\tval_loss: 4.2105\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9466,\tval_loss: 4.2614\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 4.0052,\tval_loss: 4.2762\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9827,\tval_loss: 4.1741\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9778,\tval_loss: 4.3481\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9737,\tval_loss: 4.2132\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9545,\tval_loss: 4.2822\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9151,\tval_loss: 4.2898\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8870,\tval_loss: 4.2404\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8662,\tval_loss: 4.3597\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8631,\tval_loss: 4.2822\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 3.9238,\tval_loss: 4.2550\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.8474,\tval_loss: 4.2561\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.8558,\tval_loss: 4.3292\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.8259,\tval_loss: 4.4057\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.8059,\tval_loss: 4.2935\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.8002,\tval_loss: 4.3556\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7945,\tval_loss: 4.3781\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7834,\tval_loss: 4.3724\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7869,\tval_loss: 4.3099\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7261,\tval_loss: 4.4141\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7687,\tval_loss: 4.3138\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7521,\tval_loss: 4.4109\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7171,\tval_loss: 4.4032\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.8019,\tval_loss: 4.3312\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7067,\tval_loss: 4.3520\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7659,\tval_loss: 4.4148\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7260,\tval_loss: 4.3172\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7049,\tval_loss: 4.3465\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6921,\tval_loss: 4.4148\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6583,\tval_loss: 4.3690\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6023,\tval_loss: 4.4466\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6591,\tval_loss: 4.3799\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6779,\tval_loss: 4.4440\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.6523,\tval_loss: 4.4260\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6917,\tval_loss: 4.3671\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6513,\tval_loss: 4.3327\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6366,\tval_loss: 4.3742\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6111,\tval_loss: 4.3919\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6400,\tval_loss: 4.4107\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5956,\tval_loss: 4.4031\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5930,\tval_loss: 4.4510\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6472,\tval_loss: 4.2881\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5984,\tval_loss: 4.3543\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6727,\tval_loss: 4.3894\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6878,\tval_loss: 4.3122\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6445,\tval_loss: 4.3848\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5801,\tval_loss: 4.3996\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5466,\tval_loss: 4.4410\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5610,\tval_loss: 4.4350\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6826,\tval_loss: 4.4216\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6145,\tval_loss: 4.3190\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6194,\tval_loss: 4.4190\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4152,\tval_loss: 4.0447\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2736,\tval_loss: 4.0245\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2790,\tval_loss: 4.0582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2328,\tval_loss: 4.0699\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2177,\tval_loss: 4.0667\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1787,\tval_loss: 4.0937\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1570,\tval_loss: 4.0823\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1354,\tval_loss: 4.0802\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1432,\tval_loss: 4.0890\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0801,\tval_loss: 4.0896\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0997,\tval_loss: 4.1365\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0965,\tval_loss: 4.1335\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0874,\tval_loss: 4.1620\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9777,\tval_loss: 4.1141\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0292,\tval_loss: 4.1782\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9073,\tval_loss: 4.2034\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9442,\tval_loss: 4.2226\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9167,\tval_loss: 4.1662\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8927,\tval_loss: 4.2283\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8920,\tval_loss: 4.2090\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.9036,\tval_loss: 4.2384\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7479,\tval_loss: 4.2768\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8116,\tval_loss: 4.3356\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8935,\tval_loss: 4.2233\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8446,\tval_loss: 4.3211\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8254,\tval_loss: 4.2985\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7677,\tval_loss: 4.2689\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7575,\tval_loss: 4.3103\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7087,\tval_loss: 4.3073\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7279,\tval_loss: 4.3860\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7323,\tval_loss: 4.2987\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7458,\tval_loss: 4.3198\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6538,\tval_loss: 4.3615\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7688,\tval_loss: 4.3200\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7154,\tval_loss: 4.3619\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7089,\tval_loss: 4.3340\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6533,\tval_loss: 4.3452\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6317,\tval_loss: 4.4821\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6186,\tval_loss: 4.4471\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6273,\tval_loss: 4.3833\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6318,\tval_loss: 4.4242\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.5972,\tval_loss: 4.3848\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.5917,\tval_loss: 4.4374\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5937,\tval_loss: 4.4283\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5864,\tval_loss: 4.4823\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5777,\tval_loss: 4.4266\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5605,\tval_loss: 4.3835\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6169,\tval_loss: 4.3445\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5424,\tval_loss: 4.4262\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5899,\tval_loss: 4.3998\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5589,\tval_loss: 4.4428\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6847,\tval_loss: 4.4190\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5556,\tval_loss: 4.4356\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5947,\tval_loss: 4.4738\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5884,\tval_loss: 4.4029\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5337,\tval_loss: 4.4110\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5717,\tval_loss: 4.4558\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.4852,\tval_loss: 4.4535\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5549,\tval_loss: 4.4552\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5555,\tval_loss: 4.4124\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5752,\tval_loss: 4.4674\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.4832,\tval_loss: 4.4550\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.4908,\tval_loss: 4.4390\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5539,\tval_loss: 4.5154\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.5282,\tval_loss: 4.4675\n",
            "65:\t[0s / 2s],\t\ttrain_loss: 3.5782,\tval_loss: 4.4415\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5592,\tval_loss: 4.4034\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5627,\tval_loss: 4.3992\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.4350,\tval_loss: 4.4437\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4076,\tval_loss: 4.0870\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3604,\tval_loss: 4.0742\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3314,\tval_loss: 4.0605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.3078,\tval_loss: 4.0700\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.3054,\tval_loss: 4.0556\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2615,\tval_loss: 4.0647\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2762,\tval_loss: 4.0574\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2738,\tval_loss: 4.0410\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.2559,\tval_loss: 4.0709\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.2561,\tval_loss: 4.0505\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.2260,\tval_loss: 4.0298\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.2330,\tval_loss: 4.0291\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1852,\tval_loss: 4.0175\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.2101,\tval_loss: 4.0309\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.2165,\tval_loss: 4.0374\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.1813,\tval_loss: 4.0473\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.1611,\tval_loss: 4.0549\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.1512,\tval_loss: 4.0967\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.1393,\tval_loss: 4.0809\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 4.0650,\tval_loss: 4.0964\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 4.0561,\tval_loss: 4.1567\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 4.0799,\tval_loss: 4.2094\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 4.0823,\tval_loss: 4.1325\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 4.1027,\tval_loss: 4.1023\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 4.0876,\tval_loss: 4.1261\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9879,\tval_loss: 4.1900\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 4.0521,\tval_loss: 4.1129\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 4.0137,\tval_loss: 4.2442\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.9904,\tval_loss: 4.1663\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.9893,\tval_loss: 4.2485\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.9548,\tval_loss: 4.1736\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.9588,\tval_loss: 4.1931\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.9538,\tval_loss: 4.1503\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.9913,\tval_loss: 4.1725\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.9732,\tval_loss: 4.1460\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.9654,\tval_loss: 4.1597\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.8794,\tval_loss: 4.2140\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.9641,\tval_loss: 4.2228\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.9072,\tval_loss: 4.1929\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.9284,\tval_loss: 4.1826\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.8764,\tval_loss: 4.2059\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.8222,\tval_loss: 4.2224\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.8742,\tval_loss: 4.2337\n",
            "43:\t[0s / 1s],\t\ttrain_loss: 3.9657,\tval_loss: 4.1654\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.9022,\tval_loss: 4.1829\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.9287,\tval_loss: 4.1331\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.9226,\tval_loss: 4.1207\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.8716,\tval_loss: 4.1238\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.9060,\tval_loss: 4.1612\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.8784,\tval_loss: 4.2640\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.8425,\tval_loss: 4.1662\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.8560,\tval_loss: 4.1798\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.8953,\tval_loss: 4.4277\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.8917,\tval_loss: 4.1204\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.8725,\tval_loss: 4.2058\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.8034,\tval_loss: 4.1652\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.7580,\tval_loss: 4.2816\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.8756,\tval_loss: 4.1808\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.8602,\tval_loss: 4.1650\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.8590,\tval_loss: 4.1546\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.7711,\tval_loss: 4.1382\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.8617,\tval_loss: 4.2230\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.8413,\tval_loss: 4.1945\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.7718,\tval_loss: 4.2597\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.8089,\tval_loss: 4.2755\n",
            "65:\t[0s / 2s],\t\ttrain_loss: 3.8226,\tval_loss: 4.2116\n",
            "66:\t[0s / 2s],\t\ttrain_loss: 3.7743,\tval_loss: 4.2825\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.8014,\tval_loss: 4.2294\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.8044,\tval_loss: 4.2475\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.7588,\tval_loss: 4.3021\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.8243,\tval_loss: 4.3154\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.7715,\tval_loss: 4.3359\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.7271,\tval_loss: 4.2647\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.7290,\tval_loss: 4.4134\n",
            "74:\t[0s / 3s],\t\ttrain_loss: 3.7468,\tval_loss: 4.3519\n",
            "75:\t[0s / 3s],\t\ttrain_loss: 3.6812,\tval_loss: 4.3138\n",
            "76:\t[0s / 3s],\t\ttrain_loss: 3.6633,\tval_loss: 4.2985\n",
            "77:\t[0s / 3s],\t\ttrain_loss: 3.7299,\tval_loss: 4.2967\n",
            "78:\t[0s / 3s],\t\ttrain_loss: 3.7409,\tval_loss: 4.2468\n",
            "79:\t[0s / 3s],\t\ttrain_loss: 3.7566,\tval_loss: 4.2172\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4321,\tval_loss: 4.0370\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3236,\tval_loss: 4.0229\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2315,\tval_loss: 4.0127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2209,\tval_loss: 4.0188\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2191,\tval_loss: 4.0310\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2158,\tval_loss: 4.0482\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1823,\tval_loss: 4.0544\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1582,\tval_loss: 4.0535\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1632,\tval_loss: 4.0707\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1547,\tval_loss: 4.0680\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1386,\tval_loss: 4.0515\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1836,\tval_loss: 4.0650\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1148,\tval_loss: 4.0543\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0707,\tval_loss: 4.1115\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0472,\tval_loss: 4.1239\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0116,\tval_loss: 4.1429\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9801,\tval_loss: 4.1850\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9864,\tval_loss: 4.2262\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0048,\tval_loss: 4.1277\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9425,\tval_loss: 4.1774\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9161,\tval_loss: 4.2916\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9290,\tval_loss: 4.2224\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8146,\tval_loss: 4.2909\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8687,\tval_loss: 4.2989\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8447,\tval_loss: 4.2348\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8119,\tval_loss: 4.2520\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8301,\tval_loss: 4.2633\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8260,\tval_loss: 4.3817\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8932,\tval_loss: 4.1902\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8728,\tval_loss: 4.2478\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8345,\tval_loss: 4.2657\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7561,\tval_loss: 4.2859\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7480,\tval_loss: 4.3018\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7515,\tval_loss: 4.3424\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8146,\tval_loss: 4.3079\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7728,\tval_loss: 4.2781\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7410,\tval_loss: 4.3020\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7447,\tval_loss: 4.3724\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6967,\tval_loss: 4.2900\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7387,\tval_loss: 4.3471\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.8239,\tval_loss: 4.2125\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7320,\tval_loss: 4.3071\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7357,\tval_loss: 4.3322\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7296,\tval_loss: 4.2783\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7090,\tval_loss: 4.3251\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6518,\tval_loss: 4.3698\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7293,\tval_loss: 4.3217\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7628,\tval_loss: 4.2681\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6859,\tval_loss: 4.3373\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6644,\tval_loss: 4.3500\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6537,\tval_loss: 4.2922\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6191,\tval_loss: 4.3678\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6671,\tval_loss: 4.4150\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.7190,\tval_loss: 4.3139\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.7221,\tval_loss: 4.3556\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6412,\tval_loss: 4.3875\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6579,\tval_loss: 4.3120\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.7295,\tval_loss: 4.3483\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6761,\tval_loss: 4.2966\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6152,\tval_loss: 4.3573\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5946,\tval_loss: 4.3800\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6338,\tval_loss: 4.3609\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6246,\tval_loss: 4.3861\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6222,\tval_loss: 4.3988\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6402,\tval_loss: 4.3560\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6545,\tval_loss: 4.3317\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.5974,\tval_loss: 4.3868\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.5842,\tval_loss: 4.4320\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.6537,\tval_loss: 4.3483\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.6326,\tval_loss: 4.4382\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4274,\tval_loss: 4.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2798,\tval_loss: 4.0884\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2594,\tval_loss: 4.0791\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1756,\tval_loss: 4.1592\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1858,\tval_loss: 4.0976\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1525,\tval_loss: 4.1443\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1429,\tval_loss: 4.1307\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1514,\tval_loss: 4.1374\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1219,\tval_loss: 4.1317\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1613,\tval_loss: 4.1540\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1152,\tval_loss: 4.1465\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0744,\tval_loss: 4.1767\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0896,\tval_loss: 4.1310\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0842,\tval_loss: 4.1606\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.9922,\tval_loss: 4.1949\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0224,\tval_loss: 4.2235\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9807,\tval_loss: 4.1779\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 4.0278,\tval_loss: 4.2317\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9897,\tval_loss: 4.2282\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 4.0028,\tval_loss: 4.2812\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9468,\tval_loss: 4.2340\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8901,\tval_loss: 4.2777\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8407,\tval_loss: 4.3201\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8462,\tval_loss: 4.3541\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8430,\tval_loss: 4.3650\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8496,\tval_loss: 4.3845\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8207,\tval_loss: 4.3108\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8139,\tval_loss: 4.2802\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 3.7541,\tval_loss: 4.3812\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.7937,\tval_loss: 4.3791\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.8449,\tval_loss: 4.3123\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7675,\tval_loss: 4.4065\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7534,\tval_loss: 4.3497\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.7793,\tval_loss: 4.3583\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7219,\tval_loss: 4.3585\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7220,\tval_loss: 4.3982\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7338,\tval_loss: 4.3922\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7523,\tval_loss: 4.3649\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7197,\tval_loss: 4.3426\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6863,\tval_loss: 4.4124\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7005,\tval_loss: 4.3818\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6643,\tval_loss: 4.3620\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7168,\tval_loss: 4.4790\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6588,\tval_loss: 4.4802\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6500,\tval_loss: 4.4639\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6725,\tval_loss: 4.4073\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6899,\tval_loss: 4.5246\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6921,\tval_loss: 4.4074\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6466,\tval_loss: 4.5076\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6359,\tval_loss: 4.4173\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6222,\tval_loss: 4.4886\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.7348,\tval_loss: 4.3469\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6873,\tval_loss: 4.4622\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6167,\tval_loss: 4.4717\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6262,\tval_loss: 4.4406\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6413,\tval_loss: 4.6197\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5936,\tval_loss: 4.4898\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5353,\tval_loss: 4.5347\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5331,\tval_loss: 4.4776\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5996,\tval_loss: 4.5276\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6307,\tval_loss: 4.5151\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6042,\tval_loss: 4.5479\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5631,\tval_loss: 4.5218\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5154,\tval_loss: 4.6044\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6258,\tval_loss: 4.5169\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5922,\tval_loss: 4.5078\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6569,\tval_loss: 4.4699\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5956,\tval_loss: 4.4782\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4076,\tval_loss: 4.1322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2972,\tval_loss: 4.1257\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2489,\tval_loss: 4.1052\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2229,\tval_loss: 4.0825\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2614,\tval_loss: 4.0643\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2439,\tval_loss: 4.0652\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1546,\tval_loss: 4.0723\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2108,\tval_loss: 4.0646\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1925,\tval_loss: 4.0733\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1499,\tval_loss: 4.0715\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1072,\tval_loss: 4.1166\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1245,\tval_loss: 4.1085\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1106,\tval_loss: 4.0907\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0860,\tval_loss: 4.1063\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0667,\tval_loss: 4.1873\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0301,\tval_loss: 4.1410\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0389,\tval_loss: 4.1616\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9456,\tval_loss: 4.2052\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0344,\tval_loss: 4.2128\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9481,\tval_loss: 4.1982\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.9089,\tval_loss: 4.2389\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9118,\tval_loss: 4.2707\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9036,\tval_loss: 4.2917\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9036,\tval_loss: 4.3107\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8510,\tval_loss: 4.3774\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8158,\tval_loss: 4.3515\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7972,\tval_loss: 4.4193\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8183,\tval_loss: 4.4358\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8371,\tval_loss: 4.2946\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8442,\tval_loss: 4.3350\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7289,\tval_loss: 4.4404\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7676,\tval_loss: 4.3544\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7287,\tval_loss: 4.3767\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7210,\tval_loss: 4.4702\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7594,\tval_loss: 4.4261\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7371,\tval_loss: 4.3753\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7667,\tval_loss: 4.4748\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7001,\tval_loss: 4.3909\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7216,\tval_loss: 4.4508\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6468,\tval_loss: 4.4617\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6877,\tval_loss: 4.5117\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6620,\tval_loss: 4.4928\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.6833,\tval_loss: 4.4116\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6437,\tval_loss: 4.4358\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6360,\tval_loss: 4.4759\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6980,\tval_loss: 4.4709\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6832,\tval_loss: 4.4346\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6643,\tval_loss: 4.5280\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6449,\tval_loss: 4.4956\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7151,\tval_loss: 4.4347\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5554,\tval_loss: 4.5009\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5396,\tval_loss: 4.4982\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6430,\tval_loss: 4.5039\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6088,\tval_loss: 4.4222\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6726,\tval_loss: 4.5123\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.7095,\tval_loss: 4.3954\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6012,\tval_loss: 4.5142\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5503,\tval_loss: 4.4521\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5207,\tval_loss: 4.5211\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6644,\tval_loss: 4.4579\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6786,\tval_loss: 4.3941\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6216,\tval_loss: 4.4433\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6174,\tval_loss: 4.5040\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.6144,\tval_loss: 4.4268\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.5907,\tval_loss: 4.4613\n",
            "65:\t[0s / 2s],\t\ttrain_loss: 3.5948,\tval_loss: 4.4076\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5488,\tval_loss: 4.4928\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6417,\tval_loss: 4.5370\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5781,\tval_loss: 4.4605\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5822,\tval_loss: 4.4532\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5042,\tval_loss: 4.5377\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.5820,\tval_loss: 4.4794\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4174,\tval_loss: 4.0491\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3251,\tval_loss: 4.0500\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2768,\tval_loss: 4.0441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2608,\tval_loss: 4.0584\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2245,\tval_loss: 4.0855\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2165,\tval_loss: 4.1074\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1947,\tval_loss: 4.0886\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1842,\tval_loss: 4.0926\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1871,\tval_loss: 4.1264\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1679,\tval_loss: 4.1154\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1309,\tval_loss: 4.1026\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0882,\tval_loss: 4.1837\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1049,\tval_loss: 4.1396\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0984,\tval_loss: 4.1239\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0566,\tval_loss: 4.2070\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0582,\tval_loss: 4.1662\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0903,\tval_loss: 4.1612\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0102,\tval_loss: 4.1941\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0103,\tval_loss: 4.1848\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9993,\tval_loss: 4.2105\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.9717,\tval_loss: 4.2161\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9720,\tval_loss: 4.2317\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9538,\tval_loss: 4.2538\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9495,\tval_loss: 4.2703\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9140,\tval_loss: 4.3106\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9524,\tval_loss: 4.2173\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8853,\tval_loss: 4.2538\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8820,\tval_loss: 4.3346\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8327,\tval_loss: 4.2900\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8566,\tval_loss: 4.2887\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8197,\tval_loss: 4.3341\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8548,\tval_loss: 4.2041\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.9083,\tval_loss: 4.2806\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8222,\tval_loss: 4.2860\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7971,\tval_loss: 4.2583\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7914,\tval_loss: 4.2834\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7969,\tval_loss: 4.3426\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7734,\tval_loss: 4.2952\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.8049,\tval_loss: 4.3685\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7847,\tval_loss: 4.2747\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7857,\tval_loss: 4.3402\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7841,\tval_loss: 4.3701\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.7579,\tval_loss: 4.3861\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7230,\tval_loss: 4.3333\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7769,\tval_loss: 4.3468\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7763,\tval_loss: 4.3595\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7564,\tval_loss: 4.3370\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7199,\tval_loss: 4.3881\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7380,\tval_loss: 4.2845\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7461,\tval_loss: 4.4303\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7241,\tval_loss: 4.3689\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7463,\tval_loss: 4.3343\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7172,\tval_loss: 4.3479\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7379,\tval_loss: 4.4095\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7557,\tval_loss: 4.3688\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.7566,\tval_loss: 4.3689\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6827,\tval_loss: 4.4522\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.7612,\tval_loss: 4.4652\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6770,\tval_loss: 4.4515\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6663,\tval_loss: 4.4448\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6814,\tval_loss: 4.4470\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6913,\tval_loss: 4.4553\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6889,\tval_loss: 4.3813\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.7086,\tval_loss: 4.3594\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.6603,\tval_loss: 4.4907\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6809,\tval_loss: 4.4970\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6458,\tval_loss: 4.4256\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6529,\tval_loss: 4.4489\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6456,\tval_loss: 4.4467\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.7124,\tval_loss: 4.4657\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4517,\tval_loss: 4.0510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3062,\tval_loss: 4.0394\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2948,\tval_loss: 4.0322\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2183,\tval_loss: 4.0297\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2209,\tval_loss: 4.0342\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2251,\tval_loss: 4.0297\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2142,\tval_loss: 4.0415\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1666,\tval_loss: 4.0568\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1931,\tval_loss: 4.0737\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1293,\tval_loss: 4.0980\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1059,\tval_loss: 4.0895\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1398,\tval_loss: 4.0982\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0837,\tval_loss: 4.1486\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1084,\tval_loss: 4.1403\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0658,\tval_loss: 4.2271\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0112,\tval_loss: 4.2238\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9585,\tval_loss: 4.2615\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9715,\tval_loss: 4.2957\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9612,\tval_loss: 4.2627\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9392,\tval_loss: 4.2623\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9125,\tval_loss: 4.2423\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9268,\tval_loss: 4.2269\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9138,\tval_loss: 4.2358\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8954,\tval_loss: 4.3541\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8670,\tval_loss: 4.3037\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8636,\tval_loss: 4.2748\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8859,\tval_loss: 4.2531\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9110,\tval_loss: 4.2774\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7957,\tval_loss: 4.3240\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8158,\tval_loss: 4.4272\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8270,\tval_loss: 4.2871\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7851,\tval_loss: 4.4297\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7722,\tval_loss: 4.3115\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7694,\tval_loss: 4.4249\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7912,\tval_loss: 4.3530\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7799,\tval_loss: 4.3867\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7891,\tval_loss: 4.3684\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7435,\tval_loss: 4.4124\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7735,\tval_loss: 4.4372\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7354,\tval_loss: 4.4019\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7645,\tval_loss: 4.3724\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7400,\tval_loss: 4.3926\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7189,\tval_loss: 4.3845\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7519,\tval_loss: 4.4090\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7755,\tval_loss: 4.4197\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7750,\tval_loss: 4.3489\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7121,\tval_loss: 4.3960\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7278,\tval_loss: 4.3774\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7387,\tval_loss: 4.3517\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6842,\tval_loss: 4.4108\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7229,\tval_loss: 4.3873\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7001,\tval_loss: 4.4479\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6620,\tval_loss: 4.4464\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7390,\tval_loss: 4.4549\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6441,\tval_loss: 4.4661\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.7367,\tval_loss: 4.4929\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.7031,\tval_loss: 4.4373\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6900,\tval_loss: 4.3995\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6210,\tval_loss: 4.4572\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6949,\tval_loss: 4.3748\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6830,\tval_loss: 4.4553\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6958,\tval_loss: 4.3729\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6470,\tval_loss: 4.4309\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6612,\tval_loss: 4.4348\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6653,\tval_loss: 4.4670\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5622,\tval_loss: 4.4341\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5476,\tval_loss: 4.4872\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5581,\tval_loss: 4.5284\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5591,\tval_loss: 4.5254\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5785,\tval_loss: 4.5085\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6241,\tval_loss: 4.5231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4337,\tval_loss: 4.0624\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2771,\tval_loss: 4.0453\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2202,\tval_loss: 4.0515\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2086,\tval_loss: 4.0363\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1966,\tval_loss: 4.0355\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1466,\tval_loss: 4.0435\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1669,\tval_loss: 4.0380\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1341,\tval_loss: 4.0380\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1513,\tval_loss: 4.0466\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0905,\tval_loss: 4.0429\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1055,\tval_loss: 4.0271\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1099,\tval_loss: 4.0162\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0798,\tval_loss: 4.0214\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0518,\tval_loss: 4.0436\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0673,\tval_loss: 4.0320\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9922,\tval_loss: 4.1001\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 4.0589,\tval_loss: 4.0501\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9948,\tval_loss: 4.0315\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 4.0253,\tval_loss: 4.0546\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9976,\tval_loss: 4.0694\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9983,\tval_loss: 4.0369\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9823,\tval_loss: 4.0432\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9871,\tval_loss: 4.0483\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9327,\tval_loss: 4.0774\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9335,\tval_loss: 4.0878\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9306,\tval_loss: 4.0850\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8879,\tval_loss: 4.0794\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8808,\tval_loss: 4.1402\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8522,\tval_loss: 4.1341\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8966,\tval_loss: 4.1282\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.8145,\tval_loss: 4.0831\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.8795,\tval_loss: 4.1369\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.8163,\tval_loss: 4.1263\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.9015,\tval_loss: 4.1222\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.8751,\tval_loss: 4.0996\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.8275,\tval_loss: 4.0907\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.8753,\tval_loss: 4.0740\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.8584,\tval_loss: 4.1034\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7748,\tval_loss: 4.1184\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7963,\tval_loss: 4.0755\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.8042,\tval_loss: 4.1021\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7335,\tval_loss: 4.1113\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7445,\tval_loss: 4.1418\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6975,\tval_loss: 4.0939\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.6958,\tval_loss: 4.0753\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.7699,\tval_loss: 4.1111\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.7628,\tval_loss: 4.0838\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.7584,\tval_loss: 4.1359\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.7324,\tval_loss: 4.0930\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6967,\tval_loss: 4.1356\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.7071,\tval_loss: 4.1285\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.7482,\tval_loss: 4.0650\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6976,\tval_loss: 4.0643\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.7034,\tval_loss: 4.1173\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.7390,\tval_loss: 4.1524\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.7374,\tval_loss: 4.0835\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.7334,\tval_loss: 4.0934\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6594,\tval_loss: 4.0598\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6459,\tval_loss: 4.0745\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5919,\tval_loss: 4.1544\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6959,\tval_loss: 4.1100\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6818,\tval_loss: 4.0989\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6938,\tval_loss: 4.0310\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6254,\tval_loss: 4.0853\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6158,\tval_loss: 4.0989\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6284,\tval_loss: 4.1133\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6364,\tval_loss: 4.0741\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.7162,\tval_loss: 4.0578\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.6961,\tval_loss: 4.0828\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.6527,\tval_loss: 4.1210\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.5806,\tval_loss: 4.0892\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.5965,\tval_loss: 4.0845\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.5673,\tval_loss: 4.1511\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.5690,\tval_loss: 4.1110\n",
            "74:\t[0s / 4s],\t\ttrain_loss: 3.5964,\tval_loss: 4.1017\n",
            "75:\t[0s / 4s],\t\ttrain_loss: 3.5596,\tval_loss: 4.1686\n",
            "76:\t[0s / 4s],\t\ttrain_loss: 3.4937,\tval_loss: 4.1148\n",
            "77:\t[0s / 4s],\t\ttrain_loss: 3.6157,\tval_loss: 4.1186\n",
            "78:\t[0s / 4s],\t\ttrain_loss: 3.5632,\tval_loss: 4.1678\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4492,\tval_loss: 4.0801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3237,\tval_loss: 4.0565\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2904,\tval_loss: 4.0591\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2924,\tval_loss: 4.0550\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2640,\tval_loss: 4.0499\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2262,\tval_loss: 4.0534\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1918,\tval_loss: 4.0618\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1621,\tval_loss: 4.0772\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1353,\tval_loss: 4.0911\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1116,\tval_loss: 4.0852\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0318,\tval_loss: 4.1334\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0842,\tval_loss: 4.1369\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9870,\tval_loss: 4.1864\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9496,\tval_loss: 4.1524\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9488,\tval_loss: 4.2039\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9813,\tval_loss: 4.1647\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8975,\tval_loss: 4.2077\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8550,\tval_loss: 4.1914\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8772,\tval_loss: 4.2204\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8357,\tval_loss: 4.2399\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.7256,\tval_loss: 4.3093\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8008,\tval_loss: 4.2351\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7553,\tval_loss: 4.3469\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.6487,\tval_loss: 4.3478\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7795,\tval_loss: 4.2209\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7523,\tval_loss: 4.2869\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6861,\tval_loss: 4.2797\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7219,\tval_loss: 4.4235\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6831,\tval_loss: 4.3110\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7514,\tval_loss: 4.2413\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7289,\tval_loss: 4.2519\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7027,\tval_loss: 4.2245\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6975,\tval_loss: 4.3827\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.5782,\tval_loss: 4.4245\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7078,\tval_loss: 4.3984\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6469,\tval_loss: 4.3926\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6567,\tval_loss: 4.3612\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6674,\tval_loss: 4.3572\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6383,\tval_loss: 4.3853\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6816,\tval_loss: 4.3420\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6457,\tval_loss: 4.3200\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6652,\tval_loss: 4.3871\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.5776,\tval_loss: 4.3639\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6024,\tval_loss: 4.3913\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6301,\tval_loss: 4.2513\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5743,\tval_loss: 4.3843\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5618,\tval_loss: 4.4439\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5503,\tval_loss: 4.4920\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6079,\tval_loss: 4.4809\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6519,\tval_loss: 4.3725\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6434,\tval_loss: 4.2999\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6604,\tval_loss: 4.4477\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5613,\tval_loss: 4.4081\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5868,\tval_loss: 4.4082\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5197,\tval_loss: 4.3847\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5265,\tval_loss: 4.4262\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6174,\tval_loss: 4.3833\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5566,\tval_loss: 4.4037\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5277,\tval_loss: 4.4461\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5176,\tval_loss: 4.4413\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5328,\tval_loss: 4.4493\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5649,\tval_loss: 4.4226\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5401,\tval_loss: 4.4487\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.4542,\tval_loss: 4.5924\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.4668,\tval_loss: 4.4902\n",
            "65:\t[0s / 2s],\t\ttrain_loss: 3.4618,\tval_loss: 4.3788\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5324,\tval_loss: 4.5164\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5130,\tval_loss: 4.3485\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5069,\tval_loss: 4.3740\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.4798,\tval_loss: 4.5125\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5102,\tval_loss: 4.4857\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.4779,\tval_loss: 4.4613\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4199,\tval_loss: 4.1004\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2665,\tval_loss: 4.1226\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2222,\tval_loss: 4.1165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1873,\tval_loss: 4.1306\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1890,\tval_loss: 4.1328\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1680,\tval_loss: 4.1145\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1587,\tval_loss: 4.1172\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1628,\tval_loss: 4.1159\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1717,\tval_loss: 4.1156\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1310,\tval_loss: 4.1452\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1081,\tval_loss: 4.1686\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1276,\tval_loss: 4.1437\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1098,\tval_loss: 4.1175\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0884,\tval_loss: 4.1679\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0751,\tval_loss: 4.1486\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9915,\tval_loss: 4.1488\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9804,\tval_loss: 4.1419\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0115,\tval_loss: 4.1580\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9777,\tval_loss: 4.1377\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9470,\tval_loss: 4.1865\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.9799,\tval_loss: 4.1136\n",
            "21:\t[0s / 0s],\t\ttrain_loss: 3.9740,\tval_loss: 4.1942\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9108,\tval_loss: 4.2011\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9294,\tval_loss: 4.1294\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8731,\tval_loss: 4.2083\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8762,\tval_loss: 4.1749\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8538,\tval_loss: 4.1964\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9131,\tval_loss: 4.2141\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8356,\tval_loss: 4.1858\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8692,\tval_loss: 4.1447\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8514,\tval_loss: 4.2260\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8700,\tval_loss: 4.2097\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8383,\tval_loss: 4.2175\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8200,\tval_loss: 4.2770\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8085,\tval_loss: 4.1805\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7304,\tval_loss: 4.2959\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.8532,\tval_loss: 4.1562\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7378,\tval_loss: 4.2159\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7872,\tval_loss: 4.2443\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7346,\tval_loss: 4.2187\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7069,\tval_loss: 4.2419\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6978,\tval_loss: 4.2595\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.7735,\tval_loss: 4.1636\n",
            "43:\t[0s / 1s],\t\ttrain_loss: 3.7063,\tval_loss: 4.2574\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6972,\tval_loss: 4.1786\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7164,\tval_loss: 4.2050\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7714,\tval_loss: 4.2516\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7067,\tval_loss: 4.2059\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7304,\tval_loss: 4.2643\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7440,\tval_loss: 4.2325\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7246,\tval_loss: 4.2207\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7178,\tval_loss: 4.1876\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6861,\tval_loss: 4.1776\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7448,\tval_loss: 4.1776\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6229,\tval_loss: 4.2608\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.7344,\tval_loss: 4.2673\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6951,\tval_loss: 4.1972\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6236,\tval_loss: 4.2737\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6864,\tval_loss: 4.2038\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6530,\tval_loss: 4.1884\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6542,\tval_loss: 4.2372\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6403,\tval_loss: 4.2528\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6437,\tval_loss: 4.1767\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5776,\tval_loss: 4.2134\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.5624,\tval_loss: 4.2301\n",
            "65:\t[0s / 2s],\t\ttrain_loss: 3.6048,\tval_loss: 4.2477\n",
            "66:\t[0s / 2s],\t\ttrain_loss: 3.6633,\tval_loss: 4.2193\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6655,\tval_loss: 4.2058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3963,\tval_loss: 4.1029\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3213,\tval_loss: 4.0976\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2540,\tval_loss: 4.0943\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2503,\tval_loss: 4.1151\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2340,\tval_loss: 4.1235\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2371,\tval_loss: 4.1359\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1882,\tval_loss: 4.1358\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1947,\tval_loss: 4.1438\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1884,\tval_loss: 4.1561\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1265,\tval_loss: 4.1328\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1343,\tval_loss: 4.1699\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1124,\tval_loss: 4.1845\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0191,\tval_loss: 4.2685\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0946,\tval_loss: 4.2465\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0091,\tval_loss: 4.2170\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9993,\tval_loss: 4.2692\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9589,\tval_loss: 4.2803\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 4.0072,\tval_loss: 4.2984\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9236,\tval_loss: 4.2907\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9100,\tval_loss: 4.3183\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9247,\tval_loss: 4.3051\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8770,\tval_loss: 4.3177\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8679,\tval_loss: 4.4216\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8805,\tval_loss: 4.4188\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8812,\tval_loss: 4.3612\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8712,\tval_loss: 4.3881\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8487,\tval_loss: 4.3709\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9084,\tval_loss: 4.5289\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7953,\tval_loss: 4.3473\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7549,\tval_loss: 4.4196\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7379,\tval_loss: 4.5571\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8873,\tval_loss: 4.3784\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7736,\tval_loss: 4.4564\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8690,\tval_loss: 4.4082\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6504,\tval_loss: 4.5067\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6737,\tval_loss: 4.5178\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7068,\tval_loss: 4.5581\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7044,\tval_loss: 4.5113\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7885,\tval_loss: 4.4626\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6855,\tval_loss: 4.5913\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6952,\tval_loss: 4.4955\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6713,\tval_loss: 4.5145\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7031,\tval_loss: 4.5784\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5943,\tval_loss: 4.5832\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6066,\tval_loss: 4.6567\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6639,\tval_loss: 4.6147\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6418,\tval_loss: 4.5277\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6805,\tval_loss: 4.5855\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6800,\tval_loss: 4.5161\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.5862,\tval_loss: 4.5475\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6120,\tval_loss: 4.6277\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.6188,\tval_loss: 4.7033\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.5510,\tval_loss: 4.6175\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.5937,\tval_loss: 4.7188\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.5632,\tval_loss: 4.6922\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.5550,\tval_loss: 4.5670\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6101,\tval_loss: 4.6122\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5201,\tval_loss: 4.6501\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5185,\tval_loss: 4.6459\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5684,\tval_loss: 4.7293\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5643,\tval_loss: 4.5714\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.4481,\tval_loss: 4.6929\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.5992,\tval_loss: 4.6908\n",
            "63:\t[0s / 5s],\t\ttrain_loss: 3.4735,\tval_loss: 4.7272\n",
            "64:\t[0s / 5s],\t\ttrain_loss: 3.5902,\tval_loss: 4.7118\n",
            "65:\t[0s / 5s],\t\ttrain_loss: 3.6226,\tval_loss: 4.5319\n",
            "66:\t[0s / 5s],\t\ttrain_loss: 3.6235,\tval_loss: 4.5670\n",
            "67:\t[0s / 6s],\t\ttrain_loss: 3.6167,\tval_loss: 4.6550\n",
            "68:\t[0s / 6s],\t\ttrain_loss: 3.4836,\tval_loss: 4.6407\n",
            "69:\t[0s / 6s],\t\ttrain_loss: 3.5565,\tval_loss: 4.6180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4935,\tval_loss: 4.1064\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2699,\tval_loss: 4.0833\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2385,\tval_loss: 4.0788\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1833,\tval_loss: 4.0499\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1689,\tval_loss: 4.0520\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1466,\tval_loss: 4.0620\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1475,\tval_loss: 4.0487\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1074,\tval_loss: 4.0492\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1083,\tval_loss: 4.0680\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0860,\tval_loss: 4.0506\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0659,\tval_loss: 4.0771\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 4.0541,\tval_loss: 4.1139\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 3.9885,\tval_loss: 4.0658\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 3.9855,\tval_loss: 4.1191\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0235,\tval_loss: 4.1380\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0100,\tval_loss: 4.1064\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9951,\tval_loss: 4.1581\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9759,\tval_loss: 4.1367\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9401,\tval_loss: 4.1804\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9016,\tval_loss: 4.1539\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9193,\tval_loss: 4.2129\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8370,\tval_loss: 4.1662\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9072,\tval_loss: 4.1903\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7773,\tval_loss: 4.3015\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 3.8050,\tval_loss: 4.2960\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 3.7879,\tval_loss: 4.2182\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 3.8060,\tval_loss: 4.2973\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 3.7376,\tval_loss: 4.2843\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 3.7370,\tval_loss: 4.3856\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.7256,\tval_loss: 4.3320\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.6964,\tval_loss: 4.2922\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7525,\tval_loss: 4.3890\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7704,\tval_loss: 4.2906\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.7054,\tval_loss: 4.3249\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.6935,\tval_loss: 4.3101\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7062,\tval_loss: 4.3533\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.6430,\tval_loss: 4.3840\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 3.6559,\tval_loss: 4.3607\n",
            "38:\t[0s / 3s],\t\ttrain_loss: 3.6371,\tval_loss: 4.3702\n",
            "39:\t[0s / 3s],\t\ttrain_loss: 3.6428,\tval_loss: 4.3554\n",
            "40:\t[0s / 3s],\t\ttrain_loss: 3.5990,\tval_loss: 4.3333\n",
            "41:\t[0s / 3s],\t\ttrain_loss: 3.5725,\tval_loss: 4.3136\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 3.5902,\tval_loss: 4.3468\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 3.5798,\tval_loss: 4.3682\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.5671,\tval_loss: 4.4009\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.6226,\tval_loss: 4.4264\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.5714,\tval_loss: 4.4165\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.5478,\tval_loss: 4.3925\n",
            "48:\t[0s / 4s],\t\ttrain_loss: 3.6177,\tval_loss: 4.3577\n",
            "49:\t[0s / 4s],\t\ttrain_loss: 3.5848,\tval_loss: 4.3790\n",
            "50:\t[0s / 4s],\t\ttrain_loss: 3.5151,\tval_loss: 4.4077\n",
            "51:\t[0s / 4s],\t\ttrain_loss: 3.4908,\tval_loss: 4.4145\n",
            "52:\t[0s / 4s],\t\ttrain_loss: 3.4804,\tval_loss: 4.3641\n",
            "53:\t[0s / 4s],\t\ttrain_loss: 3.5673,\tval_loss: 4.3719\n",
            "54:\t[0s / 4s],\t\ttrain_loss: 3.5219,\tval_loss: 4.3751\n",
            "55:\t[0s / 4s],\t\ttrain_loss: 3.5112,\tval_loss: 4.5566\n",
            "56:\t[0s / 4s],\t\ttrain_loss: 3.5158,\tval_loss: 4.4512\n",
            "57:\t[0s / 4s],\t\ttrain_loss: 3.5515,\tval_loss: 4.4611\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 3.5498,\tval_loss: 4.3194\n",
            "59:\t[0s / 5s],\t\ttrain_loss: 3.5930,\tval_loss: 4.4547\n",
            "60:\t[0s / 5s],\t\ttrain_loss: 3.5563,\tval_loss: 4.3587\n",
            "61:\t[0s / 5s],\t\ttrain_loss: 3.5533,\tval_loss: 4.3843\n",
            "62:\t[0s / 5s],\t\ttrain_loss: 3.5491,\tval_loss: 4.3818\n",
            "63:\t[0s / 5s],\t\ttrain_loss: 3.4802,\tval_loss: 4.4016\n",
            "64:\t[0s / 5s],\t\ttrain_loss: 3.4621,\tval_loss: 4.4936\n",
            "65:\t[0s / 5s],\t\ttrain_loss: 3.5041,\tval_loss: 4.3857\n",
            "66:\t[0s / 5s],\t\ttrain_loss: 3.4778,\tval_loss: 4.5576\n",
            "67:\t[0s / 5s],\t\ttrain_loss: 3.4825,\tval_loss: 4.4218\n",
            "68:\t[0s / 5s],\t\ttrain_loss: 3.4294,\tval_loss: 4.5560\n",
            "69:\t[0s / 5s],\t\ttrain_loss: 3.5517,\tval_loss: 4.4470\n",
            "70:\t[0s / 5s],\t\ttrain_loss: 3.4546,\tval_loss: 4.7649\n",
            "71:\t[0s / 5s],\t\ttrain_loss: 3.4105,\tval_loss: 4.5446\n",
            "72:\t[0s / 5s],\t\ttrain_loss: 3.4658,\tval_loss: 4.6203\n",
            "73:\t[0s / 5s],\t\ttrain_loss: 3.4824,\tval_loss: 4.5174\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3534,\tval_loss: 4.0500\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2494,\tval_loss: 4.0515\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2205,\tval_loss: 4.0564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1618,\tval_loss: 4.0403\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1629,\tval_loss: 4.0512\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1312,\tval_loss: 4.0418\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1305,\tval_loss: 4.0543\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1077,\tval_loss: 4.0326\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0960,\tval_loss: 4.0418\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0494,\tval_loss: 4.0841\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0072,\tval_loss: 4.0852\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9937,\tval_loss: 4.1128\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9566,\tval_loss: 4.1288\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0035,\tval_loss: 4.1037\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9373,\tval_loss: 4.1515\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9379,\tval_loss: 4.1213\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8819,\tval_loss: 4.1908\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8075,\tval_loss: 4.1649\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8368,\tval_loss: 4.1620\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.7832,\tval_loss: 4.1531\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.8863,\tval_loss: 4.1314\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8091,\tval_loss: 4.1840\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7954,\tval_loss: 4.2506\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7645,\tval_loss: 4.2934\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7714,\tval_loss: 4.2611\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7902,\tval_loss: 4.2415\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7515,\tval_loss: 4.3044\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7956,\tval_loss: 4.1992\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7512,\tval_loss: 4.3083\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7358,\tval_loss: 4.3083\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7600,\tval_loss: 4.2913\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7289,\tval_loss: 4.3389\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7461,\tval_loss: 4.2503\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7195,\tval_loss: 4.3360\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7075,\tval_loss: 4.3277\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6387,\tval_loss: 4.3470\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.5585,\tval_loss: 4.3616\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7264,\tval_loss: 4.3513\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6146,\tval_loss: 4.3537\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6041,\tval_loss: 4.3914\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.4888,\tval_loss: 4.3958\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6021,\tval_loss: 4.3953\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.5796,\tval_loss: 4.3886\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5515,\tval_loss: 4.3850\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6130,\tval_loss: 4.3464\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6248,\tval_loss: 4.3238\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5719,\tval_loss: 4.3204\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5389,\tval_loss: 4.3867\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6558,\tval_loss: 4.3274\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6569,\tval_loss: 4.3304\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6224,\tval_loss: 4.3402\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6404,\tval_loss: 4.3915\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5571,\tval_loss: 4.3906\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5516,\tval_loss: 4.3313\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6246,\tval_loss: 4.3545\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5768,\tval_loss: 4.3417\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5128,\tval_loss: 4.3720\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5757,\tval_loss: 4.3680\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5654,\tval_loss: 4.3593\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5509,\tval_loss: 4.4465\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5741,\tval_loss: 4.4066\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5643,\tval_loss: 4.3497\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5455,\tval_loss: 4.4331\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.6308,\tval_loss: 4.3757\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6416,\tval_loss: 4.2580\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5864,\tval_loss: 4.3715\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5625,\tval_loss: 4.2896\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6026,\tval_loss: 4.3320\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5618,\tval_loss: 4.3924\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.4875,\tval_loss: 4.4127\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5617,\tval_loss: 4.3839\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.5542,\tval_loss: 4.4025\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.5666,\tval_loss: 4.3462\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.5919,\tval_loss: 4.4764\n",
            "74:\t[0s / 3s],\t\ttrain_loss: 3.5298,\tval_loss: 4.4644\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3201,\tval_loss: 4.0967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2490,\tval_loss: 4.0929\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2419,\tval_loss: 4.0893\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1691,\tval_loss: 4.0801\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1614,\tval_loss: 4.1074\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1576,\tval_loss: 4.1046\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1784,\tval_loss: 4.1008\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1431,\tval_loss: 4.1073\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1546,\tval_loss: 4.1185\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1311,\tval_loss: 4.1260\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0937,\tval_loss: 4.1405\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0934,\tval_loss: 4.1455\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0588,\tval_loss: 4.1852\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0132,\tval_loss: 4.1762\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9882,\tval_loss: 4.1558\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9890,\tval_loss: 4.2432\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0138,\tval_loss: 4.1716\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9185,\tval_loss: 4.2687\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9406,\tval_loss: 4.2229\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9162,\tval_loss: 4.2352\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9001,\tval_loss: 4.2100\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9164,\tval_loss: 4.2630\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8617,\tval_loss: 4.1897\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8533,\tval_loss: 4.2868\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8622,\tval_loss: 4.2587\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8399,\tval_loss: 4.2878\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8734,\tval_loss: 4.2859\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8253,\tval_loss: 4.2652\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8430,\tval_loss: 4.2628\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8451,\tval_loss: 4.3198\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8327,\tval_loss: 4.3508\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7937,\tval_loss: 4.3154\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7807,\tval_loss: 4.2663\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7909,\tval_loss: 4.3019\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8214,\tval_loss: 4.3038\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7185,\tval_loss: 4.3056\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7963,\tval_loss: 4.2969\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.8665,\tval_loss: 4.3138\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7762,\tval_loss: 4.3459\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7923,\tval_loss: 4.3100\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7420,\tval_loss: 4.3297\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7940,\tval_loss: 4.3356\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7072,\tval_loss: 4.3131\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7107,\tval_loss: 4.4275\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7453,\tval_loss: 4.3107\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7442,\tval_loss: 4.3352\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7128,\tval_loss: 4.2867\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6857,\tval_loss: 4.3440\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7352,\tval_loss: 4.4023\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7536,\tval_loss: 4.3469\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7164,\tval_loss: 4.3443\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6987,\tval_loss: 4.4177\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7442,\tval_loss: 4.3700\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7208,\tval_loss: 4.3598\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7287,\tval_loss: 4.4065\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6902,\tval_loss: 4.4290\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6602,\tval_loss: 4.4283\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6261,\tval_loss: 4.4032\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6712,\tval_loss: 4.4199\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6749,\tval_loss: 4.3924\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6209,\tval_loss: 4.4594\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6148,\tval_loss: 4.4051\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6772,\tval_loss: 4.4896\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.6570,\tval_loss: 4.4859\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5987,\tval_loss: 4.4240\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6258,\tval_loss: 4.4871\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6348,\tval_loss: 4.3692\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6179,\tval_loss: 4.4391\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6909,\tval_loss: 4.3979\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6668,\tval_loss: 4.4142\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6233,\tval_loss: 4.3916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3806,\tval_loss: 4.0932\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2754,\tval_loss: 4.0757\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2132,\tval_loss: 4.0629\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1922,\tval_loss: 4.0670\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1780,\tval_loss: 4.0780\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1716,\tval_loss: 4.0707\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1713,\tval_loss: 4.0656\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1674,\tval_loss: 4.0649\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1610,\tval_loss: 4.0652\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1515,\tval_loss: 4.0655\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1228,\tval_loss: 4.0642\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1032,\tval_loss: 4.0857\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1448,\tval_loss: 4.0849\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1021,\tval_loss: 4.0919\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.1082,\tval_loss: 4.0834\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0692,\tval_loss: 4.0851\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0320,\tval_loss: 4.0994\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0455,\tval_loss: 4.1150\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9786,\tval_loss: 4.1843\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 4.0240,\tval_loss: 4.1490\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 4.0045,\tval_loss: 4.1331\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9924,\tval_loss: 4.1269\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9272,\tval_loss: 4.1977\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9660,\tval_loss: 4.2098\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9519,\tval_loss: 4.1503\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9857,\tval_loss: 4.2228\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9367,\tval_loss: 4.1650\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8976,\tval_loss: 4.1923\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8834,\tval_loss: 4.2247\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8571,\tval_loss: 4.2258\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8544,\tval_loss: 4.2069\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8222,\tval_loss: 4.2776\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8424,\tval_loss: 4.2937\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8835,\tval_loss: 4.2156\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8623,\tval_loss: 4.1917\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8399,\tval_loss: 4.2463\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.8695,\tval_loss: 4.2324\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7753,\tval_loss: 4.2539\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7817,\tval_loss: 4.2787\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7495,\tval_loss: 4.2660\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7913,\tval_loss: 4.2255\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.8608,\tval_loss: 4.2383\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7932,\tval_loss: 4.2753\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7634,\tval_loss: 4.2986\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.8242,\tval_loss: 4.2364\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7939,\tval_loss: 4.3174\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7769,\tval_loss: 4.3073\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7565,\tval_loss: 4.3454\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7669,\tval_loss: 4.4051\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7882,\tval_loss: 4.2167\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.8447,\tval_loss: 4.2616\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7261,\tval_loss: 4.3607\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7582,\tval_loss: 4.2782\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7529,\tval_loss: 4.2529\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7224,\tval_loss: 4.4234\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.7669,\tval_loss: 4.3136\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.7674,\tval_loss: 4.3311\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.7941,\tval_loss: 4.2748\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6791,\tval_loss: 4.3204\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.7601,\tval_loss: 4.3037\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6996,\tval_loss: 4.3819\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.7964,\tval_loss: 4.2370\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6840,\tval_loss: 4.3954\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.7052,\tval_loss: 4.4639\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.7254,\tval_loss: 4.3006\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6736,\tval_loss: 4.2850\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.7194,\tval_loss: 4.3438\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6681,\tval_loss: 4.3882\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6537,\tval_loss: 4.3225\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.6667,\tval_loss: 4.3025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4659,\tval_loss: 4.0238\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3364,\tval_loss: 4.0100\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2897,\tval_loss: 4.0123\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2600,\tval_loss: 4.0146\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2463,\tval_loss: 4.0124\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2398,\tval_loss: 4.0199\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2324,\tval_loss: 4.0108\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2100,\tval_loss: 4.0151\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1731,\tval_loss: 4.0080\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1324,\tval_loss: 3.9914\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1171,\tval_loss: 4.0275\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1567,\tval_loss: 4.0236\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1144,\tval_loss: 4.0519\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1092,\tval_loss: 4.0451\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.1185,\tval_loss: 4.0575\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0597,\tval_loss: 4.0691\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 4.0082,\tval_loss: 4.1033\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9799,\tval_loss: 4.0822\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9869,\tval_loss: 4.1021\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9741,\tval_loss: 4.1004\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9281,\tval_loss: 4.1637\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9879,\tval_loss: 4.1003\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9200,\tval_loss: 4.1376\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8795,\tval_loss: 4.0764\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8815,\tval_loss: 4.1519\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8260,\tval_loss: 4.1358\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8447,\tval_loss: 4.1268\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7961,\tval_loss: 4.1743\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8158,\tval_loss: 4.2385\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.7860,\tval_loss: 4.1842\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.7630,\tval_loss: 4.1872\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7840,\tval_loss: 4.2266\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7452,\tval_loss: 4.2215\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.7966,\tval_loss: 4.2490\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7481,\tval_loss: 4.2165\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7447,\tval_loss: 4.1900\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.6958,\tval_loss: 4.2664\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7390,\tval_loss: 4.1932\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7452,\tval_loss: 4.1377\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7458,\tval_loss: 4.1905\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7017,\tval_loss: 4.1543\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6954,\tval_loss: 4.1986\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 3.6367,\tval_loss: 4.2289\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 3.5655,\tval_loss: 4.2559\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.6777,\tval_loss: 4.2511\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.6669,\tval_loss: 4.1966\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.6712,\tval_loss: 4.2254\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.6564,\tval_loss: 4.2900\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.6316,\tval_loss: 4.1827\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6716,\tval_loss: 4.2015\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6729,\tval_loss: 4.2567\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.5873,\tval_loss: 4.2341\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6385,\tval_loss: 4.2080\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6296,\tval_loss: 4.2105\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6534,\tval_loss: 4.2453\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.5586,\tval_loss: 4.3162\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6026,\tval_loss: 4.2132\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6076,\tval_loss: 4.2511\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5671,\tval_loss: 4.2706\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5772,\tval_loss: 4.2768\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5820,\tval_loss: 4.2541\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5621,\tval_loss: 4.2625\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5438,\tval_loss: 4.2313\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.4921,\tval_loss: 4.2376\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.5472,\tval_loss: 4.2981\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.5462,\tval_loss: 4.3073\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.4915,\tval_loss: 4.2545\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.5690,\tval_loss: 4.2921\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.6283,\tval_loss: 4.2428\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.5753,\tval_loss: 4.2617\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.5939,\tval_loss: 4.3136\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.5395,\tval_loss: 4.2585\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.4582,\tval_loss: 4.3983\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.4846,\tval_loss: 4.3125\n",
            "74:\t[0s / 4s],\t\ttrain_loss: 3.5580,\tval_loss: 4.2390\n",
            "75:\t[0s / 4s],\t\ttrain_loss: 3.5117,\tval_loss: 4.3633\n",
            "76:\t[0s / 4s],\t\ttrain_loss: 3.5601,\tval_loss: 4.3139\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3737,\tval_loss: 4.0907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2549,\tval_loss: 4.0865\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3021,\tval_loss: 4.0789\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2670,\tval_loss: 4.0692\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2371,\tval_loss: 4.0738\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2218,\tval_loss: 4.0750\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1814,\tval_loss: 4.0712\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2360,\tval_loss: 4.0596\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1770,\tval_loss: 4.0689\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1819,\tval_loss: 4.0921\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1467,\tval_loss: 4.0685\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1408,\tval_loss: 4.0995\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1442,\tval_loss: 4.0773\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0870,\tval_loss: 4.0901\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.1104,\tval_loss: 4.1143\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0481,\tval_loss: 4.1024\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0590,\tval_loss: 4.1277\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0598,\tval_loss: 4.1177\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0287,\tval_loss: 4.1561\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 4.0185,\tval_loss: 4.1135\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9968,\tval_loss: 4.0950\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9584,\tval_loss: 4.1463\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9698,\tval_loss: 4.1250\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9186,\tval_loss: 4.1678\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9058,\tval_loss: 4.1865\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9144,\tval_loss: 4.1854\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9071,\tval_loss: 4.2094\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8213,\tval_loss: 4.2057\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8964,\tval_loss: 4.2730\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.9329,\tval_loss: 4.1352\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7508,\tval_loss: 4.2715\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8250,\tval_loss: 4.2963\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7331,\tval_loss: 4.1780\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7633,\tval_loss: 4.3185\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7770,\tval_loss: 4.2817\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7245,\tval_loss: 4.2684\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7971,\tval_loss: 4.2573\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7161,\tval_loss: 4.3634\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7323,\tval_loss: 4.2695\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7848,\tval_loss: 4.3100\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6884,\tval_loss: 4.2776\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7150,\tval_loss: 4.4522\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6788,\tval_loss: 4.3238\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7298,\tval_loss: 4.3530\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6827,\tval_loss: 4.3491\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6709,\tval_loss: 4.4569\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6345,\tval_loss: 4.3570\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7305,\tval_loss: 4.3503\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6496,\tval_loss: 4.4970\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7035,\tval_loss: 4.3302\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6755,\tval_loss: 4.3360\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6257,\tval_loss: 4.3463\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6642,\tval_loss: 4.4122\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6325,\tval_loss: 4.3642\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5730,\tval_loss: 4.5148\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5774,\tval_loss: 4.2798\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6873,\tval_loss: 4.4226\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5680,\tval_loss: 4.4022\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5674,\tval_loss: 4.4029\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5056,\tval_loss: 4.4531\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6399,\tval_loss: 4.3162\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5968,\tval_loss: 4.3056\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6842,\tval_loss: 4.2816\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5640,\tval_loss: 4.3487\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.7092,\tval_loss: 4.3937\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5973,\tval_loss: 4.3214\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6270,\tval_loss: 4.3756\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5697,\tval_loss: 4.3524\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6064,\tval_loss: 4.3402\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5415,\tval_loss: 4.3562\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5132,\tval_loss: 4.4625\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.6371,\tval_loss: 4.2871\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.5549,\tval_loss: 4.3380\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.5495,\tval_loss: 4.3625\n",
            "74:\t[0s / 3s],\t\ttrain_loss: 3.5774,\tval_loss: 4.3182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3520,\tval_loss: 4.0943\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2699,\tval_loss: 4.0746\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2340,\tval_loss: 4.0719\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2236,\tval_loss: 4.0596\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1988,\tval_loss: 4.0639\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1558,\tval_loss: 4.0806\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1852,\tval_loss: 4.0948\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1414,\tval_loss: 4.0837\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1964,\tval_loss: 4.0843\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1232,\tval_loss: 4.1220\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1095,\tval_loss: 4.1078\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0932,\tval_loss: 4.1470\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1214,\tval_loss: 4.1146\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0812,\tval_loss: 4.0956\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0159,\tval_loss: 4.1564\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0701,\tval_loss: 4.1575\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0289,\tval_loss: 4.1349\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0004,\tval_loss: 4.1141\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0149,\tval_loss: 4.1462\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 4.0045,\tval_loss: 4.1711\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9904,\tval_loss: 4.1711\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9318,\tval_loss: 4.1221\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9217,\tval_loss: 4.2408\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9757,\tval_loss: 4.1391\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9198,\tval_loss: 4.1947\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9215,\tval_loss: 4.2392\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8922,\tval_loss: 4.1870\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8986,\tval_loss: 4.2588\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8553,\tval_loss: 4.2089\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8165,\tval_loss: 4.2397\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8229,\tval_loss: 4.2921\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8146,\tval_loss: 4.3189\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8087,\tval_loss: 4.2923\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8317,\tval_loss: 4.3212\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8553,\tval_loss: 4.2498\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8593,\tval_loss: 4.2525\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.8369,\tval_loss: 4.2448\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7251,\tval_loss: 4.2989\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7804,\tval_loss: 4.3431\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7458,\tval_loss: 4.3235\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.8034,\tval_loss: 4.2709\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.8334,\tval_loss: 4.2493\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7514,\tval_loss: 4.2509\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6770,\tval_loss: 4.3011\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7097,\tval_loss: 4.3384\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7207,\tval_loss: 4.3478\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6377,\tval_loss: 4.3050\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7091,\tval_loss: 4.2986\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7189,\tval_loss: 4.3204\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7035,\tval_loss: 4.3523\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7423,\tval_loss: 4.4007\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7345,\tval_loss: 4.3432\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7695,\tval_loss: 4.3176\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7841,\tval_loss: 4.3017\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7419,\tval_loss: 4.3656\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.7492,\tval_loss: 4.3600\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6865,\tval_loss: 4.3795\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6587,\tval_loss: 4.4065\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6736,\tval_loss: 4.4343\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6900,\tval_loss: 4.3312\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.7354,\tval_loss: 4.3493\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6887,\tval_loss: 4.4069\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6555,\tval_loss: 4.4595\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6109,\tval_loss: 4.3975\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6014,\tval_loss: 4.3985\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6053,\tval_loss: 4.3737\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6840,\tval_loss: 4.3814\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6281,\tval_loss: 4.3538\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6569,\tval_loss: 4.4032\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.7007,\tval_loss: 4.3649\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6426,\tval_loss: 4.3611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4153,\tval_loss: 4.0273\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3216,\tval_loss: 4.0191\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3302,\tval_loss: 4.0144\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2297,\tval_loss: 4.0028\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2254,\tval_loss: 3.9831\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2301,\tval_loss: 3.9901\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1884,\tval_loss: 3.9900\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1792,\tval_loss: 4.0093\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.2024,\tval_loss: 4.0316\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1416,\tval_loss: 4.0401\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1244,\tval_loss: 4.0512\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1287,\tval_loss: 4.0533\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1105,\tval_loss: 4.0546\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0652,\tval_loss: 4.0711\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0251,\tval_loss: 4.1085\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0540,\tval_loss: 4.0936\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0134,\tval_loss: 4.1227\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0342,\tval_loss: 4.1002\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9665,\tval_loss: 4.1417\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9225,\tval_loss: 4.2322\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9543,\tval_loss: 4.2313\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9377,\tval_loss: 4.1909\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9478,\tval_loss: 4.1866\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9249,\tval_loss: 4.1966\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9315,\tval_loss: 4.2071\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9106,\tval_loss: 4.2075\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8616,\tval_loss: 4.2107\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8892,\tval_loss: 4.2890\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8928,\tval_loss: 4.2085\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8467,\tval_loss: 4.2426\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8461,\tval_loss: 4.2679\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8145,\tval_loss: 4.2678\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8525,\tval_loss: 4.2957\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8207,\tval_loss: 4.2181\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8038,\tval_loss: 4.2730\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7907,\tval_loss: 4.3267\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.8546,\tval_loss: 4.2662\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7857,\tval_loss: 4.2745\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7971,\tval_loss: 4.3076\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.8274,\tval_loss: 4.2852\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.8164,\tval_loss: 4.3208\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7754,\tval_loss: 4.3259\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7639,\tval_loss: 4.3153\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7495,\tval_loss: 4.2827\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7841,\tval_loss: 4.2531\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7536,\tval_loss: 4.3119\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7618,\tval_loss: 4.3487\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7592,\tval_loss: 4.2878\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7204,\tval_loss: 4.3243\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7298,\tval_loss: 4.3485\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7151,\tval_loss: 4.2989\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6955,\tval_loss: 4.3670\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.7792,\tval_loss: 4.3554\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.7233,\tval_loss: 4.2814\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.7073,\tval_loss: 4.3785\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6748,\tval_loss: 4.3999\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.7140,\tval_loss: 4.2945\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6816,\tval_loss: 4.3577\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6724,\tval_loss: 4.3208\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6913,\tval_loss: 4.4431\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6595,\tval_loss: 4.4656\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.7530,\tval_loss: 4.2674\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.7994,\tval_loss: 4.3130\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.7028,\tval_loss: 4.3483\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.7198,\tval_loss: 4.2843\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.7151,\tval_loss: 4.4060\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.7064,\tval_loss: 4.2448\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.6750,\tval_loss: 4.3073\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.6014,\tval_loss: 4.3618\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.6821,\tval_loss: 4.3566\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.6952,\tval_loss: 4.3684\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.6559,\tval_loss: 4.3968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3679,\tval_loss: 4.0876\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2836,\tval_loss: 4.0808\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2286,\tval_loss: 4.0642\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2016,\tval_loss: 4.0530\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1813,\tval_loss: 4.0487\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1528,\tval_loss: 4.0489\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1402,\tval_loss: 4.0570\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1449,\tval_loss: 4.0664\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1123,\tval_loss: 4.0621\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1169,\tval_loss: 4.0672\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0918,\tval_loss: 4.0687\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0508,\tval_loss: 4.0936\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0275,\tval_loss: 4.1545\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9954,\tval_loss: 4.1209\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.9554,\tval_loss: 4.1462\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0047,\tval_loss: 4.1450\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9453,\tval_loss: 4.1285\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8767,\tval_loss: 4.1753\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.8651,\tval_loss: 4.1632\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8038,\tval_loss: 4.2187\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8045,\tval_loss: 4.2015\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8172,\tval_loss: 4.2782\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7937,\tval_loss: 4.2368\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7428,\tval_loss: 4.2652\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7018,\tval_loss: 4.2489\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7054,\tval_loss: 4.3966\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6885,\tval_loss: 4.2703\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6457,\tval_loss: 4.3419\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7120,\tval_loss: 4.2325\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.6499,\tval_loss: 4.3266\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.6986,\tval_loss: 4.3041\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.6489,\tval_loss: 4.3406\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.6388,\tval_loss: 4.3377\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.6208,\tval_loss: 4.3102\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.6360,\tval_loss: 4.3415\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.5825,\tval_loss: 4.3357\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.5222,\tval_loss: 4.4235\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6209,\tval_loss: 4.3404\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7073,\tval_loss: 4.3552\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.5619,\tval_loss: 4.3012\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5184,\tval_loss: 4.3974\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5725,\tval_loss: 4.3721\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5409,\tval_loss: 4.3774\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5806,\tval_loss: 4.3577\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5543,\tval_loss: 4.3736\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5770,\tval_loss: 4.3308\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5216,\tval_loss: 4.3236\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5835,\tval_loss: 4.3242\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.5332,\tval_loss: 4.3776\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.4802,\tval_loss: 4.3654\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.5146,\tval_loss: 4.4190\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.5522,\tval_loss: 4.2743\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.5505,\tval_loss: 4.3051\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.5940,\tval_loss: 4.2802\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.5607,\tval_loss: 4.2519\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6164,\tval_loss: 4.2667\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5450,\tval_loss: 4.3631\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5049,\tval_loss: 4.3249\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5942,\tval_loss: 4.3595\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.4974,\tval_loss: 4.3594\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5689,\tval_loss: 4.3505\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5277,\tval_loss: 4.3582\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5307,\tval_loss: 4.3511\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.4744,\tval_loss: 4.3797\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5465,\tval_loss: 4.3692\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.4833,\tval_loss: 4.2963\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5016,\tval_loss: 4.3021\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5426,\tval_loss: 4.3533\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.4886,\tval_loss: 4.3555\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5201,\tval_loss: 4.4183\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.4776,\tval_loss: 4.3715\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.4750,\tval_loss: 4.3835\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4101,\tval_loss: 4.0812\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3205,\tval_loss: 4.0745\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2473,\tval_loss: 4.0497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2372,\tval_loss: 4.0535\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1955,\tval_loss: 4.0326\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1740,\tval_loss: 4.0336\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1725,\tval_loss: 4.0226\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1383,\tval_loss: 4.0489\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1162,\tval_loss: 4.0091\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1163,\tval_loss: 4.0272\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0712,\tval_loss: 4.0016\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1047,\tval_loss: 4.0271\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0582,\tval_loss: 4.0504\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0254,\tval_loss: 4.0944\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0143,\tval_loss: 4.0711\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0174,\tval_loss: 4.0670\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0210,\tval_loss: 4.0826\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9931,\tval_loss: 4.0624\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9738,\tval_loss: 4.0993\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9268,\tval_loss: 4.0576\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8534,\tval_loss: 4.1400\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9350,\tval_loss: 4.0675\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9292,\tval_loss: 4.0862\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8960,\tval_loss: 4.1007\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8390,\tval_loss: 4.0932\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8545,\tval_loss: 4.1218\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8086,\tval_loss: 4.1088\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7719,\tval_loss: 4.0805\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7567,\tval_loss: 4.1019\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7776,\tval_loss: 4.1059\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8170,\tval_loss: 4.2096\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7843,\tval_loss: 4.1227\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7462,\tval_loss: 4.1241\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7207,\tval_loss: 4.1537\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7521,\tval_loss: 4.1752\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7062,\tval_loss: 4.1362\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7197,\tval_loss: 4.1521\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6731,\tval_loss: 4.1830\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6401,\tval_loss: 4.2175\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6400,\tval_loss: 4.2661\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7441,\tval_loss: 4.0939\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7044,\tval_loss: 4.1077\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7138,\tval_loss: 4.1236\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6413,\tval_loss: 4.2013\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6033,\tval_loss: 4.1845\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6279,\tval_loss: 4.1531\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6219,\tval_loss: 4.2070\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5820,\tval_loss: 4.2149\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5850,\tval_loss: 4.2385\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5285,\tval_loss: 4.2685\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5394,\tval_loss: 4.2557\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6181,\tval_loss: 4.1949\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5894,\tval_loss: 4.2335\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5433,\tval_loss: 4.2294\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6109,\tval_loss: 4.2584\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5690,\tval_loss: 4.2689\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6375,\tval_loss: 4.2293\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5509,\tval_loss: 4.2671\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6523,\tval_loss: 4.3040\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5714,\tval_loss: 4.2395\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6197,\tval_loss: 4.1896\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6090,\tval_loss: 4.2487\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5375,\tval_loss: 4.2967\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5634,\tval_loss: 4.2597\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5142,\tval_loss: 4.2623\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5296,\tval_loss: 4.3137\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6002,\tval_loss: 4.3076\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5200,\tval_loss: 4.3096\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.4863,\tval_loss: 4.3046\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.4951,\tval_loss: 4.3290\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5275,\tval_loss: 4.2729\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.5140,\tval_loss: 4.2760\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.5106,\tval_loss: 4.3014\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.5382,\tval_loss: 4.3798\n",
            "74:\t[0s / 3s],\t\ttrain_loss: 3.5055,\tval_loss: 4.2793\n",
            "75:\t[0s / 3s],\t\ttrain_loss: 3.5417,\tval_loss: 4.3165\n",
            "76:\t[0s / 3s],\t\ttrain_loss: 3.5464,\tval_loss: 4.2534\n",
            "77:\t[0s / 3s],\t\ttrain_loss: 3.4374,\tval_loss: 4.3053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4316,\tval_loss: 4.1064\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3076,\tval_loss: 4.0787\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2349,\tval_loss: 4.0720\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2279,\tval_loss: 4.0888\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2316,\tval_loss: 4.0863\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2068,\tval_loss: 4.0771\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1988,\tval_loss: 4.0962\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1404,\tval_loss: 4.1025\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1456,\tval_loss: 4.0865\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1161,\tval_loss: 4.1256\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1147,\tval_loss: 4.1292\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0995,\tval_loss: 4.1137\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0737,\tval_loss: 4.0860\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0937,\tval_loss: 4.1354\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0284,\tval_loss: 4.1238\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0052,\tval_loss: 4.1736\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 4.0182,\tval_loss: 4.2140\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9840,\tval_loss: 4.1619\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9362,\tval_loss: 4.2232\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9872,\tval_loss: 4.2172\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9513,\tval_loss: 4.1333\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9513,\tval_loss: 4.1985\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8705,\tval_loss: 4.2775\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9065,\tval_loss: 4.2177\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9057,\tval_loss: 4.2018\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8830,\tval_loss: 4.2385\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8767,\tval_loss: 4.2585\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8699,\tval_loss: 4.2207\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8239,\tval_loss: 4.2728\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.7958,\tval_loss: 4.2530\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.7819,\tval_loss: 4.3227\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.8121,\tval_loss: 4.1864\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7936,\tval_loss: 4.2729\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.8414,\tval_loss: 4.1804\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7806,\tval_loss: 4.2286\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7866,\tval_loss: 4.2907\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.8286,\tval_loss: 4.2530\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.8177,\tval_loss: 4.2672\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7602,\tval_loss: 4.2615\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7038,\tval_loss: 4.3863\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7442,\tval_loss: 4.3026\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7679,\tval_loss: 4.3329\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7765,\tval_loss: 4.2483\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7202,\tval_loss: 4.3002\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.7419,\tval_loss: 4.2937\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.7589,\tval_loss: 4.3005\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.7316,\tval_loss: 4.3995\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.7574,\tval_loss: 4.3514\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.7034,\tval_loss: 4.3894\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6627,\tval_loss: 4.3224\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6471,\tval_loss: 4.4132\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.7223,\tval_loss: 4.3469\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6418,\tval_loss: 4.3919\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6453,\tval_loss: 4.5191\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6872,\tval_loss: 4.3951\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6929,\tval_loss: 4.3430\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.7017,\tval_loss: 4.3736\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6073,\tval_loss: 4.4521\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6178,\tval_loss: 4.3718\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 3.6231,\tval_loss: 4.3998\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 3.6029,\tval_loss: 4.4019\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.5725,\tval_loss: 4.4685\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.6659,\tval_loss: 4.4258\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.6536,\tval_loss: 4.3252\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.5657,\tval_loss: 4.4716\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.5960,\tval_loss: 4.3399\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.6223,\tval_loss: 4.3494\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.5480,\tval_loss: 4.4417\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.5564,\tval_loss: 4.3827\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.5312,\tval_loss: 4.4045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4265,\tval_loss: 4.0624\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2894,\tval_loss: 4.0509\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2141,\tval_loss: 4.0544\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1454,\tval_loss: 4.0548\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1490,\tval_loss: 4.0727\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.0503,\tval_loss: 4.0864\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0545,\tval_loss: 4.1335\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0478,\tval_loss: 4.1104\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0854,\tval_loss: 4.1400\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 3.9745,\tval_loss: 4.1383\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 3.9437,\tval_loss: 4.2174\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9048,\tval_loss: 4.2743\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9150,\tval_loss: 4.2669\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 3.9300,\tval_loss: 4.2233\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.8799,\tval_loss: 4.2626\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9210,\tval_loss: 4.3085\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.8758,\tval_loss: 4.2541\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8541,\tval_loss: 4.2944\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.8546,\tval_loss: 4.3311\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9051,\tval_loss: 4.3166\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8514,\tval_loss: 4.3649\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7994,\tval_loss: 4.3523\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7955,\tval_loss: 4.3675\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7626,\tval_loss: 4.4206\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8495,\tval_loss: 4.3143\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8011,\tval_loss: 4.3613\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8330,\tval_loss: 4.2667\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7560,\tval_loss: 4.3913\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 3.7634,\tval_loss: 4.3069\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.7746,\tval_loss: 4.4223\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.7518,\tval_loss: 4.4147\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7295,\tval_loss: 4.4560\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7335,\tval_loss: 4.4766\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.7709,\tval_loss: 4.3834\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7092,\tval_loss: 4.4216\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7983,\tval_loss: 4.4263\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7817,\tval_loss: 4.2834\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6691,\tval_loss: 4.4051\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7537,\tval_loss: 4.3586\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7092,\tval_loss: 4.4208\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6612,\tval_loss: 4.3748\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7094,\tval_loss: 4.3795\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7346,\tval_loss: 4.4699\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 3.7453,\tval_loss: 4.3465\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.6110,\tval_loss: 4.3694\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.6433,\tval_loss: 4.4420\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.6102,\tval_loss: 4.4558\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.6123,\tval_loss: 4.5592\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.6765,\tval_loss: 4.4332\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6278,\tval_loss: 4.3704\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6193,\tval_loss: 4.4565\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.5948,\tval_loss: 4.3864\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6485,\tval_loss: 4.4322\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6628,\tval_loss: 4.4585\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6566,\tval_loss: 4.3889\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6367,\tval_loss: 4.4714\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6607,\tval_loss: 4.3506\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5684,\tval_loss: 4.4763\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 3.5897,\tval_loss: 4.4312\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 3.5531,\tval_loss: 4.3854\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 3.6482,\tval_loss: 4.4177\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.5872,\tval_loss: 4.3948\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.6086,\tval_loss: 4.3987\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.6470,\tval_loss: 4.3614\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.6309,\tval_loss: 4.3789\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.5428,\tval_loss: 4.4540\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.5655,\tval_loss: 4.4864\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.6595,\tval_loss: 4.4386\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.5209,\tval_loss: 4.5009\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4423,\tval_loss: 4.0648\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2720,\tval_loss: 4.0313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2220,\tval_loss: 4.0012\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1932,\tval_loss: 4.0607\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2322,\tval_loss: 3.9978\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2139,\tval_loss: 3.9969\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1697,\tval_loss: 4.0154\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1309,\tval_loss: 4.0047\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1002,\tval_loss: 4.0292\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0934,\tval_loss: 4.0361\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0584,\tval_loss: 4.1025\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0245,\tval_loss: 4.0971\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0232,\tval_loss: 4.0735\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0096,\tval_loss: 4.1631\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9887,\tval_loss: 4.1219\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9107,\tval_loss: 4.1380\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9219,\tval_loss: 4.2238\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9382,\tval_loss: 4.1535\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9393,\tval_loss: 4.1550\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8995,\tval_loss: 4.1616\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.8945,\tval_loss: 4.2438\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8954,\tval_loss: 4.1638\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8275,\tval_loss: 4.1670\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8137,\tval_loss: 4.2408\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8702,\tval_loss: 4.1547\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8116,\tval_loss: 4.1715\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8582,\tval_loss: 4.1495\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7625,\tval_loss: 4.2041\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7894,\tval_loss: 4.1049\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7288,\tval_loss: 4.2767\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7873,\tval_loss: 4.1948\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7382,\tval_loss: 4.1902\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7381,\tval_loss: 4.2396\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6885,\tval_loss: 4.2687\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6505,\tval_loss: 4.3524\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7010,\tval_loss: 4.1707\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7297,\tval_loss: 4.2430\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6427,\tval_loss: 4.2034\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6659,\tval_loss: 4.2349\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7087,\tval_loss: 4.2422\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6720,\tval_loss: 4.2214\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6359,\tval_loss: 4.2283\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7614,\tval_loss: 4.3168\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6293,\tval_loss: 4.3105\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6460,\tval_loss: 4.2942\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6618,\tval_loss: 4.3230\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5644,\tval_loss: 4.3490\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6275,\tval_loss: 4.2543\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6642,\tval_loss: 4.2627\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6145,\tval_loss: 4.2767\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5775,\tval_loss: 4.3326\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5753,\tval_loss: 4.2202\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5983,\tval_loss: 4.2351\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6271,\tval_loss: 4.3206\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7041,\tval_loss: 4.1596\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5939,\tval_loss: 4.2223\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5460,\tval_loss: 4.3125\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5179,\tval_loss: 4.3423\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5353,\tval_loss: 4.3206\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5321,\tval_loss: 4.2956\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5404,\tval_loss: 4.2701\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5594,\tval_loss: 4.3467\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5695,\tval_loss: 4.1873\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.6019,\tval_loss: 4.3080\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5682,\tval_loss: 4.3086\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5462,\tval_loss: 4.3389\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5261,\tval_loss: 4.2681\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5185,\tval_loss: 4.3423\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5587,\tval_loss: 4.2616\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5687,\tval_loss: 4.2444\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5928,\tval_loss: 4.2803\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.4931,\tval_loss: 4.2691\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.5601,\tval_loss: 4.3630\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3140,\tval_loss: 4.1062\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.1769,\tval_loss: 4.0676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1951,\tval_loss: 4.0734\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1540,\tval_loss: 4.0783\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1191,\tval_loss: 4.0950\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1071,\tval_loss: 4.0921\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0503,\tval_loss: 4.1026\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0385,\tval_loss: 4.1243\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0296,\tval_loss: 4.1001\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0241,\tval_loss: 4.0811\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0285,\tval_loss: 4.1334\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9912,\tval_loss: 4.1422\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0095,\tval_loss: 4.1378\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0047,\tval_loss: 4.1378\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.8986,\tval_loss: 4.1685\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9434,\tval_loss: 4.1707\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9281,\tval_loss: 4.1588\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9060,\tval_loss: 4.2003\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8617,\tval_loss: 4.2554\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8681,\tval_loss: 4.2871\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.8352,\tval_loss: 4.2953\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8099,\tval_loss: 4.2873\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8399,\tval_loss: 4.3464\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7215,\tval_loss: 4.3863\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7724,\tval_loss: 4.3043\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7480,\tval_loss: 4.4201\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7754,\tval_loss: 4.2847\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7039,\tval_loss: 4.3462\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7402,\tval_loss: 4.4318\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7120,\tval_loss: 4.3503\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7312,\tval_loss: 4.4849\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7223,\tval_loss: 4.3422\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6411,\tval_loss: 4.3944\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6416,\tval_loss: 4.4059\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6739,\tval_loss: 4.4068\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6837,\tval_loss: 4.4179\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6650,\tval_loss: 4.4032\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6609,\tval_loss: 4.3770\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6323,\tval_loss: 4.4910\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6516,\tval_loss: 4.4862\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6942,\tval_loss: 4.4958\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6467,\tval_loss: 4.4905\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6541,\tval_loss: 4.5101\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5775,\tval_loss: 4.5016\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5835,\tval_loss: 4.5832\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6333,\tval_loss: 4.4868\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6210,\tval_loss: 4.4831\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5460,\tval_loss: 4.4866\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6025,\tval_loss: 4.5342\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6034,\tval_loss: 4.5184\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.4844,\tval_loss: 4.5960\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5415,\tval_loss: 4.5860\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5572,\tval_loss: 4.5701\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5524,\tval_loss: 4.5645\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5083,\tval_loss: 4.5706\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5604,\tval_loss: 4.4972\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5947,\tval_loss: 4.5561\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5659,\tval_loss: 4.4437\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5146,\tval_loss: 4.5586\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5713,\tval_loss: 4.5909\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5737,\tval_loss: 4.5436\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5689,\tval_loss: 4.4737\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5267,\tval_loss: 4.5169\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5455,\tval_loss: 4.4700\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5366,\tval_loss: 4.5858\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5573,\tval_loss: 4.5398\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5050,\tval_loss: 4.5611\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4931,\tval_loss: 4.5755\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5345,\tval_loss: 4.5796\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3680,\tval_loss: 4.0688\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2261,\tval_loss: 4.0998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2167,\tval_loss: 4.1144\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1649,\tval_loss: 4.0796\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1986,\tval_loss: 4.0740\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1380,\tval_loss: 4.0554\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1033,\tval_loss: 4.0828\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1021,\tval_loss: 4.1106\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0713,\tval_loss: 4.0951\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0234,\tval_loss: 4.0878\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0300,\tval_loss: 4.1232\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0184,\tval_loss: 4.1090\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9968,\tval_loss: 4.0963\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9716,\tval_loss: 4.0802\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9232,\tval_loss: 4.1818\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9028,\tval_loss: 4.1956\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8628,\tval_loss: 4.1760\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8373,\tval_loss: 4.2142\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8389,\tval_loss: 4.1980\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8911,\tval_loss: 4.1663\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.8628,\tval_loss: 4.1829\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8453,\tval_loss: 4.1913\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7940,\tval_loss: 4.2350\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7649,\tval_loss: 4.2600\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7366,\tval_loss: 4.2701\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7494,\tval_loss: 4.2725\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7303,\tval_loss: 4.2824\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7681,\tval_loss: 4.2583\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7305,\tval_loss: 4.3151\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7080,\tval_loss: 4.3188\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6844,\tval_loss: 4.3393\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6931,\tval_loss: 4.3101\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6973,\tval_loss: 4.2498\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.5569,\tval_loss: 4.3489\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6048,\tval_loss: 4.4104\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7022,\tval_loss: 4.3014\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6879,\tval_loss: 4.2688\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6905,\tval_loss: 4.2973\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6716,\tval_loss: 4.3267\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6822,\tval_loss: 4.3673\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6269,\tval_loss: 4.3426\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6607,\tval_loss: 4.3552\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5494,\tval_loss: 4.3445\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5605,\tval_loss: 4.3734\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6658,\tval_loss: 4.3763\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5716,\tval_loss: 4.3701\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6024,\tval_loss: 4.3174\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5803,\tval_loss: 4.3021\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5762,\tval_loss: 4.3541\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5882,\tval_loss: 4.3182\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6078,\tval_loss: 4.3218\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5511,\tval_loss: 4.3474\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6180,\tval_loss: 4.3376\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5228,\tval_loss: 4.3581\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5153,\tval_loss: 4.3496\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5325,\tval_loss: 4.3197\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6125,\tval_loss: 4.2810\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6011,\tval_loss: 4.3749\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5248,\tval_loss: 4.3236\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5252,\tval_loss: 4.3749\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5453,\tval_loss: 4.2921\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5507,\tval_loss: 4.3232\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5540,\tval_loss: 4.3133\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5703,\tval_loss: 4.3152\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5609,\tval_loss: 4.3380\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.4971,\tval_loss: 4.3411\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4948,\tval_loss: 4.3742\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5273,\tval_loss: 4.3659\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5029,\tval_loss: 4.3291\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5761,\tval_loss: 4.2590\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.4576,\tval_loss: 4.4281\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.4740,\tval_loss: 4.3769\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.5221,\tval_loss: 4.3610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.2906,\tval_loss: 4.0458\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.1783,\tval_loss: 4.0862\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1456,\tval_loss: 4.0490\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1149,\tval_loss: 4.0853\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.0928,\tval_loss: 4.1461\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.0578,\tval_loss: 4.1838\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 3.9960,\tval_loss: 4.1899\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0003,\tval_loss: 4.1179\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0456,\tval_loss: 4.1639\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 3.9925,\tval_loss: 4.1733\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 3.9830,\tval_loss: 4.1871\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9462,\tval_loss: 4.1703\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9296,\tval_loss: 4.2742\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 3.8513,\tval_loss: 4.2765\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.8416,\tval_loss: 4.2465\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9034,\tval_loss: 4.2723\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.8231,\tval_loss: 4.3342\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.7829,\tval_loss: 4.3017\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.8664,\tval_loss: 4.3858\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8470,\tval_loss: 4.2775\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.7111,\tval_loss: 4.4529\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7539,\tval_loss: 4.3951\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7243,\tval_loss: 4.4183\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.6845,\tval_loss: 4.4451\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.6638,\tval_loss: 4.4420\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6659,\tval_loss: 4.4473\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7074,\tval_loss: 4.4302\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7440,\tval_loss: 4.4177\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 3.6745,\tval_loss: 4.3718\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.6780,\tval_loss: 4.4620\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.7061,\tval_loss: 4.4970\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.6295,\tval_loss: 4.4153\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.6657,\tval_loss: 4.5320\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.6150,\tval_loss: 4.5716\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.5433,\tval_loss: 4.5106\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.5861,\tval_loss: 4.5678\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.6348,\tval_loss: 4.4829\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6706,\tval_loss: 4.4887\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.5945,\tval_loss: 4.5049\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.5891,\tval_loss: 4.5132\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5762,\tval_loss: 4.6214\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6253,\tval_loss: 4.6311\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6021,\tval_loss: 4.5711\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 3.5568,\tval_loss: 4.4979\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.4869,\tval_loss: 4.6087\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.5516,\tval_loss: 4.5940\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.5765,\tval_loss: 4.5525\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.6225,\tval_loss: 4.4744\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.5849,\tval_loss: 4.6350\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.5766,\tval_loss: 4.5123\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.5934,\tval_loss: 4.5264\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.4583,\tval_loss: 4.6886\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.4781,\tval_loss: 4.6400\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.5046,\tval_loss: 4.6374\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.5332,\tval_loss: 4.6383\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.5963,\tval_loss: 4.5408\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5217,\tval_loss: 4.6058\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5083,\tval_loss: 4.6656\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 3.4455,\tval_loss: 4.5671\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 3.4810,\tval_loss: 4.6092\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 3.4895,\tval_loss: 4.6771\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.6106,\tval_loss: 4.6143\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.5933,\tval_loss: 4.5877\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.5365,\tval_loss: 4.6014\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.4646,\tval_loss: 4.6355\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.5741,\tval_loss: 4.5848\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.5022,\tval_loss: 4.7249\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.5281,\tval_loss: 4.5803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4435,\tval_loss: 4.0529\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3027,\tval_loss: 4.0265\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2377,\tval_loss: 4.0380\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2233,\tval_loss: 4.0359\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1723,\tval_loss: 4.0260\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1426,\tval_loss: 4.0572\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1007,\tval_loss: 4.0685\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1024,\tval_loss: 4.0822\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0991,\tval_loss: 4.0803\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0599,\tval_loss: 4.1023\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0625,\tval_loss: 4.0618\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0243,\tval_loss: 4.1333\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9721,\tval_loss: 4.0987\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9901,\tval_loss: 4.1400\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9318,\tval_loss: 4.1051\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9090,\tval_loss: 4.1709\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9740,\tval_loss: 4.1475\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9058,\tval_loss: 4.1534\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9411,\tval_loss: 4.1775\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9221,\tval_loss: 4.1508\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8598,\tval_loss: 4.1954\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8540,\tval_loss: 4.2204\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7994,\tval_loss: 4.2716\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7870,\tval_loss: 4.2451\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7983,\tval_loss: 4.2213\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7904,\tval_loss: 4.1728\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8355,\tval_loss: 4.1936\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7732,\tval_loss: 4.2958\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7501,\tval_loss: 4.2345\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7836,\tval_loss: 4.3186\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7822,\tval_loss: 4.2458\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7086,\tval_loss: 4.2967\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7031,\tval_loss: 4.3135\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7257,\tval_loss: 4.2495\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7815,\tval_loss: 4.2166\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7067,\tval_loss: 4.2352\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7115,\tval_loss: 4.2949\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7037,\tval_loss: 4.2610\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7796,\tval_loss: 4.2383\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7118,\tval_loss: 4.2926\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6925,\tval_loss: 4.2561\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6651,\tval_loss: 4.3357\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6753,\tval_loss: 4.3290\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6603,\tval_loss: 4.3069\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6735,\tval_loss: 4.3431\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6599,\tval_loss: 4.3229\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6834,\tval_loss: 4.3689\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6626,\tval_loss: 4.3771\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7268,\tval_loss: 4.3363\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6877,\tval_loss: 4.2976\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6558,\tval_loss: 4.3140\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6282,\tval_loss: 4.2760\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7034,\tval_loss: 4.2745\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6338,\tval_loss: 4.2713\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6498,\tval_loss: 4.3626\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5810,\tval_loss: 4.4124\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6313,\tval_loss: 4.3017\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6458,\tval_loss: 4.2917\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6553,\tval_loss: 4.2519\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5988,\tval_loss: 4.3223\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6542,\tval_loss: 4.2777\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6655,\tval_loss: 4.2366\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6588,\tval_loss: 4.2236\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6692,\tval_loss: 4.2603\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6609,\tval_loss: 4.2291\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6000,\tval_loss: 4.2223\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6265,\tval_loss: 4.2505\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6276,\tval_loss: 4.2518\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6549,\tval_loss: 4.1692\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6056,\tval_loss: 4.2594\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.7410,\tval_loss: 4.2186\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.6804,\tval_loss: 4.1985\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4907,\tval_loss: 4.1170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3100,\tval_loss: 4.0889\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2871,\tval_loss: 4.1006\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2949,\tval_loss: 4.0820\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2709,\tval_loss: 4.0752\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2444,\tval_loss: 4.0902\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2022,\tval_loss: 4.0996\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2070,\tval_loss: 4.0866\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.2069,\tval_loss: 4.0826\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1742,\tval_loss: 4.0874\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1216,\tval_loss: 4.1219\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1700,\tval_loss: 4.0984\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1646,\tval_loss: 4.1086\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1326,\tval_loss: 4.1276\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.1343,\tval_loss: 4.1454\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.1384,\tval_loss: 4.1866\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.1172,\tval_loss: 4.0940\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0971,\tval_loss: 4.1623\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0809,\tval_loss: 4.1554\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 4.0698,\tval_loss: 4.1442\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 4.0177,\tval_loss: 4.2003\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 4.0478,\tval_loss: 4.1739\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 4.0093,\tval_loss: 4.1552\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9405,\tval_loss: 4.2887\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9158,\tval_loss: 4.2064\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9082,\tval_loss: 4.2899\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9403,\tval_loss: 4.3441\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9381,\tval_loss: 4.2652\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8940,\tval_loss: 4.2691\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8916,\tval_loss: 4.2981\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8811,\tval_loss: 4.2429\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8446,\tval_loss: 4.3206\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8771,\tval_loss: 4.1962\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8368,\tval_loss: 4.4962\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8271,\tval_loss: 4.2231\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8051,\tval_loss: 4.3042\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7329,\tval_loss: 4.3972\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.8309,\tval_loss: 4.4127\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6519,\tval_loss: 4.4476\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.8437,\tval_loss: 4.4084\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7866,\tval_loss: 4.3907\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6817,\tval_loss: 4.3348\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6425,\tval_loss: 4.4758\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6919,\tval_loss: 4.4047\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6830,\tval_loss: 4.4083\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6353,\tval_loss: 4.4530\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5952,\tval_loss: 4.4411\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6704,\tval_loss: 4.4752\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6765,\tval_loss: 4.5418\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6424,\tval_loss: 4.5431\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5991,\tval_loss: 4.5427\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6237,\tval_loss: 4.3576\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6849,\tval_loss: 4.4356\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6522,\tval_loss: 4.4851\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6236,\tval_loss: 4.5400\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6437,\tval_loss: 4.4338\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.7030,\tval_loss: 4.4270\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6790,\tval_loss: 4.4736\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6083,\tval_loss: 4.4999\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5691,\tval_loss: 4.4921\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6994,\tval_loss: 4.4948\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6255,\tval_loss: 4.5542\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6250,\tval_loss: 4.5484\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6573,\tval_loss: 4.4613\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5386,\tval_loss: 4.4603\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5599,\tval_loss: 4.5150\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5634,\tval_loss: 4.5007\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6019,\tval_loss: 4.5153\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5238,\tval_loss: 4.5857\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6028,\tval_loss: 4.4805\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5644,\tval_loss: 4.4933\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.5306,\tval_loss: 4.5729\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3818,\tval_loss: 4.0225\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2843,\tval_loss: 4.0384\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2112,\tval_loss: 4.0602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2610,\tval_loss: 4.0561\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2167,\tval_loss: 4.0596\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1958,\tval_loss: 4.0545\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1398,\tval_loss: 4.0901\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1545,\tval_loss: 4.0880\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0906,\tval_loss: 4.0970\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1141,\tval_loss: 4.0993\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0463,\tval_loss: 4.1349\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0281,\tval_loss: 4.0957\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9925,\tval_loss: 4.1502\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0149,\tval_loss: 4.2063\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9380,\tval_loss: 4.2093\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0015,\tval_loss: 4.1829\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8746,\tval_loss: 4.2107\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9491,\tval_loss: 4.2810\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8753,\tval_loss: 4.2923\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8266,\tval_loss: 4.2812\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8078,\tval_loss: 4.3073\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7620,\tval_loss: 4.3517\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8152,\tval_loss: 4.2870\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8006,\tval_loss: 4.3618\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7815,\tval_loss: 4.3368\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6816,\tval_loss: 4.3379\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7420,\tval_loss: 4.4345\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7002,\tval_loss: 4.3533\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6631,\tval_loss: 4.4024\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7232,\tval_loss: 4.3340\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7641,\tval_loss: 4.3513\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7737,\tval_loss: 4.3781\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6545,\tval_loss: 4.4502\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7160,\tval_loss: 4.4228\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6869,\tval_loss: 4.4064\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6655,\tval_loss: 4.4547\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6334,\tval_loss: 4.4479\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6482,\tval_loss: 4.4426\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7308,\tval_loss: 4.2940\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.5841,\tval_loss: 4.4520\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6382,\tval_loss: 4.4409\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6096,\tval_loss: 4.4347\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6082,\tval_loss: 4.4154\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5985,\tval_loss: 4.4186\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6448,\tval_loss: 4.3863\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5951,\tval_loss: 4.5017\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5990,\tval_loss: 4.4294\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6229,\tval_loss: 4.3972\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5982,\tval_loss: 4.5201\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5623,\tval_loss: 4.5104\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6533,\tval_loss: 4.3824\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5325,\tval_loss: 4.4273\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5738,\tval_loss: 4.5095\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5434,\tval_loss: 4.4186\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5560,\tval_loss: 4.4854\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5028,\tval_loss: 4.4862\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5990,\tval_loss: 4.4606\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5636,\tval_loss: 4.4166\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5690,\tval_loss: 4.4162\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.4619,\tval_loss: 4.5488\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.4946,\tval_loss: 4.4346\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5505,\tval_loss: 4.4571\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5783,\tval_loss: 4.3949\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5719,\tval_loss: 4.4011\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5291,\tval_loss: 4.3904\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5984,\tval_loss: 4.4023\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4979,\tval_loss: 4.3726\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5148,\tval_loss: 4.4581\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4343,\tval_loss: 4.0463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2831,\tval_loss: 4.0445\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2199,\tval_loss: 4.0365\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2253,\tval_loss: 4.0551\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2228,\tval_loss: 4.0601\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1597,\tval_loss: 4.0689\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1455,\tval_loss: 4.0928\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1232,\tval_loss: 4.1292\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1077,\tval_loss: 4.1429\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0687,\tval_loss: 4.1817\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 3.9984,\tval_loss: 4.2626\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0227,\tval_loss: 4.2979\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9898,\tval_loss: 4.3171\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 3.9059,\tval_loss: 4.4270\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.9376,\tval_loss: 4.3679\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9454,\tval_loss: 4.3534\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.8800,\tval_loss: 4.3721\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8893,\tval_loss: 4.3369\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.8784,\tval_loss: 4.3622\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8105,\tval_loss: 4.4045\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8316,\tval_loss: 4.3474\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7596,\tval_loss: 4.4251\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7634,\tval_loss: 4.5402\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8305,\tval_loss: 4.3490\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7485,\tval_loss: 4.3782\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7086,\tval_loss: 4.4149\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6861,\tval_loss: 4.4367\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 3.6634,\tval_loss: 4.4990\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 3.6999,\tval_loss: 4.5136\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.6811,\tval_loss: 4.4101\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.6335,\tval_loss: 4.5373\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.6854,\tval_loss: 4.4318\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.6989,\tval_loss: 4.4105\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.6713,\tval_loss: 4.3781\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7063,\tval_loss: 4.5196\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.5655,\tval_loss: 4.4547\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.5832,\tval_loss: 4.4763\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.5174,\tval_loss: 4.4921\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.5855,\tval_loss: 4.4591\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.5685,\tval_loss: 4.5384\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5744,\tval_loss: 4.5357\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5956,\tval_loss: 4.5057\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 3.6312,\tval_loss: 4.4311\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 3.5014,\tval_loss: 4.4160\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.5715,\tval_loss: 4.4834\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.5742,\tval_loss: 4.5679\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.5475,\tval_loss: 4.4779\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.5445,\tval_loss: 4.5409\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.4680,\tval_loss: 4.5883\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.5052,\tval_loss: 4.5187\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.5103,\tval_loss: 4.6444\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.5042,\tval_loss: 4.5851\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.4892,\tval_loss: 4.5090\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.5548,\tval_loss: 4.5114\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.4454,\tval_loss: 4.4972\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.4445,\tval_loss: 4.6249\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.4969,\tval_loss: 4.5303\n",
            "57:\t[0s / 4s],\t\ttrain_loss: 3.5337,\tval_loss: 4.4854\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 3.5127,\tval_loss: 4.5143\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 3.5224,\tval_loss: 4.5240\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 3.4430,\tval_loss: 4.5571\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.4904,\tval_loss: 4.6370\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.5214,\tval_loss: 4.4835\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.5296,\tval_loss: 4.5020\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.5245,\tval_loss: 4.5405\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.5153,\tval_loss: 4.5018\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.4754,\tval_loss: 4.5062\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.5281,\tval_loss: 4.5400\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.5135,\tval_loss: 4.5367\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.4698,\tval_loss: 4.4482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4882,\tval_loss: 4.1594\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3082,\tval_loss: 4.1150\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2509,\tval_loss: 4.0942\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2121,\tval_loss: 4.0915\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1828,\tval_loss: 4.1022\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1693,\tval_loss: 4.1186\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1271,\tval_loss: 4.0808\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1018,\tval_loss: 4.1087\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0722,\tval_loss: 4.1182\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0135,\tval_loss: 4.1210\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0482,\tval_loss: 4.1276\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0461,\tval_loss: 4.1320\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0480,\tval_loss: 4.1208\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9744,\tval_loss: 4.1136\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9658,\tval_loss: 4.1636\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9540,\tval_loss: 4.1832\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9794,\tval_loss: 4.1250\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9299,\tval_loss: 4.1605\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.8637,\tval_loss: 4.2204\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9043,\tval_loss: 4.1717\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9047,\tval_loss: 4.1291\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9115,\tval_loss: 4.1720\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8672,\tval_loss: 4.1534\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8681,\tval_loss: 4.1739\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7851,\tval_loss: 4.2341\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7841,\tval_loss: 4.1944\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7838,\tval_loss: 4.2650\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6825,\tval_loss: 4.2461\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7662,\tval_loss: 4.2057\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7211,\tval_loss: 4.1949\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6427,\tval_loss: 4.2994\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7133,\tval_loss: 4.2216\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6586,\tval_loss: 4.2631\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6766,\tval_loss: 4.1521\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6576,\tval_loss: 4.2397\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6302,\tval_loss: 4.2512\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6857,\tval_loss: 4.1727\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6393,\tval_loss: 4.2809\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6056,\tval_loss: 4.2549\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6186,\tval_loss: 4.2369\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5461,\tval_loss: 4.2733\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6729,\tval_loss: 4.2702\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6027,\tval_loss: 4.2571\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6539,\tval_loss: 4.1635\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6626,\tval_loss: 4.2145\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5689,\tval_loss: 4.2485\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5834,\tval_loss: 4.2924\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6286,\tval_loss: 4.3482\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6430,\tval_loss: 4.2630\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5678,\tval_loss: 4.2662\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5036,\tval_loss: 4.2975\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.4721,\tval_loss: 4.3382\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.4744,\tval_loss: 4.3471\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5302,\tval_loss: 4.2803\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5780,\tval_loss: 4.3576\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5859,\tval_loss: 4.2901\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.4970,\tval_loss: 4.2886\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.4516,\tval_loss: 4.3461\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5816,\tval_loss: 4.3370\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5365,\tval_loss: 4.3295\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5160,\tval_loss: 4.3033\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.4846,\tval_loss: 4.3194\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5298,\tval_loss: 4.2298\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5605,\tval_loss: 4.2846\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5321,\tval_loss: 4.2701\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5365,\tval_loss: 4.2694\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5010,\tval_loss: 4.3120\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4612,\tval_loss: 4.3129\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.4230,\tval_loss: 4.4160\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5061,\tval_loss: 4.3092\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5360,\tval_loss: 4.3344\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.4954,\tval_loss: 4.2333\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.4378,\tval_loss: 4.2884\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.4179,\tval_loss: 4.4003\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.5273,\tval_loss: 4.0857\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3633,\tval_loss: 4.0931\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3177,\tval_loss: 4.0905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2845,\tval_loss: 4.0860\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2853,\tval_loss: 4.0790\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2535,\tval_loss: 4.0847\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2588,\tval_loss: 4.0716\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2531,\tval_loss: 4.0690\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.2295,\tval_loss: 4.0982\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.2176,\tval_loss: 4.1052\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.2006,\tval_loss: 4.0914\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.2066,\tval_loss: 4.1433\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1784,\tval_loss: 4.1234\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1816,\tval_loss: 4.1260\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.1602,\tval_loss: 4.1350\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.1447,\tval_loss: 4.1219\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.1495,\tval_loss: 4.0906\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0834,\tval_loss: 4.1456\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.1249,\tval_loss: 4.1389\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 4.1006,\tval_loss: 4.1654\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 4.0693,\tval_loss: 4.1938\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 4.0314,\tval_loss: 4.1748\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 4.0147,\tval_loss: 4.1968\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 4.0480,\tval_loss: 4.2334\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 4.0175,\tval_loss: 4.1940\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 4.0272,\tval_loss: 4.2248\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9895,\tval_loss: 4.2669\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 4.0060,\tval_loss: 4.2080\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.9193,\tval_loss: 4.2421\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.9060,\tval_loss: 4.3245\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8763,\tval_loss: 4.3055\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8494,\tval_loss: 4.3390\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.9108,\tval_loss: 4.3339\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8844,\tval_loss: 4.3590\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8981,\tval_loss: 4.2737\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.9327,\tval_loss: 4.2578\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.8739,\tval_loss: 4.3058\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.9181,\tval_loss: 4.3248\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.8754,\tval_loss: 4.3728\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.8371,\tval_loss: 4.3797\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.8531,\tval_loss: 4.3459\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.8510,\tval_loss: 4.3072\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.8629,\tval_loss: 4.3227\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.8478,\tval_loss: 4.2971\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.8346,\tval_loss: 4.3813\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.8141,\tval_loss: 4.3756\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.8542,\tval_loss: 4.3380\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.8708,\tval_loss: 4.4006\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7858,\tval_loss: 4.4303\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7553,\tval_loss: 4.3434\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7994,\tval_loss: 4.3629\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7430,\tval_loss: 4.4125\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7895,\tval_loss: 4.4001\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7847,\tval_loss: 4.3406\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.8669,\tval_loss: 4.4180\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.8634,\tval_loss: 4.3604\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.8115,\tval_loss: 4.3983\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.7642,\tval_loss: 4.4727\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.8169,\tval_loss: 4.3868\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.8208,\tval_loss: 4.4307\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.8336,\tval_loss: 4.3932\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.7721,\tval_loss: 4.3897\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.7979,\tval_loss: 4.4032\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.8021,\tval_loss: 4.4259\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.7868,\tval_loss: 4.4135\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.7856,\tval_loss: 4.4083\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.7983,\tval_loss: 4.3712\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.7535,\tval_loss: 4.4416\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.7014,\tval_loss: 4.4975\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.7743,\tval_loss: 4.4023\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.7306,\tval_loss: 4.4801\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.6932,\tval_loss: 4.4960\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.7165,\tval_loss: 4.4507\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.7601,\tval_loss: 4.4732\n",
            "74:\t[0s / 3s],\t\ttrain_loss: 3.7636,\tval_loss: 4.3884\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4059,\tval_loss: 4.0476\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3283,\tval_loss: 4.0495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2792,\tval_loss: 4.0567\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2842,\tval_loss: 4.0688\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2179,\tval_loss: 4.0690\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2132,\tval_loss: 4.0648\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1615,\tval_loss: 4.0886\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1593,\tval_loss: 4.0772\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1721,\tval_loss: 4.0826\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1149,\tval_loss: 4.1086\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1175,\tval_loss: 4.0973\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0685,\tval_loss: 4.1114\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0868,\tval_loss: 4.1101\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0555,\tval_loss: 4.1166\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9941,\tval_loss: 4.1458\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0176,\tval_loss: 4.1671\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9981,\tval_loss: 4.0962\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9079,\tval_loss: 4.1892\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9163,\tval_loss: 4.1969\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9445,\tval_loss: 4.2481\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.8676,\tval_loss: 4.1887\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9434,\tval_loss: 4.2538\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8550,\tval_loss: 4.1940\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8941,\tval_loss: 4.2920\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8455,\tval_loss: 4.2411\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8464,\tval_loss: 4.2172\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8921,\tval_loss: 4.2606\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8562,\tval_loss: 4.3373\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8206,\tval_loss: 4.3143\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8263,\tval_loss: 4.2506\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7409,\tval_loss: 4.3431\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7758,\tval_loss: 4.3322\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7505,\tval_loss: 4.3390\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7317,\tval_loss: 4.3061\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7297,\tval_loss: 4.3957\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7702,\tval_loss: 4.3182\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7170,\tval_loss: 4.3183\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6671,\tval_loss: 4.3130\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7606,\tval_loss: 4.3867\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7475,\tval_loss: 4.3147\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6301,\tval_loss: 4.3420\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7006,\tval_loss: 4.3490\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.6304,\tval_loss: 4.4134\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6870,\tval_loss: 4.3592\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7162,\tval_loss: 4.3000\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7226,\tval_loss: 4.3086\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6666,\tval_loss: 4.3443\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6571,\tval_loss: 4.2991\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6073,\tval_loss: 4.3518\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6337,\tval_loss: 4.4576\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6318,\tval_loss: 4.3170\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6280,\tval_loss: 4.3517\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5893,\tval_loss: 4.3831\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6220,\tval_loss: 4.3467\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5057,\tval_loss: 4.4270\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5635,\tval_loss: 4.3990\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5992,\tval_loss: 4.3698\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5921,\tval_loss: 4.3885\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6253,\tval_loss: 4.3856\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6031,\tval_loss: 4.3980\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5373,\tval_loss: 4.3908\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5074,\tval_loss: 4.3956\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5624,\tval_loss: 4.4133\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5801,\tval_loss: 4.4088\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.5586,\tval_loss: 4.4153\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5369,\tval_loss: 4.4306\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6106,\tval_loss: 4.3721\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5096,\tval_loss: 4.3980\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3604,\tval_loss: 4.0964\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2875,\tval_loss: 4.0709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2727,\tval_loss: 4.0477\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2758,\tval_loss: 4.0265\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2276,\tval_loss: 4.0328\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2431,\tval_loss: 4.0268\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1881,\tval_loss: 4.0144\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1776,\tval_loss: 3.9889\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1487,\tval_loss: 4.0180\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1230,\tval_loss: 3.9970\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0614,\tval_loss: 3.9646\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0984,\tval_loss: 4.0074\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0605,\tval_loss: 4.0103\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1119,\tval_loss: 4.0078\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0035,\tval_loss: 4.0037\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9774,\tval_loss: 4.0106\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9569,\tval_loss: 4.0411\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9542,\tval_loss: 4.0699\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 4.0142,\tval_loss: 4.0069\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9040,\tval_loss: 4.0442\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9137,\tval_loss: 4.1006\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8255,\tval_loss: 4.0765\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9162,\tval_loss: 4.0809\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8668,\tval_loss: 4.0636\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7978,\tval_loss: 4.1418\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8031,\tval_loss: 4.0394\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7730,\tval_loss: 4.0728\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7593,\tval_loss: 4.1114\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7469,\tval_loss: 4.1000\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.8245,\tval_loss: 4.0939\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.7626,\tval_loss: 4.1556\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7605,\tval_loss: 4.1241\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7330,\tval_loss: 4.1106\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.6383,\tval_loss: 4.1667\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.6777,\tval_loss: 4.1230\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.6091,\tval_loss: 4.2017\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.6821,\tval_loss: 4.1612\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6699,\tval_loss: 4.1332\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.5744,\tval_loss: 4.1321\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6497,\tval_loss: 4.1873\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5851,\tval_loss: 4.2257\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7326,\tval_loss: 4.2158\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6879,\tval_loss: 4.1277\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6761,\tval_loss: 4.1562\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5276,\tval_loss: 4.1180\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.5502,\tval_loss: 4.1315\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.5780,\tval_loss: 4.1941\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.6516,\tval_loss: 4.1806\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.6165,\tval_loss: 4.2332\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.5513,\tval_loss: 4.1962\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.5980,\tval_loss: 4.1476\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.5729,\tval_loss: 4.1690\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.4697,\tval_loss: 4.1820\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.5595,\tval_loss: 4.3099\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6275,\tval_loss: 4.2002\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.5541,\tval_loss: 4.1253\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5368,\tval_loss: 4.2304\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5105,\tval_loss: 4.1862\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.4782,\tval_loss: 4.2040\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5152,\tval_loss: 4.2502\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5472,\tval_loss: 4.1982\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.4603,\tval_loss: 4.2185\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.5082,\tval_loss: 4.2500\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.4725,\tval_loss: 4.2601\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.5003,\tval_loss: 4.2247\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.4657,\tval_loss: 4.2266\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.5073,\tval_loss: 4.2279\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.4016,\tval_loss: 4.2505\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.4324,\tval_loss: 4.2277\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.4694,\tval_loss: 4.2429\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.4083,\tval_loss: 4.2331\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.5178,\tval_loss: 4.2040\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.4634,\tval_loss: 4.1845\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.3950,\tval_loss: 4.2460\n",
            "74:\t[0s / 4s],\t\ttrain_loss: 3.4692,\tval_loss: 4.3073\n",
            "75:\t[0s / 4s],\t\ttrain_loss: 3.4444,\tval_loss: 4.2347\n",
            "76:\t[0s / 5s],\t\ttrain_loss: 3.4464,\tval_loss: 4.2187\n",
            "77:\t[0s / 5s],\t\ttrain_loss: 3.4467,\tval_loss: 4.2284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4200,\tval_loss: 4.0848\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3237,\tval_loss: 4.0493\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2805,\tval_loss: 4.0397\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2597,\tval_loss: 4.0480\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2433,\tval_loss: 4.0616\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2138,\tval_loss: 4.0669\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1939,\tval_loss: 4.0667\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1726,\tval_loss: 4.0628\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1408,\tval_loss: 4.0878\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0956,\tval_loss: 4.1164\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1024,\tval_loss: 4.1402\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1216,\tval_loss: 4.1699\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0752,\tval_loss: 4.1890\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0318,\tval_loss: 4.2285\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0054,\tval_loss: 4.1897\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0187,\tval_loss: 4.2435\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0181,\tval_loss: 4.2198\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9263,\tval_loss: 4.2293\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9417,\tval_loss: 4.3639\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8617,\tval_loss: 4.3746\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8957,\tval_loss: 4.2977\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9079,\tval_loss: 4.3865\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9145,\tval_loss: 4.3507\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8248,\tval_loss: 4.3745\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8528,\tval_loss: 4.4163\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7605,\tval_loss: 4.4335\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8263,\tval_loss: 4.3961\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7737,\tval_loss: 4.4930\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7784,\tval_loss: 4.4801\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7122,\tval_loss: 4.5889\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7204,\tval_loss: 4.5702\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7009,\tval_loss: 4.4927\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7522,\tval_loss: 4.4698\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6915,\tval_loss: 4.5633\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7134,\tval_loss: 4.5686\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6793,\tval_loss: 4.6405\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6892,\tval_loss: 4.4975\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6559,\tval_loss: 4.6160\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6238,\tval_loss: 4.5739\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7115,\tval_loss: 4.5927\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6770,\tval_loss: 4.5536\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6302,\tval_loss: 4.6224\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6973,\tval_loss: 4.5976\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6643,\tval_loss: 4.6269\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5975,\tval_loss: 4.6466\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6125,\tval_loss: 4.6630\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6161,\tval_loss: 4.5615\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5974,\tval_loss: 4.6597\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6155,\tval_loss: 4.6258\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5793,\tval_loss: 4.7102\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5918,\tval_loss: 4.6563\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6288,\tval_loss: 4.5793\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5896,\tval_loss: 4.6874\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5811,\tval_loss: 4.7602\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5354,\tval_loss: 4.6982\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5874,\tval_loss: 4.7012\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5376,\tval_loss: 4.7317\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5284,\tval_loss: 4.7933\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5894,\tval_loss: 4.7595\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6241,\tval_loss: 4.6517\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6645,\tval_loss: 4.6161\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5872,\tval_loss: 4.6589\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5471,\tval_loss: 4.7657\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5425,\tval_loss: 4.7813\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5731,\tval_loss: 4.7395\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5798,\tval_loss: 4.7754\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5565,\tval_loss: 4.7398\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4772,\tval_loss: 4.7080\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5550,\tval_loss: 4.7278\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5275,\tval_loss: 4.7686\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4733,\tval_loss: 4.0988\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3092,\tval_loss: 4.0797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2397,\tval_loss: 4.0694\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2095,\tval_loss: 4.0577\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1751,\tval_loss: 4.0370\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1404,\tval_loss: 4.0407\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1395,\tval_loss: 4.0060\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1077,\tval_loss: 4.0179\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0946,\tval_loss: 4.0081\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0594,\tval_loss: 4.0586\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 3.9955,\tval_loss: 4.0736\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9388,\tval_loss: 4.0521\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9837,\tval_loss: 4.0987\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9327,\tval_loss: 4.0934\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.8841,\tval_loss: 4.1779\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9010,\tval_loss: 4.1602\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8040,\tval_loss: 4.2468\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8676,\tval_loss: 4.1816\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8267,\tval_loss: 4.2762\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.7248,\tval_loss: 4.2596\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.7377,\tval_loss: 4.3971\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7642,\tval_loss: 4.2848\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7672,\tval_loss: 4.3665\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.6965,\tval_loss: 4.3352\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.6904,\tval_loss: 4.3405\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6692,\tval_loss: 4.4153\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7241,\tval_loss: 4.3334\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6184,\tval_loss: 4.4571\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6254,\tval_loss: 4.4257\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.6855,\tval_loss: 4.4068\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.5944,\tval_loss: 4.3639\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6056,\tval_loss: 4.4089\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6127,\tval_loss: 4.4635\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.5687,\tval_loss: 4.3838\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.5530,\tval_loss: 4.4646\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.5664,\tval_loss: 4.3831\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.4978,\tval_loss: 4.5840\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.5146,\tval_loss: 4.4591\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.5615,\tval_loss: 4.4460\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.5748,\tval_loss: 4.4539\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.5677,\tval_loss: 4.3990\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.5165,\tval_loss: 4.4197\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.5502,\tval_loss: 4.4665\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5430,\tval_loss: 4.4019\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.4271,\tval_loss: 4.4613\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.4641,\tval_loss: 4.5313\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.4497,\tval_loss: 4.5382\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.4257,\tval_loss: 4.5988\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5282,\tval_loss: 4.5453\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.4437,\tval_loss: 4.4243\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.4057,\tval_loss: 4.5850\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.4622,\tval_loss: 4.5392\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.4759,\tval_loss: 4.5635\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5261,\tval_loss: 4.4292\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.4593,\tval_loss: 4.5007\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.4122,\tval_loss: 4.5319\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.3884,\tval_loss: 4.5678\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.4827,\tval_loss: 4.5077\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.4180,\tval_loss: 4.4638\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.4905,\tval_loss: 4.4065\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.4683,\tval_loss: 4.5091\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.4387,\tval_loss: 4.4718\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.4133,\tval_loss: 4.5041\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.4647,\tval_loss: 4.5420\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.4584,\tval_loss: 4.4879\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.3843,\tval_loss: 4.5579\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4536,\tval_loss: 4.4377\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.3071,\tval_loss: 4.5615\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.3515,\tval_loss: 4.5221\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.4125,\tval_loss: 4.5276\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.3838,\tval_loss: 4.5773\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.4234,\tval_loss: 4.4538\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.3634,\tval_loss: 4.5549\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.3695,\tval_loss: 4.5137\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.5564,\tval_loss: 4.1271\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3717,\tval_loss: 4.1195\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3295,\tval_loss: 4.1189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.3069,\tval_loss: 4.1113\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2397,\tval_loss: 4.1033\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2267,\tval_loss: 4.1348\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2339,\tval_loss: 4.0901\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2172,\tval_loss: 4.1381\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1945,\tval_loss: 4.1356\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1415,\tval_loss: 4.1434\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1515,\tval_loss: 4.1773\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1105,\tval_loss: 4.2030\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0923,\tval_loss: 4.2356\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0581,\tval_loss: 4.2172\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0577,\tval_loss: 4.2357\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9559,\tval_loss: 4.2882\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9249,\tval_loss: 4.2850\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9494,\tval_loss: 4.2912\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8543,\tval_loss: 4.3546\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8749,\tval_loss: 4.3240\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.8877,\tval_loss: 4.3445\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8695,\tval_loss: 4.3716\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8167,\tval_loss: 4.4266\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8435,\tval_loss: 4.3924\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7730,\tval_loss: 4.4067\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8041,\tval_loss: 4.4026\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7995,\tval_loss: 4.4435\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7696,\tval_loss: 4.3579\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7567,\tval_loss: 4.4535\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7183,\tval_loss: 4.5633\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7418,\tval_loss: 4.4482\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6649,\tval_loss: 4.6130\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6687,\tval_loss: 4.4991\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7783,\tval_loss: 4.3967\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7011,\tval_loss: 4.5292\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6880,\tval_loss: 4.4735\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7373,\tval_loss: 4.6004\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6755,\tval_loss: 4.5144\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6917,\tval_loss: 4.4189\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6039,\tval_loss: 4.5818\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6118,\tval_loss: 4.5209\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7039,\tval_loss: 4.4378\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.7508,\tval_loss: 4.4767\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6468,\tval_loss: 4.5827\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6297,\tval_loss: 4.5761\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6024,\tval_loss: 4.5688\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6036,\tval_loss: 4.5769\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5816,\tval_loss: 4.6068\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5953,\tval_loss: 4.6388\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5954,\tval_loss: 4.5393\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5721,\tval_loss: 4.5347\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6410,\tval_loss: 4.5875\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6188,\tval_loss: 4.5309\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6408,\tval_loss: 4.4817\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.5361,\tval_loss: 4.7193\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6002,\tval_loss: 4.6443\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6061,\tval_loss: 4.5713\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5724,\tval_loss: 4.6366\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6058,\tval_loss: 4.5124\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5255,\tval_loss: 4.6444\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5599,\tval_loss: 4.5057\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5143,\tval_loss: 4.6068\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5394,\tval_loss: 4.6232\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.4952,\tval_loss: 4.7544\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6350,\tval_loss: 4.4855\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5576,\tval_loss: 4.6538\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5980,\tval_loss: 4.6055\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5648,\tval_loss: 4.6543\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.5293,\tval_loss: 4.5649\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.5473,\tval_loss: 4.6562\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.5765,\tval_loss: 4.6735\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.5539,\tval_loss: 4.6135\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.5530,\tval_loss: 4.6261\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.5384,\tval_loss: 4.6791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3437,\tval_loss: 4.0516\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.1871,\tval_loss: 4.0686\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1109,\tval_loss: 4.0617\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1461,\tval_loss: 4.0671\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1220,\tval_loss: 4.0769\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1087,\tval_loss: 4.0787\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0610,\tval_loss: 4.0866\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0460,\tval_loss: 4.0860\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0546,\tval_loss: 4.1105\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0530,\tval_loss: 4.1283\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0550,\tval_loss: 4.1448\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9925,\tval_loss: 4.1109\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0013,\tval_loss: 4.1648\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 4.0080,\tval_loss: 4.1911\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.8993,\tval_loss: 4.1795\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9236,\tval_loss: 4.2416\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9093,\tval_loss: 4.2458\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8890,\tval_loss: 4.2831\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.8832,\tval_loss: 4.2851\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9239,\tval_loss: 4.2737\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9048,\tval_loss: 4.2708\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8505,\tval_loss: 4.3610\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8535,\tval_loss: 4.2919\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8626,\tval_loss: 4.3537\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7576,\tval_loss: 4.3935\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8161,\tval_loss: 4.3947\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7671,\tval_loss: 4.4230\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7594,\tval_loss: 4.4004\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 3.8154,\tval_loss: 4.4010\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.7464,\tval_loss: 4.4444\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.7467,\tval_loss: 4.3926\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7315,\tval_loss: 4.4606\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.5847,\tval_loss: 4.4212\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.7078,\tval_loss: 4.4619\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7512,\tval_loss: 4.3997\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7268,\tval_loss: 4.4213\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7257,\tval_loss: 4.5150\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7329,\tval_loss: 4.3997\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6315,\tval_loss: 4.5071\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7090,\tval_loss: 4.4656\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6686,\tval_loss: 4.4208\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6558,\tval_loss: 4.4395\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6474,\tval_loss: 4.4415\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 3.6740,\tval_loss: 4.5546\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.6904,\tval_loss: 4.4606\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.6337,\tval_loss: 4.5074\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.7493,\tval_loss: 4.4221\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.6544,\tval_loss: 4.4002\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.6535,\tval_loss: 4.4327\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6614,\tval_loss: 4.4380\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6608,\tval_loss: 4.4044\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.6712,\tval_loss: 4.4036\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6654,\tval_loss: 4.4686\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6033,\tval_loss: 4.4939\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6494,\tval_loss: 4.4718\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6504,\tval_loss: 4.4319\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6848,\tval_loss: 4.4988\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6446,\tval_loss: 4.3466\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 3.5742,\tval_loss: 4.4633\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 3.6361,\tval_loss: 4.4982\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 3.6224,\tval_loss: 4.5208\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.6057,\tval_loss: 4.4266\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.6410,\tval_loss: 4.4572\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.6426,\tval_loss: 4.3980\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.6372,\tval_loss: 4.4259\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.6324,\tval_loss: 4.4239\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.5915,\tval_loss: 4.4099\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.5539,\tval_loss: 4.5304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4415,\tval_loss: 4.0675\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3278,\tval_loss: 4.0460\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3094,\tval_loss: 4.0384\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2543,\tval_loss: 4.0233\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1968,\tval_loss: 4.0186\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1779,\tval_loss: 4.0215\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2182,\tval_loss: 4.0048\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1923,\tval_loss: 4.0275\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1870,\tval_loss: 4.0167\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1446,\tval_loss: 4.0074\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1463,\tval_loss: 4.0092\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1076,\tval_loss: 4.0489\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0663,\tval_loss: 4.0719\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0675,\tval_loss: 4.0688\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0580,\tval_loss: 4.1053\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0196,\tval_loss: 4.1129\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9540,\tval_loss: 4.1834\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9182,\tval_loss: 4.1755\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0236,\tval_loss: 4.1366\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9771,\tval_loss: 4.1623\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.8615,\tval_loss: 4.1989\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8906,\tval_loss: 4.1864\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9049,\tval_loss: 4.2147\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9155,\tval_loss: 4.1239\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8637,\tval_loss: 4.1725\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8411,\tval_loss: 4.2200\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7521,\tval_loss: 4.2886\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7574,\tval_loss: 4.2471\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7863,\tval_loss: 4.2219\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7903,\tval_loss: 4.3204\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7462,\tval_loss: 4.2729\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7086,\tval_loss: 4.2891\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7243,\tval_loss: 4.3099\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6683,\tval_loss: 4.3680\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7381,\tval_loss: 4.2816\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6750,\tval_loss: 4.3042\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6325,\tval_loss: 4.3371\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7039,\tval_loss: 4.3117\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7607,\tval_loss: 4.3156\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6964,\tval_loss: 4.3310\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6413,\tval_loss: 4.3800\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7008,\tval_loss: 4.3051\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6050,\tval_loss: 4.3445\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6507,\tval_loss: 4.3839\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6869,\tval_loss: 4.3018\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5929,\tval_loss: 4.3266\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5539,\tval_loss: 4.4426\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6655,\tval_loss: 4.2881\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5887,\tval_loss: 4.3645\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5646,\tval_loss: 4.3670\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5158,\tval_loss: 4.4352\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5749,\tval_loss: 4.4193\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6737,\tval_loss: 4.3679\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6303,\tval_loss: 4.3786\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5962,\tval_loss: 4.3601\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5486,\tval_loss: 4.3445\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6421,\tval_loss: 4.3104\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6476,\tval_loss: 4.3156\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.4902,\tval_loss: 4.4572\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5347,\tval_loss: 4.3881\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5383,\tval_loss: 4.3929\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5096,\tval_loss: 4.3907\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.4364,\tval_loss: 4.4200\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5377,\tval_loss: 4.4076\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5915,\tval_loss: 4.3533\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5522,\tval_loss: 4.2776\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5784,\tval_loss: 4.3539\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5931,\tval_loss: 4.3655\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.4988,\tval_loss: 4.3364\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5153,\tval_loss: 4.3938\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.4812,\tval_loss: 4.4015\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.5085,\tval_loss: 4.3619\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.4925,\tval_loss: 4.3694\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.5607,\tval_loss: 4.3922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4489,\tval_loss: 4.0227\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3692,\tval_loss: 4.0523\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3148,\tval_loss: 4.0242\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.3120,\tval_loss: 4.0144\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2676,\tval_loss: 4.0185\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2602,\tval_loss: 4.0190\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2472,\tval_loss: 4.0278\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2391,\tval_loss: 4.0292\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.2132,\tval_loss: 4.0025\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.2027,\tval_loss: 4.0099\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1854,\tval_loss: 4.0139\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1477,\tval_loss: 4.0127\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1483,\tval_loss: 4.0509\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1590,\tval_loss: 4.0309\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.1001,\tval_loss: 4.0460\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0792,\tval_loss: 4.0675\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0408,\tval_loss: 4.0913\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0145,\tval_loss: 4.0941\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0437,\tval_loss: 4.0449\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9599,\tval_loss: 4.1435\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 4.0030,\tval_loss: 4.1111\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9606,\tval_loss: 4.1283\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9795,\tval_loss: 4.1263\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9398,\tval_loss: 4.1302\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9625,\tval_loss: 4.1206\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8977,\tval_loss: 4.1221\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9356,\tval_loss: 4.1251\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9272,\tval_loss: 4.1036\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.9262,\tval_loss: 4.0825\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8985,\tval_loss: 4.1435\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8400,\tval_loss: 4.1035\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8802,\tval_loss: 4.1532\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7626,\tval_loss: 4.1603\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8231,\tval_loss: 4.1583\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8314,\tval_loss: 4.2014\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8311,\tval_loss: 4.2218\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.8467,\tval_loss: 4.1611\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.8455,\tval_loss: 4.1570\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.8205,\tval_loss: 4.2046\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.8128,\tval_loss: 4.2410\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7450,\tval_loss: 4.2091\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7027,\tval_loss: 4.2152\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.7999,\tval_loss: 4.2048\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7616,\tval_loss: 4.2492\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7594,\tval_loss: 4.1711\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7147,\tval_loss: 4.2003\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7324,\tval_loss: 4.2507\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7634,\tval_loss: 4.2115\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7253,\tval_loss: 4.2402\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7227,\tval_loss: 4.1788\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6991,\tval_loss: 4.3000\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7281,\tval_loss: 4.2603\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7892,\tval_loss: 4.2261\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6849,\tval_loss: 4.1921\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6710,\tval_loss: 4.3016\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6547,\tval_loss: 4.2787\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.7169,\tval_loss: 4.2449\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.7726,\tval_loss: 4.2389\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6856,\tval_loss: 4.2845\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6811,\tval_loss: 4.2629\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.7622,\tval_loss: 4.2436\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.7147,\tval_loss: 4.2315\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.7111,\tval_loss: 4.2785\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.6567,\tval_loss: 4.3059\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.6875,\tval_loss: 4.2860\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.7239,\tval_loss: 4.1829\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.7093,\tval_loss: 4.2243\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.7310,\tval_loss: 4.2506\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6629,\tval_loss: 4.3102\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6846,\tval_loss: 4.2343\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6385,\tval_loss: 4.2189\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.6264,\tval_loss: 4.2257\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.7233,\tval_loss: 4.2534\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.7071,\tval_loss: 4.2818\n",
            "74:\t[0s / 3s],\t\ttrain_loss: 3.6831,\tval_loss: 4.3074\n",
            "75:\t[0s / 3s],\t\ttrain_loss: 3.6602,\tval_loss: 4.3095\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3865,\tval_loss: 4.1087\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2893,\tval_loss: 4.1122\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2526,\tval_loss: 4.0936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2252,\tval_loss: 4.0890\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2262,\tval_loss: 4.0832\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2082,\tval_loss: 4.0914\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1914,\tval_loss: 4.0781\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1955,\tval_loss: 4.0953\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1492,\tval_loss: 4.0660\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1240,\tval_loss: 4.0798\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1689,\tval_loss: 4.1095\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0685,\tval_loss: 4.0900\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0959,\tval_loss: 4.0856\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0668,\tval_loss: 4.1103\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0417,\tval_loss: 4.1369\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9878,\tval_loss: 4.1677\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9221,\tval_loss: 4.1760\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0199,\tval_loss: 4.1783\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9800,\tval_loss: 4.2019\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9105,\tval_loss: 4.2015\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8946,\tval_loss: 4.2448\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9483,\tval_loss: 4.1647\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8765,\tval_loss: 4.2588\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8693,\tval_loss: 4.3005\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8630,\tval_loss: 4.2452\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8365,\tval_loss: 4.2301\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9777,\tval_loss: 4.2191\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7809,\tval_loss: 4.3051\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8693,\tval_loss: 4.3093\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8250,\tval_loss: 4.3061\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8339,\tval_loss: 4.2859\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8114,\tval_loss: 4.2671\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8209,\tval_loss: 4.2114\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7913,\tval_loss: 4.2357\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8031,\tval_loss: 4.2723\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7714,\tval_loss: 4.2930\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7531,\tval_loss: 4.3118\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6968,\tval_loss: 4.4354\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7716,\tval_loss: 4.2213\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7199,\tval_loss: 4.3583\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7758,\tval_loss: 4.3045\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7767,\tval_loss: 4.2325\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7747,\tval_loss: 4.3185\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7646,\tval_loss: 4.2663\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6975,\tval_loss: 4.2878\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6626,\tval_loss: 4.3946\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.8029,\tval_loss: 4.2956\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7345,\tval_loss: 4.3278\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7657,\tval_loss: 4.3186\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7357,\tval_loss: 4.2676\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7496,\tval_loss: 4.3698\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7450,\tval_loss: 4.2100\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7141,\tval_loss: 4.2517\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7246,\tval_loss: 4.2822\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7657,\tval_loss: 4.2839\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.7313,\tval_loss: 4.2633\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.7565,\tval_loss: 4.2936\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.7275,\tval_loss: 4.2324\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6423,\tval_loss: 4.2866\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6238,\tval_loss: 4.3082\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.7039,\tval_loss: 4.3285\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.7283,\tval_loss: 4.3065\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.7125,\tval_loss: 4.3294\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6853,\tval_loss: 4.2238\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6586,\tval_loss: 4.3393\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5962,\tval_loss: 4.3549\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.7288,\tval_loss: 4.2270\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6913,\tval_loss: 4.2277\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6980,\tval_loss: 4.2363\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6699,\tval_loss: 4.2590\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.7216,\tval_loss: 4.2132\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.6786,\tval_loss: 4.2634\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.6673,\tval_loss: 4.3037\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.6661,\tval_loss: 4.2756\n",
            "74:\t[0s / 3s],\t\ttrain_loss: 3.6460,\tval_loss: 4.2970\n",
            "75:\t[0s / 3s],\t\ttrain_loss: 3.7533,\tval_loss: 4.2367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3678,\tval_loss: 4.0956\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2189,\tval_loss: 4.0788\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2045,\tval_loss: 4.0804\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2051,\tval_loss: 4.0877\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1451,\tval_loss: 4.0849\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1371,\tval_loss: 4.1065\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1588,\tval_loss: 4.0848\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1284,\tval_loss: 4.0847\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1275,\tval_loss: 4.0962\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1616,\tval_loss: 4.1027\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1179,\tval_loss: 4.0837\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0911,\tval_loss: 4.1055\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1159,\tval_loss: 4.0885\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0759,\tval_loss: 4.1039\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.1019,\tval_loss: 4.0944\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0604,\tval_loss: 4.0872\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 4.0130,\tval_loss: 4.1302\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9943,\tval_loss: 4.1167\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9929,\tval_loss: 4.1373\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9752,\tval_loss: 4.1458\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8914,\tval_loss: 4.1424\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9509,\tval_loss: 4.1347\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8816,\tval_loss: 4.2417\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7972,\tval_loss: 4.1492\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8847,\tval_loss: 4.2570\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8715,\tval_loss: 4.2667\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7788,\tval_loss: 4.2509\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8697,\tval_loss: 4.2790\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8348,\tval_loss: 4.2727\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.8007,\tval_loss: 4.2472\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.7200,\tval_loss: 4.3023\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7425,\tval_loss: 4.2973\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7512,\tval_loss: 4.3063\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.7349,\tval_loss: 4.3688\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.6560,\tval_loss: 4.3469\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7126,\tval_loss: 4.3697\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7243,\tval_loss: 4.3830\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7440,\tval_loss: 4.4306\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6195,\tval_loss: 4.4668\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6972,\tval_loss: 4.3722\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6803,\tval_loss: 4.4330\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6393,\tval_loss: 4.4221\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5999,\tval_loss: 4.4949\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 3.5718,\tval_loss: 4.4563\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.6141,\tval_loss: 4.4072\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.6100,\tval_loss: 4.4402\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.5337,\tval_loss: 4.4386\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.6250,\tval_loss: 4.4668\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.6146,\tval_loss: 4.4660\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.5190,\tval_loss: 4.4719\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.5825,\tval_loss: 4.4822\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.5811,\tval_loss: 4.4889\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.5711,\tval_loss: 4.5365\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.5486,\tval_loss: 4.5241\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.4927,\tval_loss: 4.6389\n",
            "55:\t[0s / 4s],\t\ttrain_loss: 3.4833,\tval_loss: 4.5926\n",
            "56:\t[0s / 4s],\t\ttrain_loss: 3.5044,\tval_loss: 4.5634\n",
            "57:\t[0s / 4s],\t\ttrain_loss: 3.5173,\tval_loss: 4.4939\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 3.5410,\tval_loss: 4.5263\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 3.4408,\tval_loss: 4.5060\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 3.5923,\tval_loss: 4.5224\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.5110,\tval_loss: 4.4853\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.5035,\tval_loss: 4.5085\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.5103,\tval_loss: 4.5821\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.4304,\tval_loss: 4.6074\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.4396,\tval_loss: 4.5017\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.5228,\tval_loss: 4.5409\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.5256,\tval_loss: 4.5456\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.4923,\tval_loss: 4.5119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4790,\tval_loss: 4.0681\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3340,\tval_loss: 4.0450\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3152,\tval_loss: 4.0457\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2641,\tval_loss: 4.0438\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2443,\tval_loss: 4.0453\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2310,\tval_loss: 4.0386\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2193,\tval_loss: 4.0297\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2070,\tval_loss: 4.0515\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1740,\tval_loss: 4.0488\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1390,\tval_loss: 4.0744\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1442,\tval_loss: 4.1011\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1069,\tval_loss: 4.1089\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0853,\tval_loss: 4.0954\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0452,\tval_loss: 4.1628\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0635,\tval_loss: 4.1503\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0018,\tval_loss: 4.1636\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9922,\tval_loss: 4.1819\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9750,\tval_loss: 4.1970\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9501,\tval_loss: 4.1980\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9135,\tval_loss: 4.2667\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9167,\tval_loss: 4.2885\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9053,\tval_loss: 4.2740\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9635,\tval_loss: 4.2329\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8893,\tval_loss: 4.2700\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9027,\tval_loss: 4.3362\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8602,\tval_loss: 4.3214\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8408,\tval_loss: 4.2917\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8716,\tval_loss: 4.3277\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8254,\tval_loss: 4.3613\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8473,\tval_loss: 4.2789\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.8866,\tval_loss: 4.3222\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7663,\tval_loss: 4.3036\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7981,\tval_loss: 4.3068\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.8038,\tval_loss: 4.3921\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.8366,\tval_loss: 4.2607\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.8649,\tval_loss: 4.3214\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.8016,\tval_loss: 4.3438\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7799,\tval_loss: 4.3427\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.8027,\tval_loss: 4.3073\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7429,\tval_loss: 4.3818\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7557,\tval_loss: 4.3944\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7082,\tval_loss: 4.3094\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7335,\tval_loss: 4.3676\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7509,\tval_loss: 4.3298\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6920,\tval_loss: 4.3513\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.7241,\tval_loss: 4.3860\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.6822,\tval_loss: 4.3840\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.7639,\tval_loss: 4.4087\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.7189,\tval_loss: 4.4220\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6832,\tval_loss: 4.3923\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6820,\tval_loss: 4.4272\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.7111,\tval_loss: 4.3091\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.7034,\tval_loss: 4.3403\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6665,\tval_loss: 4.3786\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6713,\tval_loss: 4.3679\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6628,\tval_loss: 4.3744\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6686,\tval_loss: 4.4875\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6493,\tval_loss: 4.3809\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.7091,\tval_loss: 4.3822\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6789,\tval_loss: 4.3677\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6812,\tval_loss: 4.3859\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.6113,\tval_loss: 4.4189\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.6191,\tval_loss: 4.4755\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.7181,\tval_loss: 4.3329\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.6550,\tval_loss: 4.4189\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.5617,\tval_loss: 4.5031\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.6073,\tval_loss: 4.4393\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.6356,\tval_loss: 4.4152\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.7305,\tval_loss: 4.3905\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.6494,\tval_loss: 4.3838\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.6175,\tval_loss: 4.4314\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.5804,\tval_loss: 4.4393\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.5994,\tval_loss: 4.4232\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.6613,\tval_loss: 4.4280\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4226,\tval_loss: 4.0977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2618,\tval_loss: 4.0682\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2244,\tval_loss: 4.0740\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1834,\tval_loss: 4.0831\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1546,\tval_loss: 4.0575\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1374,\tval_loss: 4.0640\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0801,\tval_loss: 4.0809\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0763,\tval_loss: 4.1095\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1152,\tval_loss: 4.0949\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0960,\tval_loss: 4.0997\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0716,\tval_loss: 4.1158\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0655,\tval_loss: 4.1182\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0870,\tval_loss: 4.0952\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0790,\tval_loss: 4.1019\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0397,\tval_loss: 4.1530\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0179,\tval_loss: 4.1534\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9795,\tval_loss: 4.1673\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9246,\tval_loss: 4.1639\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9074,\tval_loss: 4.2174\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8661,\tval_loss: 4.2771\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8873,\tval_loss: 4.2885\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8282,\tval_loss: 4.3176\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8934,\tval_loss: 4.2295\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8352,\tval_loss: 4.3382\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8118,\tval_loss: 4.3155\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8212,\tval_loss: 4.2865\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7741,\tval_loss: 4.2941\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8357,\tval_loss: 4.2923\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7592,\tval_loss: 4.3735\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7807,\tval_loss: 4.3482\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7181,\tval_loss: 4.3279\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7177,\tval_loss: 4.3527\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7382,\tval_loss: 4.3024\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6900,\tval_loss: 4.4099\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6931,\tval_loss: 4.3922\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6894,\tval_loss: 4.3625\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6858,\tval_loss: 4.3957\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6333,\tval_loss: 4.3392\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6537,\tval_loss: 4.4051\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6283,\tval_loss: 4.4471\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.5732,\tval_loss: 4.4407\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6167,\tval_loss: 4.4625\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6832,\tval_loss: 4.4532\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5838,\tval_loss: 4.3974\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6358,\tval_loss: 4.4366\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6608,\tval_loss: 4.4035\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6289,\tval_loss: 4.4266\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5848,\tval_loss: 4.4019\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5380,\tval_loss: 4.4976\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6328,\tval_loss: 4.4679\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5787,\tval_loss: 4.4961\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5314,\tval_loss: 4.4471\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5674,\tval_loss: 4.5018\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.4959,\tval_loss: 4.5135\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5632,\tval_loss: 4.4901\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5279,\tval_loss: 4.4584\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5295,\tval_loss: 4.5449\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5392,\tval_loss: 4.5566\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5591,\tval_loss: 4.4747\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5981,\tval_loss: 4.4252\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5316,\tval_loss: 4.4204\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.4886,\tval_loss: 4.4912\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.4567,\tval_loss: 4.4935\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5382,\tval_loss: 4.5151\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5218,\tval_loss: 4.4914\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5263,\tval_loss: 4.5048\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4875,\tval_loss: 4.5040\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5109,\tval_loss: 4.5051\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5295,\tval_loss: 4.4767\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5144,\tval_loss: 4.4840\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5099,\tval_loss: 4.5553\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.4777,\tval_loss: 4.5457\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4433,\tval_loss: 4.0800\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2741,\tval_loss: 4.0965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2284,\tval_loss: 4.0893\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2167,\tval_loss: 4.0701\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2309,\tval_loss: 4.0645\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2080,\tval_loss: 4.0679\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1338,\tval_loss: 4.0603\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1447,\tval_loss: 4.0781\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1451,\tval_loss: 4.0685\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0698,\tval_loss: 4.0606\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0819,\tval_loss: 4.1006\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0536,\tval_loss: 4.1028\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0417,\tval_loss: 4.0945\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0481,\tval_loss: 4.1180\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9882,\tval_loss: 4.1002\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9184,\tval_loss: 4.1461\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9980,\tval_loss: 4.1648\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9013,\tval_loss: 4.1863\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9277,\tval_loss: 4.2032\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8719,\tval_loss: 4.2450\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8947,\tval_loss: 4.2596\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8522,\tval_loss: 4.2295\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7933,\tval_loss: 4.2541\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8472,\tval_loss: 4.2537\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8097,\tval_loss: 4.2559\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8222,\tval_loss: 4.2977\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7364,\tval_loss: 4.3332\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8775,\tval_loss: 4.2327\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7912,\tval_loss: 4.2903\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7580,\tval_loss: 4.3857\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7729,\tval_loss: 4.3185\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7455,\tval_loss: 4.2951\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8060,\tval_loss: 4.2966\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6827,\tval_loss: 4.3815\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6983,\tval_loss: 4.3548\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6877,\tval_loss: 4.3561\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7589,\tval_loss: 4.3006\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6692,\tval_loss: 4.3575\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6684,\tval_loss: 4.3760\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6438,\tval_loss: 4.3937\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5872,\tval_loss: 4.4203\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5603,\tval_loss: 4.5393\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6783,\tval_loss: 4.4523\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7308,\tval_loss: 4.4157\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6782,\tval_loss: 4.3594\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6919,\tval_loss: 4.4028\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6423,\tval_loss: 4.4969\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6334,\tval_loss: 4.4370\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6091,\tval_loss: 4.4555\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6842,\tval_loss: 4.4060\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7105,\tval_loss: 4.3471\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.6566,\tval_loss: 4.4401\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6255,\tval_loss: 4.4898\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6411,\tval_loss: 4.4356\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6394,\tval_loss: 4.3860\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6636,\tval_loss: 4.4733\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5800,\tval_loss: 4.4469\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5784,\tval_loss: 4.5175\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5161,\tval_loss: 4.5329\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.4982,\tval_loss: 4.5635\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5662,\tval_loss: 4.5101\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6082,\tval_loss: 4.5030\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5693,\tval_loss: 4.4890\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.4879,\tval_loss: 4.6223\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5173,\tval_loss: 4.5672\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.6096,\tval_loss: 4.4736\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.5667,\tval_loss: 4.5181\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.5369,\tval_loss: 4.5178\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.6252,\tval_loss: 4.5328\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.5548,\tval_loss: 4.4305\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.4253,\tval_loss: 4.5715\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.4822,\tval_loss: 4.5249\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.5756,\tval_loss: 4.4829\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.5519,\tval_loss: 4.5686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3766,\tval_loss: 4.0594\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.1959,\tval_loss: 4.0593\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1575,\tval_loss: 4.0949\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1058,\tval_loss: 4.0985\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1381,\tval_loss: 4.0811\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.0989,\tval_loss: 4.0875\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0374,\tval_loss: 4.1220\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0316,\tval_loss: 4.1255\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 3.9683,\tval_loss: 4.1624\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0024,\tval_loss: 4.1862\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 3.9949,\tval_loss: 4.2307\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9881,\tval_loss: 4.1672\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9400,\tval_loss: 4.2457\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.8325,\tval_loss: 4.2862\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.8430,\tval_loss: 4.2515\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.8059,\tval_loss: 4.3335\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.8160,\tval_loss: 4.2952\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8138,\tval_loss: 4.3212\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.7222,\tval_loss: 4.3107\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.7536,\tval_loss: 4.2695\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.7397,\tval_loss: 4.3670\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.6103,\tval_loss: 4.2702\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.6938,\tval_loss: 4.3128\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.6750,\tval_loss: 4.3274\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.6363,\tval_loss: 4.4436\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6580,\tval_loss: 4.3148\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6798,\tval_loss: 4.4726\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6196,\tval_loss: 4.3546\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6189,\tval_loss: 4.3956\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.5806,\tval_loss: 4.4402\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.6047,\tval_loss: 4.2918\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.6475,\tval_loss: 4.3532\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.6408,\tval_loss: 4.4869\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.5714,\tval_loss: 4.3244\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.6470,\tval_loss: 4.4457\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.6155,\tval_loss: 4.3977\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.5536,\tval_loss: 4.3709\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6197,\tval_loss: 4.3791\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.5840,\tval_loss: 4.3637\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.5779,\tval_loss: 4.3666\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5819,\tval_loss: 4.3763\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5348,\tval_loss: 4.4245\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.4977,\tval_loss: 4.4728\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.4969,\tval_loss: 4.4263\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.4713,\tval_loss: 4.6132\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5335,\tval_loss: 4.5057\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5015,\tval_loss: 4.3440\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5347,\tval_loss: 4.4656\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.3677,\tval_loss: 4.5987\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5482,\tval_loss: 4.2834\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.4987,\tval_loss: 4.4892\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.4978,\tval_loss: 4.4973\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.4070,\tval_loss: 4.4897\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.4678,\tval_loss: 4.6159\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.4946,\tval_loss: 4.3553\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.4795,\tval_loss: 4.4196\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.4747,\tval_loss: 4.4371\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5528,\tval_loss: 4.3787\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.3833,\tval_loss: 4.4461\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.4312,\tval_loss: 4.3811\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.4922,\tval_loss: 4.4488\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.4938,\tval_loss: 4.3917\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.4840,\tval_loss: 4.3774\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.4890,\tval_loss: 4.3713\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5321,\tval_loss: 4.3308\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.4444,\tval_loss: 4.3794\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4834,\tval_loss: 4.4674\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4264,\tval_loss: 4.4559\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.3215,\tval_loss: 4.4533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4030,\tval_loss: 4.0341\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2179,\tval_loss: 4.0305\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1892,\tval_loss: 4.0422\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1497,\tval_loss: 4.0406\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1489,\tval_loss: 4.0380\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1280,\tval_loss: 4.0504\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0717,\tval_loss: 4.0683\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0822,\tval_loss: 4.0704\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0576,\tval_loss: 4.0649\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0469,\tval_loss: 4.0690\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0087,\tval_loss: 4.0840\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9917,\tval_loss: 4.0514\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9040,\tval_loss: 4.1584\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9524,\tval_loss: 4.1660\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.8906,\tval_loss: 4.1866\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.8637,\tval_loss: 4.1986\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8341,\tval_loss: 4.2316\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.7313,\tval_loss: 4.2848\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.7728,\tval_loss: 4.3179\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.7209,\tval_loss: 4.2299\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.7174,\tval_loss: 4.3486\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.6770,\tval_loss: 4.3729\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.6518,\tval_loss: 4.3266\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.6667,\tval_loss: 4.3226\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.6176,\tval_loss: 4.3360\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.5590,\tval_loss: 4.5158\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.4876,\tval_loss: 4.3637\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.5598,\tval_loss: 4.5493\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.5355,\tval_loss: 4.4382\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.5998,\tval_loss: 4.4143\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.5893,\tval_loss: 4.3684\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.4842,\tval_loss: 4.4966\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.5229,\tval_loss: 4.4639\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.5016,\tval_loss: 4.4938\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.5445,\tval_loss: 4.5438\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.5592,\tval_loss: 4.4059\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.5050,\tval_loss: 4.5317\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.5068,\tval_loss: 4.5280\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.5319,\tval_loss: 4.5490\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.4634,\tval_loss: 4.5607\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.4023,\tval_loss: 4.6469\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.4346,\tval_loss: 4.5431\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.4156,\tval_loss: 4.5123\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.4111,\tval_loss: 4.5917\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.4359,\tval_loss: 4.5069\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.4054,\tval_loss: 4.6308\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.4209,\tval_loss: 4.5634\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.4761,\tval_loss: 4.5071\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.4190,\tval_loss: 4.5011\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.3604,\tval_loss: 4.4822\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.3733,\tval_loss: 4.5160\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.4012,\tval_loss: 4.6373\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.4187,\tval_loss: 4.5971\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.3991,\tval_loss: 4.5714\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.3914,\tval_loss: 4.4902\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.4074,\tval_loss: 4.5437\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.3883,\tval_loss: 4.5862\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.4156,\tval_loss: 4.5892\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.3521,\tval_loss: 4.5791\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.4213,\tval_loss: 4.5901\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.4050,\tval_loss: 4.6012\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.4413,\tval_loss: 4.5745\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.4181,\tval_loss: 4.5489\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.3977,\tval_loss: 4.5883\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.3319,\tval_loss: 4.6017\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.4066,\tval_loss: 4.7275\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4048,\tval_loss: 4.5681\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.3671,\tval_loss: 4.6203\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.3260,\tval_loss: 4.6242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3949,\tval_loss: 4.0490\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3206,\tval_loss: 4.0303\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2508,\tval_loss: 4.0225\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2218,\tval_loss: 4.0264\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2394,\tval_loss: 4.0288\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2210,\tval_loss: 4.0264\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1883,\tval_loss: 4.0305\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2158,\tval_loss: 4.0334\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.2001,\tval_loss: 4.0402\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1511,\tval_loss: 4.0750\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1592,\tval_loss: 4.0416\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1457,\tval_loss: 4.0859\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1063,\tval_loss: 4.0958\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0777,\tval_loss: 4.0878\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0277,\tval_loss: 4.0878\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9589,\tval_loss: 4.1906\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0058,\tval_loss: 4.1472\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9827,\tval_loss: 4.1725\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9564,\tval_loss: 4.2114\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8848,\tval_loss: 4.1942\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.8923,\tval_loss: 4.1961\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9185,\tval_loss: 4.1771\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7902,\tval_loss: 4.2611\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8558,\tval_loss: 4.2533\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8235,\tval_loss: 4.2524\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8044,\tval_loss: 4.2828\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8158,\tval_loss: 4.2705\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8122,\tval_loss: 4.2533\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7370,\tval_loss: 4.2977\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.6990,\tval_loss: 4.2905\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7383,\tval_loss: 4.2747\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6985,\tval_loss: 4.3553\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7870,\tval_loss: 4.2778\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7952,\tval_loss: 4.3062\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6988,\tval_loss: 4.3335\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7210,\tval_loss: 4.2975\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6295,\tval_loss: 4.3500\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6212,\tval_loss: 4.3575\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.5838,\tval_loss: 4.3230\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6649,\tval_loss: 4.3228\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6738,\tval_loss: 4.2647\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6683,\tval_loss: 4.3364\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.5994,\tval_loss: 4.3879\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6256,\tval_loss: 4.3512\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6357,\tval_loss: 4.2900\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6893,\tval_loss: 4.4462\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6177,\tval_loss: 4.3730\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6388,\tval_loss: 4.3827\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5332,\tval_loss: 4.3738\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6396,\tval_loss: 4.3843\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6036,\tval_loss: 4.3673\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5949,\tval_loss: 4.3250\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5613,\tval_loss: 4.3795\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5206,\tval_loss: 4.5008\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6157,\tval_loss: 4.3824\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6580,\tval_loss: 4.3490\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5594,\tval_loss: 4.3152\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5329,\tval_loss: 4.3709\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5171,\tval_loss: 4.3921\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5796,\tval_loss: 4.3833\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6458,\tval_loss: 4.4304\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5125,\tval_loss: 4.4253\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5254,\tval_loss: 4.3783\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5268,\tval_loss: 4.4870\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.4731,\tval_loss: 4.3953\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5509,\tval_loss: 4.3563\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4857,\tval_loss: 4.4595\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5944,\tval_loss: 4.3778\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.4233,\tval_loss: 4.4396\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.4908,\tval_loss: 4.3966\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3668,\tval_loss: 4.0176\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3026,\tval_loss: 4.0422\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2393,\tval_loss: 4.0528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2375,\tval_loss: 4.0460\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2179,\tval_loss: 4.0541\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2184,\tval_loss: 4.0526\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1924,\tval_loss: 4.0555\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1988,\tval_loss: 4.0323\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1590,\tval_loss: 4.0360\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1913,\tval_loss: 4.0566\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1619,\tval_loss: 4.0794\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1645,\tval_loss: 4.0715\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1457,\tval_loss: 4.0702\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1039,\tval_loss: 4.0871\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0828,\tval_loss: 4.0882\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0430,\tval_loss: 4.1188\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0968,\tval_loss: 4.0725\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0626,\tval_loss: 4.1212\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9820,\tval_loss: 4.0782\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9940,\tval_loss: 4.1138\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.9658,\tval_loss: 4.1174\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9713,\tval_loss: 4.1419\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 4.0197,\tval_loss: 4.1202\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 4.0040,\tval_loss: 4.1034\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9432,\tval_loss: 4.1648\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9097,\tval_loss: 4.1068\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8781,\tval_loss: 4.1855\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8727,\tval_loss: 4.1493\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8724,\tval_loss: 4.1893\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.9627,\tval_loss: 4.1586\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8541,\tval_loss: 4.1393\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8328,\tval_loss: 4.1388\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8497,\tval_loss: 4.1538\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8543,\tval_loss: 4.2152\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8129,\tval_loss: 4.1737\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8467,\tval_loss: 4.1232\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7519,\tval_loss: 4.1776\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.8212,\tval_loss: 4.2002\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.8085,\tval_loss: 4.2007\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7428,\tval_loss: 4.2506\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7257,\tval_loss: 4.1754\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7346,\tval_loss: 4.1582\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7088,\tval_loss: 4.2127\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7321,\tval_loss: 4.1812\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7879,\tval_loss: 4.1470\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7565,\tval_loss: 4.2365\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6851,\tval_loss: 4.1949\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7950,\tval_loss: 4.2463\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6736,\tval_loss: 4.2699\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7225,\tval_loss: 4.2981\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7015,\tval_loss: 4.2006\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6511,\tval_loss: 4.2602\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6647,\tval_loss: 4.2273\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6378,\tval_loss: 4.1825\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6096,\tval_loss: 4.2343\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.7067,\tval_loss: 4.2263\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6393,\tval_loss: 4.2154\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6713,\tval_loss: 4.1748\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6333,\tval_loss: 4.2512\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6569,\tval_loss: 4.2406\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6417,\tval_loss: 4.2293\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5923,\tval_loss: 4.2787\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.7154,\tval_loss: 4.3649\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.7098,\tval_loss: 4.2065\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6634,\tval_loss: 4.1477\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6772,\tval_loss: 4.1760\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6561,\tval_loss: 4.2065\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5975,\tval_loss: 4.2562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4792,\tval_loss: 4.0971\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3358,\tval_loss: 4.0752\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2993,\tval_loss: 4.0712\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2686,\tval_loss: 4.0685\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2294,\tval_loss: 4.0871\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2195,\tval_loss: 4.0729\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1982,\tval_loss: 4.1008\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1284,\tval_loss: 4.1188\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0719,\tval_loss: 4.1120\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0618,\tval_loss: 4.0973\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0758,\tval_loss: 4.1610\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9793,\tval_loss: 4.1661\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9420,\tval_loss: 4.1913\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9003,\tval_loss: 4.2313\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.8616,\tval_loss: 4.1892\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.8119,\tval_loss: 4.2828\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.7911,\tval_loss: 4.3228\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8282,\tval_loss: 4.2657\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.7877,\tval_loss: 4.3081\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.7603,\tval_loss: 4.3214\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.7811,\tval_loss: 4.2810\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7140,\tval_loss: 4.3037\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7227,\tval_loss: 4.3501\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7370,\tval_loss: 4.3161\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.6903,\tval_loss: 4.3034\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6171,\tval_loss: 4.3953\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6060,\tval_loss: 4.3778\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6314,\tval_loss: 4.3398\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.5877,\tval_loss: 4.3168\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.6661,\tval_loss: 4.3490\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.6253,\tval_loss: 4.3450\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.6369,\tval_loss: 4.3438\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.5477,\tval_loss: 4.3704\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.5780,\tval_loss: 4.4311\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.5485,\tval_loss: 4.3359\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.5889,\tval_loss: 4.4385\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.5764,\tval_loss: 4.3502\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.5042,\tval_loss: 4.4231\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.5075,\tval_loss: 4.3615\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.4644,\tval_loss: 4.5259\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5605,\tval_loss: 4.3123\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5181,\tval_loss: 4.4058\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5226,\tval_loss: 4.3830\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5638,\tval_loss: 4.3513\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.4996,\tval_loss: 4.4215\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.5585,\tval_loss: 4.4010\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.4828,\tval_loss: 4.4790\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.4650,\tval_loss: 4.4691\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.4690,\tval_loss: 4.3890\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.5233,\tval_loss: 4.3460\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.4442,\tval_loss: 4.4093\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.4576,\tval_loss: 4.4265\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.5123,\tval_loss: 4.3901\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.4494,\tval_loss: 4.4507\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.4240,\tval_loss: 4.5270\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.5038,\tval_loss: 4.4914\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.4718,\tval_loss: 4.4150\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.4785,\tval_loss: 4.3633\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.4608,\tval_loss: 4.4774\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.3842,\tval_loss: 4.4012\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.4501,\tval_loss: 4.4550\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.4455,\tval_loss: 4.4032\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.4088,\tval_loss: 4.3362\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5027,\tval_loss: 4.4385\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5008,\tval_loss: 4.3690\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.4892,\tval_loss: 4.3858\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.4238,\tval_loss: 4.4056\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.3921,\tval_loss: 4.5182\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.4174,\tval_loss: 4.4695\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.3978,\tval_loss: 4.4625\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.3924,\tval_loss: 4.4254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.5011,\tval_loss: 4.0397\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3491,\tval_loss: 4.0350\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2968,\tval_loss: 4.0405\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2450,\tval_loss: 4.0334\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2473,\tval_loss: 4.0368\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2317,\tval_loss: 4.0307\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2110,\tval_loss: 4.0374\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1982,\tval_loss: 4.0261\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1740,\tval_loss: 4.0381\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1791,\tval_loss: 4.0463\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1241,\tval_loss: 4.0356\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1300,\tval_loss: 4.0301\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1079,\tval_loss: 4.0613\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1053,\tval_loss: 4.0624\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.1062,\tval_loss: 4.0390\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0107,\tval_loss: 4.0686\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0117,\tval_loss: 4.0756\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9623,\tval_loss: 4.2013\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9247,\tval_loss: 4.1188\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9697,\tval_loss: 4.1246\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.8910,\tval_loss: 4.1565\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9249,\tval_loss: 4.1509\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8377,\tval_loss: 4.1484\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9070,\tval_loss: 4.1146\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8934,\tval_loss: 4.1376\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8459,\tval_loss: 4.1213\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8640,\tval_loss: 4.1296\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8994,\tval_loss: 4.1437\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8731,\tval_loss: 4.1352\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7702,\tval_loss: 4.1956\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8873,\tval_loss: 4.0981\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8365,\tval_loss: 4.1410\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8069,\tval_loss: 4.1314\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7174,\tval_loss: 4.1786\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7862,\tval_loss: 4.1667\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8179,\tval_loss: 4.1557\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7472,\tval_loss: 4.1851\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7402,\tval_loss: 4.1926\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7111,\tval_loss: 4.1263\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7355,\tval_loss: 4.1398\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7325,\tval_loss: 4.1988\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6607,\tval_loss: 4.1807\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.7401,\tval_loss: 4.1907\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6977,\tval_loss: 4.2061\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7289,\tval_loss: 4.1639\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7030,\tval_loss: 4.1629\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7243,\tval_loss: 4.1988\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7142,\tval_loss: 4.1987\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7022,\tval_loss: 4.1621\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6582,\tval_loss: 4.1391\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6663,\tval_loss: 4.1850\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6695,\tval_loss: 4.1640\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6888,\tval_loss: 4.2211\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6818,\tval_loss: 4.1660\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6234,\tval_loss: 4.1445\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6786,\tval_loss: 4.1589\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.7531,\tval_loss: 4.1623\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6733,\tval_loss: 4.1377\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6516,\tval_loss: 4.1656\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.7638,\tval_loss: 4.1149\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6426,\tval_loss: 4.1037\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.7127,\tval_loss: 4.1122\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6353,\tval_loss: 4.1596\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.6672,\tval_loss: 4.1378\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.6285,\tval_loss: 4.2137\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6473,\tval_loss: 4.1588\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.7293,\tval_loss: 4.1323\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6960,\tval_loss: 4.1312\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5850,\tval_loss: 4.1316\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6885,\tval_loss: 4.1622\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5620,\tval_loss: 4.1657\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.6617,\tval_loss: 4.1443\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.6997,\tval_loss: 4.0836\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.6155,\tval_loss: 4.1723\n",
            "74:\t[0s / 3s],\t\ttrain_loss: 3.6557,\tval_loss: 4.1615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4599,\tval_loss: 4.0601\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2751,\tval_loss: 4.0823\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2704,\tval_loss: 4.0686\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2262,\tval_loss: 4.1018\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2171,\tval_loss: 4.0932\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1379,\tval_loss: 4.1240\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1880,\tval_loss: 4.1183\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1517,\tval_loss: 4.1134\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1524,\tval_loss: 4.0578\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1661,\tval_loss: 4.0889\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1189,\tval_loss: 4.1022\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1039,\tval_loss: 4.1166\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0991,\tval_loss: 4.1638\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0894,\tval_loss: 4.1498\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0126,\tval_loss: 4.2150\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0383,\tval_loss: 4.1915\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0539,\tval_loss: 4.1667\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0409,\tval_loss: 4.1814\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9685,\tval_loss: 4.1904\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9872,\tval_loss: 4.2019\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 4.0014,\tval_loss: 4.2831\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9520,\tval_loss: 4.2342\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8963,\tval_loss: 4.2308\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8723,\tval_loss: 4.3231\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9466,\tval_loss: 4.2025\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8978,\tval_loss: 4.2487\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8695,\tval_loss: 4.3095\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8796,\tval_loss: 4.3336\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8711,\tval_loss: 4.2738\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8476,\tval_loss: 4.2514\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.9092,\tval_loss: 4.3170\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8371,\tval_loss: 4.3061\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8342,\tval_loss: 4.3195\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7962,\tval_loss: 4.3406\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8409,\tval_loss: 4.3241\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8731,\tval_loss: 4.2951\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7778,\tval_loss: 4.3608\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7664,\tval_loss: 4.3778\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7828,\tval_loss: 4.3135\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7681,\tval_loss: 4.4275\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7847,\tval_loss: 4.4081\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7604,\tval_loss: 4.3714\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.8057,\tval_loss: 4.4313\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7457,\tval_loss: 4.4268\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7693,\tval_loss: 4.4512\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7417,\tval_loss: 4.3539\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7594,\tval_loss: 4.4265\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7679,\tval_loss: 4.4227\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7084,\tval_loss: 4.4369\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.8034,\tval_loss: 4.4256\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7020,\tval_loss: 4.3858\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6692,\tval_loss: 4.5077\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7429,\tval_loss: 4.4441\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7051,\tval_loss: 4.5046\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7611,\tval_loss: 4.3999\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.7391,\tval_loss: 4.4052\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.7373,\tval_loss: 4.4440\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.7284,\tval_loss: 4.4727\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.7079,\tval_loss: 4.5608\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.7185,\tval_loss: 4.4569\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6624,\tval_loss: 4.4761\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6999,\tval_loss: 4.5046\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6525,\tval_loss: 4.5075\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.7181,\tval_loss: 4.3988\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.7315,\tval_loss: 4.5001\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6807,\tval_loss: 4.4976\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.7706,\tval_loss: 4.4168\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.7146,\tval_loss: 4.3799\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6678,\tval_loss: 4.5128\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.8386,\tval_loss: 4.4394\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6615,\tval_loss: 4.4904\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.7421,\tval_loss: 4.4798\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.7508,\tval_loss: 4.4774\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.6523,\tval_loss: 4.4763\n",
            "74:\t[0s / 3s],\t\ttrain_loss: 3.6570,\tval_loss: 4.5545\n",
            "75:\t[0s / 3s],\t\ttrain_loss: 3.6837,\tval_loss: 4.4353\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4141,\tval_loss: 4.1103\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2945,\tval_loss: 4.0656\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2566,\tval_loss: 4.0651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2007,\tval_loss: 4.0652\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2039,\tval_loss: 4.0491\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1949,\tval_loss: 4.0210\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1414,\tval_loss: 4.0431\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1418,\tval_loss: 4.0189\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1504,\tval_loss: 4.0269\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1246,\tval_loss: 4.0181\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1303,\tval_loss: 4.0106\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1225,\tval_loss: 4.0247\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1378,\tval_loss: 4.0287\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0589,\tval_loss: 4.0160\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0810,\tval_loss: 4.0355\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.1083,\tval_loss: 4.0173\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0316,\tval_loss: 4.0069\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0370,\tval_loss: 4.0294\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0583,\tval_loss: 4.0570\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 4.0101,\tval_loss: 4.0659\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 4.0121,\tval_loss: 4.0496\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 4.0463,\tval_loss: 4.0624\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9713,\tval_loss: 4.0602\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9198,\tval_loss: 4.0251\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9150,\tval_loss: 4.1258\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8832,\tval_loss: 4.0286\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8879,\tval_loss: 4.0871\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8716,\tval_loss: 4.0841\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.9155,\tval_loss: 4.0807\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8652,\tval_loss: 4.1439\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8877,\tval_loss: 4.1230\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8292,\tval_loss: 4.1875\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8039,\tval_loss: 4.1599\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7881,\tval_loss: 4.1802\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8216,\tval_loss: 4.1202\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8121,\tval_loss: 4.1454\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7712,\tval_loss: 4.2360\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7381,\tval_loss: 4.1702\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7705,\tval_loss: 4.1699\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7788,\tval_loss: 4.2229\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7479,\tval_loss: 4.1937\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7546,\tval_loss: 4.1751\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7074,\tval_loss: 4.2538\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6724,\tval_loss: 4.2977\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7114,\tval_loss: 4.2269\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6950,\tval_loss: 4.2768\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6644,\tval_loss: 4.2438\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7123,\tval_loss: 4.2097\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6629,\tval_loss: 4.2664\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6688,\tval_loss: 4.2423\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7097,\tval_loss: 4.2478\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6175,\tval_loss: 4.2611\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6452,\tval_loss: 4.2529\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6986,\tval_loss: 4.2720\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6453,\tval_loss: 4.2874\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6838,\tval_loss: 4.1608\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6251,\tval_loss: 4.2824\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6541,\tval_loss: 4.2313\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6235,\tval_loss: 4.2194\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6218,\tval_loss: 4.2866\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6539,\tval_loss: 4.2277\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6142,\tval_loss: 4.2598\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5916,\tval_loss: 4.2658\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6339,\tval_loss: 4.2871\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6529,\tval_loss: 4.1556\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6047,\tval_loss: 4.2859\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5980,\tval_loss: 4.3064\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5958,\tval_loss: 4.3028\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6061,\tval_loss: 4.2834\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.5964,\tval_loss: 4.2571\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.6483,\tval_loss: 4.2895\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.6095,\tval_loss: 4.2668\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.5761,\tval_loss: 4.2860\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.5676,\tval_loss: 4.2379\n",
            "74:\t[0s / 4s],\t\ttrain_loss: 3.5075,\tval_loss: 4.3077\n",
            "75:\t[0s / 4s],\t\ttrain_loss: 3.5335,\tval_loss: 4.3448\n",
            "76:\t[0s / 4s],\t\ttrain_loss: 3.5199,\tval_loss: 4.3526\n",
            "77:\t[0s / 4s],\t\ttrain_loss: 3.6171,\tval_loss: 4.2401\n",
            "78:\t[0s / 4s],\t\ttrain_loss: 3.5424,\tval_loss: 4.3209\n",
            "79:\t[0s / 4s],\t\ttrain_loss: 3.5211,\tval_loss: 4.2865\n",
            "80:\t[0s / 4s],\t\ttrain_loss: 3.5386,\tval_loss: 4.4309\n",
            "81:\t[0s / 4s],\t\ttrain_loss: 3.5422,\tval_loss: 4.2639\n",
            "82:\t[0s / 4s],\t\ttrain_loss: 3.5939,\tval_loss: 4.2642\n",
            "83:\t[0s / 4s],\t\ttrain_loss: 3.5763,\tval_loss: 4.3204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4112,\tval_loss: 4.0554\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2859,\tval_loss: 4.0595\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3028,\tval_loss: 4.0700\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2475,\tval_loss: 4.0588\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2192,\tval_loss: 4.0711\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2454,\tval_loss: 4.0682\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2137,\tval_loss: 4.0633\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2102,\tval_loss: 4.0511\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1517,\tval_loss: 4.0632\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1649,\tval_loss: 4.0523\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1724,\tval_loss: 4.0847\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1700,\tval_loss: 4.0770\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1160,\tval_loss: 4.0804\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1130,\tval_loss: 4.0811\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.1123,\tval_loss: 4.0850\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0579,\tval_loss: 4.0866\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 4.0111,\tval_loss: 4.1198\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 4.0104,\tval_loss: 4.1490\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9479,\tval_loss: 4.1292\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9261,\tval_loss: 4.1850\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9377,\tval_loss: 4.2443\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9334,\tval_loss: 4.1762\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8525,\tval_loss: 4.2630\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8623,\tval_loss: 4.2320\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8340,\tval_loss: 4.2316\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8496,\tval_loss: 4.2787\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7666,\tval_loss: 4.2663\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7740,\tval_loss: 4.3157\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7437,\tval_loss: 4.3415\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7115,\tval_loss: 4.4243\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.7897,\tval_loss: 4.3777\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.6750,\tval_loss: 4.2974\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7859,\tval_loss: 4.3406\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.6980,\tval_loss: 4.4324\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7346,\tval_loss: 4.3561\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.6827,\tval_loss: 4.4474\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7231,\tval_loss: 4.3123\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.8172,\tval_loss: 4.3224\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6390,\tval_loss: 4.4272\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6132,\tval_loss: 4.4280\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7194,\tval_loss: 4.3651\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5135,\tval_loss: 4.6277\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6520,\tval_loss: 4.3951\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6470,\tval_loss: 4.4164\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6456,\tval_loss: 4.4236\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6027,\tval_loss: 4.4062\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6168,\tval_loss: 4.4007\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6480,\tval_loss: 4.4340\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5671,\tval_loss: 4.4325\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6017,\tval_loss: 4.5577\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6446,\tval_loss: 4.3865\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6004,\tval_loss: 4.4633\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.5755,\tval_loss: 4.3717\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.5464,\tval_loss: 4.6217\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.5779,\tval_loss: 4.4249\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6113,\tval_loss: 4.5120\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5813,\tval_loss: 4.4891\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5466,\tval_loss: 4.5358\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5916,\tval_loss: 4.4313\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6210,\tval_loss: 4.3872\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5753,\tval_loss: 4.3766\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5452,\tval_loss: 4.4639\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5213,\tval_loss: 4.3423\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5675,\tval_loss: 4.3996\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.4651,\tval_loss: 4.4783\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5669,\tval_loss: 4.4768\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5484,\tval_loss: 4.5332\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5565,\tval_loss: 4.4611\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5728,\tval_loss: 4.4827\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5701,\tval_loss: 4.5164\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5350,\tval_loss: 4.4485\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.5668,\tval_loss: 4.4108\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.5478,\tval_loss: 4.4227\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.5835,\tval_loss: 4.3982\n",
            "74:\t[0s / 4s],\t\ttrain_loss: 3.4776,\tval_loss: 4.5255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3826,\tval_loss: 4.0690\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2504,\tval_loss: 4.0909\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2000,\tval_loss: 4.0904\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1948,\tval_loss: 4.0797\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1791,\tval_loss: 4.0906\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1579,\tval_loss: 4.1032\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1279,\tval_loss: 4.0881\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1453,\tval_loss: 4.1080\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1029,\tval_loss: 4.1045\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1558,\tval_loss: 4.0797\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0878,\tval_loss: 4.1485\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0452,\tval_loss: 4.1799\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0596,\tval_loss: 4.1102\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0176,\tval_loss: 4.1673\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9823,\tval_loss: 4.1931\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9426,\tval_loss: 4.2250\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9544,\tval_loss: 4.1536\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9187,\tval_loss: 4.1670\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8854,\tval_loss: 4.1905\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8498,\tval_loss: 4.1799\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.7441,\tval_loss: 4.2000\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7678,\tval_loss: 4.2508\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7815,\tval_loss: 4.2370\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.6815,\tval_loss: 4.2535\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7732,\tval_loss: 4.2457\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6859,\tval_loss: 4.2768\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6362,\tval_loss: 4.3532\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6798,\tval_loss: 4.3340\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7564,\tval_loss: 4.2687\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.5894,\tval_loss: 4.4148\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6248,\tval_loss: 4.3522\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6544,\tval_loss: 4.3982\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6110,\tval_loss: 4.3899\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6288,\tval_loss: 4.4226\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.5576,\tval_loss: 4.4246\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.4734,\tval_loss: 4.4852\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.5672,\tval_loss: 4.4249\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.4526,\tval_loss: 4.4503\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.5168,\tval_loss: 4.4405\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6276,\tval_loss: 4.2797\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.5494,\tval_loss: 4.3396\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.5789,\tval_loss: 4.3157\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.6188,\tval_loss: 4.3507\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5639,\tval_loss: 4.4031\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.4202,\tval_loss: 4.3980\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5501,\tval_loss: 4.4719\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5197,\tval_loss: 4.3631\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.4389,\tval_loss: 4.4816\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5000,\tval_loss: 4.4411\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.4187,\tval_loss: 4.4112\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.3719,\tval_loss: 4.5328\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.4629,\tval_loss: 4.5176\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.4483,\tval_loss: 4.3366\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.4855,\tval_loss: 4.4240\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.4062,\tval_loss: 4.4656\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.4611,\tval_loss: 4.5081\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.3670,\tval_loss: 4.3120\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.3989,\tval_loss: 4.4101\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.4251,\tval_loss: 4.4820\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.4179,\tval_loss: 4.4681\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.3775,\tval_loss: 4.3907\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.4116,\tval_loss: 4.4461\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.3528,\tval_loss: 4.3851\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.3957,\tval_loss: 4.3935\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.4095,\tval_loss: 4.4635\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.4322,\tval_loss: 4.2647\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.3809,\tval_loss: 4.3733\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.3951,\tval_loss: 4.4125\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3295,\tval_loss: 4.1055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.1741,\tval_loss: 4.0536\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1007,\tval_loss: 4.0375\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.0733,\tval_loss: 4.0495\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.0596,\tval_loss: 4.0562\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.0146,\tval_loss: 4.0647\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0249,\tval_loss: 4.0595\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 3.9847,\tval_loss: 4.1069\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 3.9907,\tval_loss: 4.0736\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 3.9829,\tval_loss: 4.1027\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 3.9437,\tval_loss: 4.0823\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9261,\tval_loss: 4.1546\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9135,\tval_loss: 4.1471\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9044,\tval_loss: 4.1477\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.8779,\tval_loss: 4.1288\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.8514,\tval_loss: 4.1369\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.7896,\tval_loss: 4.2114\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8489,\tval_loss: 4.1955\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8562,\tval_loss: 4.1849\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.7308,\tval_loss: 4.2730\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.8169,\tval_loss: 4.1699\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8582,\tval_loss: 4.2409\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7499,\tval_loss: 4.2386\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7055,\tval_loss: 4.2688\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7393,\tval_loss: 4.2310\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7060,\tval_loss: 4.2298\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6990,\tval_loss: 4.1866\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7053,\tval_loss: 4.2327\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.5999,\tval_loss: 4.3221\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.5933,\tval_loss: 4.2934\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6182,\tval_loss: 4.3253\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6300,\tval_loss: 4.3070\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6271,\tval_loss: 4.2897\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6374,\tval_loss: 4.3841\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6375,\tval_loss: 4.3302\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.5744,\tval_loss: 4.3690\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6087,\tval_loss: 4.2875\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.5569,\tval_loss: 4.2121\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.5990,\tval_loss: 4.4372\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6377,\tval_loss: 4.3053\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6156,\tval_loss: 4.3421\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.5694,\tval_loss: 4.4004\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5654,\tval_loss: 4.3660\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5917,\tval_loss: 4.3350\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.4877,\tval_loss: 4.3727\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5886,\tval_loss: 4.3383\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5133,\tval_loss: 4.3441\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5404,\tval_loss: 4.3608\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.4494,\tval_loss: 4.3801\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5085,\tval_loss: 4.3553\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.4700,\tval_loss: 4.4099\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.4541,\tval_loss: 4.3147\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.4859,\tval_loss: 4.4275\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.4708,\tval_loss: 4.4227\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5363,\tval_loss: 4.3343\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.4870,\tval_loss: 4.3477\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.4400,\tval_loss: 4.5194\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.4510,\tval_loss: 4.4114\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.4713,\tval_loss: 4.4028\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.4704,\tval_loss: 4.3170\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5255,\tval_loss: 4.4236\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.4769,\tval_loss: 4.4313\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.3512,\tval_loss: 4.3741\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.4866,\tval_loss: 4.3406\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5010,\tval_loss: 4.3951\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.4678,\tval_loss: 4.4101\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.3576,\tval_loss: 4.5562\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5604,\tval_loss: 4.2694\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5217,\tval_loss: 4.4527\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.4263,\tval_loss: 4.3749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4361,\tval_loss: 4.0148\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3089,\tval_loss: 4.0170\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2294,\tval_loss: 4.0228\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1993,\tval_loss: 4.0343\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1588,\tval_loss: 4.0445\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1223,\tval_loss: 4.0252\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1287,\tval_loss: 4.0247\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0704,\tval_loss: 4.0589\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0881,\tval_loss: 4.0757\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0667,\tval_loss: 4.1224\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0220,\tval_loss: 4.1348\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0078,\tval_loss: 4.1618\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9235,\tval_loss: 4.2580\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.8967,\tval_loss: 4.1689\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9177,\tval_loss: 4.2473\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.8450,\tval_loss: 4.1989\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8824,\tval_loss: 4.2170\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8424,\tval_loss: 4.2783\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.7600,\tval_loss: 4.2381\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.7713,\tval_loss: 4.2305\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.7501,\tval_loss: 4.3476\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7717,\tval_loss: 4.2304\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7123,\tval_loss: 4.3598\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7260,\tval_loss: 4.2215\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7310,\tval_loss: 4.3355\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6787,\tval_loss: 4.3302\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6624,\tval_loss: 4.2890\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6717,\tval_loss: 4.4172\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6854,\tval_loss: 4.3229\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.6863,\tval_loss: 4.3238\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6785,\tval_loss: 4.3364\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.5974,\tval_loss: 4.3875\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.5908,\tval_loss: 4.3638\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.5188,\tval_loss: 4.4426\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.5153,\tval_loss: 4.4652\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.5552,\tval_loss: 4.4016\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.5657,\tval_loss: 4.4095\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.5115,\tval_loss: 4.4211\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.5837,\tval_loss: 4.4924\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.5675,\tval_loss: 4.3967\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5685,\tval_loss: 4.5197\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5852,\tval_loss: 4.3756\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5920,\tval_loss: 4.4380\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6252,\tval_loss: 4.3107\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5426,\tval_loss: 4.4377\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5924,\tval_loss: 4.3543\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5380,\tval_loss: 4.4666\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5159,\tval_loss: 4.4682\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.4426,\tval_loss: 4.6103\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5328,\tval_loss: 4.3878\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5278,\tval_loss: 4.4406\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.4875,\tval_loss: 4.3908\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.4238,\tval_loss: 4.4700\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.4884,\tval_loss: 4.4302\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.4970,\tval_loss: 4.4730\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.4552,\tval_loss: 4.5048\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.3654,\tval_loss: 4.6098\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.4894,\tval_loss: 4.4420\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5396,\tval_loss: 4.5189\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5073,\tval_loss: 4.4122\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5259,\tval_loss: 4.5453\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.4942,\tval_loss: 4.4318\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.4354,\tval_loss: 4.5506\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.4650,\tval_loss: 4.5350\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.4643,\tval_loss: 4.5166\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5006,\tval_loss: 4.4887\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4543,\tval_loss: 4.4948\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4273,\tval_loss: 4.4311\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3917,\tval_loss: 4.1176"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2834,\tval_loss: 4.0629\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2119,\tval_loss: 4.0582\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2047,\tval_loss: 4.0580\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1755,\tval_loss: 4.0384\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1468,\tval_loss: 4.0487\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1177,\tval_loss: 4.0674\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1088,\tval_loss: 4.0288\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1000,\tval_loss: 4.0785\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0669,\tval_loss: 4.0615\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0447,\tval_loss: 4.1071\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0300,\tval_loss: 4.0769\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0104,\tval_loss: 4.1562\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0023,\tval_loss: 4.0768\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.9771,\tval_loss: 4.1354\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9930,\tval_loss: 4.0772\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9259,\tval_loss: 4.1396\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8483,\tval_loss: 4.1787\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.8891,\tval_loss: 4.1826\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9110,\tval_loss: 4.1492\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8478,\tval_loss: 4.1607\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8368,\tval_loss: 4.2051\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8727,\tval_loss: 4.1965\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7845,\tval_loss: 4.2199\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8184,\tval_loss: 4.2612\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7960,\tval_loss: 4.2635\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8210,\tval_loss: 4.2582\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7648,\tval_loss: 4.1741\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7782,\tval_loss: 4.2615\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.8213,\tval_loss: 4.1965\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.7320,\tval_loss: 4.3150\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7713,\tval_loss: 4.1920\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7914,\tval_loss: 4.2601\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.6753,\tval_loss: 4.2850\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7574,\tval_loss: 4.2683\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7481,\tval_loss: 4.1773\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7516,\tval_loss: 4.2009\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7170,\tval_loss: 4.2441\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7249,\tval_loss: 4.1986\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.8195,\tval_loss: 4.2572\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6802,\tval_loss: 4.2709\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7023,\tval_loss: 4.2184\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7068,\tval_loss: 4.3372\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7149,\tval_loss: 4.2095\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.7100,\tval_loss: 4.2853\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.7433,\tval_loss: 4.1879\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.7032,\tval_loss: 4.2891\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.7442,\tval_loss: 4.2475\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.6715,\tval_loss: 4.2772\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6553,\tval_loss: 4.2550\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6876,\tval_loss: 4.2839\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.6744,\tval_loss: 4.3492\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6564,\tval_loss: 4.3397\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6488,\tval_loss: 4.3895\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6304,\tval_loss: 4.2838\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6572,\tval_loss: 4.3083\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5910,\tval_loss: 4.3264\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6324,\tval_loss: 4.2716\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6755,\tval_loss: 4.1897\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6592,\tval_loss: 4.4280\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6864,\tval_loss: 4.2086\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6297,\tval_loss: 4.3069\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6268,\tval_loss: 4.2336\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6446,\tval_loss: 4.2683\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6715,\tval_loss: 4.2087\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6710,\tval_loss: 4.3381\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.7502,\tval_loss: 4.2624\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.7063,\tval_loss: 4.2762\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.6143,\tval_loss: 4.2601\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.5856,\tval_loss: 4.3985\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.6367,\tval_loss: 4.2786\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.5851,\tval_loss: 4.3093\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.5927,\tval_loss: 4.2805\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.6149,\tval_loss: 4.2984\n",
            "74:\t[0s / 4s],\t\ttrain_loss: 3.5773,\tval_loss: 4.3642\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3957,\tval_loss: 4.0743\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2274,\tval_loss: 4.0641\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1720,\tval_loss: 4.0548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1452,\tval_loss: 4.0795\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1287,\tval_loss: 4.0871\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1835,\tval_loss: 4.0900\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1162,\tval_loss: 4.0856\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1128,\tval_loss: 4.0825\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1332,\tval_loss: 4.0920\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1055,\tval_loss: 4.0949\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0431,\tval_loss: 4.1715\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1050,\tval_loss: 4.1253\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0442,\tval_loss: 4.1065\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0432,\tval_loss: 4.1078\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0894,\tval_loss: 4.0984\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9866,\tval_loss: 4.1240\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9942,\tval_loss: 4.1637\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9474,\tval_loss: 4.1931\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9359,\tval_loss: 4.2289\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9375,\tval_loss: 4.1868\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.9203,\tval_loss: 4.2108\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9321,\tval_loss: 4.1611\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8936,\tval_loss: 4.2389\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8345,\tval_loss: 4.2451\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8570,\tval_loss: 4.2609\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8666,\tval_loss: 4.2585\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8258,\tval_loss: 4.2574\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8290,\tval_loss: 4.2314\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8853,\tval_loss: 4.2408\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7720,\tval_loss: 4.3275\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7209,\tval_loss: 4.3147\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7402,\tval_loss: 4.3489\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8146,\tval_loss: 4.2745\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7983,\tval_loss: 4.2772\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7674,\tval_loss: 4.3250\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8103,\tval_loss: 4.2884\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7102,\tval_loss: 4.3081\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6934,\tval_loss: 4.3763\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7064,\tval_loss: 4.2597\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7797,\tval_loss: 4.2859\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6947,\tval_loss: 4.3073\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7005,\tval_loss: 4.3088\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.6253,\tval_loss: 4.3267\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6689,\tval_loss: 4.2439\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6992,\tval_loss: 4.3347\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6651,\tval_loss: 4.3271\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7155,\tval_loss: 4.3167\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6049,\tval_loss: 4.3631\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6737,\tval_loss: 4.3491\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7391,\tval_loss: 4.2938\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6394,\tval_loss: 4.3469\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6564,\tval_loss: 4.3536\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6187,\tval_loss: 4.3276\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5926,\tval_loss: 4.4011\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5856,\tval_loss: 4.3897\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6409,\tval_loss: 4.3168\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6004,\tval_loss: 4.4193\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6436,\tval_loss: 4.3719\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6420,\tval_loss: 4.3990\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6734,\tval_loss: 4.3615\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6529,\tval_loss: 4.4317\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5874,\tval_loss: 4.3865\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5661,\tval_loss: 4.3380\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.6028,\tval_loss: 4.3196\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.5980,\tval_loss: 4.2784\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6136,\tval_loss: 4.3456\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6256,\tval_loss: 4.2773\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6448,\tval_loss: 4.3499\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6022,\tval_loss: 4.3226\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5981,\tval_loss: 4.3147\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4689,\tval_loss: 4.1255\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2797,\tval_loss: 4.0813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2033,\tval_loss: 4.0541\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1662,\tval_loss: 4.0561\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1670,\tval_loss: 4.0559\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1019,\tval_loss: 4.0556\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0797,\tval_loss: 4.0684\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0913,\tval_loss: 4.0510\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0722,\tval_loss: 4.0536\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 3.9971,\tval_loss: 4.0814\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0138,\tval_loss: 4.1023\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9378,\tval_loss: 4.1359\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9777,\tval_loss: 4.0901\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9829,\tval_loss: 4.1073\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9814,\tval_loss: 4.1487\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9102,\tval_loss: 4.0878\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9547,\tval_loss: 4.1068\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9157,\tval_loss: 4.1175\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9127,\tval_loss: 4.1613\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8782,\tval_loss: 4.1934\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8646,\tval_loss: 4.1748\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8508,\tval_loss: 4.1841\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8467,\tval_loss: 4.1534\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8372,\tval_loss: 4.2367\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7890,\tval_loss: 4.1997\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8193,\tval_loss: 4.2573\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7439,\tval_loss: 4.2622\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7892,\tval_loss: 4.1819\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7447,\tval_loss: 4.2330\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7840,\tval_loss: 4.2796\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7635,\tval_loss: 4.2022\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7024,\tval_loss: 4.2233\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7270,\tval_loss: 4.1834\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7194,\tval_loss: 4.2380\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7363,\tval_loss: 4.2780\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6775,\tval_loss: 4.2123\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6667,\tval_loss: 4.2614\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6710,\tval_loss: 4.3534\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6560,\tval_loss: 4.3202\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7060,\tval_loss: 4.3479\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7255,\tval_loss: 4.2976\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6325,\tval_loss: 4.3363\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5609,\tval_loss: 4.3153\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5922,\tval_loss: 4.3641\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6047,\tval_loss: 4.4201\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6319,\tval_loss: 4.3556\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5852,\tval_loss: 4.4033\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6319,\tval_loss: 4.3560\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6084,\tval_loss: 4.3833\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6140,\tval_loss: 4.3682\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6021,\tval_loss: 4.4449\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7006,\tval_loss: 4.3403\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5425,\tval_loss: 4.3884\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5498,\tval_loss: 4.3737\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5212,\tval_loss: 4.4006\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5733,\tval_loss: 4.3957\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5943,\tval_loss: 4.4421\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5832,\tval_loss: 4.4136\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5538,\tval_loss: 4.4320\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5524,\tval_loss: 4.3774\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5648,\tval_loss: 4.5256\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5451,\tval_loss: 4.3425\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5084,\tval_loss: 4.5651\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5178,\tval_loss: 4.3930\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5480,\tval_loss: 4.4608\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5612,\tval_loss: 4.4133\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5433,\tval_loss: 4.3922\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5028,\tval_loss: 4.4765\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5331,\tval_loss: 4.4124\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5426,\tval_loss: 4.4475\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5346,\tval_loss: 4.4508\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.4659,\tval_loss: 4.5805\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.5377,\tval_loss: 4.3933\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.5058,\tval_loss: 4.4331\n",
            "74:\t[0s / 4s],\t\ttrain_loss: 3.5569,\tval_loss: 4.4574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3167,\tval_loss: 4.0683\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2422,\tval_loss: 4.0731\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2004,\tval_loss: 4.0550\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1230,\tval_loss: 4.0565\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1591,\tval_loss: 4.0368\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1010,\tval_loss: 4.0409\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0867,\tval_loss: 4.0558\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0829,\tval_loss: 4.0674\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0370,\tval_loss: 4.0814\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0311,\tval_loss: 4.1186\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 3.9957,\tval_loss: 4.1071\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0057,\tval_loss: 4.0761\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9754,\tval_loss: 4.1255\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9977,\tval_loss: 4.0936\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0102,\tval_loss: 4.1065\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9188,\tval_loss: 4.1031\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9474,\tval_loss: 4.1003\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9312,\tval_loss: 4.1370\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9098,\tval_loss: 4.1080\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9242,\tval_loss: 4.1284\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9052,\tval_loss: 4.1562\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8858,\tval_loss: 4.1709\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8979,\tval_loss: 4.2108\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8713,\tval_loss: 4.1700\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8071,\tval_loss: 4.2361\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8503,\tval_loss: 4.2000\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8581,\tval_loss: 4.1536\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7975,\tval_loss: 4.2507\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 3.7787,\tval_loss: 4.3561\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.8208,\tval_loss: 4.2130\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.8101,\tval_loss: 4.1882\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7793,\tval_loss: 4.2315\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7216,\tval_loss: 4.2101\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.7413,\tval_loss: 4.3222\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7630,\tval_loss: 4.1648\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7600,\tval_loss: 4.2760\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7337,\tval_loss: 4.2841\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7444,\tval_loss: 4.2675\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7288,\tval_loss: 4.2530\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7207,\tval_loss: 4.2132\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.8031,\tval_loss: 4.1856\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6933,\tval_loss: 4.2309\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 3.6922,\tval_loss: 4.2862\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 3.7176,\tval_loss: 4.3067\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.6744,\tval_loss: 4.2718\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.6605,\tval_loss: 4.2579\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.6436,\tval_loss: 4.2729\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.6266,\tval_loss: 4.3183\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.6120,\tval_loss: 4.3984\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6679,\tval_loss: 4.2435\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.7160,\tval_loss: 4.3163\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.6691,\tval_loss: 4.2714\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6539,\tval_loss: 4.2553\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6267,\tval_loss: 4.2973\n",
            "54:\t[0s / 4s],\t\ttrain_loss: 3.5750,\tval_loss: 4.2616\n",
            "55:\t[0s / 4s],\t\ttrain_loss: 3.6229,\tval_loss: 4.2760\n",
            "56:\t[0s / 4s],\t\ttrain_loss: 3.6412,\tval_loss: 4.2885\n",
            "57:\t[0s / 4s],\t\ttrain_loss: 3.6379,\tval_loss: 4.2962\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 3.6063,\tval_loss: 4.2616\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 3.5202,\tval_loss: 4.3448\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 3.5857,\tval_loss: 4.3391\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.6033,\tval_loss: 4.4388\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.6845,\tval_loss: 4.2508\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.6048,\tval_loss: 4.3693\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.6147,\tval_loss: 4.4409\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.5750,\tval_loss: 4.3301\n",
            "66:\t[0s / 5s],\t\ttrain_loss: 3.5146,\tval_loss: 4.3144\n",
            "67:\t[0s / 5s],\t\ttrain_loss: 3.5587,\tval_loss: 4.3909\n",
            "68:\t[0s / 5s],\t\ttrain_loss: 3.5924,\tval_loss: 4.2977\n",
            "69:\t[0s / 5s],\t\ttrain_loss: 3.5593,\tval_loss: 4.3502\n",
            "70:\t[0s / 5s],\t\ttrain_loss: 3.5559,\tval_loss: 4.3502\n",
            "71:\t[0s / 5s],\t\ttrain_loss: 3.6060,\tval_loss: 4.3493\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.5467,\tval_loss: 4.0364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3888,\tval_loss: 4.0582\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3519,\tval_loss: 4.0537\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.3425,\tval_loss: 4.0563\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.3092,\tval_loss: 4.0667\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2814,\tval_loss: 4.0770\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2996,\tval_loss: 4.0593\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2822,\tval_loss: 4.0623\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.2573,\tval_loss: 4.0953\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.2483,\tval_loss: 4.0751\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.2166,\tval_loss: 4.1149\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.2346,\tval_loss: 4.1109\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1930,\tval_loss: 4.1128\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1921,\tval_loss: 4.1363\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.1160,\tval_loss: 4.0932\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.1235,\tval_loss: 4.1020\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 4.0894,\tval_loss: 4.1204\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 4.1173,\tval_loss: 4.1210\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 4.0262,\tval_loss: 4.0777\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9807,\tval_loss: 4.1541\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9797,\tval_loss: 4.1093\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 4.0552,\tval_loss: 4.0837\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9973,\tval_loss: 4.1608\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9214,\tval_loss: 4.1299\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9064,\tval_loss: 4.1648\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8784,\tval_loss: 4.1930\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8519,\tval_loss: 4.2298\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8850,\tval_loss: 4.2246\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8182,\tval_loss: 4.2439\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.8923,\tval_loss: 4.1888\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.8096,\tval_loss: 4.2310\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.8329,\tval_loss: 4.2102\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.8409,\tval_loss: 4.1885\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.7540,\tval_loss: 4.2604\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.8428,\tval_loss: 4.2338\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7627,\tval_loss: 4.2234\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7431,\tval_loss: 4.2629\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7376,\tval_loss: 4.3440\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7762,\tval_loss: 4.2159\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7659,\tval_loss: 4.1798\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7572,\tval_loss: 4.2343\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7493,\tval_loss: 4.1729\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6784,\tval_loss: 4.1954\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7429,\tval_loss: 4.2344\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7693,\tval_loss: 4.2708\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6518,\tval_loss: 4.1899\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6611,\tval_loss: 4.2655\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.6529,\tval_loss: 4.2737\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.8092,\tval_loss: 4.2028\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.7006,\tval_loss: 4.2751\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6950,\tval_loss: 4.2248\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.6523,\tval_loss: 4.2406\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.7018,\tval_loss: 4.3179\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6407,\tval_loss: 4.2341\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6501,\tval_loss: 4.2796\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6367,\tval_loss: 4.2254\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6605,\tval_loss: 4.2265\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6171,\tval_loss: 4.2120\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5850,\tval_loss: 4.2435\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5789,\tval_loss: 4.2189\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6308,\tval_loss: 4.1783\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6094,\tval_loss: 4.2389\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5263,\tval_loss: 4.2471\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6006,\tval_loss: 4.2756\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6478,\tval_loss: 4.2170\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5795,\tval_loss: 4.2748\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6508,\tval_loss: 4.2311\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6180,\tval_loss: 4.2816\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4131,\tval_loss: 4.0465\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2235,\tval_loss: 4.0363\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1936,\tval_loss: 4.0293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1571,\tval_loss: 4.0216\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1674,\tval_loss: 4.0097\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1110,\tval_loss: 4.0135\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0576,\tval_loss: 3.9979\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0310,\tval_loss: 3.9995\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0647,\tval_loss: 4.0120\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0549,\tval_loss: 3.9921\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0314,\tval_loss: 4.0200\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0327,\tval_loss: 4.0056\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9447,\tval_loss: 4.0274\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9582,\tval_loss: 4.0159\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9281,\tval_loss: 4.0363\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.8926,\tval_loss: 4.0381\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8754,\tval_loss: 4.0230\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8966,\tval_loss: 4.0530\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.7922,\tval_loss: 4.0921\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.7766,\tval_loss: 4.0903\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.7221,\tval_loss: 4.0980\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7952,\tval_loss: 4.1311\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7097,\tval_loss: 4.1807\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.6290,\tval_loss: 4.2367\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7408,\tval_loss: 4.1324\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6535,\tval_loss: 4.2132\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.5859,\tval_loss: 4.2470\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6065,\tval_loss: 4.2419\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6624,\tval_loss: 4.1937\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7179,\tval_loss: 4.2058\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6054,\tval_loss: 4.1956\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.5845,\tval_loss: 4.1906\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6238,\tval_loss: 4.2375\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.5863,\tval_loss: 4.1973\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.5438,\tval_loss: 4.2272\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.5627,\tval_loss: 4.2932\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6024,\tval_loss: 4.2204\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.5566,\tval_loss: 4.2522\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6109,\tval_loss: 4.2257\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.5905,\tval_loss: 4.2351\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.4720,\tval_loss: 4.2465\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.4959,\tval_loss: 4.2369\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.5723,\tval_loss: 4.2822\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5029,\tval_loss: 4.2667\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.4728,\tval_loss: 4.2707\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.4859,\tval_loss: 4.2052\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5098,\tval_loss: 4.2115\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5000,\tval_loss: 4.2705\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.4891,\tval_loss: 4.1827\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.4904,\tval_loss: 4.3626\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5239,\tval_loss: 4.2388\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.2895,\tval_loss: 4.3214\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.4994,\tval_loss: 4.3382\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.4109,\tval_loss: 4.2099\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.4405,\tval_loss: 4.3581\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.4292,\tval_loss: 4.2781\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.4504,\tval_loss: 4.3002\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.3536,\tval_loss: 4.2746\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.3970,\tval_loss: 4.2909\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5282,\tval_loss: 4.2962\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.4010,\tval_loss: 4.2514\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.3229,\tval_loss: 4.2810\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.3339,\tval_loss: 4.2853\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.3892,\tval_loss: 4.3046\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.3348,\tval_loss: 4.2773\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5047,\tval_loss: 4.1867\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4693,\tval_loss: 4.2791\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4052,\tval_loss: 4.2865\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.3810,\tval_loss: 4.2149\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.3101,\tval_loss: 4.3243\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.4459,\tval_loss: 4.2526\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.4247,\tval_loss: 4.2700\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.3616,\tval_loss: 4.3025\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.4068,\tval_loss: 4.3656\n",
            "74:\t[0s / 3s],\t\ttrain_loss: 3.3520,\tval_loss: 4.3394\n",
            "75:\t[0s / 3s],\t\ttrain_loss: 3.3868,\tval_loss: 4.2766\n",
            "76:\t[0s / 3s],\t\ttrain_loss: 3.3565,\tval_loss: 4.3703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3031,\tval_loss: 4.1188\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2546,\tval_loss: 4.0803\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2240,\tval_loss: 4.0759\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1897,\tval_loss: 4.0835\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1990,\tval_loss: 4.0836\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1592,\tval_loss: 4.0684\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1643,\tval_loss: 4.0541\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1248,\tval_loss: 4.0641\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1216,\tval_loss: 4.1094\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0752,\tval_loss: 4.1102\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1003,\tval_loss: 4.0981\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0176,\tval_loss: 4.1358\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0432,\tval_loss: 4.1193\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0502,\tval_loss: 4.1452\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0426,\tval_loss: 4.1667\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0300,\tval_loss: 4.1598\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0001,\tval_loss: 4.1735\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0152,\tval_loss: 4.2006\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9346,\tval_loss: 4.1994\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9107,\tval_loss: 4.2504\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.9682,\tval_loss: 4.1695\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9378,\tval_loss: 4.2186\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9176,\tval_loss: 4.2102\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9281,\tval_loss: 4.2371\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8910,\tval_loss: 4.2501\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8830,\tval_loss: 4.2352\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8225,\tval_loss: 4.2120\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9237,\tval_loss: 4.1942\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8880,\tval_loss: 4.1840\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8874,\tval_loss: 4.2894\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8245,\tval_loss: 4.2565\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8435,\tval_loss: 4.2315\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8761,\tval_loss: 4.2066\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8932,\tval_loss: 4.2122\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8007,\tval_loss: 4.2591\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7995,\tval_loss: 4.2650\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.8713,\tval_loss: 4.1865\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7975,\tval_loss: 4.2417\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.8332,\tval_loss: 4.2222\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7827,\tval_loss: 4.2748\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7928,\tval_loss: 4.2255\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7927,\tval_loss: 4.2727\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.7431,\tval_loss: 4.3295\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7605,\tval_loss: 4.3048\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7685,\tval_loss: 4.2552\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7567,\tval_loss: 4.3051\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7615,\tval_loss: 4.3196\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.8081,\tval_loss: 4.2503\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7618,\tval_loss: 4.2961\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6969,\tval_loss: 4.3360\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7473,\tval_loss: 4.2982\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7913,\tval_loss: 4.2569\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6998,\tval_loss: 4.3021\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7082,\tval_loss: 4.3487\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7305,\tval_loss: 4.3290\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6994,\tval_loss: 4.2874\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.7134,\tval_loss: 4.2987\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6686,\tval_loss: 4.3880\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.7477,\tval_loss: 4.2941\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.7101,\tval_loss: 4.3302\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6721,\tval_loss: 4.3451\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6742,\tval_loss: 4.3389\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6979,\tval_loss: 4.3753\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.7000,\tval_loss: 4.3240\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.7420,\tval_loss: 4.2967\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.7147,\tval_loss: 4.3131\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.7252,\tval_loss: 4.2754\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.7502,\tval_loss: 4.3503\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6709,\tval_loss: 4.3377\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.7067,\tval_loss: 4.3717\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.7439,\tval_loss: 4.3235\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.6325,\tval_loss: 4.4138\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.7297,\tval_loss: 4.3518\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.6907,\tval_loss: 4.3887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4006,\tval_loss: 4.0800\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3155,\tval_loss: 4.0379\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2962,\tval_loss: 4.0315\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2557,\tval_loss: 4.0404\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2417,\tval_loss: 4.0254\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2393,\tval_loss: 4.0244\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2124,\tval_loss: 4.0272\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1859,\tval_loss: 4.0217\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1363,\tval_loss: 4.0262\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1321,\tval_loss: 4.0584\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0960,\tval_loss: 4.1109\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0680,\tval_loss: 4.1135\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0491,\tval_loss: 4.1065\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0364,\tval_loss: 4.1595\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0099,\tval_loss: 4.1508\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0101,\tval_loss: 4.1247\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0388,\tval_loss: 4.1586\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9736,\tval_loss: 4.2125\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9463,\tval_loss: 4.2200\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9185,\tval_loss: 4.2202\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9653,\tval_loss: 4.2374\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8364,\tval_loss: 4.2929\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9043,\tval_loss: 4.2633\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8073,\tval_loss: 4.2800\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8752,\tval_loss: 4.2600\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8128,\tval_loss: 4.3581\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8118,\tval_loss: 4.3934\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7549,\tval_loss: 4.3752\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7655,\tval_loss: 4.3686\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7799,\tval_loss: 4.3818\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7992,\tval_loss: 4.4007\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6984,\tval_loss: 4.4020\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7233,\tval_loss: 4.4622\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7052,\tval_loss: 4.4422\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7046,\tval_loss: 4.4530\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7493,\tval_loss: 4.4604\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6840,\tval_loss: 4.4946\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7347,\tval_loss: 4.4266\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6736,\tval_loss: 4.4717\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6855,\tval_loss: 4.4559\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6752,\tval_loss: 4.4604\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6212,\tval_loss: 4.4710\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6879,\tval_loss: 4.4821\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6738,\tval_loss: 4.4568\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6503,\tval_loss: 4.4871\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6588,\tval_loss: 4.4958\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6513,\tval_loss: 4.4436\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6665,\tval_loss: 4.4384\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6350,\tval_loss: 4.4643\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6095,\tval_loss: 4.4889\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5932,\tval_loss: 4.4697\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6646,\tval_loss: 4.4754\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5989,\tval_loss: 4.5749\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.5867,\tval_loss: 4.5969\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.5892,\tval_loss: 4.4630\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.5775,\tval_loss: 4.5742\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5332,\tval_loss: 4.5476\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5505,\tval_loss: 4.5041\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5598,\tval_loss: 4.5848\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5484,\tval_loss: 4.5864\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6097,\tval_loss: 4.5291\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6134,\tval_loss: 4.5277\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5359,\tval_loss: 4.4280\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5633,\tval_loss: 4.5264\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.4995,\tval_loss: 4.5943\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5327,\tval_loss: 4.5445\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5166,\tval_loss: 4.5105\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5056,\tval_loss: 4.6004\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.4997,\tval_loss: 4.5262\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.6217,\tval_loss: 4.5131\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.5115,\tval_loss: 4.5441\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.5227,\tval_loss: 4.5702\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.5759,\tval_loss: 4.4776\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.5938,\tval_loss: 4.4880\n",
            "74:\t[0s / 4s],\t\ttrain_loss: 3.5669,\tval_loss: 4.5668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4157,\tval_loss: 4.0490\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3173,\tval_loss: 4.0425\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3182,\tval_loss: 4.0258\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2348,\tval_loss: 4.0304\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2467,\tval_loss: 4.0185\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2288,\tval_loss: 4.0238\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2020,\tval_loss: 4.0133\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1694,\tval_loss: 4.0290\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1329,\tval_loss: 4.0571\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1295,\tval_loss: 4.0545\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0243,\tval_loss: 4.0654\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0762,\tval_loss: 4.0484\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0456,\tval_loss: 4.0689\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9796,\tval_loss: 4.0708\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.9300,\tval_loss: 4.1230\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9630,\tval_loss: 4.0905\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9457,\tval_loss: 4.1399\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9033,\tval_loss: 4.1190\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9507,\tval_loss: 4.1051\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8932,\tval_loss: 4.1198\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8969,\tval_loss: 4.1000\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8303,\tval_loss: 4.1775\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8582,\tval_loss: 4.1896\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8416,\tval_loss: 4.1594\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8004,\tval_loss: 4.1924\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7458,\tval_loss: 4.2027\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8100,\tval_loss: 4.1686\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7388,\tval_loss: 4.2463\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7517,\tval_loss: 4.2978\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.7519,\tval_loss: 4.2253\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.7739,\tval_loss: 4.2167\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7388,\tval_loss: 4.2564\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7775,\tval_loss: 4.2393\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.6851,\tval_loss: 4.3049\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7401,\tval_loss: 4.2591\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7515,\tval_loss: 4.2596\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.6864,\tval_loss: 4.2761\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6969,\tval_loss: 4.2297\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6596,\tval_loss: 4.3443\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7203,\tval_loss: 4.1765\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7543,\tval_loss: 4.2627\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6832,\tval_loss: 4.2508\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6147,\tval_loss: 4.3125\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6128,\tval_loss: 4.2969\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6590,\tval_loss: 4.2815\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6649,\tval_loss: 4.3218\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6682,\tval_loss: 4.3164\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7259,\tval_loss: 4.2836\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.7005,\tval_loss: 4.2348\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.7331,\tval_loss: 4.3538\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6659,\tval_loss: 4.3062\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.6608,\tval_loss: 4.2890\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6508,\tval_loss: 4.3338\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6342,\tval_loss: 4.3003\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.5972,\tval_loss: 4.3589\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6218,\tval_loss: 4.3808\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6028,\tval_loss: 4.4371\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6185,\tval_loss: 4.3432\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6153,\tval_loss: 4.3459\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6081,\tval_loss: 4.2976\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6600,\tval_loss: 4.2650\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5884,\tval_loss: 4.3182\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6386,\tval_loss: 4.2891\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6091,\tval_loss: 4.3429\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5868,\tval_loss: 4.2985\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5192,\tval_loss: 4.3385\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5192,\tval_loss: 4.3669\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5441,\tval_loss: 4.3952\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5239,\tval_loss: 4.3851\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5271,\tval_loss: 4.4242\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.5816,\tval_loss: 4.4043\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.5793,\tval_loss: 4.3375\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.5552,\tval_loss: 4.3499\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.5987,\tval_loss: 4.3440\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4251,\tval_loss: 4.0235\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2906,\tval_loss: 4.0325\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2718,\tval_loss: 4.0285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2303,\tval_loss: 4.0352\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1887,\tval_loss: 4.0278\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1982,\tval_loss: 4.0101\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1835,\tval_loss: 4.0195\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1167,\tval_loss: 4.0791\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1055,\tval_loss: 4.0604\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1080,\tval_loss: 4.0228\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0969,\tval_loss: 4.0795\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0799,\tval_loss: 4.0562\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0736,\tval_loss: 4.0332\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0477,\tval_loss: 4.0062\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0048,\tval_loss: 4.0520\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0575,\tval_loss: 4.0269\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0175,\tval_loss: 4.0603\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0381,\tval_loss: 4.0564\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9931,\tval_loss: 4.0792\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9545,\tval_loss: 4.0494\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9751,\tval_loss: 4.0285\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9482,\tval_loss: 4.0775\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9246,\tval_loss: 4.1012\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9728,\tval_loss: 4.1237\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9048,\tval_loss: 4.0489\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9042,\tval_loss: 4.0951\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9450,\tval_loss: 4.1248\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8956,\tval_loss: 4.0795\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8783,\tval_loss: 4.1755\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8875,\tval_loss: 4.0588\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.9086,\tval_loss: 4.1516\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8515,\tval_loss: 4.1369\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8582,\tval_loss: 4.1668\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7836,\tval_loss: 4.0986\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8409,\tval_loss: 4.1766\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7763,\tval_loss: 4.1617\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.8395,\tval_loss: 4.1345\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.8561,\tval_loss: 4.1214\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.8222,\tval_loss: 4.1379\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.8256,\tval_loss: 4.0819\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.8066,\tval_loss: 4.1846\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7453,\tval_loss: 4.1696\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7543,\tval_loss: 4.1504\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7189,\tval_loss: 4.1865\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7297,\tval_loss: 4.1618\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7862,\tval_loss: 4.1287\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7801,\tval_loss: 4.1698\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7357,\tval_loss: 4.1561\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7383,\tval_loss: 4.1252\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6494,\tval_loss: 4.1917\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6925,\tval_loss: 4.1408\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7096,\tval_loss: 4.1692\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7014,\tval_loss: 4.1752\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6371,\tval_loss: 4.1404\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7091,\tval_loss: 4.2379\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6572,\tval_loss: 4.1759\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6937,\tval_loss: 4.1809\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6392,\tval_loss: 4.2003\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6454,\tval_loss: 4.2200\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5966,\tval_loss: 4.1786\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6100,\tval_loss: 4.2119\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6133,\tval_loss: 4.1734\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6159,\tval_loss: 4.2683\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6915,\tval_loss: 4.2714\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6238,\tval_loss: 4.1722\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6051,\tval_loss: 4.2156\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6479,\tval_loss: 4.2249\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6441,\tval_loss: 4.2496\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6391,\tval_loss: 4.2202\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6521,\tval_loss: 4.2438\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6410,\tval_loss: 4.1921\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.6603,\tval_loss: 4.2533\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.6426,\tval_loss: 4.2113\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.5753,\tval_loss: 4.2195\n",
            "74:\t[0s / 3s],\t\ttrain_loss: 3.6405,\tval_loss: 4.2299\n",
            "75:\t[0s / 3s],\t\ttrain_loss: 3.5939,\tval_loss: 4.2067\n",
            "76:\t[0s / 3s],\t\ttrain_loss: 3.6389,\tval_loss: 4.1919\n",
            "77:\t[0s / 3s],\t\ttrain_loss: 3.6314,\tval_loss: 4.2226\n",
            "78:\t[0s / 3s],\t\ttrain_loss: 3.6270,\tval_loss: 4.2235\n",
            "79:\t[0s / 3s],\t\ttrain_loss: 3.6564,\tval_loss: 4.2056\n",
            "80:\t[0s / 3s],\t\ttrain_loss: 3.5872,\tval_loss: 4.2515\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4033,\tval_loss: 4.0655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2690,\tval_loss: 4.0771\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2474,\tval_loss: 4.0551\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2117,\tval_loss: 4.0772\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1847,\tval_loss: 4.0714\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2153,\tval_loss: 4.0833\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1720,\tval_loss: 4.0793\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1646,\tval_loss: 4.1075\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1196,\tval_loss: 4.1207\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0900,\tval_loss: 4.1532\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0369,\tval_loss: 4.1280\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0615,\tval_loss: 4.2478\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0545,\tval_loss: 4.1634\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0179,\tval_loss: 4.1601\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0532,\tval_loss: 4.2016\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9230,\tval_loss: 4.2798\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0031,\tval_loss: 4.2053\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9940,\tval_loss: 4.1585\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9947,\tval_loss: 4.2026\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9640,\tval_loss: 4.1408\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.9620,\tval_loss: 4.2150\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9004,\tval_loss: 4.1891\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8848,\tval_loss: 4.2129\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8540,\tval_loss: 4.2168\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9207,\tval_loss: 4.1877\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8534,\tval_loss: 4.2366\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8617,\tval_loss: 4.2361\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8843,\tval_loss: 4.1932\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8208,\tval_loss: 4.2459\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8047,\tval_loss: 4.1631\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7752,\tval_loss: 4.2455\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8101,\tval_loss: 4.2052\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7861,\tval_loss: 4.2190\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7537,\tval_loss: 4.3045\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7549,\tval_loss: 4.2377\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8090,\tval_loss: 4.2532\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7283,\tval_loss: 4.2570\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7838,\tval_loss: 4.1988\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7568,\tval_loss: 4.2047\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7447,\tval_loss: 4.2616\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7364,\tval_loss: 4.2707\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7550,\tval_loss: 4.2262\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.7698,\tval_loss: 4.2072\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7118,\tval_loss: 4.2211\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7116,\tval_loss: 4.2603\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7196,\tval_loss: 4.1934\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6746,\tval_loss: 4.2522\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6742,\tval_loss: 4.2218\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7382,\tval_loss: 4.1610\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7092,\tval_loss: 4.3308\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7135,\tval_loss: 4.1435\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6820,\tval_loss: 4.2327\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6713,\tval_loss: 4.2913\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7545,\tval_loss: 4.2666\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7148,\tval_loss: 4.2151\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.7115,\tval_loss: 4.2827\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6901,\tval_loss: 4.2022\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6391,\tval_loss: 4.3099\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6484,\tval_loss: 4.2123\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6240,\tval_loss: 4.2879\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6749,\tval_loss: 4.2140\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6266,\tval_loss: 4.2436\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6388,\tval_loss: 4.2634\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.6732,\tval_loss: 4.1820\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.6202,\tval_loss: 4.3512\n",
            "65:\t[0s / 2s],\t\ttrain_loss: 3.6613,\tval_loss: 4.2734\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6762,\tval_loss: 4.2425\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6517,\tval_loss: 4.2283\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6687,\tval_loss: 4.2252\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5870,\tval_loss: 4.1929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4107,\tval_loss: 4.1429\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2536,\tval_loss: 4.0947\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2236,\tval_loss: 4.0980\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1479,\tval_loss: 4.0844\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1591,\tval_loss: 4.0627\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1629,\tval_loss: 4.0748\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1842,\tval_loss: 4.0595\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0982,\tval_loss: 4.0969\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1265,\tval_loss: 4.0615\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0582,\tval_loss: 4.1279\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0655,\tval_loss: 4.1638\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0321,\tval_loss: 4.1804\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9778,\tval_loss: 4.1956\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9646,\tval_loss: 4.2652\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9001,\tval_loss: 4.2843\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9726,\tval_loss: 4.2355\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9228,\tval_loss: 4.2580\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8911,\tval_loss: 4.2581\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9088,\tval_loss: 4.2953\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9218,\tval_loss: 4.2390\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.8384,\tval_loss: 4.3820\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8570,\tval_loss: 4.3240\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8603,\tval_loss: 4.2744\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8205,\tval_loss: 4.3506\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7679,\tval_loss: 4.3862\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7789,\tval_loss: 4.4144\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8082,\tval_loss: 4.3335\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7033,\tval_loss: 4.4420\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7591,\tval_loss: 4.3864\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8595,\tval_loss: 4.3405\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7375,\tval_loss: 4.4090\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7458,\tval_loss: 4.3873\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7081,\tval_loss: 4.4416\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7068,\tval_loss: 4.4485\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6809,\tval_loss: 4.3277\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6461,\tval_loss: 4.5608\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6202,\tval_loss: 4.5012\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7003,\tval_loss: 4.3798\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7558,\tval_loss: 4.3973\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7201,\tval_loss: 4.3709\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6828,\tval_loss: 4.3003\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6731,\tval_loss: 4.3954\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5972,\tval_loss: 4.3675\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6192,\tval_loss: 4.5318\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6199,\tval_loss: 4.4453\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6462,\tval_loss: 4.4223\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6081,\tval_loss: 4.5852\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5479,\tval_loss: 4.4466\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6339,\tval_loss: 4.3467\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6152,\tval_loss: 4.4217\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6362,\tval_loss: 4.3792\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6102,\tval_loss: 4.3872\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6406,\tval_loss: 4.3117\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.5803,\tval_loss: 4.4934\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.5145,\tval_loss: 4.4034\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.5469,\tval_loss: 4.4576\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5590,\tval_loss: 4.4246\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6954,\tval_loss: 4.4026\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6518,\tval_loss: 4.3659\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5307,\tval_loss: 4.5803\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5568,\tval_loss: 4.3568\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5407,\tval_loss: 4.3701\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5198,\tval_loss: 4.5433\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5658,\tval_loss: 4.4694\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5182,\tval_loss: 4.4776\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.4993,\tval_loss: 4.4687\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5062,\tval_loss: 4.4639\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.5421,\tval_loss: 4.5434\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.5825,\tval_loss: 4.3922\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.4397,\tval_loss: 4.4807\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.4662,\tval_loss: 4.5269\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.5001,\tval_loss: 4.4504\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.5553,\tval_loss: 4.4351\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.4961,\tval_loss: 4.5405\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3838,\tval_loss: 4.1159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2861,\tval_loss: 4.1012\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2192,\tval_loss: 4.1031\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2151,\tval_loss: 4.0948\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1801,\tval_loss: 4.1066\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1419,\tval_loss: 4.1049\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1573,\tval_loss: 4.0872\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1376,\tval_loss: 4.0998\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1130,\tval_loss: 4.1229\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0945,\tval_loss: 4.1113\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0372,\tval_loss: 4.1509\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0083,\tval_loss: 4.1679\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9801,\tval_loss: 4.1716\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 3.9679,\tval_loss: 4.2068\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.9875,\tval_loss: 4.2149\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9253,\tval_loss: 4.1901\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.8931,\tval_loss: 4.3078\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9294,\tval_loss: 4.2503\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9143,\tval_loss: 4.2369\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9223,\tval_loss: 4.1970\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8851,\tval_loss: 4.2306\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8671,\tval_loss: 4.2436\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7953,\tval_loss: 4.2725\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8552,\tval_loss: 4.2082\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8195,\tval_loss: 4.2555\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8447,\tval_loss: 4.2739\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6986,\tval_loss: 4.3628\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7886,\tval_loss: 4.2995\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 3.8140,\tval_loss: 4.3075\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.7377,\tval_loss: 4.3462\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.7642,\tval_loss: 4.2840\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7112,\tval_loss: 4.3907\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7413,\tval_loss: 4.3990\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.7836,\tval_loss: 4.3376\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.6588,\tval_loss: 4.4389\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.8001,\tval_loss: 4.3243\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7959,\tval_loss: 4.3801\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7574,\tval_loss: 4.3653\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6903,\tval_loss: 4.3717\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7382,\tval_loss: 4.4102\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6872,\tval_loss: 4.3766\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6948,\tval_loss: 4.4185\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6179,\tval_loss: 4.3854\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6846,\tval_loss: 4.4065\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7136,\tval_loss: 4.3754\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6160,\tval_loss: 4.4223\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6724,\tval_loss: 4.3971\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6738,\tval_loss: 4.3839\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6565,\tval_loss: 4.4319\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6611,\tval_loss: 4.4140\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6122,\tval_loss: 4.4185\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.6502,\tval_loss: 4.3719\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6292,\tval_loss: 4.4083\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6096,\tval_loss: 4.4339\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6295,\tval_loss: 4.3619\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6217,\tval_loss: 4.4589\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5498,\tval_loss: 4.3961\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6048,\tval_loss: 4.4088\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5953,\tval_loss: 4.4143\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6322,\tval_loss: 4.3989\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6408,\tval_loss: 4.3731\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5628,\tval_loss: 4.4488\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5933,\tval_loss: 4.4153\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5979,\tval_loss: 4.4156\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5629,\tval_loss: 4.4913\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5675,\tval_loss: 4.3960\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5861,\tval_loss: 4.3867\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5817,\tval_loss: 4.4347\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5445,\tval_loss: 4.4474\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5597,\tval_loss: 4.4260\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5654,\tval_loss: 4.3467\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.5196,\tval_loss: 4.4843\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.6046,\tval_loss: 4.4795\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.5412,\tval_loss: 4.4285\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4830,\tval_loss: 4.0568\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3461,\tval_loss: 4.0679\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2030,\tval_loss: 4.0600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2558,\tval_loss: 4.0525\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2175,\tval_loss: 4.0503\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2030,\tval_loss: 4.0623\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1695,\tval_loss: 4.0551\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1283,\tval_loss: 4.0534\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1510,\tval_loss: 4.0736\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1883,\tval_loss: 4.0909\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1058,\tval_loss: 4.1009\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0773,\tval_loss: 4.1063\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0382,\tval_loss: 4.1459\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0205,\tval_loss: 4.1772\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0347,\tval_loss: 4.1935\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9657,\tval_loss: 4.2020\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8428,\tval_loss: 4.2083\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9153,\tval_loss: 4.2563\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8650,\tval_loss: 4.2287\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8306,\tval_loss: 4.2881\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8468,\tval_loss: 4.2899\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8050,\tval_loss: 4.2719\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8023,\tval_loss: 4.2657\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7277,\tval_loss: 4.2466\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7321,\tval_loss: 4.3029\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7189,\tval_loss: 4.2958\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6376,\tval_loss: 4.3301\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6244,\tval_loss: 4.3944\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.5117,\tval_loss: 4.3877\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.5086,\tval_loss: 4.4465\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.5817,\tval_loss: 4.3988\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.5723,\tval_loss: 4.3845\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.5578,\tval_loss: 4.5413\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.5681,\tval_loss: 4.3807\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.5488,\tval_loss: 4.5608\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.5307,\tval_loss: 4.4111\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.5273,\tval_loss: 4.3949\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.5641,\tval_loss: 4.5025\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.5252,\tval_loss: 4.5013\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.5447,\tval_loss: 4.4189\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.5117,\tval_loss: 4.4362\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.5232,\tval_loss: 4.4196\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5441,\tval_loss: 4.5093\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.4509,\tval_loss: 4.4183\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.4117,\tval_loss: 4.7067\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.4244,\tval_loss: 4.4666\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.3976,\tval_loss: 4.5088\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.4307,\tval_loss: 4.4942\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.3862,\tval_loss: 4.5369\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.4245,\tval_loss: 4.4201\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.4011,\tval_loss: 4.6130\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.3641,\tval_loss: 4.5355\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.4190,\tval_loss: 4.5757\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.3113,\tval_loss: 4.5659\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.4234,\tval_loss: 4.5820\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.4816,\tval_loss: 4.5255\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.3849,\tval_loss: 4.5280\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.3816,\tval_loss: 4.4992\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.3684,\tval_loss: 4.6398\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.3457,\tval_loss: 4.6235\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.4852,\tval_loss: 4.4738\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.3655,\tval_loss: 4.5729\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.2985,\tval_loss: 4.6171\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.3913,\tval_loss: 4.5653\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.3442,\tval_loss: 4.5006\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.3295,\tval_loss: 4.5240\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.3836,\tval_loss: 4.5457\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4117,\tval_loss: 4.5062\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.3635,\tval_loss: 4.5433\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.2907,\tval_loss: 4.5720\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.2805,\tval_loss: 4.5727\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.3906,\tval_loss: 4.6180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4347,\tval_loss: 4.0073\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2828,\tval_loss: 3.9895\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2624,\tval_loss: 3.9757\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2250,\tval_loss: 3.9813\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2427,\tval_loss: 3.9753\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2039,\tval_loss: 3.9981\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1437,\tval_loss: 3.9884\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1608,\tval_loss: 4.0104\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1142,\tval_loss: 3.9999\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1110,\tval_loss: 4.0380\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0954,\tval_loss: 4.0078\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0457,\tval_loss: 4.0266\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0223,\tval_loss: 4.0430\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0980,\tval_loss: 4.0350\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0083,\tval_loss: 4.0344\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0674,\tval_loss: 4.0513\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0635,\tval_loss: 4.0579\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9749,\tval_loss: 4.1080\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9797,\tval_loss: 4.1174\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 4.0458,\tval_loss: 4.1143\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.9986,\tval_loss: 4.1046\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 4.0211,\tval_loss: 4.1081\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9367,\tval_loss: 4.1740\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9396,\tval_loss: 4.2142\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9649,\tval_loss: 4.1612\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8786,\tval_loss: 4.2456\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8968,\tval_loss: 4.1425\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8647,\tval_loss: 4.1385\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.9111,\tval_loss: 4.1820\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8805,\tval_loss: 4.1880\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8446,\tval_loss: 4.1926\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8560,\tval_loss: 4.1580\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8424,\tval_loss: 4.2252\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8591,\tval_loss: 4.2207\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8292,\tval_loss: 4.1918\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7891,\tval_loss: 4.2079\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7875,\tval_loss: 4.1970\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.8143,\tval_loss: 4.2203\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7233,\tval_loss: 4.2915\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.8305,\tval_loss: 4.2063\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7389,\tval_loss: 4.2437\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7088,\tval_loss: 4.3131\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.7292,\tval_loss: 4.2535\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.8289,\tval_loss: 4.2276\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7445,\tval_loss: 4.2372\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7593,\tval_loss: 4.2359\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7459,\tval_loss: 4.3171\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7492,\tval_loss: 4.2414\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6725,\tval_loss: 4.3255\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7390,\tval_loss: 4.2790\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7339,\tval_loss: 4.2601\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7231,\tval_loss: 4.2669\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7824,\tval_loss: 4.2748\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6723,\tval_loss: 4.2646\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6619,\tval_loss: 4.2560\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6875,\tval_loss: 4.3212\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6527,\tval_loss: 4.2678\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.7172,\tval_loss: 4.2314\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.7252,\tval_loss: 4.3182\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6982,\tval_loss: 4.2513\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6208,\tval_loss: 4.3379\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6531,\tval_loss: 4.2506\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6931,\tval_loss: 4.2514\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.6717,\tval_loss: 4.2975\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.7092,\tval_loss: 4.2389\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6649,\tval_loss: 4.2485\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6671,\tval_loss: 4.2655\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6820,\tval_loss: 4.1990\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6357,\tval_loss: 4.2934\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5453,\tval_loss: 4.2164\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6281,\tval_loss: 4.2368\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.5845,\tval_loss: 4.2090\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4110,\tval_loss: 4.1146\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2982,\tval_loss: 4.0857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2634,\tval_loss: 4.0881\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2400,\tval_loss: 4.1224\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2346,\tval_loss: 4.1017\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1697,\tval_loss: 4.1379\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1604,\tval_loss: 4.0753\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1863,\tval_loss: 4.1030\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1529,\tval_loss: 4.1079\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1230,\tval_loss: 4.1328\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0788,\tval_loss: 4.1109\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0522,\tval_loss: 4.1220\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1005,\tval_loss: 4.1481\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0289,\tval_loss: 4.1472\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9754,\tval_loss: 4.1092\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0062,\tval_loss: 4.0600\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9645,\tval_loss: 4.1502\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9387,\tval_loss: 4.0824\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9692,\tval_loss: 4.0758\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9236,\tval_loss: 4.1468\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8900,\tval_loss: 4.1225\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8353,\tval_loss: 4.0875\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8032,\tval_loss: 4.0914\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8735,\tval_loss: 4.1270\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8104,\tval_loss: 4.1510\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7732,\tval_loss: 4.1805\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8451,\tval_loss: 4.1281\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7806,\tval_loss: 4.1605\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7414,\tval_loss: 4.0760\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7527,\tval_loss: 4.1219\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7405,\tval_loss: 4.2669\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6965,\tval_loss: 4.1248\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7057,\tval_loss: 4.1626\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6982,\tval_loss: 4.1983\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7240,\tval_loss: 4.1147\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7430,\tval_loss: 4.1635\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.6813,\tval_loss: 4.1852\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6879,\tval_loss: 4.1618\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7048,\tval_loss: 4.1480\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6762,\tval_loss: 4.1687\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6618,\tval_loss: 4.1729\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6652,\tval_loss: 4.2083\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6983,\tval_loss: 4.1726\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6624,\tval_loss: 4.2331\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6945,\tval_loss: 4.1699\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6969,\tval_loss: 4.1943\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6427,\tval_loss: 4.2695\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7202,\tval_loss: 4.1439\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6790,\tval_loss: 4.1960\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6226,\tval_loss: 4.2108\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6330,\tval_loss: 4.2356\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.5880,\tval_loss: 4.3289\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6726,\tval_loss: 4.1973\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6889,\tval_loss: 4.2576\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.5861,\tval_loss: 4.3907\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.5998,\tval_loss: 4.2281\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6430,\tval_loss: 4.2445\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5764,\tval_loss: 4.2445\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5759,\tval_loss: 4.2365\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6175,\tval_loss: 4.2401\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5922,\tval_loss: 4.2983\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5919,\tval_loss: 4.2671\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5438,\tval_loss: 4.2665\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5903,\tval_loss: 4.2766\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.5772,\tval_loss: 4.3315\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.6476,\tval_loss: 4.2121\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.5364,\tval_loss: 4.2844\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.5459,\tval_loss: 4.2991\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.5779,\tval_loss: 4.3152\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.6171,\tval_loss: 4.2852\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.5136,\tval_loss: 4.3721\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.5427,\tval_loss: 4.2659\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.5341,\tval_loss: 4.2694\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.5515,\tval_loss: 4.2636\n",
            "74:\t[0s / 4s],\t\ttrain_loss: 3.5862,\tval_loss: 4.2596\n",
            "75:\t[0s / 4s],\t\ttrain_loss: 3.5273,\tval_loss: 4.2710\n",
            "76:\t[0s / 4s],\t\ttrain_loss: 3.5067,\tval_loss: 4.2831\n",
            "77:\t[0s / 4s],\t\ttrain_loss: 3.5004,\tval_loss: 4.2871\n",
            "78:\t[0s / 4s],\t\ttrain_loss: 3.5822,\tval_loss: 4.2075\n",
            "79:\t[0s / 4s],\t\ttrain_loss: 3.4582,\tval_loss: 4.3348\n",
            "80:\t[0s / 5s],\t\ttrain_loss: 3.4912,\tval_loss: 4.3214\n",
            "81:\t[0s / 5s],\t\ttrain_loss: 3.5015,\tval_loss: 4.2902\n",
            "82:\t[0s / 5s],\t\ttrain_loss: 3.4780,\tval_loss: 4.2313\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3483,\tval_loss: 4.1486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2687,\tval_loss: 4.1527\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2455,\tval_loss: 4.1610\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2398,\tval_loss: 4.1440\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2463,\tval_loss: 4.1395\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2002,\tval_loss: 4.1673\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2269,\tval_loss: 4.1517\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1994,\tval_loss: 4.1625\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1983,\tval_loss: 4.1413\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1447,\tval_loss: 4.1739\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1597,\tval_loss: 4.1792\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1243,\tval_loss: 4.1884\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 4.1564,\tval_loss: 4.1862\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 4.1037,\tval_loss: 4.2170\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.1092,\tval_loss: 4.2388\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0727,\tval_loss: 4.2695\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 4.0515,\tval_loss: 4.2752\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 4.0164,\tval_loss: 4.2582\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 4.0304,\tval_loss: 4.3662\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 4.0134,\tval_loss: 4.2404\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 4.0182,\tval_loss: 4.3460\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9575,\tval_loss: 4.3947\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9320,\tval_loss: 4.4233\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9046,\tval_loss: 4.4615\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9142,\tval_loss: 4.4410\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8403,\tval_loss: 4.4511\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8362,\tval_loss: 4.5381\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7679,\tval_loss: 4.5621\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8450,\tval_loss: 4.5145\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7552,\tval_loss: 4.5677\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7536,\tval_loss: 4.5222\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8057,\tval_loss: 4.5066\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7768,\tval_loss: 4.5633\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7507,\tval_loss: 4.4819\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6223,\tval_loss: 4.6467\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7358,\tval_loss: 4.5402\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7226,\tval_loss: 4.3806\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7196,\tval_loss: 4.6291\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7522,\tval_loss: 4.4673\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6892,\tval_loss: 4.5799\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6617,\tval_loss: 4.5609\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7282,\tval_loss: 4.4468\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6409,\tval_loss: 4.6375\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6771,\tval_loss: 4.4636\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6609,\tval_loss: 4.5484\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6525,\tval_loss: 4.5594\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6197,\tval_loss: 4.5912\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6678,\tval_loss: 4.6472\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6670,\tval_loss: 4.5851\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6565,\tval_loss: 4.5408\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6172,\tval_loss: 4.4832\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6896,\tval_loss: 4.5005\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6307,\tval_loss: 4.5547\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5923,\tval_loss: 4.4787\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6424,\tval_loss: 4.5492\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6161,\tval_loss: 4.5910\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6398,\tval_loss: 4.4908\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5638,\tval_loss: 4.6009\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5743,\tval_loss: 4.6291\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6507,\tval_loss: 4.4994\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6000,\tval_loss: 4.5984\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6019,\tval_loss: 4.4895\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5150,\tval_loss: 4.5945\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5202,\tval_loss: 4.6089\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5674,\tval_loss: 4.5537\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6512,\tval_loss: 4.5580\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5402,\tval_loss: 4.6386\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5523,\tval_loss: 4.5956\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5657,\tval_loss: 4.6740\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.4978,\tval_loss: 4.5917\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6454,\tval_loss: 4.5341\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.6121,\tval_loss: 4.4957\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4547,\tval_loss: 4.0699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2883,\tval_loss: 4.0564\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2087,\tval_loss: 4.0614\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2507,\tval_loss: 4.0802\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2230,\tval_loss: 4.0826\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2379,\tval_loss: 4.1036\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2325,\tval_loss: 4.0965\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2042,\tval_loss: 4.1202\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.2197,\tval_loss: 4.1075\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.2070,\tval_loss: 4.1308\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1877,\tval_loss: 4.1438\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1791,\tval_loss: 4.1266\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1435,\tval_loss: 4.1613\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1607,\tval_loss: 4.1337\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.1542,\tval_loss: 4.2073\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.1205,\tval_loss: 4.1547\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.1338,\tval_loss: 4.1301\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0927,\tval_loss: 4.1748\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0550,\tval_loss: 4.2211\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 4.0282,\tval_loss: 4.2031\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 4.0484,\tval_loss: 4.2431\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 4.0311,\tval_loss: 4.1901\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 4.0184,\tval_loss: 4.2442\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9854,\tval_loss: 4.2277\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 4.0163,\tval_loss: 4.2346\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9836,\tval_loss: 4.1683\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9628,\tval_loss: 4.1617\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9452,\tval_loss: 4.2290\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.9529,\tval_loss: 4.1805\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.9804,\tval_loss: 4.1885\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.9307,\tval_loss: 4.2037\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.9359,\tval_loss: 4.2170\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.9249,\tval_loss: 4.2231\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.9580,\tval_loss: 4.1636\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.9240,\tval_loss: 4.2194\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8622,\tval_loss: 4.1815\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.8981,\tval_loss: 4.2090\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.8801,\tval_loss: 4.2173\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.9043,\tval_loss: 4.2332\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.8400,\tval_loss: 4.2666\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.8563,\tval_loss: 4.2775\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.8875,\tval_loss: 4.1997\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.8057,\tval_loss: 4.3108\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.8761,\tval_loss: 4.2078\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.8656,\tval_loss: 4.2716\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.8430,\tval_loss: 4.2501\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.8239,\tval_loss: 4.2899\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.8263,\tval_loss: 4.2685\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.8697,\tval_loss: 4.2421\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.8749,\tval_loss: 4.2104\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.8604,\tval_loss: 4.1894\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7743,\tval_loss: 4.2790\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.8136,\tval_loss: 4.2481\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.8451,\tval_loss: 4.2382\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.8169,\tval_loss: 4.2406\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.7932,\tval_loss: 4.2338\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.8344,\tval_loss: 4.2267\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.8166,\tval_loss: 4.2488\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.8404,\tval_loss: 4.2140\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.7578,\tval_loss: 4.2701\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.8095,\tval_loss: 4.2623\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.8024,\tval_loss: 4.2573\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.8745,\tval_loss: 4.2303\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.8190,\tval_loss: 4.2349\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.8134,\tval_loss: 4.3019\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.8691,\tval_loss: 4.2298\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.7982,\tval_loss: 4.2736\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.7472,\tval_loss: 4.3248\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.8114,\tval_loss: 4.3253\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4438,\tval_loss: 4.0940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3188,\tval_loss: 4.0834\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2951,\tval_loss: 4.0879\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2713,\tval_loss: 4.1046\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2492,\tval_loss: 4.0843\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1964,\tval_loss: 4.0969\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1955,\tval_loss: 4.0704\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1484,\tval_loss: 4.0944\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1527,\tval_loss: 4.1160\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0990,\tval_loss: 4.1217\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0815,\tval_loss: 4.1407\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0761,\tval_loss: 4.1700\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0477,\tval_loss: 4.1926\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0335,\tval_loss: 4.1715\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0532,\tval_loss: 4.1967\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9688,\tval_loss: 4.1801\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9805,\tval_loss: 4.2546\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9429,\tval_loss: 4.2318\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8995,\tval_loss: 4.2262\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9305,\tval_loss: 4.2267\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8954,\tval_loss: 4.2681\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8204,\tval_loss: 4.3042\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8057,\tval_loss: 4.2451\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8563,\tval_loss: 4.2829\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8242,\tval_loss: 4.3046\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7421,\tval_loss: 4.3401\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7556,\tval_loss: 4.4441\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7369,\tval_loss: 4.3996\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7372,\tval_loss: 4.2906\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7650,\tval_loss: 4.3296\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7483,\tval_loss: 4.3921\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7353,\tval_loss: 4.2888\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7168,\tval_loss: 4.4904\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7150,\tval_loss: 4.2555\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6718,\tval_loss: 4.4102\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6565,\tval_loss: 4.4229\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7113,\tval_loss: 4.4819\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6452,\tval_loss: 4.3891\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6403,\tval_loss: 4.3938\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6384,\tval_loss: 4.4053\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5840,\tval_loss: 4.4634\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6092,\tval_loss: 4.4465\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5752,\tval_loss: 4.4594\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6090,\tval_loss: 4.4786\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6369,\tval_loss: 4.4679\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5574,\tval_loss: 4.5223\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6052,\tval_loss: 4.4815\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5550,\tval_loss: 4.5127\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6004,\tval_loss: 4.4957\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5665,\tval_loss: 4.4975\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.5974,\tval_loss: 4.4315\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.5468,\tval_loss: 4.4540\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.5175,\tval_loss: 4.5205\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.5644,\tval_loss: 4.4245\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.5401,\tval_loss: 4.4900\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.4437,\tval_loss: 4.5307\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5431,\tval_loss: 4.5331\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5477,\tval_loss: 4.4159\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.4907,\tval_loss: 4.3878\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5340,\tval_loss: 4.5471\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.3875,\tval_loss: 4.4617\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5419,\tval_loss: 4.4776\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5068,\tval_loss: 4.5101\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.4500,\tval_loss: 4.5741\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5369,\tval_loss: 4.5891\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.5286,\tval_loss: 4.4167\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.5054,\tval_loss: 4.6265\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.4033,\tval_loss: 4.5949\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.3653,\tval_loss: 4.5790\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.5177,\tval_loss: 4.5431\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.4320,\tval_loss: 4.5780\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.4739,\tval_loss: 4.4413\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.4309,\tval_loss: 4.5315\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.5210,\tval_loss: 4.4433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4193,\tval_loss: 4.0727\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2626,\tval_loss: 4.0606\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2467,\tval_loss: 4.0638\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1945,\tval_loss: 4.0515\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1969,\tval_loss: 4.0495\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1236,\tval_loss: 4.0740\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1588,\tval_loss: 4.0721\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1511,\tval_loss: 4.0867\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1198,\tval_loss: 4.1201\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1249,\tval_loss: 4.1025\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1347,\tval_loss: 4.0985\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 4.1051,\tval_loss: 4.1342\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 4.0486,\tval_loss: 4.1237\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 4.0367,\tval_loss: 4.1487\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0269,\tval_loss: 4.2566\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0395,\tval_loss: 4.2101\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9435,\tval_loss: 4.2509\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9401,\tval_loss: 4.2868\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9940,\tval_loss: 4.3151\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8949,\tval_loss: 4.3397\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8921,\tval_loss: 4.3328\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8155,\tval_loss: 4.4276\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8783,\tval_loss: 4.5193\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 3.8344,\tval_loss: 4.4118\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 3.8210,\tval_loss: 4.4731\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 3.8320,\tval_loss: 4.4625\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 3.8009,\tval_loss: 4.4691\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 3.7375,\tval_loss: 4.5581\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 3.7453,\tval_loss: 4.5261\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.7229,\tval_loss: 4.4851\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.7625,\tval_loss: 4.5052\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7137,\tval_loss: 4.4726\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7541,\tval_loss: 4.5396\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.7322,\tval_loss: 4.5630\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.6509,\tval_loss: 4.6060\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 3.6676,\tval_loss: 4.5492\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 3.7024,\tval_loss: 4.5650\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 3.7330,\tval_loss: 4.5720\n",
            "38:\t[0s / 3s],\t\ttrain_loss: 3.7368,\tval_loss: 4.6353\n",
            "39:\t[0s / 3s],\t\ttrain_loss: 3.7001,\tval_loss: 4.5944\n",
            "40:\t[0s / 3s],\t\ttrain_loss: 3.6732,\tval_loss: 4.5578\n",
            "41:\t[0s / 3s],\t\ttrain_loss: 3.7093,\tval_loss: 4.5850\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 3.6264,\tval_loss: 4.6103\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 3.6102,\tval_loss: 4.6548\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.5297,\tval_loss: 4.6437\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.6431,\tval_loss: 4.6595\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.5433,\tval_loss: 4.6543\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.5221,\tval_loss: 4.5861\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.6015,\tval_loss: 4.7572\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6145,\tval_loss: 4.6278\n",
            "50:\t[0s / 4s],\t\ttrain_loss: 3.6420,\tval_loss: 4.5533\n",
            "51:\t[0s / 4s],\t\ttrain_loss: 3.6227,\tval_loss: 4.5467\n",
            "52:\t[0s / 4s],\t\ttrain_loss: 3.5419,\tval_loss: 4.7251\n",
            "53:\t[0s / 4s],\t\ttrain_loss: 3.5445,\tval_loss: 4.6441\n",
            "54:\t[0s / 4s],\t\ttrain_loss: 3.5722,\tval_loss: 4.6071\n",
            "55:\t[0s / 4s],\t\ttrain_loss: 3.6337,\tval_loss: 4.6143\n",
            "56:\t[0s / 4s],\t\ttrain_loss: 3.5959,\tval_loss: 4.5739\n",
            "57:\t[0s / 4s],\t\ttrain_loss: 3.6356,\tval_loss: 4.5796\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 3.5877,\tval_loss: 4.6211\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 3.5854,\tval_loss: 4.6363\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 3.5526,\tval_loss: 4.6650\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.5932,\tval_loss: 4.6366\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.5528,\tval_loss: 4.6132\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.5583,\tval_loss: 4.6416\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.4933,\tval_loss: 4.6904\n",
            "65:\t[0s / 5s],\t\ttrain_loss: 3.5286,\tval_loss: 4.6737\n",
            "66:\t[0s / 5s],\t\ttrain_loss: 3.5686,\tval_loss: 4.7452\n",
            "67:\t[0s / 5s],\t\ttrain_loss: 3.5816,\tval_loss: 4.5554\n",
            "68:\t[0s / 5s],\t\ttrain_loss: 3.6465,\tval_loss: 4.5155\n",
            "69:\t[0s / 5s],\t\ttrain_loss: 3.4787,\tval_loss: 4.6784\n",
            "70:\t[0s / 5s],\t\ttrain_loss: 3.5981,\tval_loss: 4.6418\n",
            "71:\t[0s / 5s],\t\ttrain_loss: 3.4554,\tval_loss: 4.6663\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3500,\tval_loss: 4.0439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2193,\tval_loss: 4.0218\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1422,\tval_loss: 4.0279\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1231,\tval_loss: 4.0370\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1138,\tval_loss: 4.0552\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1194,\tval_loss: 4.0454\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0974,\tval_loss: 4.0721\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0805,\tval_loss: 4.0518\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0433,\tval_loss: 4.0737\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0156,\tval_loss: 4.1311\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0343,\tval_loss: 4.0643\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0346,\tval_loss: 4.0973\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9423,\tval_loss: 4.1461\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9752,\tval_loss: 4.1533\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9406,\tval_loss: 4.1176\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.8861,\tval_loss: 4.1852\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.8697,\tval_loss: 4.1959\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8129,\tval_loss: 4.2447\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.7960,\tval_loss: 4.2018\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.7762,\tval_loss: 4.2609\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8167,\tval_loss: 4.2430\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7530,\tval_loss: 4.3156\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7520,\tval_loss: 4.2517\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7305,\tval_loss: 4.3091\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.6632,\tval_loss: 4.2624\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6339,\tval_loss: 4.2566\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6570,\tval_loss: 4.3165\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6837,\tval_loss: 4.2521\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6376,\tval_loss: 4.2371\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.5887,\tval_loss: 4.3842\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.5864,\tval_loss: 4.2771\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6583,\tval_loss: 4.2768\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.5708,\tval_loss: 4.3992\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6352,\tval_loss: 4.2729\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.5986,\tval_loss: 4.3357\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6175,\tval_loss: 4.3649\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.5945,\tval_loss: 4.2956\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.5398,\tval_loss: 4.3753\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.5224,\tval_loss: 4.4061\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6910,\tval_loss: 4.2827\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5812,\tval_loss: 4.3452\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5209,\tval_loss: 4.3623\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5186,\tval_loss: 4.4100\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5330,\tval_loss: 4.4815\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5934,\tval_loss: 4.3649\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.4958,\tval_loss: 4.3959\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5532,\tval_loss: 4.3942\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5603,\tval_loss: 4.4969\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5854,\tval_loss: 4.3543\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5578,\tval_loss: 4.4108\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5103,\tval_loss: 4.4167\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5010,\tval_loss: 4.3743\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5130,\tval_loss: 4.4797\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5085,\tval_loss: 4.4373\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5442,\tval_loss: 4.4141\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.4621,\tval_loss: 4.4971\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.4827,\tval_loss: 4.4603\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.4208,\tval_loss: 4.4170\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5063,\tval_loss: 4.5326\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5036,\tval_loss: 4.4684\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5545,\tval_loss: 4.4606\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5255,\tval_loss: 4.3724\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.3691,\tval_loss: 4.4616\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.4525,\tval_loss: 4.3932\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.4626,\tval_loss: 4.4883\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.4733,\tval_loss: 4.5170\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4900,\tval_loss: 4.4248\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4210,\tval_loss: 4.4818\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.4005,\tval_loss: 4.5294\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4275,\tval_loss: 4.0343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2803,\tval_loss: 4.0302\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2452,\tval_loss: 4.0278\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2442,\tval_loss: 4.0470\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2129,\tval_loss: 4.0500\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1743,\tval_loss: 4.0418\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1876,\tval_loss: 4.0396\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1736,\tval_loss: 4.0561\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1368,\tval_loss: 4.0681\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1424,\tval_loss: 4.0848\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0979,\tval_loss: 4.1159\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0842,\tval_loss: 4.0673\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0963,\tval_loss: 4.1033\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0506,\tval_loss: 4.0880\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0629,\tval_loss: 4.1262\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0566,\tval_loss: 4.1163\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0292,\tval_loss: 4.1297\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9823,\tval_loss: 4.2200\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0305,\tval_loss: 4.1380\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9974,\tval_loss: 4.1527\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9356,\tval_loss: 4.2013\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9185,\tval_loss: 4.2539\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9476,\tval_loss: 4.2204\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9084,\tval_loss: 4.2668\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8792,\tval_loss: 4.2473\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9079,\tval_loss: 4.3023\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8754,\tval_loss: 4.2680\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8519,\tval_loss: 4.3054\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8824,\tval_loss: 4.3186\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8478,\tval_loss: 4.3006\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8309,\tval_loss: 4.3018\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8147,\tval_loss: 4.3182\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8525,\tval_loss: 4.4084\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8297,\tval_loss: 4.3159\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8155,\tval_loss: 4.3156\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8220,\tval_loss: 4.3700\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.8053,\tval_loss: 4.3497\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.8042,\tval_loss: 4.3182\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7611,\tval_loss: 4.4374\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7978,\tval_loss: 4.3984\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7535,\tval_loss: 4.3528\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.8047,\tval_loss: 4.3764\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7975,\tval_loss: 4.3265\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7227,\tval_loss: 4.3802\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7506,\tval_loss: 4.4105\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7637,\tval_loss: 4.3357\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7355,\tval_loss: 4.3592\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6607,\tval_loss: 4.4441\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7502,\tval_loss: 4.4352\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.8024,\tval_loss: 4.3724\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7435,\tval_loss: 4.4008\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7718,\tval_loss: 4.3821\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6815,\tval_loss: 4.4104\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7311,\tval_loss: 4.4337\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7571,\tval_loss: 4.4162\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6656,\tval_loss: 4.4394\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.7900,\tval_loss: 4.3633\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.8020,\tval_loss: 4.3927\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6964,\tval_loss: 4.3617\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.7125,\tval_loss: 4.4413\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6968,\tval_loss: 4.3489\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6981,\tval_loss: 4.4646\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.7453,\tval_loss: 4.3910\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.7226,\tval_loss: 4.3777\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.7511,\tval_loss: 4.4030\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6523,\tval_loss: 4.4653\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6263,\tval_loss: 4.4560\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6414,\tval_loss: 4.4692\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.7000,\tval_loss: 4.3990\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6714,\tval_loss: 4.5160\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4245,\tval_loss: 4.0624\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3257,\tval_loss: 4.0593\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2923,\tval_loss: 4.0698\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2625,\tval_loss: 4.0570\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2593,\tval_loss: 4.0524\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2526,\tval_loss: 4.0470\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2155,\tval_loss: 4.0529\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1697,\tval_loss: 4.0612\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.2260,\tval_loss: 4.0838\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1653,\tval_loss: 4.0489\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1391,\tval_loss: 4.0584\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1155,\tval_loss: 4.0775\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1092,\tval_loss: 4.0943\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0483,\tval_loss: 4.1175\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0903,\tval_loss: 4.1306\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0286,\tval_loss: 4.1542\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9506,\tval_loss: 4.1705\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9674,\tval_loss: 4.1827\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9396,\tval_loss: 4.1731\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8968,\tval_loss: 4.2224\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.9238,\tval_loss: 4.1587\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7955,\tval_loss: 4.2405\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8603,\tval_loss: 4.2507\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8782,\tval_loss: 4.1966\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8271,\tval_loss: 4.2568\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8415,\tval_loss: 4.2601\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7282,\tval_loss: 4.3394\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7328,\tval_loss: 4.2829\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8197,\tval_loss: 4.2450\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7819,\tval_loss: 4.2417\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7431,\tval_loss: 4.2959\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7748,\tval_loss: 4.3165\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7051,\tval_loss: 4.2644\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7157,\tval_loss: 4.2609\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7006,\tval_loss: 4.3214\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6683,\tval_loss: 4.2490\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6634,\tval_loss: 4.4112\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6270,\tval_loss: 4.4592\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6746,\tval_loss: 4.3101\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6464,\tval_loss: 4.4291\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6455,\tval_loss: 4.4438\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6438,\tval_loss: 4.4021\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6343,\tval_loss: 4.4020\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6369,\tval_loss: 4.4107\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6643,\tval_loss: 4.3866\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5214,\tval_loss: 4.4487\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5480,\tval_loss: 4.4837\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5707,\tval_loss: 4.4704\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5788,\tval_loss: 4.4085\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5330,\tval_loss: 4.4571\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5286,\tval_loss: 4.4486\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5052,\tval_loss: 4.5360\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5864,\tval_loss: 4.4417\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5349,\tval_loss: 4.4478\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5913,\tval_loss: 4.4397\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6124,\tval_loss: 4.4198\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5483,\tval_loss: 4.4234\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5826,\tval_loss: 4.4791\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.4874,\tval_loss: 4.5159\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.4872,\tval_loss: 4.5107\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.4670,\tval_loss: 4.4450\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5264,\tval_loss: 4.6357\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5029,\tval_loss: 4.5215\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.4424,\tval_loss: 4.5275\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.4473,\tval_loss: 4.5321\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.4168,\tval_loss: 4.5482\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5350,\tval_loss: 4.5650\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4857,\tval_loss: 4.6539\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.4913,\tval_loss: 4.5679\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.4836,\tval_loss: 4.5378\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.4375,\tval_loss: 4.5792\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.4952,\tval_loss: 4.5791\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.4969,\tval_loss: 4.4983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4871,\tval_loss: 4.0607\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3060,\tval_loss: 4.0486\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2797,\tval_loss: 4.0168\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2653,\tval_loss: 4.0070\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2004,\tval_loss: 4.0167\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2236,\tval_loss: 3.9993\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2204,\tval_loss: 3.9759\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1723,\tval_loss: 4.0040\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1086,\tval_loss: 4.0167\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0934,\tval_loss: 4.0471\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1006,\tval_loss: 3.9989\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1165,\tval_loss: 4.0732\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0500,\tval_loss: 4.0240\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0315,\tval_loss: 4.0418\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0046,\tval_loss: 4.0160\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9558,\tval_loss: 3.9857\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9227,\tval_loss: 4.0621\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8783,\tval_loss: 4.0681\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9010,\tval_loss: 4.0380\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9522,\tval_loss: 4.1012\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8341,\tval_loss: 4.0741\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7722,\tval_loss: 4.0850\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7629,\tval_loss: 4.0664\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8119,\tval_loss: 4.1248\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7827,\tval_loss: 4.0389\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7565,\tval_loss: 4.0966\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6640,\tval_loss: 4.1766\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6409,\tval_loss: 4.1984\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6649,\tval_loss: 4.1869\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7131,\tval_loss: 4.1424\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6254,\tval_loss: 4.2361\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7479,\tval_loss: 4.1594\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.6254,\tval_loss: 4.1549\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.6351,\tval_loss: 4.1247\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.6433,\tval_loss: 4.1506\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.6405,\tval_loss: 4.0769\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.5633,\tval_loss: 4.1837\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.5684,\tval_loss: 4.1511\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.5915,\tval_loss: 4.2300\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6061,\tval_loss: 4.1044\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5594,\tval_loss: 4.1203\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5512,\tval_loss: 4.1459\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5125,\tval_loss: 4.2001\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5976,\tval_loss: 4.1373\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5240,\tval_loss: 4.1562\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5160,\tval_loss: 4.1942\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.4969,\tval_loss: 4.1037\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.5194,\tval_loss: 4.1647\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.3498,\tval_loss: 4.2068\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.4583,\tval_loss: 4.2587\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.5485,\tval_loss: 4.1749\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.5097,\tval_loss: 4.2370\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.4869,\tval_loss: 4.1623\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.4613,\tval_loss: 4.2524\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.3929,\tval_loss: 4.2693\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.3862,\tval_loss: 4.2300\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.3384,\tval_loss: 4.3699\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.3705,\tval_loss: 4.1891\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.4507,\tval_loss: 4.1651\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.3872,\tval_loss: 4.2660\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.4069,\tval_loss: 4.2171\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.4160,\tval_loss: 4.2113\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.4789,\tval_loss: 4.1241\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.3610,\tval_loss: 4.2313\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.3821,\tval_loss: 4.3209\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.4281,\tval_loss: 4.2460\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.3570,\tval_loss: 4.1865\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.4041,\tval_loss: 4.2891\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.3032,\tval_loss: 4.3054\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.3577,\tval_loss: 4.4082\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.3813,\tval_loss: 4.1931\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.3899,\tval_loss: 4.4070\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.3946,\tval_loss: 4.2086\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.4078,\tval_loss: 4.2314\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4403,\tval_loss: 4.0262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2949,\tval_loss: 4.0514\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2770,\tval_loss: 4.0488\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2222,\tval_loss: 4.0612\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2142,\tval_loss: 4.0449\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2131,\tval_loss: 4.0502\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1445,\tval_loss: 4.0621\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1612,\tval_loss: 4.0639\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0886,\tval_loss: 4.0844\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0853,\tval_loss: 4.0657\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0858,\tval_loss: 4.0781\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0689,\tval_loss: 4.1311\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9783,\tval_loss: 4.1263\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0321,\tval_loss: 4.1335\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.9967,\tval_loss: 4.1289\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9878,\tval_loss: 4.2179\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9762,\tval_loss: 4.2265\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9383,\tval_loss: 4.2102\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9497,\tval_loss: 4.2019\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8913,\tval_loss: 4.2493\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.7692,\tval_loss: 4.2551\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9185,\tval_loss: 4.2625\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8621,\tval_loss: 4.2255\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8658,\tval_loss: 4.2889\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8231,\tval_loss: 4.2428\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7801,\tval_loss: 4.2989\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7668,\tval_loss: 4.2720\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8247,\tval_loss: 4.3516\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7386,\tval_loss: 4.3188\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7280,\tval_loss: 4.3469\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6999,\tval_loss: 4.3130\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7166,\tval_loss: 4.4407\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7235,\tval_loss: 4.2932\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7051,\tval_loss: 4.4230\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7040,\tval_loss: 4.3969\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7070,\tval_loss: 4.4445\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7648,\tval_loss: 4.2963\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6917,\tval_loss: 4.3854\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6101,\tval_loss: 4.2856\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6426,\tval_loss: 4.3464\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6355,\tval_loss: 4.4113\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6681,\tval_loss: 4.2926\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6573,\tval_loss: 4.3596\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6164,\tval_loss: 4.2917\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6580,\tval_loss: 4.3719\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5700,\tval_loss: 4.3374\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6497,\tval_loss: 4.4058\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6538,\tval_loss: 4.2646\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6256,\tval_loss: 4.2803\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5192,\tval_loss: 4.3746\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5691,\tval_loss: 4.3126\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5857,\tval_loss: 4.3510\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6043,\tval_loss: 4.2866\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5712,\tval_loss: 4.3063\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5525,\tval_loss: 4.2980\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6513,\tval_loss: 4.3998\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5873,\tval_loss: 4.2251\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5313,\tval_loss: 4.2927\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5981,\tval_loss: 4.3712\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.4983,\tval_loss: 4.2719\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5413,\tval_loss: 4.3337\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5349,\tval_loss: 4.3123\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5138,\tval_loss: 4.3603\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6078,\tval_loss: 4.3699\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.4874,\tval_loss: 4.3005\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5425,\tval_loss: 4.3352\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5124,\tval_loss: 4.3261\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5192,\tval_loss: 4.3501\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4490,\tval_loss: 4.0504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3013,\tval_loss: 4.0463\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2983,\tval_loss: 4.0650\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2419,\tval_loss: 4.0860\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2222,\tval_loss: 4.0978\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1843,\tval_loss: 4.1000\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2166,\tval_loss: 4.1313\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1959,\tval_loss: 4.1167\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1168,\tval_loss: 4.1476\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1355,\tval_loss: 4.1520\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1095,\tval_loss: 4.1640\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1054,\tval_loss: 4.1681\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0784,\tval_loss: 4.1738\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0942,\tval_loss: 4.1946\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0693,\tval_loss: 4.1925\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0458,\tval_loss: 4.1851\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0440,\tval_loss: 4.1778\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0519,\tval_loss: 4.1655\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9955,\tval_loss: 4.2378\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 4.0091,\tval_loss: 4.2223\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.9472,\tval_loss: 4.2249\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9914,\tval_loss: 4.2300\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9925,\tval_loss: 4.2589\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9258,\tval_loss: 4.2194\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9029,\tval_loss: 4.1976\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9248,\tval_loss: 4.2335\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9270,\tval_loss: 4.2259\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8392,\tval_loss: 4.3944\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8807,\tval_loss: 4.3063\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8651,\tval_loss: 4.2546\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8735,\tval_loss: 4.2987\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8288,\tval_loss: 4.3379\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8189,\tval_loss: 4.2357\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8647,\tval_loss: 4.2620\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8457,\tval_loss: 4.3655\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7705,\tval_loss: 4.3860\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.8066,\tval_loss: 4.2372\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7863,\tval_loss: 4.3391\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7131,\tval_loss: 4.3130\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7036,\tval_loss: 4.3091\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7608,\tval_loss: 4.3005\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7583,\tval_loss: 4.2914\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.7397,\tval_loss: 4.3403\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7470,\tval_loss: 4.3591\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6703,\tval_loss: 4.5368\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7068,\tval_loss: 4.3824\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6718,\tval_loss: 4.4496\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6800,\tval_loss: 4.3475\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5981,\tval_loss: 4.3901\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6319,\tval_loss: 4.4613\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6269,\tval_loss: 4.4528\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6152,\tval_loss: 4.4163\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6206,\tval_loss: 4.4789\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6771,\tval_loss: 4.3657\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7182,\tval_loss: 4.4073\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6442,\tval_loss: 4.3569\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5757,\tval_loss: 4.4868\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5637,\tval_loss: 4.5069\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5280,\tval_loss: 4.5790\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6271,\tval_loss: 4.3379\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6166,\tval_loss: 4.4513\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5975,\tval_loss: 4.4556\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6333,\tval_loss: 4.4112\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.6458,\tval_loss: 4.3356\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.6561,\tval_loss: 4.3380\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5971,\tval_loss: 4.3738\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5763,\tval_loss: 4.4529\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5862,\tval_loss: 4.5251\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5646,\tval_loss: 4.3916\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3418,\tval_loss: 4.0770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2460,\tval_loss: 4.0708\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1462,\tval_loss: 4.0721\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1221,\tval_loss: 4.0964\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1402,\tval_loss: 4.0587\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1019,\tval_loss: 4.0850\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0882,\tval_loss: 4.0823\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0860,\tval_loss: 4.0743\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0251,\tval_loss: 4.0833\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0131,\tval_loss: 4.0777\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 3.9691,\tval_loss: 4.1102\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9869,\tval_loss: 4.0773\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9894,\tval_loss: 4.0740\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9387,\tval_loss: 4.0987\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9487,\tval_loss: 4.1256\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.8995,\tval_loss: 4.1039\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9314,\tval_loss: 4.0777\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9065,\tval_loss: 4.1300\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8809,\tval_loss: 4.1719\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8577,\tval_loss: 4.1197\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8895,\tval_loss: 4.1031\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8395,\tval_loss: 4.1807\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8736,\tval_loss: 4.1315\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8460,\tval_loss: 4.1513\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8322,\tval_loss: 4.1781\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8485,\tval_loss: 4.1810\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7994,\tval_loss: 4.1991\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7768,\tval_loss: 4.1499\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8113,\tval_loss: 4.1534\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8190,\tval_loss: 4.1602\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7912,\tval_loss: 4.2139\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7906,\tval_loss: 4.1128\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7859,\tval_loss: 4.2054\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7754,\tval_loss: 4.2085\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7721,\tval_loss: 4.1849\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7807,\tval_loss: 4.1499\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7587,\tval_loss: 4.1989\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7534,\tval_loss: 4.2126\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7086,\tval_loss: 4.2314\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7563,\tval_loss: 4.2648\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7556,\tval_loss: 4.1993\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6951,\tval_loss: 4.2266\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7073,\tval_loss: 4.2008\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7534,\tval_loss: 4.1974\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6625,\tval_loss: 4.1995\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6844,\tval_loss: 4.2115\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7232,\tval_loss: 4.2515\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7277,\tval_loss: 4.2143\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7062,\tval_loss: 4.2073\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7034,\tval_loss: 4.2465\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7167,\tval_loss: 4.1673\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7685,\tval_loss: 4.1987\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7024,\tval_loss: 4.1478\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7218,\tval_loss: 4.2129\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7016,\tval_loss: 4.1878\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.7064,\tval_loss: 4.1748\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6972,\tval_loss: 4.1634\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.7164,\tval_loss: 4.1996\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.7093,\tval_loss: 4.1948\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6903,\tval_loss: 4.2409\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6623,\tval_loss: 4.2271\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.7031,\tval_loss: 4.1902\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6873,\tval_loss: 4.1781\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.6571,\tval_loss: 4.2291\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6643,\tval_loss: 4.2254\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6357,\tval_loss: 4.2233\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6633,\tval_loss: 4.1725\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6768,\tval_loss: 4.1607\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6684,\tval_loss: 4.2074\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6626,\tval_loss: 4.1853\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6321,\tval_loss: 4.1440\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.6336,\tval_loss: 4.1934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4214,\tval_loss: 4.0702\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3138,\tval_loss: 4.0641\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3278,\tval_loss: 4.0688\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2989,\tval_loss: 4.0595\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.3006,\tval_loss: 4.0592\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2379,\tval_loss: 4.0669\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2521,\tval_loss: 4.0558\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2272,\tval_loss: 4.0401\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.2121,\tval_loss: 4.0604\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1653,\tval_loss: 4.0661\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1502,\tval_loss: 4.0897\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1164,\tval_loss: 4.1035\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1446,\tval_loss: 4.0961\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1143,\tval_loss: 4.1783\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.1040,\tval_loss: 4.1770\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0483,\tval_loss: 4.1543\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0187,\tval_loss: 4.1552\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0228,\tval_loss: 4.1752\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0118,\tval_loss: 4.2098\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 4.0075,\tval_loss: 4.2170\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9949,\tval_loss: 4.2346\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9707,\tval_loss: 4.1886\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9912,\tval_loss: 4.2151\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9431,\tval_loss: 4.2562\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9338,\tval_loss: 4.1883\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9110,\tval_loss: 4.2273\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9263,\tval_loss: 4.1751\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9672,\tval_loss: 4.2399\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.9004,\tval_loss: 4.2393\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8528,\tval_loss: 4.2238\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.9353,\tval_loss: 4.2022\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.9400,\tval_loss: 4.1546\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8751,\tval_loss: 4.2886\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.8745,\tval_loss: 4.2463\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.8846,\tval_loss: 4.2544\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.8519,\tval_loss: 4.1999\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.8650,\tval_loss: 4.2425\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.8473,\tval_loss: 4.2770\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.8303,\tval_loss: 4.2696\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.8107,\tval_loss: 4.2352\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.8092,\tval_loss: 4.2486\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7812,\tval_loss: 4.1907\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7838,\tval_loss: 4.2939\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7585,\tval_loss: 4.2389\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.8125,\tval_loss: 4.3019\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7701,\tval_loss: 4.2656\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7600,\tval_loss: 4.2383\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.8220,\tval_loss: 4.2706\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.8113,\tval_loss: 4.2887\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.7903,\tval_loss: 4.2521\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.8158,\tval_loss: 4.2515\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.8023,\tval_loss: 4.2514\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.7902,\tval_loss: 4.2561\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.7451,\tval_loss: 4.2676\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6305,\tval_loss: 4.2917\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.7492,\tval_loss: 4.2436\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.8084,\tval_loss: 4.2287\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.7398,\tval_loss: 4.2275\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.7754,\tval_loss: 4.2331\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.7512,\tval_loss: 4.2465\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.7905,\tval_loss: 4.2779\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.7534,\tval_loss: 4.2538\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.7866,\tval_loss: 4.2247\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.7633,\tval_loss: 4.2592\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.7552,\tval_loss: 4.2315\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.7456,\tval_loss: 4.2434\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.6767,\tval_loss: 4.2941\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.7486,\tval_loss: 4.2703\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.7312,\tval_loss: 4.2220\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.7505,\tval_loss: 4.1890\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.7155,\tval_loss: 4.2857\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.7546,\tval_loss: 4.2366\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.7416,\tval_loss: 4.2659\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.6893,\tval_loss: 4.2121\n",
            "74:\t[0s / 4s],\t\ttrain_loss: 3.7026,\tval_loss: 4.2210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3555,\tval_loss: 4.1014\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2622,\tval_loss: 4.1144\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2656,\tval_loss: 4.0840\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2426,\tval_loss: 4.0913\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1920,\tval_loss: 4.1139\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1900,\tval_loss: 4.1151\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1378,\tval_loss: 4.1302\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1392,\tval_loss: 4.1368\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1027,\tval_loss: 4.1269\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0849,\tval_loss: 4.1334\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0351,\tval_loss: 4.1208\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0618,\tval_loss: 4.1587\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0213,\tval_loss: 4.1194\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 3.9901,\tval_loss: 4.1752\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.9647,\tval_loss: 4.1653\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9649,\tval_loss: 4.1979\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.8553,\tval_loss: 4.2100\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8805,\tval_loss: 4.2327\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.8158,\tval_loss: 4.2838\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8507,\tval_loss: 4.3014\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8544,\tval_loss: 4.3927\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7751,\tval_loss: 4.2722\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7717,\tval_loss: 4.4118\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7753,\tval_loss: 4.2293\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7579,\tval_loss: 4.2906\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8115,\tval_loss: 4.2497\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7561,\tval_loss: 4.2527\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6801,\tval_loss: 4.3206\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7509,\tval_loss: 4.3026\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7023,\tval_loss: 4.3778\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7024,\tval_loss: 4.3879\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8094,\tval_loss: 4.2764\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8153,\tval_loss: 4.1872\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6981,\tval_loss: 4.3209\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.6981,\tval_loss: 4.2950\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.6663,\tval_loss: 4.3934\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.6109,\tval_loss: 4.3324\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6231,\tval_loss: 4.3413\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7209,\tval_loss: 4.2475\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6514,\tval_loss: 4.3536\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5124,\tval_loss: 4.3641\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6039,\tval_loss: 4.3628\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5390,\tval_loss: 4.4586\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6105,\tval_loss: 4.2840\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5183,\tval_loss: 4.4516\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5769,\tval_loss: 4.4512\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5512,\tval_loss: 4.4280\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5979,\tval_loss: 4.3821\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5806,\tval_loss: 4.4106\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6268,\tval_loss: 4.3654\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5540,\tval_loss: 4.4205\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5688,\tval_loss: 4.3392\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5589,\tval_loss: 4.4840\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5168,\tval_loss: 4.3626\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6263,\tval_loss: 4.3466\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6081,\tval_loss: 4.3623\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5153,\tval_loss: 4.3504\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5882,\tval_loss: 4.3765\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5713,\tval_loss: 4.3938\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5841,\tval_loss: 4.4233\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5664,\tval_loss: 4.3999\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5182,\tval_loss: 4.3914\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5281,\tval_loss: 4.4325\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.4927,\tval_loss: 4.4335\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5008,\tval_loss: 4.4473\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.4811,\tval_loss: 4.4162\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4560,\tval_loss: 4.3820\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4900,\tval_loss: 4.4397\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5294,\tval_loss: 4.3662\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.4633,\tval_loss: 4.3992\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3974,\tval_loss: 4.0315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2610,\tval_loss: 4.0332\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2548,\tval_loss: 4.0382\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2516,\tval_loss: 4.0368\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1855,\tval_loss: 4.0380\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1776,\tval_loss: 4.0507\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1915,\tval_loss: 4.0564\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2057,\tval_loss: 4.0484\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1900,\tval_loss: 4.0544\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1874,\tval_loss: 4.0594\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1609,\tval_loss: 4.0709\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1166,\tval_loss: 4.0893\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1302,\tval_loss: 4.0736\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1506,\tval_loss: 4.0903\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0704,\tval_loss: 4.0981\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0698,\tval_loss: 4.1229\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0764,\tval_loss: 4.1024\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0357,\tval_loss: 4.1366\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0241,\tval_loss: 4.1200\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9435,\tval_loss: 4.1784\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 4.0165,\tval_loss: 4.1305\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9378,\tval_loss: 4.1092\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9660,\tval_loss: 4.1308\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9807,\tval_loss: 4.0809\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9477,\tval_loss: 4.1225\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9737,\tval_loss: 4.1178\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9432,\tval_loss: 4.1671\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9448,\tval_loss: 4.1695\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.9394,\tval_loss: 4.1459\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8876,\tval_loss: 4.2177\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.9288,\tval_loss: 4.1790\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8726,\tval_loss: 4.2094\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8912,\tval_loss: 4.2669\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8389,\tval_loss: 4.1972\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8921,\tval_loss: 4.1727\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8293,\tval_loss: 4.2418\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7564,\tval_loss: 4.3048\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.8371,\tval_loss: 4.2618\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.8198,\tval_loss: 4.2197\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7773,\tval_loss: 4.2701\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.8517,\tval_loss: 4.2357\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.8239,\tval_loss: 4.2757\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.8271,\tval_loss: 4.2765\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7413,\tval_loss: 4.2346\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.8130,\tval_loss: 4.2761\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7167,\tval_loss: 4.3132\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7486,\tval_loss: 4.2980\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7587,\tval_loss: 4.3105\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7250,\tval_loss: 4.3698\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6959,\tval_loss: 4.3230\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7601,\tval_loss: 4.2943\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7470,\tval_loss: 4.2421\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7796,\tval_loss: 4.2795\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6593,\tval_loss: 4.2826\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7507,\tval_loss: 4.3410\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.7135,\tval_loss: 4.3293\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.7363,\tval_loss: 4.3370\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6906,\tval_loss: 4.3068\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6715,\tval_loss: 4.4048\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.7388,\tval_loss: 4.3950\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6863,\tval_loss: 4.3470\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6671,\tval_loss: 4.3162\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6846,\tval_loss: 4.3491\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.7247,\tval_loss: 4.2629\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.7043,\tval_loss: 4.2774\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.7236,\tval_loss: 4.2512\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.7079,\tval_loss: 4.3019\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.7181,\tval_loss: 4.3564\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4653,\tval_loss: 4.0483\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3350,\tval_loss: 4.0569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2788,\tval_loss: 4.0626\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1659,\tval_loss: 4.0738\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1571,\tval_loss: 4.1299\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.0451,\tval_loss: 4.1356\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0980,\tval_loss: 4.1317\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0599,\tval_loss: 4.1586\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0507,\tval_loss: 4.1684\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0504,\tval_loss: 4.1990\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0296,\tval_loss: 4.1326\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9797,\tval_loss: 4.1962\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9514,\tval_loss: 4.1762\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9762,\tval_loss: 4.1874\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9151,\tval_loss: 4.1813\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9062,\tval_loss: 4.2142\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8433,\tval_loss: 4.2476\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8917,\tval_loss: 4.1988\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8986,\tval_loss: 4.1940\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9276,\tval_loss: 4.1819\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.8207,\tval_loss: 4.2384\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7966,\tval_loss: 4.2404\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8421,\tval_loss: 4.2227\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8635,\tval_loss: 4.2307\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7822,\tval_loss: 4.2259\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7890,\tval_loss: 4.2695\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7759,\tval_loss: 4.2825\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7596,\tval_loss: 4.2171\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7617,\tval_loss: 4.2451\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8498,\tval_loss: 4.2422\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7546,\tval_loss: 4.2056\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8325,\tval_loss: 4.2708\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7905,\tval_loss: 4.2220\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7476,\tval_loss: 4.2010\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7002,\tval_loss: 4.2618\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7357,\tval_loss: 4.2728\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6904,\tval_loss: 4.2541\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7139,\tval_loss: 4.2180\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6131,\tval_loss: 4.2792\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7849,\tval_loss: 4.2417\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6918,\tval_loss: 4.2849\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6616,\tval_loss: 4.2479\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.7375,\tval_loss: 4.2392\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6975,\tval_loss: 4.2806\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6689,\tval_loss: 4.2334\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7238,\tval_loss: 4.2834\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6320,\tval_loss: 4.2292\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6721,\tval_loss: 4.2154\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6907,\tval_loss: 4.3010\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6088,\tval_loss: 4.2846\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6169,\tval_loss: 4.3135\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7283,\tval_loss: 4.2606\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5576,\tval_loss: 4.3387\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6011,\tval_loss: 4.2994\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.4960,\tval_loss: 4.4111\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6148,\tval_loss: 4.2979\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6215,\tval_loss: 4.3035\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5913,\tval_loss: 4.2699\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6052,\tval_loss: 4.3061\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6270,\tval_loss: 4.3482\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5422,\tval_loss: 4.3174\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5789,\tval_loss: 4.3416\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6133,\tval_loss: 4.2900\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5916,\tval_loss: 4.3030\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.6980,\tval_loss: 4.2521\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5871,\tval_loss: 4.2825\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6030,\tval_loss: 4.3474\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5419,\tval_loss: 4.3114\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4534,\tval_loss: 4.0508\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2535,\tval_loss: 4.0498\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1629,\tval_loss: 4.0343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1649,\tval_loss: 4.0660\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1382,\tval_loss: 4.0698\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1255,\tval_loss: 4.0673\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0547,\tval_loss: 4.0935\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0610,\tval_loss: 4.1122\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0609,\tval_loss: 4.1345\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0382,\tval_loss: 4.1272\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0238,\tval_loss: 4.1452\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0134,\tval_loss: 4.1568\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9782,\tval_loss: 4.1827\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9338,\tval_loss: 4.1723\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9264,\tval_loss: 4.2159\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9324,\tval_loss: 4.2403\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9204,\tval_loss: 4.1749\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8595,\tval_loss: 4.2572\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8912,\tval_loss: 4.2164\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8299,\tval_loss: 4.2654\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.7865,\tval_loss: 4.3018\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8549,\tval_loss: 4.2877\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8146,\tval_loss: 4.3881\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7977,\tval_loss: 4.3553\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8342,\tval_loss: 4.3368\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7762,\tval_loss: 4.3236\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7404,\tval_loss: 4.3603\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7740,\tval_loss: 4.4649\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7706,\tval_loss: 4.3063\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7532,\tval_loss: 4.4201\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7073,\tval_loss: 4.3931\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7150,\tval_loss: 4.3417\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6966,\tval_loss: 4.4304\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6904,\tval_loss: 4.4633\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6850,\tval_loss: 4.4134\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7448,\tval_loss: 4.3868\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7728,\tval_loss: 4.3684\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7631,\tval_loss: 4.3688\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6773,\tval_loss: 4.3152\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7027,\tval_loss: 4.4304\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7395,\tval_loss: 4.3941\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6882,\tval_loss: 4.4217\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6644,\tval_loss: 4.4932\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7018,\tval_loss: 4.3458\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6739,\tval_loss: 4.5293\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6331,\tval_loss: 4.4536\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6297,\tval_loss: 4.4777\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6129,\tval_loss: 4.5054\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6445,\tval_loss: 4.5193\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6585,\tval_loss: 4.4630\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6536,\tval_loss: 4.4770\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5931,\tval_loss: 4.4756\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6188,\tval_loss: 4.4184\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.5673,\tval_loss: 4.4476\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6779,\tval_loss: 4.3868\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6528,\tval_loss: 4.4118\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6015,\tval_loss: 4.4972\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6384,\tval_loss: 4.5128\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6150,\tval_loss: 4.4268\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5721,\tval_loss: 4.5194\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6031,\tval_loss: 4.4851\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5839,\tval_loss: 4.5814\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6119,\tval_loss: 4.4718\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6328,\tval_loss: 4.4743\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6564,\tval_loss: 4.4325\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6613,\tval_loss: 4.4494\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6768,\tval_loss: 4.4992\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.6097,\tval_loss: 4.4150\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.6189,\tval_loss: 4.4622\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.5775,\tval_loss: 4.5229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3915,\tval_loss: 4.0244\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3108,\tval_loss: 4.0224\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2736,\tval_loss: 4.0169\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2601,\tval_loss: 4.0121\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1907,\tval_loss: 4.0079\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1780,\tval_loss: 4.0137\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1604,\tval_loss: 4.0344\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0987,\tval_loss: 4.0389\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0889,\tval_loss: 4.0572\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1068,\tval_loss: 4.0168\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0701,\tval_loss: 4.0642\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0437,\tval_loss: 4.1047\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0127,\tval_loss: 4.0899\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0195,\tval_loss: 4.1329\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0043,\tval_loss: 4.1565\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9200,\tval_loss: 4.1730\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9722,\tval_loss: 4.1390\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9264,\tval_loss: 4.1940\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9198,\tval_loss: 4.1985\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8597,\tval_loss: 4.2313\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8744,\tval_loss: 4.2323\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8179,\tval_loss: 4.2091\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8816,\tval_loss: 4.2104\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8658,\tval_loss: 4.2342\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8940,\tval_loss: 4.2235\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8561,\tval_loss: 4.1797\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8034,\tval_loss: 4.2085\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8421,\tval_loss: 4.2245\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8069,\tval_loss: 4.2655\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.7686,\tval_loss: 4.2398\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.8004,\tval_loss: 4.2335\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.8062,\tval_loss: 4.1863\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7165,\tval_loss: 4.2478\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.7554,\tval_loss: 4.1999\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7964,\tval_loss: 4.1842\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.8279,\tval_loss: 4.1976\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7586,\tval_loss: 4.2782\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7268,\tval_loss: 4.2188\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7041,\tval_loss: 4.2586\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6909,\tval_loss: 4.3125\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6928,\tval_loss: 4.2748\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7331,\tval_loss: 4.2465\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6513,\tval_loss: 4.3057\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7579,\tval_loss: 4.2847\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6366,\tval_loss: 4.2369\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6788,\tval_loss: 4.3666\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6816,\tval_loss: 4.2651\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6265,\tval_loss: 4.3075\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5915,\tval_loss: 4.2538\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6918,\tval_loss: 4.2979\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6250,\tval_loss: 4.2800\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.5845,\tval_loss: 4.3515\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6727,\tval_loss: 4.2733\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6424,\tval_loss: 4.3007\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6170,\tval_loss: 4.3076\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6348,\tval_loss: 4.2969\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6713,\tval_loss: 4.2506\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6666,\tval_loss: 4.2821\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6084,\tval_loss: 4.3689\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6007,\tval_loss: 4.2544\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5442,\tval_loss: 4.3197\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5708,\tval_loss: 4.3670\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6322,\tval_loss: 4.2590\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5205,\tval_loss: 4.3797\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5317,\tval_loss: 4.3498\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5648,\tval_loss: 4.3489\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5791,\tval_loss: 4.3238\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6177,\tval_loss: 4.2788\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5326,\tval_loss: 4.2938\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5332,\tval_loss: 4.3562\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.5377,\tval_loss: 4.3148\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.5915,\tval_loss: 4.3045\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3659,\tval_loss: 4.0691\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2361,\tval_loss: 4.0620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1936,\tval_loss: 4.0547\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1848,\tval_loss: 4.0462\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1503,\tval_loss: 4.0383\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1580,\tval_loss: 4.0297\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1290,\tval_loss: 4.0582\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1092,\tval_loss: 4.0557\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0855,\tval_loss: 4.0396\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0974,\tval_loss: 4.0353\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0399,\tval_loss: 4.0729\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1091,\tval_loss: 4.0545\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0709,\tval_loss: 4.0732\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9656,\tval_loss: 4.1230\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0573,\tval_loss: 4.0992\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9927,\tval_loss: 4.1429\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9773,\tval_loss: 4.0650\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9384,\tval_loss: 4.1906\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9579,\tval_loss: 4.1185\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9093,\tval_loss: 4.0825\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.9353,\tval_loss: 4.1520\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9285,\tval_loss: 4.1416\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8841,\tval_loss: 4.1830\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8891,\tval_loss: 4.2189\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8615,\tval_loss: 4.2274\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8949,\tval_loss: 4.1508\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8496,\tval_loss: 4.2288\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8587,\tval_loss: 4.1639\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8120,\tval_loss: 4.1948\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8351,\tval_loss: 4.2261\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7601,\tval_loss: 4.1403\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7629,\tval_loss: 4.2507\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7369,\tval_loss: 4.3192\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7719,\tval_loss: 4.1893\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8908,\tval_loss: 4.1648\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7699,\tval_loss: 4.2235\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7516,\tval_loss: 4.2898\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7482,\tval_loss: 4.2866\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7581,\tval_loss: 4.2587\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7658,\tval_loss: 4.1616\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7450,\tval_loss: 4.2817\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6743,\tval_loss: 4.2355\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.6468,\tval_loss: 4.3112\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6859,\tval_loss: 4.3255\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7107,\tval_loss: 4.2350\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6867,\tval_loss: 4.2845\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6811,\tval_loss: 4.3086\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6785,\tval_loss: 4.2750\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6957,\tval_loss: 4.2982\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6677,\tval_loss: 4.2646\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6121,\tval_loss: 4.2802\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6841,\tval_loss: 4.3113\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6047,\tval_loss: 4.2760\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6439,\tval_loss: 4.2832\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6524,\tval_loss: 4.3637\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.7051,\tval_loss: 4.3174\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5726,\tval_loss: 4.3292\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6484,\tval_loss: 4.4690\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6490,\tval_loss: 4.2585\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6672,\tval_loss: 4.3524\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6441,\tval_loss: 4.2826\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5221,\tval_loss: 4.3689\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5938,\tval_loss: 4.3120\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5736,\tval_loss: 4.4578\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.5893,\tval_loss: 4.2966\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5146,\tval_loss: 4.3471\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6057,\tval_loss: 4.2879\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5516,\tval_loss: 4.3266\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6359,\tval_loss: 4.3388\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5691,\tval_loss: 4.2218\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5236,\tval_loss: 4.3693\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.4973,\tval_loss: 4.3780\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.5910,\tval_loss: 4.3727\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3740,\tval_loss: 4.0686\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2771,\tval_loss: 4.0759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2385,\tval_loss: 4.1028\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2102,\tval_loss: 4.1227\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1982,\tval_loss: 4.1155\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1870,\tval_loss: 4.1320\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1279,\tval_loss: 4.1279\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1077,\tval_loss: 4.2014\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0794,\tval_loss: 4.2269\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0607,\tval_loss: 4.2842\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 3.9992,\tval_loss: 4.2451\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0532,\tval_loss: 4.2382\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0181,\tval_loss: 4.3611\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0151,\tval_loss: 4.3418\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9541,\tval_loss: 4.3122\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9597,\tval_loss: 4.3867\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9100,\tval_loss: 4.4008\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9424,\tval_loss: 4.4116\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8493,\tval_loss: 4.4419\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8407,\tval_loss: 4.4926\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8566,\tval_loss: 4.4858\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8213,\tval_loss: 4.4602\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7908,\tval_loss: 4.5429\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7535,\tval_loss: 4.4971\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7341,\tval_loss: 4.4794\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7591,\tval_loss: 4.5624\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7816,\tval_loss: 4.5241\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7328,\tval_loss: 4.5063\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7106,\tval_loss: 4.5894\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.6539,\tval_loss: 4.6248\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6648,\tval_loss: 4.6251\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6316,\tval_loss: 4.5778\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7094,\tval_loss: 4.5984\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6406,\tval_loss: 4.5751\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6109,\tval_loss: 4.5616\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6841,\tval_loss: 4.5058\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6620,\tval_loss: 4.5706\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6507,\tval_loss: 4.5805\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6008,\tval_loss: 4.6164\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.5788,\tval_loss: 4.5920\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6249,\tval_loss: 4.6065\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.5796,\tval_loss: 4.5944\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5616,\tval_loss: 4.6283\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5860,\tval_loss: 4.5210\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5430,\tval_loss: 4.6842\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5375,\tval_loss: 4.6877\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5646,\tval_loss: 4.6400\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5565,\tval_loss: 4.5773\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5233,\tval_loss: 4.6953\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5707,\tval_loss: 4.6148\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5560,\tval_loss: 4.6620\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5004,\tval_loss: 4.6131\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5604,\tval_loss: 4.6146\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5401,\tval_loss: 4.6719\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.4981,\tval_loss: 4.5512\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5725,\tval_loss: 4.6617\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5148,\tval_loss: 4.6026\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5149,\tval_loss: 4.7869\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.4797,\tval_loss: 4.6146\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.4439,\tval_loss: 4.7800\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.4468,\tval_loss: 4.7435\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5351,\tval_loss: 4.6101\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5069,\tval_loss: 4.6435\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5068,\tval_loss: 4.7623\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.4708,\tval_loss: 4.6160\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.4640,\tval_loss: 4.7107\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5166,\tval_loss: 4.6938\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5284,\tval_loss: 4.6309\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4108,\tval_loss: 4.1047\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3139,\tval_loss: 4.0962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2658,\tval_loss: 4.0944\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.3096,\tval_loss: 4.0941\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2373,\tval_loss: 4.1017\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2302,\tval_loss: 4.1023\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2275,\tval_loss: 4.1000\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1864,\tval_loss: 4.1140\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1588,\tval_loss: 4.1202\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1766,\tval_loss: 4.1238\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1279,\tval_loss: 4.1344\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1543,\tval_loss: 4.1348\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1359,\tval_loss: 4.1816\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0794,\tval_loss: 4.2166\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0537,\tval_loss: 4.2551\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0195,\tval_loss: 4.3152\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0059,\tval_loss: 4.2827\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9945,\tval_loss: 4.2450\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9881,\tval_loss: 4.3092\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9886,\tval_loss: 4.2982\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.9674,\tval_loss: 4.2649\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9542,\tval_loss: 4.2357\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9870,\tval_loss: 4.3587\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9536,\tval_loss: 4.3267\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9314,\tval_loss: 4.2686\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9268,\tval_loss: 4.3138\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9340,\tval_loss: 4.3138\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8958,\tval_loss: 4.3926\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8801,\tval_loss: 4.3579\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8342,\tval_loss: 4.3706\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.9010,\tval_loss: 4.3648\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8938,\tval_loss: 4.3629\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8744,\tval_loss: 4.3684\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8720,\tval_loss: 4.3989\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8578,\tval_loss: 4.3446\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8536,\tval_loss: 4.4018\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.8368,\tval_loss: 4.3936\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7785,\tval_loss: 4.4945\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7911,\tval_loss: 4.3669\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.8106,\tval_loss: 4.5379\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7473,\tval_loss: 4.4534\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7610,\tval_loss: 4.5015\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7804,\tval_loss: 4.4092\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.8184,\tval_loss: 4.4643\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7554,\tval_loss: 4.5027\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.8445,\tval_loss: 4.3811\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7932,\tval_loss: 4.4969\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7578,\tval_loss: 4.5066\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6734,\tval_loss: 4.4744\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7157,\tval_loss: 4.4505\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7444,\tval_loss: 4.5319\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6887,\tval_loss: 4.4804\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.8135,\tval_loss: 4.4967\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7474,\tval_loss: 4.5007\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7220,\tval_loss: 4.4849\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.7575,\tval_loss: 4.5507\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.7798,\tval_loss: 4.4461\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.7624,\tval_loss: 4.4783\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6812,\tval_loss: 4.4765\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.7212,\tval_loss: 4.5939\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.7027,\tval_loss: 4.4333\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6937,\tval_loss: 4.5206\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6987,\tval_loss: 4.5515\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6594,\tval_loss: 4.4995\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.7122,\tval_loss: 4.4357\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6441,\tval_loss: 4.4944\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6990,\tval_loss: 4.4908\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6716,\tval_loss: 4.5303\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5357,\tval_loss: 4.5195\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6694,\tval_loss: 4.5556\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.7911,\tval_loss: 4.4698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.8012,\tval_loss: 3.9998\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3062,\tval_loss: 4.0027\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2544,\tval_loss: 4.0181\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2425,\tval_loss: 4.0369\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1874,\tval_loss: 4.0441\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1917,\tval_loss: 4.0672\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1996,\tval_loss: 4.0243\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1580,\tval_loss: 4.0421\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1748,\tval_loss: 4.0361\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1077,\tval_loss: 4.0561\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1266,\tval_loss: 4.0532\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0950,\tval_loss: 4.0439\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0757,\tval_loss: 4.0878\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0433,\tval_loss: 4.0779\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0332,\tval_loss: 4.0746\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0265,\tval_loss: 4.1171\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9566,\tval_loss: 4.1746\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9685,\tval_loss: 4.1543\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9474,\tval_loss: 4.2140\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8934,\tval_loss: 4.1862\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9012,\tval_loss: 4.2296\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9046,\tval_loss: 4.2628\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8160,\tval_loss: 4.3042\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7618,\tval_loss: 4.3434\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8115,\tval_loss: 4.3822\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8683,\tval_loss: 4.1881\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8146,\tval_loss: 4.2752\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7656,\tval_loss: 4.2924\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7473,\tval_loss: 4.3283\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7532,\tval_loss: 4.3205\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.7854,\tval_loss: 4.3271\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7633,\tval_loss: 4.3092\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7030,\tval_loss: 4.4212\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.7601,\tval_loss: 4.3662\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7519,\tval_loss: 4.3151\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7380,\tval_loss: 4.3551\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7409,\tval_loss: 4.3559\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6129,\tval_loss: 4.3992\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6827,\tval_loss: 4.4063\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6803,\tval_loss: 4.3451\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6315,\tval_loss: 4.4541\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6221,\tval_loss: 4.4010\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6993,\tval_loss: 4.4157\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6524,\tval_loss: 4.4093\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5860,\tval_loss: 4.4819\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6120,\tval_loss: 4.4504\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.6297,\tval_loss: 4.4372\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.6715,\tval_loss: 4.4343\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.6051,\tval_loss: 4.4657\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6108,\tval_loss: 4.4490\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6575,\tval_loss: 4.4521\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.6319,\tval_loss: 4.3908\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6049,\tval_loss: 4.2953\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6287,\tval_loss: 4.4353\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6171,\tval_loss: 4.4235\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.5928,\tval_loss: 4.3793\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5294,\tval_loss: 4.4326\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6304,\tval_loss: 4.4416\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5014,\tval_loss: 4.5209\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5898,\tval_loss: 4.4259\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5463,\tval_loss: 4.3518\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6399,\tval_loss: 4.4171\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5872,\tval_loss: 4.4304\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6021,\tval_loss: 4.4199\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5030,\tval_loss: 4.4372\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5066,\tval_loss: 4.4082\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5461,\tval_loss: 4.4277\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5439,\tval_loss: 4.4212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4472,\tval_loss: 4.0770\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3008,\tval_loss: 4.0901\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2755,\tval_loss: 4.0977\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2277,\tval_loss: 4.0949\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1964,\tval_loss: 4.1423\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2387,\tval_loss: 4.1327\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1891,\tval_loss: 4.1772\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1737,\tval_loss: 4.1546\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1574,\tval_loss: 4.1635\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0829,\tval_loss: 4.1925\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0724,\tval_loss: 4.2032\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0982,\tval_loss: 4.2318\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0517,\tval_loss: 4.2667\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9981,\tval_loss: 4.2421\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9947,\tval_loss: 4.3077\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9385,\tval_loss: 4.3624\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9220,\tval_loss: 4.3384\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9277,\tval_loss: 4.4523\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8836,\tval_loss: 4.3566\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8993,\tval_loss: 4.4352\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.9049,\tval_loss: 4.3095\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8491,\tval_loss: 4.3567\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8270,\tval_loss: 4.4004\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8183,\tval_loss: 4.3770\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7848,\tval_loss: 4.3594\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8085,\tval_loss: 4.4905\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8011,\tval_loss: 4.4106\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7888,\tval_loss: 4.4451\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7638,\tval_loss: 4.3840\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7420,\tval_loss: 4.4351\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6980,\tval_loss: 4.4026\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6941,\tval_loss: 4.5420\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7019,\tval_loss: 4.5376\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7658,\tval_loss: 4.3685\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7296,\tval_loss: 4.4387\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7097,\tval_loss: 4.4401\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6593,\tval_loss: 4.5446\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6186,\tval_loss: 4.5931\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6400,\tval_loss: 4.4997\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6816,\tval_loss: 4.5337\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6219,\tval_loss: 4.5918\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6183,\tval_loss: 4.5004\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6114,\tval_loss: 4.4930\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5998,\tval_loss: 4.5863\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6128,\tval_loss: 4.5250\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7017,\tval_loss: 4.4228\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6485,\tval_loss: 4.5460\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6111,\tval_loss: 4.5657\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5687,\tval_loss: 4.6028\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.4965,\tval_loss: 4.5881\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5762,\tval_loss: 4.4620\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5693,\tval_loss: 4.5286\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5534,\tval_loss: 4.5873\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5434,\tval_loss: 4.5394\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5939,\tval_loss: 4.5449\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.4890,\tval_loss: 4.4714\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5015,\tval_loss: 4.5842\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5490,\tval_loss: 4.4604\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5376,\tval_loss: 4.6781\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5626,\tval_loss: 4.5716\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5518,\tval_loss: 4.5374\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5132,\tval_loss: 4.5423\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5921,\tval_loss: 4.4573\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5172,\tval_loss: 4.5073\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5095,\tval_loss: 4.5574\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5898,\tval_loss: 4.6177\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4742,\tval_loss: 4.5877\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4580,\tval_loss: 4.6283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3493,\tval_loss: 4.1031\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2613,\tval_loss: 4.0668\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2263,\tval_loss: 4.0697\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2245,\tval_loss: 4.0644\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2212,\tval_loss: 4.0584\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1896,\tval_loss: 4.0578\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1770,\tval_loss: 4.0371\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1774,\tval_loss: 4.0550\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1341,\tval_loss: 4.0443\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0982,\tval_loss: 4.1006\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0713,\tval_loss: 4.1210\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0912,\tval_loss: 4.1256\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0378,\tval_loss: 4.1783\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0367,\tval_loss: 4.1505\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0369,\tval_loss: 4.1556\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9373,\tval_loss: 4.2323\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8942,\tval_loss: 4.2565\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9272,\tval_loss: 4.2400\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8883,\tval_loss: 4.2417\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9371,\tval_loss: 4.2109\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9592,\tval_loss: 4.2719\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9102,\tval_loss: 4.3028\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8549,\tval_loss: 4.1939\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8148,\tval_loss: 4.2349\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8908,\tval_loss: 4.3568\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7994,\tval_loss: 4.3348\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8161,\tval_loss: 4.3816\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8095,\tval_loss: 4.3402\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8214,\tval_loss: 4.2945\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8027,\tval_loss: 4.3367\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7612,\tval_loss: 4.3551\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7559,\tval_loss: 4.3300\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7544,\tval_loss: 4.3328\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7870,\tval_loss: 4.3194\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7606,\tval_loss: 4.3115\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7688,\tval_loss: 4.3685\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7500,\tval_loss: 4.3082\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7525,\tval_loss: 4.3342\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7513,\tval_loss: 4.2661\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7113,\tval_loss: 4.4182\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7530,\tval_loss: 4.2843\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7663,\tval_loss: 4.3364\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7102,\tval_loss: 4.3694\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6925,\tval_loss: 4.3815\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6591,\tval_loss: 4.4497\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6967,\tval_loss: 4.3578\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7363,\tval_loss: 4.3025\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7334,\tval_loss: 4.3804\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7034,\tval_loss: 4.3921\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7023,\tval_loss: 4.3216\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7197,\tval_loss: 4.3850\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6694,\tval_loss: 4.3384\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6812,\tval_loss: 4.3549\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6930,\tval_loss: 4.3303\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7335,\tval_loss: 4.3928\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6774,\tval_loss: 4.3923\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.7439,\tval_loss: 4.4186\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.7224,\tval_loss: 4.3618\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6653,\tval_loss: 4.4235\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6301,\tval_loss: 4.3905\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.7039,\tval_loss: 4.3640\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6936,\tval_loss: 4.3637\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6930,\tval_loss: 4.3783\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.6807,\tval_loss: 4.3549\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6710,\tval_loss: 4.4099\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6794,\tval_loss: 4.4161\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.7146,\tval_loss: 4.3894\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6463,\tval_loss: 4.4047\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6511,\tval_loss: 4.3319\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6557,\tval_loss: 4.4119\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6587,\tval_loss: 4.3792\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.6567,\tval_loss: 4.4016\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.6189,\tval_loss: 4.4530\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.6166,\tval_loss: 4.3821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4013,\tval_loss: 4.0581\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2677,\tval_loss: 4.0705\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2143,\tval_loss: 4.0815\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1646,\tval_loss: 4.0842\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1556,\tval_loss: 4.0666\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1121,\tval_loss: 4.0769\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1624,\tval_loss: 4.0733\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0954,\tval_loss: 4.0897\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0611,\tval_loss: 4.0920\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0359,\tval_loss: 4.1522\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0315,\tval_loss: 4.1679\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0062,\tval_loss: 4.1793\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9351,\tval_loss: 4.2200\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9289,\tval_loss: 4.1863\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.8684,\tval_loss: 4.2579\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.8631,\tval_loss: 4.1915\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8141,\tval_loss: 4.2955\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8037,\tval_loss: 4.2549\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.7796,\tval_loss: 4.3204\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.7611,\tval_loss: 4.2797\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.7774,\tval_loss: 4.3506\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7523,\tval_loss: 4.3055\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7109,\tval_loss: 4.3302\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7297,\tval_loss: 4.3101\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7028,\tval_loss: 4.2935\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6450,\tval_loss: 4.3328\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7314,\tval_loss: 4.3225\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6618,\tval_loss: 4.4320\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6152,\tval_loss: 4.4568\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.6589,\tval_loss: 4.3868\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6307,\tval_loss: 4.3750\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.5858,\tval_loss: 4.3753\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6734,\tval_loss: 4.3677\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.5686,\tval_loss: 4.3579\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.5909,\tval_loss: 4.4304\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6314,\tval_loss: 4.3891\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.5815,\tval_loss: 4.4404\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.5015,\tval_loss: 4.3993\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.5973,\tval_loss: 4.4309\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.5322,\tval_loss: 4.4784\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.4847,\tval_loss: 4.6373\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.5329,\tval_loss: 4.4771\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5678,\tval_loss: 4.4029\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5823,\tval_loss: 4.4525\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5218,\tval_loss: 4.4323\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5478,\tval_loss: 4.4090\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.4816,\tval_loss: 4.4234\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.4875,\tval_loss: 4.4783\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.4565,\tval_loss: 4.4934\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.4518,\tval_loss: 4.5530\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.4952,\tval_loss: 4.4616\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5089,\tval_loss: 4.5258\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.4980,\tval_loss: 4.4593\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.4274,\tval_loss: 4.5200\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5271,\tval_loss: 4.5130\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.4629,\tval_loss: 4.4763\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.4550,\tval_loss: 4.5891\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.4814,\tval_loss: 4.4855\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.4176,\tval_loss: 4.4879\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.4334,\tval_loss: 4.5809\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5427,\tval_loss: 4.4561\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.4937,\tval_loss: 4.5455\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.4825,\tval_loss: 4.5769\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5103,\tval_loss: 4.4849\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.4336,\tval_loss: 4.5902\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.4462,\tval_loss: 4.5031\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4412,\tval_loss: 4.5194\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4595,\tval_loss: 4.5899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3608,\tval_loss: 4.0962\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2151,\tval_loss: 4.0726\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1617,\tval_loss: 4.0967\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.0998,\tval_loss: 4.0957\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1012,\tval_loss: 4.0912\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1382,\tval_loss: 4.0605\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0832,\tval_loss: 4.0866\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1102,\tval_loss: 4.0678\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0507,\tval_loss: 4.1107\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 3.9774,\tval_loss: 4.0801\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0569,\tval_loss: 4.1147\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9765,\tval_loss: 4.1048\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0097,\tval_loss: 4.1426\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9727,\tval_loss: 4.1762\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.9099,\tval_loss: 4.2455\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.8983,\tval_loss: 4.2277\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.8993,\tval_loss: 4.2885\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8387,\tval_loss: 4.2382\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.8027,\tval_loss: 4.3461\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.7686,\tval_loss: 4.2966\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.7962,\tval_loss: 4.3330\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8118,\tval_loss: 4.3164\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7185,\tval_loss: 4.3614\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7839,\tval_loss: 4.3149\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7536,\tval_loss: 4.3259\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6936,\tval_loss: 4.3662\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7231,\tval_loss: 4.4796\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6510,\tval_loss: 4.4025\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7317,\tval_loss: 4.3228\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.6916,\tval_loss: 4.4655\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.6679,\tval_loss: 4.4130\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.6123,\tval_loss: 4.4010\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.5250,\tval_loss: 4.5101\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.4990,\tval_loss: 4.5781\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.5182,\tval_loss: 4.5334\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.6026,\tval_loss: 4.4230\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.6142,\tval_loss: 4.4810\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.4803,\tval_loss: 4.5573\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.5567,\tval_loss: 4.4806\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.5230,\tval_loss: 4.4939\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5013,\tval_loss: 4.4878\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5327,\tval_loss: 4.4727\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.4612,\tval_loss: 4.5459\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6139,\tval_loss: 4.4833\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.4919,\tval_loss: 4.5146\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.5149,\tval_loss: 4.5016\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.4757,\tval_loss: 4.5621\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.5309,\tval_loss: 4.5161\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.4595,\tval_loss: 4.5761\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.4568,\tval_loss: 4.5115\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.4237,\tval_loss: 4.5341\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.4513,\tval_loss: 4.4647\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.5093,\tval_loss: 4.4985\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.4421,\tval_loss: 4.5490\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.5099,\tval_loss: 4.5016\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.4134,\tval_loss: 4.5275\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.3941,\tval_loss: 4.5711\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5162,\tval_loss: 4.5310\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.4846,\tval_loss: 4.5633\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.4887,\tval_loss: 4.5871\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 3.4191,\tval_loss: 4.5559\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.4746,\tval_loss: 4.5795\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.5415,\tval_loss: 4.5667\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.4668,\tval_loss: 4.5576\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.4724,\tval_loss: 4.5739\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.4840,\tval_loss: 4.4976\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.4595,\tval_loss: 4.6005\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.4074,\tval_loss: 4.5804\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.3492,\tval_loss: 4.5695\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.4252,\tval_loss: 4.5544\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.4769,\tval_loss: 4.5693\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.4145,\tval_loss: 4.5779\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.4239,\tval_loss: 4.5689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4677,\tval_loss: 4.1047\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2827,\tval_loss: 4.1202\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1879,\tval_loss: 4.1219\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2306,\tval_loss: 4.1134\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2255,\tval_loss: 4.1289\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2355,\tval_loss: 4.1008\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1436,\tval_loss: 4.1067\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1496,\tval_loss: 4.1248\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1138,\tval_loss: 4.0970\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1326,\tval_loss: 4.1407\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0601,\tval_loss: 4.1411\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0624,\tval_loss: 4.1595\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0835,\tval_loss: 4.1705\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0369,\tval_loss: 4.2386\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0397,\tval_loss: 4.1805\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9766,\tval_loss: 4.2438\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9845,\tval_loss: 4.2439\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9829,\tval_loss: 4.2894\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0140,\tval_loss: 4.3154\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9029,\tval_loss: 4.3089\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.9286,\tval_loss: 4.2748\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8897,\tval_loss: 4.3653\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8766,\tval_loss: 4.2941\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9064,\tval_loss: 4.2657\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8735,\tval_loss: 4.3721\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9455,\tval_loss: 4.2945\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8306,\tval_loss: 4.3832\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8572,\tval_loss: 4.3469\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8031,\tval_loss: 4.2886\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7889,\tval_loss: 4.4078\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8498,\tval_loss: 4.2894\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8327,\tval_loss: 4.3822\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7529,\tval_loss: 4.3896\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7701,\tval_loss: 4.3286\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7416,\tval_loss: 4.3894\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7045,\tval_loss: 4.3669\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7435,\tval_loss: 4.4728\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7169,\tval_loss: 4.3401\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7289,\tval_loss: 4.3922\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6623,\tval_loss: 4.4781\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7067,\tval_loss: 4.3757\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6792,\tval_loss: 4.4006\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6583,\tval_loss: 4.5501\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6113,\tval_loss: 4.4191\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6642,\tval_loss: 4.5990\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6847,\tval_loss: 4.4719\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6372,\tval_loss: 4.4735\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6386,\tval_loss: 4.4553\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5718,\tval_loss: 4.4977\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6238,\tval_loss: 4.4464\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6168,\tval_loss: 4.4927\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6379,\tval_loss: 4.5521\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.7170,\tval_loss: 4.5555\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.7017,\tval_loss: 4.5137\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6058,\tval_loss: 4.5687\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.5865,\tval_loss: 4.4574\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5828,\tval_loss: 4.4989\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5414,\tval_loss: 4.6298\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6782,\tval_loss: 4.3824\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5158,\tval_loss: 4.5840\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5381,\tval_loss: 4.5669\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5621,\tval_loss: 4.4912\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5288,\tval_loss: 4.6772\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6376,\tval_loss: 4.4783\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5703,\tval_loss: 4.5656\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5351,\tval_loss: 4.5037\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6189,\tval_loss: 4.5186\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.6521,\tval_loss: 4.5072\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.6151,\tval_loss: 4.4844\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.5099,\tval_loss: 4.4967\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.5494,\tval_loss: 4.5403\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.5533,\tval_loss: 4.4851\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.6122,\tval_loss: 4.4759\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.5613,\tval_loss: 4.6208\n",
            "74:\t[0s / 4s],\t\ttrain_loss: 3.4900,\tval_loss: 4.6031\n",
            "75:\t[0s / 4s],\t\ttrain_loss: 3.4858,\tval_loss: 4.6063\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3673,\tval_loss: 3.9805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2551,\tval_loss: 4.0195\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2623,\tval_loss: 4.0319\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1940,\tval_loss: 4.0458\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1397,\tval_loss: 4.0528\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1828,\tval_loss: 4.0529\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1575,\tval_loss: 4.0743\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1129,\tval_loss: 4.0699\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1140,\tval_loss: 4.1107\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1018,\tval_loss: 4.1060\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0989,\tval_loss: 4.1446\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0814,\tval_loss: 4.1146\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0168,\tval_loss: 4.1506\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9921,\tval_loss: 4.2111\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.9754,\tval_loss: 4.2374\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9629,\tval_loss: 4.2374\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9824,\tval_loss: 4.2702\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8994,\tval_loss: 4.2331\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9031,\tval_loss: 4.3103\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8638,\tval_loss: 4.3530\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8753,\tval_loss: 4.3604\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8296,\tval_loss: 4.4058\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7951,\tval_loss: 4.4235\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8407,\tval_loss: 4.4432\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7859,\tval_loss: 4.4259\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6927,\tval_loss: 4.4790\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7331,\tval_loss: 4.5553\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6866,\tval_loss: 4.5375\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7313,\tval_loss: 4.5623\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.6774,\tval_loss: 4.5913\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.7543,\tval_loss: 4.4682\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7262,\tval_loss: 4.5686\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7184,\tval_loss: 4.5228\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.6290,\tval_loss: 4.5429\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7051,\tval_loss: 4.5885\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7350,\tval_loss: 4.5419\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.6846,\tval_loss: 4.5073\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6742,\tval_loss: 4.5097\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7080,\tval_loss: 4.5451\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6988,\tval_loss: 4.4686\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6824,\tval_loss: 4.5577\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5718,\tval_loss: 4.5554\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6228,\tval_loss: 4.5645\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6302,\tval_loss: 4.5318\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6564,\tval_loss: 4.5858\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6207,\tval_loss: 4.5915\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6110,\tval_loss: 4.6202\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6457,\tval_loss: 4.5852\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5959,\tval_loss: 4.5833\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6126,\tval_loss: 4.5908\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5653,\tval_loss: 4.5641\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.6095,\tval_loss: 4.5982\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.5505,\tval_loss: 4.6010\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.5759,\tval_loss: 4.6325\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.5940,\tval_loss: 4.5473\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.5459,\tval_loss: 4.6099\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5476,\tval_loss: 4.6210\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5147,\tval_loss: 4.6598\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5339,\tval_loss: 4.5830\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5813,\tval_loss: 4.5993\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5680,\tval_loss: 4.5752\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6049,\tval_loss: 4.5954\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6506,\tval_loss: 4.5397\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5660,\tval_loss: 4.5963\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5377,\tval_loss: 4.6621\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5350,\tval_loss: 4.6154\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4553,\tval_loss: 4.6884\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5052,\tval_loss: 4.6386\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4292,\tval_loss: 4.0952\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3006,\tval_loss: 4.0789\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2716,\tval_loss: 4.0614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2366,\tval_loss: 4.0688\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2050,\tval_loss: 4.0731\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1861,\tval_loss: 4.0695\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1435,\tval_loss: 4.0851\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1431,\tval_loss: 4.1102\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1019,\tval_loss: 4.1052\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0997,\tval_loss: 4.0737\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1011,\tval_loss: 4.1149\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0276,\tval_loss: 4.1876\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0335,\tval_loss: 4.1362\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0261,\tval_loss: 4.1563\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0201,\tval_loss: 4.1410\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0343,\tval_loss: 4.1471\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9928,\tval_loss: 4.2122\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9788,\tval_loss: 4.1671\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 4.0068,\tval_loss: 4.1546\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9135,\tval_loss: 4.1929\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9285,\tval_loss: 4.1541\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9541,\tval_loss: 4.2370\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8768,\tval_loss: 4.1505\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8962,\tval_loss: 4.1806\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8061,\tval_loss: 4.1795\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9095,\tval_loss: 4.1784\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8641,\tval_loss: 4.1977\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8787,\tval_loss: 4.1546\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7721,\tval_loss: 4.1808\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7623,\tval_loss: 4.2183\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8507,\tval_loss: 4.2470\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8243,\tval_loss: 4.2052\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7864,\tval_loss: 4.2676\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.8048,\tval_loss: 4.1643\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.8307,\tval_loss: 4.2410\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.8106,\tval_loss: 4.1520\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7861,\tval_loss: 4.1865\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7622,\tval_loss: 4.1895\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7370,\tval_loss: 4.2755\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7504,\tval_loss: 4.1903\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7867,\tval_loss: 4.1587\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7548,\tval_loss: 4.2423\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7763,\tval_loss: 4.1867\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7809,\tval_loss: 4.1356\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7437,\tval_loss: 4.1626\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7286,\tval_loss: 4.1703\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7326,\tval_loss: 4.1962\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.7472,\tval_loss: 4.1471\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.7310,\tval_loss: 4.1966\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6443,\tval_loss: 4.2379\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.7725,\tval_loss: 4.1883\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.7441,\tval_loss: 4.1681\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.7058,\tval_loss: 4.2234\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.7925,\tval_loss: 4.1778\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.7729,\tval_loss: 4.2164\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6701,\tval_loss: 4.1864\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6753,\tval_loss: 4.2394\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.7043,\tval_loss: 4.2105\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.7526,\tval_loss: 4.2040\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6855,\tval_loss: 4.1700\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6164,\tval_loss: 4.2266\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6815,\tval_loss: 4.2608\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.6534,\tval_loss: 4.2073\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.7339,\tval_loss: 4.1346\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.6359,\tval_loss: 4.1849\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.6291,\tval_loss: 4.2218\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.6297,\tval_loss: 4.1293\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.6604,\tval_loss: 4.1917\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.7030,\tval_loss: 4.1784\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.6474,\tval_loss: 4.1833\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4698,\tval_loss: 4.0841\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3532,\tval_loss: 4.0866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3269,\tval_loss: 4.0933\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2853,\tval_loss: 4.0936\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2757,\tval_loss: 4.0808\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2489,\tval_loss: 4.0813\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2340,\tval_loss: 4.1016\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2230,\tval_loss: 4.1145\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1818,\tval_loss: 4.1429\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1554,\tval_loss: 4.1660\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1118,\tval_loss: 4.1712\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1230,\tval_loss: 4.2149\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1106,\tval_loss: 4.2501\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 4.0188,\tval_loss: 4.3217\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0665,\tval_loss: 4.3418\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0239,\tval_loss: 4.3042\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9893,\tval_loss: 4.3509\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9940,\tval_loss: 4.4489\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9365,\tval_loss: 4.3530\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9468,\tval_loss: 4.4877\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9314,\tval_loss: 4.4404\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9318,\tval_loss: 4.3971\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9135,\tval_loss: 4.4447\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8423,\tval_loss: 4.4824\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8622,\tval_loss: 4.4720\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8456,\tval_loss: 4.4975\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8687,\tval_loss: 4.5368\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8343,\tval_loss: 4.4651\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8520,\tval_loss: 4.4697\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8383,\tval_loss: 4.4609\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8315,\tval_loss: 4.5250\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7817,\tval_loss: 4.5301\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7617,\tval_loss: 4.5503\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.8687,\tval_loss: 4.4867\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7973,\tval_loss: 4.4376\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.8011,\tval_loss: 4.5402\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.8015,\tval_loss: 4.4160\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.8068,\tval_loss: 4.4974\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7503,\tval_loss: 4.4095\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6898,\tval_loss: 4.5634\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7178,\tval_loss: 4.5621\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7058,\tval_loss: 4.5145\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6921,\tval_loss: 4.5501\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7087,\tval_loss: 4.6374\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7023,\tval_loss: 4.5221\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7765,\tval_loss: 4.5450\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7143,\tval_loss: 4.5643\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6564,\tval_loss: 4.5737\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6080,\tval_loss: 4.6737\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7152,\tval_loss: 4.5438\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6316,\tval_loss: 4.6687\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6929,\tval_loss: 4.6079\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6882,\tval_loss: 4.6133\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6873,\tval_loss: 4.6212\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6556,\tval_loss: 4.6134\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6908,\tval_loss: 4.6226\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6811,\tval_loss: 4.5608\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6631,\tval_loss: 4.6545\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.7087,\tval_loss: 4.5934\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6291,\tval_loss: 4.6089\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6399,\tval_loss: 4.6940\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6804,\tval_loss: 4.5744\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6176,\tval_loss: 4.7023\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5871,\tval_loss: 4.7220\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.7316,\tval_loss: 4.5720\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6079,\tval_loss: 4.5898\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5944,\tval_loss: 4.7473\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6052,\tval_loss: 4.5589\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6566,\tval_loss: 4.6928\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6372,\tval_loss: 4.6463\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5267,\tval_loss: 4.7051\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.5853,\tval_loss: 4.6716\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4225,\tval_loss: 4.1239\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2894,\tval_loss: 4.1066\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1720,\tval_loss: 4.1031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1779,\tval_loss: 4.0876\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1832,\tval_loss: 4.0920\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1260,\tval_loss: 4.0617\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0927,\tval_loss: 4.0961\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0514,\tval_loss: 4.1267\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0606,\tval_loss: 4.1783\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0263,\tval_loss: 4.1416\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 3.9513,\tval_loss: 4.1640\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9831,\tval_loss: 4.2165\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9674,\tval_loss: 4.1852\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9020,\tval_loss: 4.2257\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.8558,\tval_loss: 4.3024\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9030,\tval_loss: 4.2963\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9180,\tval_loss: 4.2782\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8166,\tval_loss: 4.3241\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8474,\tval_loss: 4.3932\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8663,\tval_loss: 4.2308\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.7896,\tval_loss: 4.2601\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7971,\tval_loss: 4.2993\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7915,\tval_loss: 4.3055\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7495,\tval_loss: 4.2908\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7591,\tval_loss: 4.3768\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7752,\tval_loss: 4.3784\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6648,\tval_loss: 4.3395\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6893,\tval_loss: 4.3803\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6933,\tval_loss: 4.4111\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.6440,\tval_loss: 4.4197\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6449,\tval_loss: 4.3728\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6216,\tval_loss: 4.4882\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.5883,\tval_loss: 4.4043\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.5837,\tval_loss: 4.5146\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6507,\tval_loss: 4.4627\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6068,\tval_loss: 4.4716\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.5783,\tval_loss: 4.3986\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6215,\tval_loss: 4.3552\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.5229,\tval_loss: 4.4259\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.5764,\tval_loss: 4.4671\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6003,\tval_loss: 4.4176\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.5802,\tval_loss: 4.4678\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.5444,\tval_loss: 4.3489\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5213,\tval_loss: 4.5807\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5949,\tval_loss: 4.4409\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5673,\tval_loss: 4.4601\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5916,\tval_loss: 4.4865\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5667,\tval_loss: 4.5654\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.4940,\tval_loss: 4.5923\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.4949,\tval_loss: 4.5203\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5124,\tval_loss: 4.4621\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5002,\tval_loss: 4.4753\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5999,\tval_loss: 4.5242\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.4109,\tval_loss: 4.5677\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.4643,\tval_loss: 4.5397\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.4713,\tval_loss: 4.5756\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5016,\tval_loss: 4.4524\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.4475,\tval_loss: 4.4941\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.4853,\tval_loss: 4.6514\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.4272,\tval_loss: 4.5041\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.4628,\tval_loss: 4.5723\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.4802,\tval_loss: 4.5619\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.3477,\tval_loss: 4.6660\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.4494,\tval_loss: 4.4971\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.4659,\tval_loss: 4.5064\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5093,\tval_loss: 4.5547\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4399,\tval_loss: 4.5440\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4350,\tval_loss: 4.5782\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.3282,\tval_loss: 4.6971\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.4637,\tval_loss: 4.5584\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.4725,\tval_loss: 4.6170\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.4269,\tval_loss: 4.5702\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.3754,\tval_loss: 4.6883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3971,\tval_loss: 4.0361\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2617,\tval_loss: 4.0321\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2597,\tval_loss: 4.0461\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2245,\tval_loss: 4.0477\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1984,\tval_loss: 4.0558\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2136,\tval_loss: 4.0530\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1766,\tval_loss: 4.0441\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1706,\tval_loss: 4.0432\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1697,\tval_loss: 4.0485\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1465,\tval_loss: 4.0849\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1366,\tval_loss: 4.0786\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1225,\tval_loss: 4.0997\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0775,\tval_loss: 4.1543\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0873,\tval_loss: 4.1292\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0639,\tval_loss: 4.1459\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0264,\tval_loss: 4.1400\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0067,\tval_loss: 4.2051\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9813,\tval_loss: 4.1853\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9702,\tval_loss: 4.2618\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9506,\tval_loss: 4.2391\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.9201,\tval_loss: 4.2423\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8323,\tval_loss: 4.3697\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9270,\tval_loss: 4.2661\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8129,\tval_loss: 4.2578\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8292,\tval_loss: 4.3088\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7629,\tval_loss: 4.4443\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7939,\tval_loss: 4.3837\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8100,\tval_loss: 4.3960\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8206,\tval_loss: 4.3554\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7285,\tval_loss: 4.4425\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7237,\tval_loss: 4.4286\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7127,\tval_loss: 4.5425\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6513,\tval_loss: 4.4445\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6857,\tval_loss: 4.4520\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7531,\tval_loss: 4.4681\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7571,\tval_loss: 4.4809\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6630,\tval_loss: 4.5255\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7335,\tval_loss: 4.4840\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6174,\tval_loss: 4.5553\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6198,\tval_loss: 4.5751\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7128,\tval_loss: 4.5508\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6635,\tval_loss: 4.5146\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.6436,\tval_loss: 4.5226\n",
            "43:\t[0s / 1s],\t\ttrain_loss: 3.6341,\tval_loss: 4.5585\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6521,\tval_loss: 4.5804\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6211,\tval_loss: 4.5214\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5536,\tval_loss: 4.5210\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6430,\tval_loss: 4.6537\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6064,\tval_loss: 4.6386\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6106,\tval_loss: 4.5073\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6069,\tval_loss: 4.6655\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5664,\tval_loss: 4.6156\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5719,\tval_loss: 4.6977\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5056,\tval_loss: 4.6568\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5264,\tval_loss: 4.7184\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5291,\tval_loss: 4.6740\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.4984,\tval_loss: 4.7093\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5165,\tval_loss: 4.5733\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5024,\tval_loss: 4.7019\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5254,\tval_loss: 4.6204\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.4996,\tval_loss: 4.7277\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5197,\tval_loss: 4.6414\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5159,\tval_loss: 4.6674\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.4763,\tval_loss: 4.6659\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.5290,\tval_loss: 4.6157\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5289,\tval_loss: 4.6426\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5626,\tval_loss: 4.6118\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4711,\tval_loss: 4.6785\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.4482,\tval_loss: 4.8530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3357,\tval_loss: 4.1300\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2332,\tval_loss: 4.1509\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1744,\tval_loss: 4.1445\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1351,\tval_loss: 4.1730\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1453,\tval_loss: 4.1793\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1212,\tval_loss: 4.2083\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0858,\tval_loss: 4.2016\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0421,\tval_loss: 4.2527\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0621,\tval_loss: 4.2196\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0695,\tval_loss: 4.2899\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0402,\tval_loss: 4.2362\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0079,\tval_loss: 4.2690\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9680,\tval_loss: 4.2491\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.8746,\tval_loss: 4.3911\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9098,\tval_loss: 4.3041\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.8453,\tval_loss: 4.3913\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8556,\tval_loss: 4.3963\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8048,\tval_loss: 4.5611\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8017,\tval_loss: 4.3409\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.7957,\tval_loss: 4.4237\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.7984,\tval_loss: 4.4288\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7159,\tval_loss: 4.5167\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7044,\tval_loss: 4.4548\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.6831,\tval_loss: 4.4800\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7453,\tval_loss: 4.5190\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6483,\tval_loss: 4.5825\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6116,\tval_loss: 4.4762\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7478,\tval_loss: 4.4385\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7418,\tval_loss: 4.4081\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.6640,\tval_loss: 4.5250\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6506,\tval_loss: 4.5410\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6142,\tval_loss: 4.5515\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.5688,\tval_loss: 4.6396\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6112,\tval_loss: 4.5170\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6503,\tval_loss: 4.6433\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.6085,\tval_loss: 4.5602\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.6255,\tval_loss: 4.5066\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6703,\tval_loss: 4.5754\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.5891,\tval_loss: 4.4711\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.5675,\tval_loss: 4.5626\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5284,\tval_loss: 4.5952\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5815,\tval_loss: 4.5996\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5460,\tval_loss: 4.7418\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5815,\tval_loss: 4.5475\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5200,\tval_loss: 4.7674\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5155,\tval_loss: 4.5448\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5725,\tval_loss: 4.6376\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.4813,\tval_loss: 4.6543\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.4465,\tval_loss: 4.6760\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5689,\tval_loss: 4.6074\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.4948,\tval_loss: 4.5845\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.4595,\tval_loss: 4.6660\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.4187,\tval_loss: 4.6481\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.4695,\tval_loss: 4.7048\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.5040,\tval_loss: 4.6369\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.4681,\tval_loss: 4.6209\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5265,\tval_loss: 4.7893\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.4489,\tval_loss: 4.6379\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.4822,\tval_loss: 4.7352\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5256,\tval_loss: 4.6969\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.3768,\tval_loss: 4.7177\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.4482,\tval_loss: 4.8006\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.3935,\tval_loss: 4.7499\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.4415,\tval_loss: 4.6256\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.4600,\tval_loss: 4.7663\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.3901,\tval_loss: 4.7200\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.4455,\tval_loss: 4.6956\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.4775,\tval_loss: 4.6923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4005,\tval_loss: 4.0960\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3348,\tval_loss: 4.0752\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2813,\tval_loss: 4.0821\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2419,\tval_loss: 4.0897\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2425,\tval_loss: 4.0988\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2593,\tval_loss: 4.0847\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2001,\tval_loss: 4.0992\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2104,\tval_loss: 4.0833\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1878,\tval_loss: 4.0936\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1313,\tval_loss: 4.1081\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1552,\tval_loss: 4.0830\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0807,\tval_loss: 4.1248\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0815,\tval_loss: 4.0821\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0411,\tval_loss: 4.1200\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0726,\tval_loss: 4.1823\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9703,\tval_loss: 4.1608\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 4.0148,\tval_loss: 4.2040\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9337,\tval_loss: 4.2063\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9779,\tval_loss: 4.2543\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9555,\tval_loss: 4.2531\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9939,\tval_loss: 4.2056\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9685,\tval_loss: 4.1303\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8993,\tval_loss: 4.1902\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8836,\tval_loss: 4.2451\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8989,\tval_loss: 4.2319\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8891,\tval_loss: 4.2837\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7598,\tval_loss: 4.2437\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 3.7963,\tval_loss: 4.3258\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 3.8058,\tval_loss: 4.2871\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.7664,\tval_loss: 4.4319\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.7303,\tval_loss: 4.3439\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7366,\tval_loss: 4.2785\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.6925,\tval_loss: 4.4641\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.6530,\tval_loss: 4.4309\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.6319,\tval_loss: 4.4021\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7012,\tval_loss: 4.3675\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.6805,\tval_loss: 4.3611\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.5818,\tval_loss: 4.4599\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6325,\tval_loss: 4.4516\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6585,\tval_loss: 4.3748\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7064,\tval_loss: 4.3471\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5798,\tval_loss: 4.3082\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6331,\tval_loss: 4.3617\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6305,\tval_loss: 4.3452\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6017,\tval_loss: 4.3694\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6177,\tval_loss: 4.3901\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6787,\tval_loss: 4.3331\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6186,\tval_loss: 4.4019\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.5713,\tval_loss: 4.4120\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6872,\tval_loss: 4.4030\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6315,\tval_loss: 4.4086\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.5204,\tval_loss: 4.4119\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.5103,\tval_loss: 4.4133\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.5464,\tval_loss: 4.4343\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.5593,\tval_loss: 4.4820\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.5829,\tval_loss: 4.3832\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5465,\tval_loss: 4.4173\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5439,\tval_loss: 4.4661\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5659,\tval_loss: 4.3675\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6180,\tval_loss: 4.4291\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.4985,\tval_loss: 4.3969\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5204,\tval_loss: 4.5749\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5826,\tval_loss: 4.4508\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5938,\tval_loss: 4.4138\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.4730,\tval_loss: 4.5073\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5684,\tval_loss: 4.4562\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5399,\tval_loss: 4.4425\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5027,\tval_loss: 4.5442\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5758,\tval_loss: 4.4123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4838,\tval_loss: 4.0068\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3195,\tval_loss: 4.0229\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2775,\tval_loss: 4.0204\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2370,\tval_loss: 4.0277\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2202,\tval_loss: 4.0340\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1249,\tval_loss: 4.0624\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1625,\tval_loss: 4.0449\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1328,\tval_loss: 4.0592\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1200,\tval_loss: 4.0683\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1002,\tval_loss: 4.0491\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0639,\tval_loss: 4.1017\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9971,\tval_loss: 4.1483\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0425,\tval_loss: 4.1216\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9828,\tval_loss: 4.1287\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0140,\tval_loss: 4.1945\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0107,\tval_loss: 4.1832\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8810,\tval_loss: 4.2794\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8752,\tval_loss: 4.2456\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8859,\tval_loss: 4.2462\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9256,\tval_loss: 4.2711\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8876,\tval_loss: 4.2705\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8320,\tval_loss: 4.3049\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8752,\tval_loss: 4.2855\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8892,\tval_loss: 4.2627\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8481,\tval_loss: 4.2467\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8699,\tval_loss: 4.2354\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8301,\tval_loss: 4.2304\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7999,\tval_loss: 4.2913\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8497,\tval_loss: 4.3086\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8120,\tval_loss: 4.3842\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7770,\tval_loss: 4.3564\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7823,\tval_loss: 4.3417\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7919,\tval_loss: 4.3192\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7428,\tval_loss: 4.2978\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6981,\tval_loss: 4.3614\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7551,\tval_loss: 4.3446\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7479,\tval_loss: 4.3258\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6973,\tval_loss: 4.3538\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6929,\tval_loss: 4.3029\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6967,\tval_loss: 4.4179\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7265,\tval_loss: 4.3958\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6950,\tval_loss: 4.3548\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7141,\tval_loss: 4.3291\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7523,\tval_loss: 4.3321\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7132,\tval_loss: 4.3470\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6782,\tval_loss: 4.3683\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6355,\tval_loss: 4.4198\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6948,\tval_loss: 4.3371\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6678,\tval_loss: 4.3938\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6306,\tval_loss: 4.4088\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6259,\tval_loss: 4.4519\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5826,\tval_loss: 4.3887\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6283,\tval_loss: 4.3977\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6252,\tval_loss: 4.3585\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6157,\tval_loss: 4.3912\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6340,\tval_loss: 4.3897\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6633,\tval_loss: 4.4536\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6591,\tval_loss: 4.3181\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5866,\tval_loss: 4.3621\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5586,\tval_loss: 4.3327\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6437,\tval_loss: 4.3891\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6111,\tval_loss: 4.3663\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5495,\tval_loss: 4.3794\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5652,\tval_loss: 4.3918\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5484,\tval_loss: 4.4596\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5751,\tval_loss: 4.3888\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6544,\tval_loss: 4.3025\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5379,\tval_loss: 4.3751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4192,\tval_loss: 4.0899\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3428,\tval_loss: 4.0669\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2628,\tval_loss: 4.0710\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2755,\tval_loss: 4.0527\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2320,\tval_loss: 4.0375\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2241,\tval_loss: 4.0272\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2242,\tval_loss: 4.0156\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2011,\tval_loss: 4.0166\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1889,\tval_loss: 3.9910\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1764,\tval_loss: 4.0147\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1575,\tval_loss: 4.0305\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1188,\tval_loss: 4.0242\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0962,\tval_loss: 4.0648\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0939,\tval_loss: 4.0579\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0994,\tval_loss: 4.0764\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0759,\tval_loss: 4.0830\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0959,\tval_loss: 4.0697\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0087,\tval_loss: 4.1322\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0302,\tval_loss: 4.1115\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 4.0145,\tval_loss: 4.1390\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.9959,\tval_loss: 4.1550\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9888,\tval_loss: 4.1608\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9645,\tval_loss: 4.1708\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9559,\tval_loss: 4.1702\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9566,\tval_loss: 4.1825\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9964,\tval_loss: 4.2164\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9484,\tval_loss: 4.1693\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9235,\tval_loss: 4.1571\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8623,\tval_loss: 4.2110\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8697,\tval_loss: 4.2338\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8405,\tval_loss: 4.1947\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8674,\tval_loss: 4.2060\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8393,\tval_loss: 4.2854\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8703,\tval_loss: 4.2707\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7845,\tval_loss: 4.2589\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8288,\tval_loss: 4.2627\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7969,\tval_loss: 4.2501\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.8126,\tval_loss: 4.2096\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7780,\tval_loss: 4.2464\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7906,\tval_loss: 4.3112\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.8298,\tval_loss: 4.2295\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.8164,\tval_loss: 4.2356\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.7945,\tval_loss: 4.2706\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7871,\tval_loss: 4.2460\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7924,\tval_loss: 4.2121\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7841,\tval_loss: 4.2621\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.8081,\tval_loss: 4.2653\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7635,\tval_loss: 4.2497\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6718,\tval_loss: 4.3591\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7714,\tval_loss: 4.2572\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7632,\tval_loss: 4.2566\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.8090,\tval_loss: 4.2707\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7875,\tval_loss: 4.2270\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7167,\tval_loss: 4.2904\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6926,\tval_loss: 4.2939\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.7431,\tval_loss: 4.3423\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6908,\tval_loss: 4.2809\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.7362,\tval_loss: 4.2402\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6636,\tval_loss: 4.3191\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6699,\tval_loss: 4.2778\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6385,\tval_loss: 4.3166\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6567,\tval_loss: 4.3003\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6436,\tval_loss: 4.3446\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.6761,\tval_loss: 4.3397\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.6200,\tval_loss: 4.3574\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6691,\tval_loss: 4.3480\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6674,\tval_loss: 4.3926\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6153,\tval_loss: 4.3552\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6990,\tval_loss: 4.2773\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5998,\tval_loss: 4.3348\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6482,\tval_loss: 4.3271\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.6284,\tval_loss: 4.3456\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.6347,\tval_loss: 4.3363\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.6324,\tval_loss: 4.2639\n",
            "74:\t[0s / 3s],\t\ttrain_loss: 3.6697,\tval_loss: 4.2485\n",
            "75:\t[0s / 3s],\t\ttrain_loss: 3.6228,\tval_loss: 4.2832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.5748,\tval_loss: 4.0418\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.4076,\tval_loss: 4.0342\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3709,\tval_loss: 4.0384\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.3574,\tval_loss: 4.0450\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.3462,\tval_loss: 4.0361\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.3361,\tval_loss: 4.0432\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.3361,\tval_loss: 4.0469\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.3291,\tval_loss: 4.0479\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.2969,\tval_loss: 4.0685\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.2818,\tval_loss: 4.0695\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.2726,\tval_loss: 4.0634\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.2562,\tval_loss: 4.0789\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.2783,\tval_loss: 4.0790\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.2644,\tval_loss: 4.0928\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.1999,\tval_loss: 4.1153\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.1926,\tval_loss: 4.1630\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.1934,\tval_loss: 4.1886\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.1378,\tval_loss: 4.1765\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.1423,\tval_loss: 4.1785\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 4.0939,\tval_loss: 4.2108\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 4.1087,\tval_loss: 4.2706\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 4.0677,\tval_loss: 4.2293\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 4.0675,\tval_loss: 4.3134\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 4.0352,\tval_loss: 4.2855\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9257,\tval_loss: 4.3149\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9149,\tval_loss: 4.3706\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9766,\tval_loss: 4.3993\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9547,\tval_loss: 4.2587\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.9743,\tval_loss: 4.3632\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.9481,\tval_loss: 4.3132\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.9023,\tval_loss: 4.3395\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8949,\tval_loss: 4.4025\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.9064,\tval_loss: 4.4516\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8521,\tval_loss: 4.4553\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7797,\tval_loss: 4.4874\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.9025,\tval_loss: 4.4452\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.9008,\tval_loss: 4.4012\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.8848,\tval_loss: 4.4255\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.8639,\tval_loss: 4.3972\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.8963,\tval_loss: 4.4190\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.8153,\tval_loss: 4.4253\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.8549,\tval_loss: 4.4445\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.8347,\tval_loss: 4.3758\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7945,\tval_loss: 4.4118\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7145,\tval_loss: 4.4954\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7677,\tval_loss: 4.4323\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7452,\tval_loss: 4.5011\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7731,\tval_loss: 4.4301\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.8273,\tval_loss: 4.4826\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7554,\tval_loss: 4.5140\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6945,\tval_loss: 4.5471\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.7489,\tval_loss: 4.4502\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.7446,\tval_loss: 4.5051\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.7479,\tval_loss: 4.5398\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.7092,\tval_loss: 4.5293\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.7982,\tval_loss: 4.5073\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6931,\tval_loss: 4.4596\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.7059,\tval_loss: 4.5755\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.7840,\tval_loss: 4.4091\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6169,\tval_loss: 4.4829\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6925,\tval_loss: 4.5367\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6227,\tval_loss: 4.5123\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6761,\tval_loss: 4.5167\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6127,\tval_loss: 4.5169\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6038,\tval_loss: 4.5319\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.7168,\tval_loss: 4.5104\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.6752,\tval_loss: 4.4664\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.6460,\tval_loss: 4.4764\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.7479,\tval_loss: 4.4872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3489,\tval_loss: 4.0862\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2326,\tval_loss: 4.1175\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2238,\tval_loss: 4.1173\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1882,\tval_loss: 4.1307\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1274,\tval_loss: 4.1674\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1301,\tval_loss: 4.1289\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1465,\tval_loss: 4.1568\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0984,\tval_loss: 4.1826\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1386,\tval_loss: 4.1621\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0741,\tval_loss: 4.1694\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0851,\tval_loss: 4.2046\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0707,\tval_loss: 4.1708\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0369,\tval_loss: 4.2225\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0286,\tval_loss: 4.1987\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0095,\tval_loss: 4.3441\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9980,\tval_loss: 4.2169\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9356,\tval_loss: 4.2800\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9701,\tval_loss: 4.3264\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9470,\tval_loss: 4.2946\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9239,\tval_loss: 4.3831\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8869,\tval_loss: 4.3564\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9372,\tval_loss: 4.3184\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8626,\tval_loss: 4.3297\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8959,\tval_loss: 4.3369\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9093,\tval_loss: 4.4631\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8255,\tval_loss: 4.3896\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8426,\tval_loss: 4.4687\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 3.8292,\tval_loss: 4.4044\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 3.7922,\tval_loss: 4.4347\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.7134,\tval_loss: 4.5724\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.7863,\tval_loss: 4.3850\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7237,\tval_loss: 4.4546\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7643,\tval_loss: 4.3982\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.7234,\tval_loss: 4.6057\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7491,\tval_loss: 4.3989\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7685,\tval_loss: 4.4392\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7672,\tval_loss: 4.4455\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6964,\tval_loss: 4.4699\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6503,\tval_loss: 4.5475\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7046,\tval_loss: 4.4856\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6631,\tval_loss: 4.4756\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7114,\tval_loss: 4.4054\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6282,\tval_loss: 4.4860\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7378,\tval_loss: 4.5039\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6778,\tval_loss: 4.5433\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6199,\tval_loss: 4.5550\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5552,\tval_loss: 4.6147\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6718,\tval_loss: 4.4242\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.6309,\tval_loss: 4.6193\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6075,\tval_loss: 4.4800\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.5897,\tval_loss: 4.4938\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.6361,\tval_loss: 4.4871\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6943,\tval_loss: 4.4320\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6076,\tval_loss: 4.5322\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6226,\tval_loss: 4.3571\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6197,\tval_loss: 4.4836\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5873,\tval_loss: 4.5212\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5472,\tval_loss: 4.5138\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6837,\tval_loss: 4.4813\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5926,\tval_loss: 4.5016\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5752,\tval_loss: 4.4478\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6373,\tval_loss: 4.4691\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5597,\tval_loss: 4.4851\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5358,\tval_loss: 4.5432\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5644,\tval_loss: 4.4610\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5902,\tval_loss: 4.4348\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5654,\tval_loss: 4.4586\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5932,\tval_loss: 4.4668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3556,\tval_loss: 4.1452\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2706,\tval_loss: 4.1376\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2207,\tval_loss: 4.1116\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2103,\tval_loss: 4.1231\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1574,\tval_loss: 4.1071\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1102,\tval_loss: 4.1289\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1282,\tval_loss: 4.1006\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1590,\tval_loss: 4.1178\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1143,\tval_loss: 4.1746\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0905,\tval_loss: 4.1495\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0733,\tval_loss: 4.1608\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0257,\tval_loss: 4.2138\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0437,\tval_loss: 4.1922\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9944,\tval_loss: 4.2116\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9971,\tval_loss: 4.1932\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9693,\tval_loss: 4.2343\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8988,\tval_loss: 4.2520\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9447,\tval_loss: 4.2331\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8983,\tval_loss: 4.1950\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9067,\tval_loss: 4.2502\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8650,\tval_loss: 4.2332\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8613,\tval_loss: 4.2365\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8586,\tval_loss: 4.2388\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8163,\tval_loss: 4.2162\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7495,\tval_loss: 4.3513\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7705,\tval_loss: 4.2700\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7565,\tval_loss: 4.2491\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6879,\tval_loss: 4.3562\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8057,\tval_loss: 4.1965\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7681,\tval_loss: 4.2582\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7148,\tval_loss: 4.2772\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7720,\tval_loss: 4.2366\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7524,\tval_loss: 4.2111\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7040,\tval_loss: 4.2027\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6860,\tval_loss: 4.3829\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7603,\tval_loss: 4.2100\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6968,\tval_loss: 4.2670\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7238,\tval_loss: 4.2391\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6766,\tval_loss: 4.2424\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6735,\tval_loss: 4.2616\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7029,\tval_loss: 4.2855\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7126,\tval_loss: 4.2587\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6149,\tval_loss: 4.3201\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6367,\tval_loss: 4.2930\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6686,\tval_loss: 4.2184\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6972,\tval_loss: 4.2712\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5877,\tval_loss: 4.2824\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6253,\tval_loss: 4.4033\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6559,\tval_loss: 4.2582\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6561,\tval_loss: 4.2574\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7409,\tval_loss: 4.2618\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6463,\tval_loss: 4.2970\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6632,\tval_loss: 4.2573\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6884,\tval_loss: 4.2973\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6225,\tval_loss: 4.3647\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6641,\tval_loss: 4.3139\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6712,\tval_loss: 4.3244\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6806,\tval_loss: 4.2669\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6366,\tval_loss: 4.2832\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6036,\tval_loss: 4.2756\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6195,\tval_loss: 4.4412\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6284,\tval_loss: 4.2967\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6773,\tval_loss: 4.3426\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6257,\tval_loss: 4.2809\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5673,\tval_loss: 4.2989\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5840,\tval_loss: 4.4227\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5376,\tval_loss: 4.3433\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5027,\tval_loss: 4.4283\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.6266,\tval_loss: 4.3668\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.5532,\tval_loss: 4.3103\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.5769,\tval_loss: 4.2934\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.6265,\tval_loss: 4.3778\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.5908,\tval_loss: 4.4422\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.4639,\tval_loss: 4.3609\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3147,\tval_loss: 4.1047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.1873,\tval_loss: 4.1076\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1971,\tval_loss: 4.1214\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1184,\tval_loss: 4.1373\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1186,\tval_loss: 4.1259\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1477,\tval_loss: 4.1292\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0691,\tval_loss: 4.1458\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0409,\tval_loss: 4.1231\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0498,\tval_loss: 4.1465\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0565,\tval_loss: 4.1068\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 3.9975,\tval_loss: 4.1224\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0027,\tval_loss: 4.1489\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9834,\tval_loss: 4.1073\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0254,\tval_loss: 4.1234\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9498,\tval_loss: 4.1796\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9301,\tval_loss: 4.1175\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.8791,\tval_loss: 4.1330\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9125,\tval_loss: 4.1529\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.8912,\tval_loss: 4.1713\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8858,\tval_loss: 4.2661\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8222,\tval_loss: 4.2147\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8792,\tval_loss: 4.2314\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8285,\tval_loss: 4.2435\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7544,\tval_loss: 4.2524\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7598,\tval_loss: 4.2881\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7661,\tval_loss: 4.2732\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7001,\tval_loss: 4.3507\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8257,\tval_loss: 4.2617\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6980,\tval_loss: 4.3430\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7040,\tval_loss: 4.3494\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.6527,\tval_loss: 4.3794\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7064,\tval_loss: 4.3971\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.6690,\tval_loss: 4.4038\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.6402,\tval_loss: 4.4611\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.6224,\tval_loss: 4.4028\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.6432,\tval_loss: 4.4146\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.5949,\tval_loss: 4.4452\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.5640,\tval_loss: 4.4477\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6381,\tval_loss: 4.4366\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.5816,\tval_loss: 4.4054\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5752,\tval_loss: 4.4561\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5252,\tval_loss: 4.4690\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5337,\tval_loss: 4.4809\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5269,\tval_loss: 4.5093\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5405,\tval_loss: 4.4672\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.4248,\tval_loss: 4.4660\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.4704,\tval_loss: 4.6021\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.4416,\tval_loss: 4.6543\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5509,\tval_loss: 4.4338\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.4756,\tval_loss: 4.5278\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.4607,\tval_loss: 4.5535\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.4621,\tval_loss: 4.5635\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.5282,\tval_loss: 4.4588\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.4939,\tval_loss: 4.6409\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.4338,\tval_loss: 4.6549\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.4363,\tval_loss: 4.5803\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.4469,\tval_loss: 4.5358\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.4573,\tval_loss: 4.4990\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.4403,\tval_loss: 4.5894\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.4135,\tval_loss: 4.5653\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.4521,\tval_loss: 4.6495\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.4137,\tval_loss: 4.6137\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.4114,\tval_loss: 4.5085\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.3783,\tval_loss: 4.5552\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.3111,\tval_loss: 4.5146\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.3810,\tval_loss: 4.5164\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.3653,\tval_loss: 4.5390\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.3880,\tval_loss: 4.6453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4338,\tval_loss: 4.0896\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3084,\tval_loss: 4.0468\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2639,\tval_loss: 4.0469\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2410,\tval_loss: 4.0530\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1811,\tval_loss: 4.0312\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1849,\tval_loss: 4.0566\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1119,\tval_loss: 4.0584\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1255,\tval_loss: 4.0633\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0789,\tval_loss: 4.0296\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0726,\tval_loss: 4.0036\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0737,\tval_loss: 4.0244\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0358,\tval_loss: 4.0097\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0434,\tval_loss: 3.9854\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9709,\tval_loss: 3.9969\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.9987,\tval_loss: 4.0129\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0074,\tval_loss: 4.0375\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9263,\tval_loss: 4.0241\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 4.0064,\tval_loss: 4.0577\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9797,\tval_loss: 4.0427\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8881,\tval_loss: 4.0589\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8901,\tval_loss: 4.0728\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9080,\tval_loss: 4.0729\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9063,\tval_loss: 4.0301\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9130,\tval_loss: 4.0130\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8741,\tval_loss: 4.0473\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8481,\tval_loss: 4.0384\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8326,\tval_loss: 4.1314\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7910,\tval_loss: 4.1040\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7551,\tval_loss: 4.1523\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.8456,\tval_loss: 4.0341\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.8503,\tval_loss: 3.9966\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.8544,\tval_loss: 3.9946\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7676,\tval_loss: 4.0303\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.7693,\tval_loss: 4.0340\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7726,\tval_loss: 4.0332\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7903,\tval_loss: 4.0853\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7830,\tval_loss: 4.0780\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7260,\tval_loss: 4.0944\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6756,\tval_loss: 4.0824\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7073,\tval_loss: 4.1172\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6739,\tval_loss: 4.0620\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6488,\tval_loss: 4.0594\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6809,\tval_loss: 4.0825\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7579,\tval_loss: 4.0511\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.6987,\tval_loss: 4.1112\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.6248,\tval_loss: 4.0765\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.7072,\tval_loss: 4.0876\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.6616,\tval_loss: 4.0647\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.6388,\tval_loss: 4.1260\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6734,\tval_loss: 4.1417\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6677,\tval_loss: 4.1016\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.6558,\tval_loss: 4.1385\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.5950,\tval_loss: 4.0543\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.5658,\tval_loss: 4.1157\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6193,\tval_loss: 4.1486\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6359,\tval_loss: 4.1589\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6233,\tval_loss: 4.1328\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6437,\tval_loss: 4.1216\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5540,\tval_loss: 4.1445\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 3.5544,\tval_loss: 4.1539\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 3.6312,\tval_loss: 4.1206\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.5833,\tval_loss: 4.1183\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.5421,\tval_loss: 4.1411\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.5488,\tval_loss: 4.1628\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.5962,\tval_loss: 4.1738\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.6498,\tval_loss: 4.1277\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.5924,\tval_loss: 4.0985\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.6251,\tval_loss: 4.0921\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.5838,\tval_loss: 4.0874\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.5466,\tval_loss: 4.1552\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.5681,\tval_loss: 4.1498\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.5545,\tval_loss: 4.1025\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.6045,\tval_loss: 4.1661\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.6423,\tval_loss: 4.0795\n",
            "74:\t[0s / 5s],\t\ttrain_loss: 3.6396,\tval_loss: 4.0707\n",
            "75:\t[0s / 5s],\t\ttrain_loss: 3.5956,\tval_loss: 4.0896\n",
            "76:\t[0s / 5s],\t\ttrain_loss: 3.5737,\tval_loss: 4.1585\n",
            "77:\t[0s / 5s],\t\ttrain_loss: 3.5367,\tval_loss: 4.1099\n",
            "78:\t[0s / 5s],\t\ttrain_loss: 3.5426,\tval_loss: 4.1689\n",
            "79:\t[0s / 5s],\t\ttrain_loss: 3.5033,\tval_loss: 4.1500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4445,\tval_loss: 4.0952\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3252,\tval_loss: 4.0727\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2954,\tval_loss: 4.0676\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2598,\tval_loss: 4.0820\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2538,\tval_loss: 4.0511\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2527,\tval_loss: 4.0667\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2280,\tval_loss: 4.0851\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2116,\tval_loss: 4.0580\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1957,\tval_loss: 4.1050\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1512,\tval_loss: 4.0926\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1497,\tval_loss: 4.0750\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1058,\tval_loss: 4.1070\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0820,\tval_loss: 4.0798\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0841,\tval_loss: 4.1380\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0520,\tval_loss: 4.0878\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9672,\tval_loss: 4.1212\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9887,\tval_loss: 4.1250\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9627,\tval_loss: 4.1509\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9305,\tval_loss: 4.1580\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9379,\tval_loss: 4.2270\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8799,\tval_loss: 4.2202\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9326,\tval_loss: 4.2245\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8603,\tval_loss: 4.1901\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9687,\tval_loss: 4.1643\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8846,\tval_loss: 4.2298\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8296,\tval_loss: 4.2357\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8726,\tval_loss: 4.2502\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8385,\tval_loss: 4.2271\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7808,\tval_loss: 4.3496\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7877,\tval_loss: 4.2518\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8273,\tval_loss: 4.2444\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7395,\tval_loss: 4.3943\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7385,\tval_loss: 4.2782\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7114,\tval_loss: 4.3191\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7150,\tval_loss: 4.3588\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7613,\tval_loss: 4.3857\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7338,\tval_loss: 4.3704\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6887,\tval_loss: 4.3382\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6625,\tval_loss: 4.4220\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7114,\tval_loss: 4.2847\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6999,\tval_loss: 4.4388\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6331,\tval_loss: 4.4023\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.6499,\tval_loss: 4.4454\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6129,\tval_loss: 4.5737\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6735,\tval_loss: 4.4335\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6346,\tval_loss: 4.4568\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6281,\tval_loss: 4.4729\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6557,\tval_loss: 4.4547\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6357,\tval_loss: 4.4729\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6196,\tval_loss: 4.4385\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6309,\tval_loss: 4.4449\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5710,\tval_loss: 4.5047\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5797,\tval_loss: 4.4643\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5482,\tval_loss: 4.4473\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6475,\tval_loss: 4.4384\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5852,\tval_loss: 4.4391\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5968,\tval_loss: 4.5087\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6231,\tval_loss: 4.4204\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6371,\tval_loss: 4.5015\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6057,\tval_loss: 4.5209\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5591,\tval_loss: 4.5086\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5706,\tval_loss: 4.5064\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5378,\tval_loss: 4.5103\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5523,\tval_loss: 4.4692\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.4533,\tval_loss: 4.5597\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5434,\tval_loss: 4.5616\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5381,\tval_loss: 4.5949\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5500,\tval_loss: 4.5504\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.4784,\tval_loss: 4.4247\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5194,\tval_loss: 4.5751\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.4972,\tval_loss: 4.5860\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.5703,\tval_loss: 4.4783\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4668,\tval_loss: 4.0974\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3334,\tval_loss: 4.0687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3044,\tval_loss: 4.0534\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2620,\tval_loss: 4.0381\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2336,\tval_loss: 4.0302\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2069,\tval_loss: 4.0367\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1725,\tval_loss: 4.0302\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1738,\tval_loss: 4.0445\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1560,\tval_loss: 4.0436\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1641,\tval_loss: 4.0508\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1372,\tval_loss: 4.0857\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1007,\tval_loss: 4.1050\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1250,\tval_loss: 4.1020\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0772,\tval_loss: 4.1599\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0819,\tval_loss: 4.1828\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.1089,\tval_loss: 4.1335\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0182,\tval_loss: 4.1669\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0388,\tval_loss: 4.1539\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0034,\tval_loss: 4.1924\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9764,\tval_loss: 4.1970\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 4.0042,\tval_loss: 4.2573\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9765,\tval_loss: 4.2479\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8983,\tval_loss: 4.2942\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8876,\tval_loss: 4.2759\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9823,\tval_loss: 4.2274\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9534,\tval_loss: 4.2685\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8557,\tval_loss: 4.2418\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8290,\tval_loss: 4.3897\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8689,\tval_loss: 4.2714\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8140,\tval_loss: 4.3128\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8338,\tval_loss: 4.3297\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7912,\tval_loss: 4.3410\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7309,\tval_loss: 4.3981\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7734,\tval_loss: 4.4253\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7926,\tval_loss: 4.3840\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6785,\tval_loss: 4.4167\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7174,\tval_loss: 4.4033\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7168,\tval_loss: 4.4742\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6474,\tval_loss: 4.4442\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6932,\tval_loss: 4.4176\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7059,\tval_loss: 4.4408\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6835,\tval_loss: 4.4399\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.6687,\tval_loss: 4.5091\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6605,\tval_loss: 4.4827\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6650,\tval_loss: 4.4832\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6842,\tval_loss: 4.4851\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6096,\tval_loss: 4.5115\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5786,\tval_loss: 4.4896\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6273,\tval_loss: 4.6070\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6042,\tval_loss: 4.5151\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5963,\tval_loss: 4.4921\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6624,\tval_loss: 4.4595\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6463,\tval_loss: 4.5849\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5434,\tval_loss: 4.5436\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5944,\tval_loss: 4.6230\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5819,\tval_loss: 4.4794\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5635,\tval_loss: 4.4892\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5277,\tval_loss: 4.5052\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6728,\tval_loss: 4.3974\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5888,\tval_loss: 4.4714\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6324,\tval_loss: 4.4517\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5889,\tval_loss: 4.4671\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5667,\tval_loss: 4.4772\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5753,\tval_loss: 4.5755\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.4910,\tval_loss: 4.6457\n",
            "65:\t[0s / 2s],\t\ttrain_loss: 3.4948,\tval_loss: 4.6614\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4818,\tval_loss: 4.6344\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5549,\tval_loss: 4.5302\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5997,\tval_loss: 4.4903\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.4938,\tval_loss: 4.5250\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5638,\tval_loss: 4.5290\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.5656,\tval_loss: 4.4977\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.4959,\tval_loss: 4.5545\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.5693,\tval_loss: 4.5485\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4637,\tval_loss: 4.0681\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3023,\tval_loss: 4.0804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2304,\tval_loss: 4.0766\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1980,\tval_loss: 4.0881\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2022,\tval_loss: 4.0852\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2020,\tval_loss: 4.0465\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1695,\tval_loss: 4.1573\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1729,\tval_loss: 4.1235\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1471,\tval_loss: 4.1250\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1649,\tval_loss: 4.1295\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1291,\tval_loss: 4.1461\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1811,\tval_loss: 4.1064\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1062,\tval_loss: 4.1201\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0776,\tval_loss: 4.1554\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0796,\tval_loss: 4.1379\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0707,\tval_loss: 4.1521\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0782,\tval_loss: 4.1186\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0337,\tval_loss: 4.2052\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0716,\tval_loss: 4.1802\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 4.0018,\tval_loss: 4.1182\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 4.0128,\tval_loss: 4.1990\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9624,\tval_loss: 4.2215\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9839,\tval_loss: 4.1355\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9409,\tval_loss: 4.2462\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9306,\tval_loss: 4.1677\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8912,\tval_loss: 4.1664\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8584,\tval_loss: 4.1977\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8879,\tval_loss: 4.1669\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8873,\tval_loss: 4.1891\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8530,\tval_loss: 4.2052\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8686,\tval_loss: 4.1901\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8646,\tval_loss: 4.1601\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8357,\tval_loss: 4.2138\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8327,\tval_loss: 4.2104\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7657,\tval_loss: 4.2557\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8750,\tval_loss: 4.1241\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.8202,\tval_loss: 4.3796\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7882,\tval_loss: 4.2065\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7397,\tval_loss: 4.2808\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7538,\tval_loss: 4.1617\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.8147,\tval_loss: 4.2171\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7462,\tval_loss: 4.2625\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7764,\tval_loss: 4.2198\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6625,\tval_loss: 4.2628\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7382,\tval_loss: 4.2634\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7040,\tval_loss: 4.2843\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6993,\tval_loss: 4.2998\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6743,\tval_loss: 4.2407\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7062,\tval_loss: 4.2665\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6620,\tval_loss: 4.3562\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6477,\tval_loss: 4.2506\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6175,\tval_loss: 4.3401\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6693,\tval_loss: 4.1887\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6582,\tval_loss: 4.2558\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6192,\tval_loss: 4.3785\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6219,\tval_loss: 4.3234\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5914,\tval_loss: 4.2775\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6762,\tval_loss: 4.2679\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5969,\tval_loss: 4.3351\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6289,\tval_loss: 4.3750\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5964,\tval_loss: 4.3363\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6012,\tval_loss: 4.2860\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6164,\tval_loss: 4.2656\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.6840,\tval_loss: 4.3553\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.6880,\tval_loss: 4.1804\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6992,\tval_loss: 4.3172\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6743,\tval_loss: 4.2311\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6268,\tval_loss: 4.2977\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5919,\tval_loss: 4.3414\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6502,\tval_loss: 4.3155\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6172,\tval_loss: 4.2538\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.6120,\tval_loss: 4.2248\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.6352,\tval_loss: 4.2416\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4956,\tval_loss: 4.0963\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2634,\tval_loss: 4.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2484,\tval_loss: 4.0910\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2143,\tval_loss: 4.0800\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1769,\tval_loss: 4.0925\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2021,\tval_loss: 4.0745\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1716,\tval_loss: 4.1433\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1144,\tval_loss: 4.0838\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1380,\tval_loss: 4.1298\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1151,\tval_loss: 4.1262\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1074,\tval_loss: 4.1948\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0817,\tval_loss: 4.1611\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0602,\tval_loss: 4.1619\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9951,\tval_loss: 4.1961\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0067,\tval_loss: 4.1629\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9017,\tval_loss: 4.2121\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9752,\tval_loss: 4.1911\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9494,\tval_loss: 4.2169\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9481,\tval_loss: 4.1875\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8678,\tval_loss: 4.2759\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8455,\tval_loss: 4.3231\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8968,\tval_loss: 4.2524\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7907,\tval_loss: 4.3288\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7351,\tval_loss: 4.3622\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7796,\tval_loss: 4.3306\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7472,\tval_loss: 4.3432\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7380,\tval_loss: 4.3140\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8063,\tval_loss: 4.3459\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6703,\tval_loss: 4.3420\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.7399,\tval_loss: 4.4013\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.6645,\tval_loss: 4.4126\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7846,\tval_loss: 4.3786\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7148,\tval_loss: 4.4012\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.6857,\tval_loss: 4.3104\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7058,\tval_loss: 4.3482\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.6007,\tval_loss: 4.3901\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.6770,\tval_loss: 4.3259\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6725,\tval_loss: 4.4510\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6034,\tval_loss: 4.3584\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6733,\tval_loss: 4.3712\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6181,\tval_loss: 4.3533\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6711,\tval_loss: 4.3916\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5441,\tval_loss: 4.3522\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5761,\tval_loss: 4.3585\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.6046,\tval_loss: 4.3695\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.5658,\tval_loss: 4.3434\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.5701,\tval_loss: 4.3588\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.5269,\tval_loss: 4.3403\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.5567,\tval_loss: 4.4013\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6148,\tval_loss: 4.3887\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.5032,\tval_loss: 4.4128\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.5608,\tval_loss: 4.3644\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6282,\tval_loss: 4.3226\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.5491,\tval_loss: 4.3487\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.5783,\tval_loss: 4.4061\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.5593,\tval_loss: 4.3899\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5896,\tval_loss: 4.3527\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5956,\tval_loss: 4.4085\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5052,\tval_loss: 4.3629\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 3.5227,\tval_loss: 4.4017\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 3.6155,\tval_loss: 4.3690\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.5813,\tval_loss: 4.3362\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.5573,\tval_loss: 4.3977\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.5103,\tval_loss: 4.3869\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.5051,\tval_loss: 4.4902\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.4712,\tval_loss: 4.3868\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.4762,\tval_loss: 4.4655\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.5061,\tval_loss: 4.4855\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.5552,\tval_loss: 4.4157\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.5239,\tval_loss: 4.3683\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.5092,\tval_loss: 4.4190\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.4544,\tval_loss: 4.4011\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.4511,\tval_loss: 4.3928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4417,\tval_loss: 4.0183\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3656,\tval_loss: 4.0063\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3021,\tval_loss: 4.0406\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2952,\tval_loss: 4.0337\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2681,\tval_loss: 4.0197\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2481,\tval_loss: 4.0443\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2089,\tval_loss: 4.0378\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1983,\tval_loss: 4.0439\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1860,\tval_loss: 4.0488\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1406,\tval_loss: 4.0597\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1047,\tval_loss: 4.1034\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1393,\tval_loss: 4.0697\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0351,\tval_loss: 4.0839\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0275,\tval_loss: 4.0989\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0367,\tval_loss: 4.1330\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9834,\tval_loss: 4.0940\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0074,\tval_loss: 4.1007\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9834,\tval_loss: 4.1278\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9670,\tval_loss: 4.1029\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9126,\tval_loss: 4.1331\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9004,\tval_loss: 4.1091\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8645,\tval_loss: 4.1220\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8668,\tval_loss: 4.1811\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7972,\tval_loss: 4.1196\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9182,\tval_loss: 4.1616\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8540,\tval_loss: 4.1848\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7903,\tval_loss: 4.1129\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8633,\tval_loss: 4.1568\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8584,\tval_loss: 4.1218\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8488,\tval_loss: 4.1343\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8645,\tval_loss: 4.1307\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8010,\tval_loss: 4.1304\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7896,\tval_loss: 4.1366\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7816,\tval_loss: 4.1378\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7607,\tval_loss: 4.1281\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7651,\tval_loss: 4.1762\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7139,\tval_loss: 4.1373\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6774,\tval_loss: 4.2181\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7329,\tval_loss: 4.1117\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7245,\tval_loss: 4.2250\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7156,\tval_loss: 4.1394\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7576,\tval_loss: 4.1348\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7010,\tval_loss: 4.1832\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6350,\tval_loss: 4.2277\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6582,\tval_loss: 4.2929\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7405,\tval_loss: 4.1744\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6530,\tval_loss: 4.2084\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6007,\tval_loss: 4.2278\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6330,\tval_loss: 4.1694\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6913,\tval_loss: 4.1954\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6376,\tval_loss: 4.1999\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6923,\tval_loss: 4.2266\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6708,\tval_loss: 4.1582\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6340,\tval_loss: 4.1843\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5578,\tval_loss: 4.2287\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6210,\tval_loss: 4.1649\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6105,\tval_loss: 4.1584\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6296,\tval_loss: 4.2025\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6716,\tval_loss: 4.1075\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6641,\tval_loss: 4.2241\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5881,\tval_loss: 4.1572\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6907,\tval_loss: 4.1626\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6635,\tval_loss: 4.1918\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6335,\tval_loss: 4.1483\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5452,\tval_loss: 4.2328\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6566,\tval_loss: 4.1699\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5485,\tval_loss: 4.2367\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6068,\tval_loss: 4.1501\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5716,\tval_loss: 4.2631\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4294,\tval_loss: 4.0928\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2792,\tval_loss: 4.0827\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2583,\tval_loss: 4.0981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2438,\tval_loss: 4.1061\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2249,\tval_loss: 4.1205\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1818,\tval_loss: 4.1245\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1991,\tval_loss: 4.1379\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1932,\tval_loss: 4.1607\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1574,\tval_loss: 4.1567\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1370,\tval_loss: 4.1741\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1091,\tval_loss: 4.1794\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0512,\tval_loss: 4.1988\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0428,\tval_loss: 4.1989\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0380,\tval_loss: 4.2670\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0081,\tval_loss: 4.2687\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9667,\tval_loss: 4.3039\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9633,\tval_loss: 4.3738\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9585,\tval_loss: 4.2555\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9025,\tval_loss: 4.3956\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8897,\tval_loss: 4.2921\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.7971,\tval_loss: 4.3159\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9133,\tval_loss: 4.3061\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8842,\tval_loss: 4.3449\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7484,\tval_loss: 4.5103\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8343,\tval_loss: 4.4795\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8323,\tval_loss: 4.3057\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8380,\tval_loss: 4.4027\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8243,\tval_loss: 4.3987\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7744,\tval_loss: 4.3967\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7731,\tval_loss: 4.4192\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7651,\tval_loss: 4.3965\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7107,\tval_loss: 4.4891\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7480,\tval_loss: 4.3998\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6916,\tval_loss: 4.5400\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7716,\tval_loss: 4.3490\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7376,\tval_loss: 4.3258\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6916,\tval_loss: 4.3875\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6734,\tval_loss: 4.4894\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6647,\tval_loss: 4.3746\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7058,\tval_loss: 4.4829\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6681,\tval_loss: 4.3591\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6249,\tval_loss: 4.4657\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.6640,\tval_loss: 4.4390\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6182,\tval_loss: 4.5016\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5960,\tval_loss: 4.5071\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6474,\tval_loss: 4.4043\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6706,\tval_loss: 4.5580\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5762,\tval_loss: 4.4240\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5856,\tval_loss: 4.4845\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5769,\tval_loss: 4.5539\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6574,\tval_loss: 4.4819\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5864,\tval_loss: 4.5638\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5877,\tval_loss: 4.3925\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5254,\tval_loss: 4.5686\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6310,\tval_loss: 4.4427\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5828,\tval_loss: 4.5729\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5882,\tval_loss: 4.5034\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5302,\tval_loss: 4.5192\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5622,\tval_loss: 4.5811\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6488,\tval_loss: 4.4511\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6195,\tval_loss: 4.4020\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6003,\tval_loss: 4.5165\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5077,\tval_loss: 4.5450\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5260,\tval_loss: 4.4921\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5542,\tval_loss: 4.4228\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5854,\tval_loss: 4.5650\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6009,\tval_loss: 4.3870\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5621,\tval_loss: 4.4996\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.4543,\tval_loss: 4.5005\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4551,\tval_loss: 4.0883\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2882,\tval_loss: 4.0632\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2420,\tval_loss: 4.0335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2466,\tval_loss: 4.0524\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2370,\tval_loss: 4.0409\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1920,\tval_loss: 4.0487\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1831,\tval_loss: 4.0469\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1801,\tval_loss: 4.0706\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1335,\tval_loss: 4.0418\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1481,\tval_loss: 4.0579\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0932,\tval_loss: 4.1114\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0791,\tval_loss: 4.1363\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0758,\tval_loss: 4.1364\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0344,\tval_loss: 4.1823\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0171,\tval_loss: 4.1583\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0328,\tval_loss: 4.1397\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9664,\tval_loss: 4.2127\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9282,\tval_loss: 4.2315\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8953,\tval_loss: 4.2894\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9388,\tval_loss: 4.2561\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.8398,\tval_loss: 4.3316\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8883,\tval_loss: 4.2593\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8706,\tval_loss: 4.2119\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8587,\tval_loss: 4.2744\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8391,\tval_loss: 4.3000\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8333,\tval_loss: 4.2955\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7720,\tval_loss: 4.3142\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8115,\tval_loss: 4.3873\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7045,\tval_loss: 4.2959\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8654,\tval_loss: 4.3074\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7973,\tval_loss: 4.3690\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7669,\tval_loss: 4.3048\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7277,\tval_loss: 4.4042\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7952,\tval_loss: 4.3131\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7761,\tval_loss: 4.3348\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7623,\tval_loss: 4.3515\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7165,\tval_loss: 4.3871\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6885,\tval_loss: 4.3399\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7312,\tval_loss: 4.3225\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7103,\tval_loss: 4.3222\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6963,\tval_loss: 4.3451\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7322,\tval_loss: 4.3440\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.6415,\tval_loss: 4.4170\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5993,\tval_loss: 4.4121\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6283,\tval_loss: 4.4609\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7038,\tval_loss: 4.3354\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6959,\tval_loss: 4.3948\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6033,\tval_loss: 4.3583\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6628,\tval_loss: 4.3717\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6854,\tval_loss: 4.3509\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6413,\tval_loss: 4.4080\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6719,\tval_loss: 4.3903\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6492,\tval_loss: 4.3630\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6774,\tval_loss: 4.3650\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6229,\tval_loss: 4.3491\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6052,\tval_loss: 4.3680\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5530,\tval_loss: 4.4526\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6105,\tval_loss: 4.4386\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6741,\tval_loss: 4.3842\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5914,\tval_loss: 4.4310\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6973,\tval_loss: 4.3725\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5941,\tval_loss: 4.3432\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5896,\tval_loss: 4.4642\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5763,\tval_loss: 4.4442\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.6899,\tval_loss: 4.3198\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6619,\tval_loss: 4.3458\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6487,\tval_loss: 4.3187\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5197,\tval_loss: 4.4105\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5769,\tval_loss: 4.3785\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5489,\tval_loss: 4.2735\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4170,\tval_loss: 4.0765\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3125,\tval_loss: 4.0783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2872,\tval_loss: 4.0805\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2946,\tval_loss: 4.0784\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2534,\tval_loss: 4.0783\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2619,\tval_loss: 4.0553\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2304,\tval_loss: 4.0720\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2224,\tval_loss: 4.0670\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.2124,\tval_loss: 4.0559\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.2007,\tval_loss: 4.0691\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.2040,\tval_loss: 4.0560\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1753,\tval_loss: 4.0760\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1549,\tval_loss: 4.0791\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1067,\tval_loss: 4.0830\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.1206,\tval_loss: 4.1157\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.1514,\tval_loss: 4.0882\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.1245,\tval_loss: 4.0874\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 4.0819,\tval_loss: 4.1528\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 4.0971,\tval_loss: 4.1103\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 4.0992,\tval_loss: 4.1591\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 4.1154,\tval_loss: 4.1006\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9943,\tval_loss: 4.1783\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 4.0480,\tval_loss: 4.1253\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 4.0180,\tval_loss: 4.2037\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9804,\tval_loss: 4.1462\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 4.0239,\tval_loss: 4.2030\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 4.0170,\tval_loss: 4.1704\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9768,\tval_loss: 4.2078\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.9958,\tval_loss: 4.1142\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 4.0037,\tval_loss: 4.1285\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.9577,\tval_loss: 4.1959\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8983,\tval_loss: 4.1896\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.8889,\tval_loss: 4.2104\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.9563,\tval_loss: 4.1003\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.9226,\tval_loss: 4.1784\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.9233,\tval_loss: 4.1449\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.8651,\tval_loss: 4.1610\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.8487,\tval_loss: 4.1637\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.8450,\tval_loss: 4.2048\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.8281,\tval_loss: 4.1575\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.8753,\tval_loss: 4.1427\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.8228,\tval_loss: 4.2145\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.8375,\tval_loss: 4.1599\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7854,\tval_loss: 4.2267\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7875,\tval_loss: 4.2307\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7962,\tval_loss: 4.1714\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.8071,\tval_loss: 4.1953\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.7482,\tval_loss: 4.1882\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.7978,\tval_loss: 4.1542\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.7518,\tval_loss: 4.2050\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.7246,\tval_loss: 4.1831\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.7586,\tval_loss: 4.1358\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.7212,\tval_loss: 4.2009\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.7715,\tval_loss: 4.0950\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.7820,\tval_loss: 4.1866\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.7560,\tval_loss: 4.1780\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.7491,\tval_loss: 4.1892\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.7644,\tval_loss: 4.1667\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.7216,\tval_loss: 4.1983\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.7606,\tval_loss: 4.2008\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.7642,\tval_loss: 4.1230\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.7331,\tval_loss: 4.2013\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.7517,\tval_loss: 4.2209\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.7079,\tval_loss: 4.1640\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.7235,\tval_loss: 4.1643\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.6915,\tval_loss: 4.1245\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.7329,\tval_loss: 4.1482\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.7057,\tval_loss: 4.1386\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.6777,\tval_loss: 4.2066\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.7588,\tval_loss: 4.1229\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.7256,\tval_loss: 4.1399\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.7035,\tval_loss: 4.1555\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.7007,\tval_loss: 4.1218\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4177,\tval_loss: 4.0337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2427,\tval_loss: 4.0603\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2477,\tval_loss: 4.0646\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2397,\tval_loss: 4.0704\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2306,\tval_loss: 4.0721\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1697,\tval_loss: 4.0820\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1332,\tval_loss: 4.1125\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0643,\tval_loss: 4.1705\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0892,\tval_loss: 4.1221\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0878,\tval_loss: 4.1804\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0205,\tval_loss: 4.1684\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9929,\tval_loss: 4.1912\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0157,\tval_loss: 4.2448\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 3.9793,\tval_loss: 4.1847\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.9366,\tval_loss: 4.2933\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.8842,\tval_loss: 4.1775\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.8712,\tval_loss: 4.2356\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8414,\tval_loss: 4.2750\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.8561,\tval_loss: 4.2567\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8900,\tval_loss: 4.2916\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8038,\tval_loss: 4.2720\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7637,\tval_loss: 4.2590\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8176,\tval_loss: 4.3009\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7463,\tval_loss: 4.3410\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7632,\tval_loss: 4.3538\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8155,\tval_loss: 4.2641\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7484,\tval_loss: 4.3090\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6970,\tval_loss: 4.3775\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8103,\tval_loss: 4.2749\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7160,\tval_loss: 4.2889\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6928,\tval_loss: 4.3541\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6914,\tval_loss: 4.3852\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7228,\tval_loss: 4.3740\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6712,\tval_loss: 4.3344\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.6738,\tval_loss: 4.3609\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.6111,\tval_loss: 4.3604\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.6207,\tval_loss: 4.4159\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6235,\tval_loss: 4.3355\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6253,\tval_loss: 4.3067\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6277,\tval_loss: 4.3364\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7051,\tval_loss: 4.4347\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6305,\tval_loss: 4.3348\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6188,\tval_loss: 4.3379\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5717,\tval_loss: 4.3357\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6509,\tval_loss: 4.3295\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6768,\tval_loss: 4.3430\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5213,\tval_loss: 4.3589\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5894,\tval_loss: 4.3832\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5777,\tval_loss: 4.3652\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5563,\tval_loss: 4.3859\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6167,\tval_loss: 4.3993\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5880,\tval_loss: 4.4159\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6420,\tval_loss: 4.3823\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6041,\tval_loss: 4.3669\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5622,\tval_loss: 4.4333\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.5802,\tval_loss: 4.4073\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5397,\tval_loss: 4.3324\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5699,\tval_loss: 4.3602\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6053,\tval_loss: 4.3709\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6208,\tval_loss: 4.4345\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5314,\tval_loss: 4.4084\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6022,\tval_loss: 4.4291\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5673,\tval_loss: 4.3391\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5341,\tval_loss: 4.3625\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.4607,\tval_loss: 4.4289\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5225,\tval_loss: 4.5555\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5664,\tval_loss: 4.3961\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4675,\tval_loss: 4.3655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4836,\tval_loss: 4.1151\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2864,\tval_loss: 4.0699\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2581,\tval_loss: 4.0705\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2618,\tval_loss: 4.0698\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2253,\tval_loss: 4.0734\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2349,\tval_loss: 4.0870\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2252,\tval_loss: 4.0640\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1942,\tval_loss: 4.0552\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1603,\tval_loss: 4.0913\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1549,\tval_loss: 4.0610\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1293,\tval_loss: 4.1199\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1270,\tval_loss: 4.1263\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1144,\tval_loss: 4.0785\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0929,\tval_loss: 4.1141\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0506,\tval_loss: 4.1283\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0648,\tval_loss: 4.1442\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0822,\tval_loss: 4.1602\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0663,\tval_loss: 4.1547\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0112,\tval_loss: 4.2068\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9506,\tval_loss: 4.2483\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9313,\tval_loss: 4.2122\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9278,\tval_loss: 4.2511\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9416,\tval_loss: 4.2869\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8641,\tval_loss: 4.3371\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8704,\tval_loss: 4.3107\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8471,\tval_loss: 4.2649\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9010,\tval_loss: 4.2543\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8096,\tval_loss: 4.3297\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7857,\tval_loss: 4.3279\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8378,\tval_loss: 4.3154\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.9165,\tval_loss: 4.2547\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.9116,\tval_loss: 4.3323\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7645,\tval_loss: 4.3329\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7807,\tval_loss: 4.4059\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8056,\tval_loss: 4.3721\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7840,\tval_loss: 4.3357\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7963,\tval_loss: 4.3278\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7606,\tval_loss: 4.3007\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7688,\tval_loss: 4.3614\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.8101,\tval_loss: 4.3644\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7590,\tval_loss: 4.3292\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7521,\tval_loss: 4.3876\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.7730,\tval_loss: 4.3606\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7737,\tval_loss: 4.4248\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7643,\tval_loss: 4.2838\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.8097,\tval_loss: 4.3549\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7384,\tval_loss: 4.3514\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6863,\tval_loss: 4.3992\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6849,\tval_loss: 4.3301\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7485,\tval_loss: 4.4441\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7196,\tval_loss: 4.3572\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7586,\tval_loss: 4.2505\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6137,\tval_loss: 4.3461\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6724,\tval_loss: 4.4348\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6386,\tval_loss: 4.3740\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6465,\tval_loss: 4.3178\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6666,\tval_loss: 4.4094\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6978,\tval_loss: 4.3019\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6808,\tval_loss: 4.4174\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5791,\tval_loss: 4.3479\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6971,\tval_loss: 4.3280\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6515,\tval_loss: 4.3827\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6155,\tval_loss: 4.3287\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.6101,\tval_loss: 4.3517\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.6049,\tval_loss: 4.3170\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5967,\tval_loss: 4.4177\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6830,\tval_loss: 4.3104\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.7264,\tval_loss: 4.3254\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6948,\tval_loss: 4.3328\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6610,\tval_loss: 4.3682\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6246,\tval_loss: 4.3348\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.6106,\tval_loss: 4.4819\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.6939,\tval_loss: 4.3627\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.5884,\tval_loss: 4.3152\n",
            "74:\t[0s / 3s],\t\ttrain_loss: 3.6217,\tval_loss: 4.3576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4178,\tval_loss: 4.0727\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2695,\tval_loss: 4.0777\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2838,\tval_loss: 4.0888\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2194,\tval_loss: 4.0731\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2012,\tval_loss: 4.0930\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1833,\tval_loss: 4.0892\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1441,\tval_loss: 4.0980\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0951,\tval_loss: 4.0974\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0224,\tval_loss: 4.1558\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0037,\tval_loss: 4.1502\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0452,\tval_loss: 4.1852\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9763,\tval_loss: 4.2137\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9816,\tval_loss: 4.2085\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9695,\tval_loss: 4.1921\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9260,\tval_loss: 4.2206\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.8686,\tval_loss: 4.2035\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9338,\tval_loss: 4.2711\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8646,\tval_loss: 4.2712\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8757,\tval_loss: 4.2728\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8718,\tval_loss: 4.2783\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8510,\tval_loss: 4.2857\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8474,\tval_loss: 4.2930\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8516,\tval_loss: 4.2626\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7782,\tval_loss: 4.2858\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.6959,\tval_loss: 4.3140\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8469,\tval_loss: 4.2491\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7272,\tval_loss: 4.2823\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7522,\tval_loss: 4.3581\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6988,\tval_loss: 4.3591\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7296,\tval_loss: 4.3924\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6613,\tval_loss: 4.3902\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6720,\tval_loss: 4.3870\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6975,\tval_loss: 4.3399\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6288,\tval_loss: 4.4312\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.5980,\tval_loss: 4.4314\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.5941,\tval_loss: 4.4542\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6428,\tval_loss: 4.3631\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.5727,\tval_loss: 4.3476\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6273,\tval_loss: 4.3883\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6641,\tval_loss: 4.3335\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.5626,\tval_loss: 4.3568\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5591,\tval_loss: 4.4069\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5007,\tval_loss: 4.5149\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5471,\tval_loss: 4.3953\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5950,\tval_loss: 4.5006\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5708,\tval_loss: 4.4591\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5424,\tval_loss: 4.4770\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6115,\tval_loss: 4.4311\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5525,\tval_loss: 4.4877\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5379,\tval_loss: 4.4734\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5031,\tval_loss: 4.4648\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5236,\tval_loss: 4.5516\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5133,\tval_loss: 4.4842\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5536,\tval_loss: 4.4469\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5113,\tval_loss: 4.4671\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.4636,\tval_loss: 4.5739\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.4747,\tval_loss: 4.5612\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5113,\tval_loss: 4.4739\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.4696,\tval_loss: 4.4986\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.4456,\tval_loss: 4.5153\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5207,\tval_loss: 4.5517\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5628,\tval_loss: 4.4641\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.4663,\tval_loss: 4.4364\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.4070,\tval_loss: 4.5054\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.4576,\tval_loss: 4.4865\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.4118,\tval_loss: 4.5214\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4792,\tval_loss: 4.5144\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4695,\tval_loss: 4.4715\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4586,\tval_loss: 4.0635\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3169,\tval_loss: 4.0617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2590,\tval_loss: 4.0705\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2530,\tval_loss: 4.0791\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1847,\tval_loss: 4.1195\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2220,\tval_loss: 4.0931\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1678,\tval_loss: 4.1014\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1397,\tval_loss: 4.1123\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1399,\tval_loss: 4.1172\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1691,\tval_loss: 4.1223\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1550,\tval_loss: 4.1258\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1146,\tval_loss: 4.1316\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1368,\tval_loss: 4.1337\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0749,\tval_loss: 4.1657\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0960,\tval_loss: 4.1675\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0463,\tval_loss: 4.1396\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0715,\tval_loss: 4.1362\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0217,\tval_loss: 4.1648\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0705,\tval_loss: 4.1447\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 4.0483,\tval_loss: 4.1616\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 4.0524,\tval_loss: 4.1687\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9823,\tval_loss: 4.1179\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 4.0113,\tval_loss: 4.1838\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 4.0422,\tval_loss: 4.1439\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9588,\tval_loss: 4.1210\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9143,\tval_loss: 4.2280\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9298,\tval_loss: 4.1971\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9569,\tval_loss: 4.2129\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.9356,\tval_loss: 4.1722\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.9469,\tval_loss: 4.1878\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.9480,\tval_loss: 4.1666\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8716,\tval_loss: 4.1801\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8726,\tval_loss: 4.2425\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8912,\tval_loss: 4.1973\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.8617,\tval_loss: 4.1766\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.8296,\tval_loss: 4.1693\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.8612,\tval_loss: 4.1312\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.9246,\tval_loss: 4.1419\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.8920,\tval_loss: 4.1340\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.8105,\tval_loss: 4.1478\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.8756,\tval_loss: 4.2016\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7917,\tval_loss: 4.1913\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.8347,\tval_loss: 4.1715\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.8607,\tval_loss: 4.1786\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.8535,\tval_loss: 4.1360\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.8194,\tval_loss: 4.1565\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7819,\tval_loss: 4.2021\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.8696,\tval_loss: 4.1366\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.8017,\tval_loss: 4.1488\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.8310,\tval_loss: 4.1487\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.7696,\tval_loss: 4.2102\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.8328,\tval_loss: 4.2254\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.7547,\tval_loss: 4.1871\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.8232,\tval_loss: 4.2601\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.7644,\tval_loss: 4.2183\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.8413,\tval_loss: 4.2217\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.8510,\tval_loss: 4.2661\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.7654,\tval_loss: 4.2145\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.7731,\tval_loss: 4.2575\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.7883,\tval_loss: 4.1901\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.8582,\tval_loss: 4.2193\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.7652,\tval_loss: 4.2476\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.8077,\tval_loss: 4.2103\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.7571,\tval_loss: 4.2812\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.7899,\tval_loss: 4.1741\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.7660,\tval_loss: 4.2669\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.7820,\tval_loss: 4.2429\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.7810,\tval_loss: 4.2265\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.7437,\tval_loss: 4.2532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4763,\tval_loss: 4.0696\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2827,\tval_loss: 4.0551\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2857,\tval_loss: 4.0518\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2581,\tval_loss: 4.0436\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2440,\tval_loss: 4.0524\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1913,\tval_loss: 4.0437\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2035,\tval_loss: 4.0446\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1705,\tval_loss: 4.0396\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1207,\tval_loss: 4.0748\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1260,\tval_loss: 4.0897\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0911,\tval_loss: 4.0974\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0690,\tval_loss: 4.0872\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0583,\tval_loss: 4.1436\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0298,\tval_loss: 4.1223\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0466,\tval_loss: 4.1718\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0460,\tval_loss: 4.1404\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9723,\tval_loss: 4.2257\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 4.0091,\tval_loss: 4.1758\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9930,\tval_loss: 4.2385\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9966,\tval_loss: 4.2376\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9688,\tval_loss: 4.2082\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8668,\tval_loss: 4.2771\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9106,\tval_loss: 4.2601\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8762,\tval_loss: 4.2824\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8937,\tval_loss: 4.2653\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8312,\tval_loss: 4.3207\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8582,\tval_loss: 4.2648\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8134,\tval_loss: 4.3415\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8249,\tval_loss: 4.3390\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7505,\tval_loss: 4.3411\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.8074,\tval_loss: 4.3488\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.8978,\tval_loss: 4.3578\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.8146,\tval_loss: 4.3464\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.8528,\tval_loss: 4.3150\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.8074,\tval_loss: 4.3338\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7473,\tval_loss: 4.4245\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.8062,\tval_loss: 4.2347\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.8261,\tval_loss: 4.3492\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7334,\tval_loss: 4.3802\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.8186,\tval_loss: 4.3198\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7611,\tval_loss: 4.3107\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.8139,\tval_loss: 4.3282\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7274,\tval_loss: 4.3942\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6591,\tval_loss: 4.3852\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6633,\tval_loss: 4.3544\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7729,\tval_loss: 4.3781\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6680,\tval_loss: 4.3512\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6937,\tval_loss: 4.4495\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7047,\tval_loss: 4.4016\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7735,\tval_loss: 4.3505\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6976,\tval_loss: 4.4351\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6969,\tval_loss: 4.3425\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.7907,\tval_loss: 4.4027\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6555,\tval_loss: 4.3473\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6821,\tval_loss: 4.4720\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.7018,\tval_loss: 4.3860\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6787,\tval_loss: 4.3577\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5931,\tval_loss: 4.4394\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.7079,\tval_loss: 4.3813\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6378,\tval_loss: 4.4055\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6999,\tval_loss: 4.3373\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6077,\tval_loss: 4.4289\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.7068,\tval_loss: 4.3836\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6744,\tval_loss: 4.3738\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6363,\tval_loss: 4.3372\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6055,\tval_loss: 4.4604\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6431,\tval_loss: 4.3670\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6728,\tval_loss: 4.4378\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6220,\tval_loss: 4.4706\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6176,\tval_loss: 4.4061\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.7344,\tval_loss: 4.3810\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.6256,\tval_loss: 4.3959\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.6155,\tval_loss: 4.4744\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.7037,\tval_loss: 4.3907\n",
            "74:\t[0s / 4s],\t\ttrain_loss: 3.6423,\tval_loss: 4.4148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4541,\tval_loss: 4.0739\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3431,\tval_loss: 4.0445\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3004,\tval_loss: 4.0376\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2666,\tval_loss: 4.0551\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2668,\tval_loss: 4.0343\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2611,\tval_loss: 4.0554\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1990,\tval_loss: 4.0940\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2136,\tval_loss: 4.0751\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1680,\tval_loss: 4.0512\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1626,\tval_loss: 4.0491\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1839,\tval_loss: 4.0709\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1014,\tval_loss: 4.0597\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1626,\tval_loss: 4.0867\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1153,\tval_loss: 4.0977\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0769,\tval_loss: 4.1025\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0202,\tval_loss: 4.1655\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.1193,\tval_loss: 4.0933\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0378,\tval_loss: 4.1575\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0631,\tval_loss: 4.0847\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 4.0240,\tval_loss: 4.1087\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.9221,\tval_loss: 4.1813\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 4.0150,\tval_loss: 4.1266\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9838,\tval_loss: 4.1294\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9895,\tval_loss: 4.1603\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9173,\tval_loss: 4.1974\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8842,\tval_loss: 4.2935\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9489,\tval_loss: 4.2030\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9066,\tval_loss: 4.2991\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8425,\tval_loss: 4.2338\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8853,\tval_loss: 4.2604\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7716,\tval_loss: 4.3557\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8162,\tval_loss: 4.2695\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8235,\tval_loss: 4.2745\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8750,\tval_loss: 4.2383\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8813,\tval_loss: 4.2503\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8074,\tval_loss: 4.3249\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7700,\tval_loss: 4.3556\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7890,\tval_loss: 4.3401\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.8300,\tval_loss: 4.3015\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7519,\tval_loss: 4.2891\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7978,\tval_loss: 4.2871\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7504,\tval_loss: 4.2333\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 3.7770,\tval_loss: 4.3076\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7673,\tval_loss: 4.2493\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7565,\tval_loss: 4.3913\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.8882,\tval_loss: 4.2204\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7571,\tval_loss: 4.2971\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7408,\tval_loss: 4.2876\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7525,\tval_loss: 4.3059\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.8566,\tval_loss: 4.3600\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7583,\tval_loss: 4.2064\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.8172,\tval_loss: 4.1981\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6955,\tval_loss: 4.2553\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7180,\tval_loss: 4.2717\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7157,\tval_loss: 4.3025\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.7543,\tval_loss: 4.2434\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.7872,\tval_loss: 4.2863\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.7189,\tval_loss: 4.2655\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.7717,\tval_loss: 4.2858\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.7120,\tval_loss: 4.2692\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6941,\tval_loss: 4.2687\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5676,\tval_loss: 4.4526\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.7294,\tval_loss: 4.3591\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.7526,\tval_loss: 4.2913\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 3.7635,\tval_loss: 4.2904\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.7322,\tval_loss: 4.2882\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6867,\tval_loss: 4.3601\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.7414,\tval_loss: 4.3545\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.7115,\tval_loss: 4.3038\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6705,\tval_loss: 4.3498\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6093,\tval_loss: 4.4093\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.7131,\tval_loss: 4.3036\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3499,\tval_loss: 4.0965\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2792,\tval_loss: 4.0678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2202,\tval_loss: 4.0711\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2114,\tval_loss: 4.0601\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1875,\tval_loss: 4.0447\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1455,\tval_loss: 4.0524\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1208,\tval_loss: 4.0533\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1240,\tval_loss: 4.0666\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1141,\tval_loss: 4.0401\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1081,\tval_loss: 4.0646\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0807,\tval_loss: 4.0974\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0333,\tval_loss: 4.0975\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0191,\tval_loss: 4.1079\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9977,\tval_loss: 4.1422\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9885,\tval_loss: 4.1211\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9923,\tval_loss: 4.1550\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9369,\tval_loss: 4.1887\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9254,\tval_loss: 4.1811\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9427,\tval_loss: 4.2043\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9303,\tval_loss: 4.1691\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8402,\tval_loss: 4.2128\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9136,\tval_loss: 4.2248\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8573,\tval_loss: 4.2526\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8054,\tval_loss: 4.2325\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8350,\tval_loss: 4.3509\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8200,\tval_loss: 4.2737\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7826,\tval_loss: 4.2409\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7492,\tval_loss: 4.2735\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8190,\tval_loss: 4.2283\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7375,\tval_loss: 4.3398\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7194,\tval_loss: 4.2890\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7208,\tval_loss: 4.3120\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7418,\tval_loss: 4.3240\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7067,\tval_loss: 4.3181\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7655,\tval_loss: 4.2481\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6703,\tval_loss: 4.3975\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6810,\tval_loss: 4.3791\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6846,\tval_loss: 4.3387\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6718,\tval_loss: 4.3375\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6604,\tval_loss: 4.3608\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6699,\tval_loss: 4.3261\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6468,\tval_loss: 4.3323\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6846,\tval_loss: 4.3253\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6834,\tval_loss: 4.3375\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6510,\tval_loss: 4.3265\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6930,\tval_loss: 4.3639\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7041,\tval_loss: 4.2613\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6855,\tval_loss: 4.3049\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6446,\tval_loss: 4.2961\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5649,\tval_loss: 4.3909\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5986,\tval_loss: 4.4008\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5903,\tval_loss: 4.3823\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6039,\tval_loss: 4.3612\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5798,\tval_loss: 4.3705\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5920,\tval_loss: 4.3778\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5491,\tval_loss: 4.3976\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5831,\tval_loss: 4.3872\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5756,\tval_loss: 4.3889\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5350,\tval_loss: 4.4402\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5491,\tval_loss: 4.4193\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5674,\tval_loss: 4.3660\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6357,\tval_loss: 4.3749\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5480,\tval_loss: 4.3856\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5328,\tval_loss: 4.3964\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6391,\tval_loss: 4.3978\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5696,\tval_loss: 4.4333\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5834,\tval_loss: 4.4305\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5457,\tval_loss: 4.4068\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5480,\tval_loss: 4.4034\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5505,\tval_loss: 4.4162\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.4762,\tval_loss: 4.4025\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.5334,\tval_loss: 4.4151\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.4825,\tval_loss: 4.4696\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.5120,\tval_loss: 4.4434\n",
            "74:\t[0s / 3s],\t\ttrain_loss: 3.5152,\tval_loss: 4.4392\n",
            "75:\t[0s / 3s],\t\ttrain_loss: 3.5093,\tval_loss: 4.3888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4128,\tval_loss: 4.0367\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3334,\tval_loss: 4.0483\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2708,\tval_loss: 4.0209\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2576,\tval_loss: 4.0248\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2674,\tval_loss: 4.0201\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2312,\tval_loss: 4.0107\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1762,\tval_loss: 4.0240\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1649,\tval_loss: 4.0379\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1495,\tval_loss: 4.0653\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1504,\tval_loss: 4.0326\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1619,\tval_loss: 4.0559\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1155,\tval_loss: 4.0580\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1486,\tval_loss: 4.0688\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0941,\tval_loss: 4.1037\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0647,\tval_loss: 4.1125\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0396,\tval_loss: 4.0899\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9973,\tval_loss: 4.1170\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9391,\tval_loss: 4.1686\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9491,\tval_loss: 4.1425\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9542,\tval_loss: 4.2092\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9583,\tval_loss: 4.2019\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9103,\tval_loss: 4.1681\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8724,\tval_loss: 4.2216\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9130,\tval_loss: 4.1659\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8664,\tval_loss: 4.2452\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8987,\tval_loss: 4.1400\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9113,\tval_loss: 4.1781\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8166,\tval_loss: 4.2034\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8129,\tval_loss: 4.2274\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8355,\tval_loss: 4.2716\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8188,\tval_loss: 4.2265\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7517,\tval_loss: 4.3039\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8285,\tval_loss: 4.1778\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.7835,\tval_loss: 4.2551\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7191,\tval_loss: 4.2762\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7948,\tval_loss: 4.1974\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7181,\tval_loss: 4.2469\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6959,\tval_loss: 4.2194\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7214,\tval_loss: 4.2456\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7204,\tval_loss: 4.3431\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7882,\tval_loss: 4.2662\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7329,\tval_loss: 4.2220\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7302,\tval_loss: 4.2633\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7028,\tval_loss: 4.2384\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6286,\tval_loss: 4.2856\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7040,\tval_loss: 4.2256\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6744,\tval_loss: 4.3039\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.6807,\tval_loss: 4.3087\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.7080,\tval_loss: 4.3013\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6323,\tval_loss: 4.3461\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.7053,\tval_loss: 4.2854\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.6800,\tval_loss: 4.3247\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6676,\tval_loss: 4.2839\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6555,\tval_loss: 4.2636\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6353,\tval_loss: 4.3101\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6222,\tval_loss: 4.3084\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5927,\tval_loss: 4.2855\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5720,\tval_loss: 4.2884\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5694,\tval_loss: 4.2954\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6255,\tval_loss: 4.3535\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6226,\tval_loss: 4.3171\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6137,\tval_loss: 4.2919\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6442,\tval_loss: 4.3237\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.6233,\tval_loss: 4.2912\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.5994,\tval_loss: 4.3004\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.5347,\tval_loss: 4.4045\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.6249,\tval_loss: 4.3744\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.5747,\tval_loss: 4.2790\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.5690,\tval_loss: 4.2809\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.6013,\tval_loss: 4.2985\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.6110,\tval_loss: 4.3088\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.6164,\tval_loss: 4.3519\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.5828,\tval_loss: 4.3054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3651,\tval_loss: 4.0982\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2543,\tval_loss: 4.0852\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1570,\tval_loss: 4.0703\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1363,\tval_loss: 4.0763\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1549,\tval_loss: 4.0841\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1114,\tval_loss: 4.0829\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1118,\tval_loss: 4.0956\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0667,\tval_loss: 4.1219\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0600,\tval_loss: 4.1210\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0249,\tval_loss: 4.1286\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0102,\tval_loss: 4.1455\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0266,\tval_loss: 4.1484\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9708,\tval_loss: 4.2026\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 3.9466,\tval_loss: 4.1932\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.9526,\tval_loss: 4.1886\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.8923,\tval_loss: 4.2193\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.8808,\tval_loss: 4.2430\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8018,\tval_loss: 4.2317\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.7507,\tval_loss: 4.2676\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.7327,\tval_loss: 4.2387\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.7173,\tval_loss: 4.2890\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7614,\tval_loss: 4.3334\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7585,\tval_loss: 4.2792\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.6539,\tval_loss: 4.3550\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.6502,\tval_loss: 4.3367\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6834,\tval_loss: 4.3169\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.5588,\tval_loss: 4.3252\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6822,\tval_loss: 4.3191\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.5736,\tval_loss: 4.3671\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.6935,\tval_loss: 4.3264\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6190,\tval_loss: 4.3708\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6671,\tval_loss: 4.3466\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.5928,\tval_loss: 4.4263\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.6005,\tval_loss: 4.3621\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.6160,\tval_loss: 4.4141\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.6320,\tval_loss: 4.3634\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.5549,\tval_loss: 4.4022\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.5610,\tval_loss: 4.4635\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6093,\tval_loss: 4.3695\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.5307,\tval_loss: 4.3663\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5455,\tval_loss: 4.3785\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5671,\tval_loss: 4.4123\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.4626,\tval_loss: 4.3364\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5441,\tval_loss: 4.4079\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5036,\tval_loss: 4.3918\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6262,\tval_loss: 4.3530\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6285,\tval_loss: 4.2669\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5265,\tval_loss: 4.3551\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5478,\tval_loss: 4.3434\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5698,\tval_loss: 4.3221\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5281,\tval_loss: 4.3385\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5033,\tval_loss: 4.3808\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.4788,\tval_loss: 4.3081\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.4821,\tval_loss: 4.4584\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.4916,\tval_loss: 4.3215\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5419,\tval_loss: 4.3206\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.4873,\tval_loss: 4.3838\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.4284,\tval_loss: 4.3684\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.4849,\tval_loss: 4.3726\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.4791,\tval_loss: 4.4451\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.4042,\tval_loss: 4.4588\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.4705,\tval_loss: 4.3995\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5159,\tval_loss: 4.3271\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.4679,\tval_loss: 4.3503\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.4509,\tval_loss: 4.4152\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5074,\tval_loss: 4.3924\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4776,\tval_loss: 4.4328\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4533,\tval_loss: 4.2971\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.3722,\tval_loss: 4.3876\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.4639,\tval_loss: 4.3726\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4206,\tval_loss: 4.0564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2949,\tval_loss: 4.0401\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2488,\tval_loss: 4.0508\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2795,\tval_loss: 4.0508\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2171,\tval_loss: 4.0745\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2061,\tval_loss: 4.0818\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1974,\tval_loss: 4.0810\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1966,\tval_loss: 4.0952\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1789,\tval_loss: 4.0913\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1675,\tval_loss: 4.0891\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1383,\tval_loss: 4.1310\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1535,\tval_loss: 4.0885\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0900,\tval_loss: 4.0742\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0616,\tval_loss: 4.1339\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0314,\tval_loss: 4.1008\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0540,\tval_loss: 4.1469\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0394,\tval_loss: 4.1486\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0198,\tval_loss: 4.1913\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9960,\tval_loss: 4.2528\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9832,\tval_loss: 4.2733\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9397,\tval_loss: 4.2109\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8640,\tval_loss: 4.3277\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9224,\tval_loss: 4.2441\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8960,\tval_loss: 4.3116\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8989,\tval_loss: 4.2562\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9316,\tval_loss: 4.2967\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8850,\tval_loss: 4.2620\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8714,\tval_loss: 4.3993\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8784,\tval_loss: 4.2831\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8403,\tval_loss: 4.2481\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8132,\tval_loss: 4.4304\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8853,\tval_loss: 4.3650\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8774,\tval_loss: 4.3229\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8398,\tval_loss: 4.3527\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7768,\tval_loss: 4.4397\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7983,\tval_loss: 4.3832\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7223,\tval_loss: 4.3805\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7129,\tval_loss: 4.3709\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7401,\tval_loss: 4.3836\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7006,\tval_loss: 4.4278\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7802,\tval_loss: 4.3547\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.8278,\tval_loss: 4.3906\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7458,\tval_loss: 4.4396\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7841,\tval_loss: 4.3605\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7768,\tval_loss: 4.3841\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7201,\tval_loss: 4.3839\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7497,\tval_loss: 4.4792\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7753,\tval_loss: 4.4010\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7872,\tval_loss: 4.3677\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7274,\tval_loss: 4.4800\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7120,\tval_loss: 4.3653\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7522,\tval_loss: 4.4237\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6918,\tval_loss: 4.4103\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6792,\tval_loss: 4.5032\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7187,\tval_loss: 4.4239\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6648,\tval_loss: 4.4674\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6614,\tval_loss: 4.4096\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6573,\tval_loss: 4.4458\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6958,\tval_loss: 4.4562\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6997,\tval_loss: 4.3909\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6223,\tval_loss: 4.4005\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6254,\tval_loss: 4.4176\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6826,\tval_loss: 4.3946\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.6406,\tval_loss: 4.4605\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.7280,\tval_loss: 4.3258\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6750,\tval_loss: 4.4414\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6489,\tval_loss: 4.4748\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.7178,\tval_loss: 4.4221\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6624,\tval_loss: 4.4276\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3660,\tval_loss: 4.0359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2459,\tval_loss: 4.0120\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1962,\tval_loss: 4.0067\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1628,\tval_loss: 4.0150\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1702,\tval_loss: 4.0232\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1590,\tval_loss: 4.0168\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1335,\tval_loss: 4.0090\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1428,\tval_loss: 4.0267\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1187,\tval_loss: 4.0316\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1071,\tval_loss: 4.0266\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0740,\tval_loss: 4.0401\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0861,\tval_loss: 4.0886\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0944,\tval_loss: 4.0530\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0476,\tval_loss: 4.0771\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9786,\tval_loss: 4.1053\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9730,\tval_loss: 4.1244\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9736,\tval_loss: 4.1123\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9393,\tval_loss: 4.1300\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9277,\tval_loss: 4.1453\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9925,\tval_loss: 4.1470\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9759,\tval_loss: 4.1205\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8980,\tval_loss: 4.1409\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9210,\tval_loss: 4.1754\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8613,\tval_loss: 4.1830\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9281,\tval_loss: 4.1649\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8820,\tval_loss: 4.1824\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8724,\tval_loss: 4.1778\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8415,\tval_loss: 4.2204\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8203,\tval_loss: 4.1812\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7713,\tval_loss: 4.2190\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8122,\tval_loss: 4.2102\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8726,\tval_loss: 4.1822\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.9458,\tval_loss: 4.1721\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8178,\tval_loss: 4.2245\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8013,\tval_loss: 4.1937\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7636,\tval_loss: 4.2282\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7639,\tval_loss: 4.2225\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7860,\tval_loss: 4.2050\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.8081,\tval_loss: 4.1853\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.8129,\tval_loss: 4.1981\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7431,\tval_loss: 4.2118\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7889,\tval_loss: 4.2255\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7172,\tval_loss: 4.2909\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6981,\tval_loss: 4.2097\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7520,\tval_loss: 4.2293\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7462,\tval_loss: 4.2127\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7437,\tval_loss: 4.1931\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7781,\tval_loss: 4.2177\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7280,\tval_loss: 4.2467\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7285,\tval_loss: 4.2356\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6843,\tval_loss: 4.3387\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7978,\tval_loss: 4.2539\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7736,\tval_loss: 4.1448\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7331,\tval_loss: 4.2842\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6798,\tval_loss: 4.2377\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6407,\tval_loss: 4.2102\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6570,\tval_loss: 4.2548\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6967,\tval_loss: 4.2980\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6414,\tval_loss: 4.2162\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6252,\tval_loss: 4.2883\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6166,\tval_loss: 4.3343\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6630,\tval_loss: 4.2571\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.7298,\tval_loss: 4.2146\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.7034,\tval_loss: 4.2457\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6981,\tval_loss: 4.2337\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6359,\tval_loss: 4.2685\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.7434,\tval_loss: 4.2717\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6951,\tval_loss: 4.2069\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6918,\tval_loss: 4.1587\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6848,\tval_loss: 4.1893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3602,\tval_loss: 4.0608\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2930,\tval_loss: 4.0443\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2795,\tval_loss: 4.0307\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2258,\tval_loss: 4.0177\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2071,\tval_loss: 4.0436\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1839,\tval_loss: 4.0521\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1480,\tval_loss: 4.0793\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1660,\tval_loss: 4.0542\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1500,\tval_loss: 4.0846\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0805,\tval_loss: 4.0640\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0724,\tval_loss: 4.0831\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0523,\tval_loss: 4.1182\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9927,\tval_loss: 4.0899\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9826,\tval_loss: 4.1556\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0053,\tval_loss: 4.1199\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9532,\tval_loss: 4.1455\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9007,\tval_loss: 4.1480\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9243,\tval_loss: 4.1612\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8545,\tval_loss: 4.1874\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.7739,\tval_loss: 4.2552\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.7349,\tval_loss: 4.1836\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7339,\tval_loss: 4.2419\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7230,\tval_loss: 4.1643\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7737,\tval_loss: 4.2934\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.6685,\tval_loss: 4.2772\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7126,\tval_loss: 4.2389\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7272,\tval_loss: 4.2449\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7536,\tval_loss: 4.2257\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7045,\tval_loss: 4.2510\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.6238,\tval_loss: 4.2884\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6878,\tval_loss: 4.2278\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6197,\tval_loss: 4.3806\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6101,\tval_loss: 4.3058\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6097,\tval_loss: 4.3472\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6629,\tval_loss: 4.1754\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.6117,\tval_loss: 4.3228\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.6335,\tval_loss: 4.2984\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.5186,\tval_loss: 4.3872\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.4921,\tval_loss: 4.3440\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.5268,\tval_loss: 4.3940\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5572,\tval_loss: 4.3284\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5536,\tval_loss: 4.3292\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.4984,\tval_loss: 4.4341\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5234,\tval_loss: 4.3540\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5453,\tval_loss: 4.3176\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5542,\tval_loss: 4.3053\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.3988,\tval_loss: 4.3663\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.4505,\tval_loss: 4.4316\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.4939,\tval_loss: 4.3653\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.4208,\tval_loss: 4.4589\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.4503,\tval_loss: 4.3252\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.5595,\tval_loss: 4.3640\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.4850,\tval_loss: 4.3520\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.5129,\tval_loss: 4.3427\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.4663,\tval_loss: 4.3443\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.4667,\tval_loss: 4.3355\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.4806,\tval_loss: 4.2730\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.4597,\tval_loss: 4.3250\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.3476,\tval_loss: 4.4507\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5714,\tval_loss: 4.2558\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.4381,\tval_loss: 4.3806\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.4012,\tval_loss: 4.4094\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.4917,\tval_loss: 4.4250\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5133,\tval_loss: 4.2898\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.5487,\tval_loss: 4.3609\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.4544,\tval_loss: 4.3178\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.4406,\tval_loss: 4.3344\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.4621,\tval_loss: 4.3420\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.4137,\tval_loss: 4.3496\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.3488,\tval_loss: 4.4387\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.3482,\tval_loss: 4.3963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4125,\tval_loss: 4.0938\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3005,\tval_loss: 4.0957\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2539,\tval_loss: 4.1059\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2454,\tval_loss: 4.1223\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2415,\tval_loss: 4.1285\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2302,\tval_loss: 4.1182\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1929,\tval_loss: 4.1662\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2081,\tval_loss: 4.1548\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.2092,\tval_loss: 4.1521\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1659,\tval_loss: 4.1707\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1601,\tval_loss: 4.2100\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0717,\tval_loss: 4.2398\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1439,\tval_loss: 4.2397\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0688,\tval_loss: 4.3578\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0609,\tval_loss: 4.2570\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0175,\tval_loss: 4.3861\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9718,\tval_loss: 4.3968\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9265,\tval_loss: 4.4044\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9800,\tval_loss: 4.3878\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9511,\tval_loss: 4.3156\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9319,\tval_loss: 4.4224\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8749,\tval_loss: 4.4622\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8141,\tval_loss: 4.5099\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9444,\tval_loss: 4.3746\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8741,\tval_loss: 4.4389\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8122,\tval_loss: 4.4158\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7948,\tval_loss: 4.4403\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7524,\tval_loss: 4.5199\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8157,\tval_loss: 4.4320\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.8381,\tval_loss: 4.4341\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.8212,\tval_loss: 4.5374\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7752,\tval_loss: 4.3981\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.6800,\tval_loss: 4.4902\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.6536,\tval_loss: 4.5748\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.6496,\tval_loss: 4.5188\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7225,\tval_loss: 4.4978\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.6208,\tval_loss: 4.4678\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7260,\tval_loss: 4.5132\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.5878,\tval_loss: 4.5854\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7541,\tval_loss: 4.5140\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7311,\tval_loss: 4.4965\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6710,\tval_loss: 4.4888\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6412,\tval_loss: 4.5385\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7586,\tval_loss: 4.4764\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6563,\tval_loss: 4.5244\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6628,\tval_loss: 4.5352\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6451,\tval_loss: 4.4486\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7162,\tval_loss: 4.4716\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5846,\tval_loss: 4.4788\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5956,\tval_loss: 4.5614\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6462,\tval_loss: 4.6994\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.6711,\tval_loss: 4.5662\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6636,\tval_loss: 4.5161\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6696,\tval_loss: 4.5385\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.7001,\tval_loss: 4.4499\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6076,\tval_loss: 4.5016\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6677,\tval_loss: 4.5599\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6470,\tval_loss: 4.4437\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6425,\tval_loss: 4.5858\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5177,\tval_loss: 4.5650\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6298,\tval_loss: 4.4413\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6135,\tval_loss: 4.4860\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5824,\tval_loss: 4.5760\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6027,\tval_loss: 4.5355\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6396,\tval_loss: 4.5295\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5253,\tval_loss: 4.5536\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5278,\tval_loss: 4.5608\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5394,\tval_loss: 4.6132\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3666,\tval_loss: 4.0502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2969,\tval_loss: 4.0413\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2566,\tval_loss: 4.0421\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2203,\tval_loss: 4.0422\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2056,\tval_loss: 4.0548\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1921,\tval_loss: 4.0639\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1857,\tval_loss: 4.0465\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1938,\tval_loss: 4.0460\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1244,\tval_loss: 4.0728\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1582,\tval_loss: 4.0774\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1382,\tval_loss: 4.0606\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1039,\tval_loss: 4.0764\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0916,\tval_loss: 4.0964\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1315,\tval_loss: 4.0837\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0093,\tval_loss: 4.0952\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0646,\tval_loss: 4.0895\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0279,\tval_loss: 4.1031\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9941,\tval_loss: 4.1303\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9802,\tval_loss: 4.1550\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9236,\tval_loss: 4.2010\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9320,\tval_loss: 4.1436\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9524,\tval_loss: 4.1567\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8468,\tval_loss: 4.2073\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9067,\tval_loss: 4.1807\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8837,\tval_loss: 4.2108\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8842,\tval_loss: 4.1998\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8997,\tval_loss: 4.2135\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9160,\tval_loss: 4.1861\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8650,\tval_loss: 4.1890\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8772,\tval_loss: 4.2301\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8695,\tval_loss: 4.2576\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8035,\tval_loss: 4.2473\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8310,\tval_loss: 4.2246\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8483,\tval_loss: 4.2184\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8327,\tval_loss: 4.2163\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8153,\tval_loss: 4.2803\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.8476,\tval_loss: 4.2324\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7959,\tval_loss: 4.1996\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7809,\tval_loss: 4.2500\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.8194,\tval_loss: 4.2457\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7925,\tval_loss: 4.2214\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.8126,\tval_loss: 4.2574\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7660,\tval_loss: 4.2862\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7821,\tval_loss: 4.2947\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7690,\tval_loss: 4.2412\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.8167,\tval_loss: 4.2447\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.8278,\tval_loss: 4.1973\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7683,\tval_loss: 4.2891\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7670,\tval_loss: 4.3044\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7812,\tval_loss: 4.2944\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7541,\tval_loss: 4.3631\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7113,\tval_loss: 4.2759\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7759,\tval_loss: 4.3555\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7580,\tval_loss: 4.2718\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7385,\tval_loss: 4.3026\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.8007,\tval_loss: 4.2823\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6705,\tval_loss: 4.2579\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6886,\tval_loss: 4.3344\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6450,\tval_loss: 4.3522\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.7481,\tval_loss: 4.3102\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.7248,\tval_loss: 4.3037\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.7365,\tval_loss: 4.3018\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.7347,\tval_loss: 4.3348\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.7123,\tval_loss: 4.2961\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.7258,\tval_loss: 4.3631\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.7490,\tval_loss: 4.2859\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.7571,\tval_loss: 4.2977\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.7236,\tval_loss: 4.2979\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6980,\tval_loss: 4.3239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.5279,\tval_loss: 4.0013\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3245,\tval_loss: 4.0086\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2484,\tval_loss: 4.0044\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2582,\tval_loss: 3.9961\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2243,\tval_loss: 4.0119\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2216,\tval_loss: 4.0120\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1853,\tval_loss: 4.0255\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1462,\tval_loss: 4.0714\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1669,\tval_loss: 4.0400\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1315,\tval_loss: 4.0642\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1358,\tval_loss: 4.0714\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0949,\tval_loss: 4.1007\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0596,\tval_loss: 4.1070\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0823,\tval_loss: 4.1215\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0698,\tval_loss: 4.1010\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0096,\tval_loss: 4.1449\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9763,\tval_loss: 4.1692\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9927,\tval_loss: 4.1359\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9744,\tval_loss: 4.1713\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9887,\tval_loss: 4.1728\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9849,\tval_loss: 4.2042\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9225,\tval_loss: 4.2000\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9678,\tval_loss: 4.2084\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9474,\tval_loss: 4.1735\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8999,\tval_loss: 4.2034\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9011,\tval_loss: 4.2550\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9096,\tval_loss: 4.1764\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8872,\tval_loss: 4.1946\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.9382,\tval_loss: 4.2278\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8838,\tval_loss: 4.1904\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8706,\tval_loss: 4.2375\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8307,\tval_loss: 4.2342\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7896,\tval_loss: 4.3473\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8963,\tval_loss: 4.1956\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8624,\tval_loss: 4.2220\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8073,\tval_loss: 4.3065\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7955,\tval_loss: 4.2681\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7872,\tval_loss: 4.2876\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.8239,\tval_loss: 4.2086\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.8074,\tval_loss: 4.2506\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.8315,\tval_loss: 4.2634\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7650,\tval_loss: 4.2618\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.8316,\tval_loss: 4.2760\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7731,\tval_loss: 4.2966\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7686,\tval_loss: 4.3763\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7592,\tval_loss: 4.3360\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.8095,\tval_loss: 4.3657\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.8139,\tval_loss: 4.3334\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.8238,\tval_loss: 4.2393\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7819,\tval_loss: 4.2912\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7440,\tval_loss: 4.3540\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7493,\tval_loss: 4.3239\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7681,\tval_loss: 4.3161\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7583,\tval_loss: 4.3467\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7145,\tval_loss: 4.3720\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.7921,\tval_loss: 4.3087\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.7535,\tval_loss: 4.2756\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.7054,\tval_loss: 4.3116\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.7421,\tval_loss: 4.3132\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.7816,\tval_loss: 4.2758\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.7601,\tval_loss: 4.2698\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.7947,\tval_loss: 4.3087\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.7637,\tval_loss: 4.2304\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.7676,\tval_loss: 4.2852\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.7210,\tval_loss: 4.2780\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6871,\tval_loss: 4.3413\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6614,\tval_loss: 4.3083\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.7346,\tval_loss: 4.3608\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6797,\tval_loss: 4.2884\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6945,\tval_loss: 4.3250\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6594,\tval_loss: 4.2977\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.5448,\tval_loss: 4.0519\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2816,\tval_loss: 4.0734\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2451,\tval_loss: 4.0716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2263,\tval_loss: 4.0681\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1376,\tval_loss: 4.1008\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1397,\tval_loss: 4.0721\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1237,\tval_loss: 4.1108\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0787,\tval_loss: 4.0851\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 3.9842,\tval_loss: 4.1518\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0180,\tval_loss: 4.0943\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 3.9755,\tval_loss: 4.1219\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.8970,\tval_loss: 4.1751\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9106,\tval_loss: 4.1752\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.8157,\tval_loss: 4.2435\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9150,\tval_loss: 4.1174\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.8541,\tval_loss: 4.2198\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8269,\tval_loss: 4.2378\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8332,\tval_loss: 4.1985\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8092,\tval_loss: 4.2685\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.7466,\tval_loss: 4.2275\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.7247,\tval_loss: 4.2768\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7210,\tval_loss: 4.2804\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7154,\tval_loss: 4.3265\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7121,\tval_loss: 4.4163\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.6977,\tval_loss: 4.3605\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6815,\tval_loss: 4.4359\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6608,\tval_loss: 4.3770\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7118,\tval_loss: 4.3998\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6197,\tval_loss: 4.3711\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.5720,\tval_loss: 4.5190\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6828,\tval_loss: 4.4133\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6477,\tval_loss: 4.4989\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.5043,\tval_loss: 4.5473\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.5443,\tval_loss: 4.4794\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.5479,\tval_loss: 4.5753\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6067,\tval_loss: 4.4993\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6399,\tval_loss: 4.5045\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.5933,\tval_loss: 4.5424\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.5662,\tval_loss: 4.5586\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.5789,\tval_loss: 4.6352\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.4551,\tval_loss: 4.6160\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5012,\tval_loss: 4.5254\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5490,\tval_loss: 4.4234\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.4184,\tval_loss: 4.5527\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.4634,\tval_loss: 4.5788\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.4841,\tval_loss: 4.5186\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5231,\tval_loss: 4.5636\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.4341,\tval_loss: 4.6753\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.4233,\tval_loss: 4.6650\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.4623,\tval_loss: 4.4760\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.3950,\tval_loss: 4.6055\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.4162,\tval_loss: 4.6134\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.4260,\tval_loss: 4.7417\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.4601,\tval_loss: 4.5527\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.4272,\tval_loss: 4.7142\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.4127,\tval_loss: 4.7128\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.3168,\tval_loss: 4.6892\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.3699,\tval_loss: 4.5950\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.3595,\tval_loss: 4.7648\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.4646,\tval_loss: 4.5022\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.4975,\tval_loss: 4.5347\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.3240,\tval_loss: 4.7771\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.3000,\tval_loss: 4.7595\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.2748,\tval_loss: 4.6929\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.3663,\tval_loss: 4.7153\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.3437,\tval_loss: 4.6637\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4084,\tval_loss: 4.6591\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.2972,\tval_loss: 4.6735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4712,\tval_loss: 4.0744\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.4017,\tval_loss: 4.0716\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3288,\tval_loss: 4.0782\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.3557,\tval_loss: 4.0525\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.3409,\tval_loss: 4.0502\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2234,\tval_loss: 4.0357\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2414,\tval_loss: 4.0484\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1931,\tval_loss: 4.0155\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1640,\tval_loss: 4.0430\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1548,\tval_loss: 4.0236\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0963,\tval_loss: 4.0414\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0877,\tval_loss: 4.0199\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 4.0692,\tval_loss: 4.0360\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 4.0520,\tval_loss: 4.0253\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0024,\tval_loss: 4.0233\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0247,\tval_loss: 4.0193\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9597,\tval_loss: 4.0241\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9320,\tval_loss: 4.0186\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9618,\tval_loss: 4.0229\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9384,\tval_loss: 4.0824\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9271,\tval_loss: 4.0154\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9489,\tval_loss: 4.0621\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9023,\tval_loss: 4.0246\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8676,\tval_loss: 4.0902\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8990,\tval_loss: 4.0242\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8709,\tval_loss: 4.0726\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8673,\tval_loss: 4.0430\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 3.7755,\tval_loss: 4.1460\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 3.8055,\tval_loss: 4.0829\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.8236,\tval_loss: 4.0801\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.7458,\tval_loss: 4.1373\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7296,\tval_loss: 4.1362\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7812,\tval_loss: 4.1379\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.7267,\tval_loss: 4.1417\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7265,\tval_loss: 4.1465\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7094,\tval_loss: 4.0912\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.6614,\tval_loss: 4.2082\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6864,\tval_loss: 4.0820\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7417,\tval_loss: 4.1216\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7482,\tval_loss: 4.1607\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6717,\tval_loss: 4.1740\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7366,\tval_loss: 4.2241\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 3.7421,\tval_loss: 4.1673\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 3.7120,\tval_loss: 4.1727\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.6184,\tval_loss: 4.2670\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.6199,\tval_loss: 4.1750\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.5932,\tval_loss: 4.2294\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.6387,\tval_loss: 4.2046\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.5795,\tval_loss: 4.1755\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6419,\tval_loss: 4.2237\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6463,\tval_loss: 4.2262\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.5627,\tval_loss: 4.2645\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.5845,\tval_loss: 4.2186\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.5969,\tval_loss: 4.2226\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6129,\tval_loss: 4.2904\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.5814,\tval_loss: 4.2217\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6087,\tval_loss: 4.2136\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5898,\tval_loss: 4.1787\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6522,\tval_loss: 4.1694\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6009,\tval_loss: 4.2401\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.4896,\tval_loss: 4.2955\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5634,\tval_loss: 4.2423\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5992,\tval_loss: 4.2547\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.5548,\tval_loss: 4.2155\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.5576,\tval_loss: 4.2196\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.6895,\tval_loss: 4.1702\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.6181,\tval_loss: 4.1930\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.5644,\tval_loss: 4.2102\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.5045,\tval_loss: 4.2191\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.5369,\tval_loss: 4.1726\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.5121,\tval_loss: 4.2748\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.5244,\tval_loss: 4.2277\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.4560,\tval_loss: 4.2911\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.5964,\tval_loss: 4.2215\n",
            "74:\t[0s / 4s],\t\ttrain_loss: 3.5461,\tval_loss: 4.2637\n",
            "75:\t[0s / 4s],\t\ttrain_loss: 3.5587,\tval_loss: 4.2596\n",
            "76:\t[0s / 4s],\t\ttrain_loss: 3.5067,\tval_loss: 4.2562\n",
            "77:\t[0s / 4s],\t\ttrain_loss: 3.6324,\tval_loss: 4.1956\n",
            "78:\t[0s / 4s],\t\ttrain_loss: 3.4531,\tval_loss: 4.3326\n",
            "79:\t[0s / 4s],\t\ttrain_loss: 3.5630,\tval_loss: 4.1978\n",
            "80:\t[0s / 4s],\t\ttrain_loss: 3.4592,\tval_loss: 4.2702\n",
            "81:\t[0s / 4s],\t\ttrain_loss: 3.5511,\tval_loss: 4.2213\n",
            "82:\t[0s / 4s],\t\ttrain_loss: 3.4738,\tval_loss: 4.2645\n",
            "83:\t[0s / 4s],\t\ttrain_loss: 3.5717,\tval_loss: 4.2798\n",
            "84:\t[0s / 5s],\t\ttrain_loss: 3.5302,\tval_loss: 4.2470\n",
            "85:\t[0s / 5s],\t\ttrain_loss: 3.5722,\tval_loss: 4.1736\n",
            "86:\t[0s / 5s],\t\ttrain_loss: 3.4785,\tval_loss: 4.3135\n",
            "87:\t[0s / 5s],\t\ttrain_loss: 3.5806,\tval_loss: 4.2724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3774,\tval_loss: 4.0425\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2917,\tval_loss: 4.0522\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2311,\tval_loss: 4.0609\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1890,\tval_loss: 4.0742\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2119,\tval_loss: 4.0638\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1790,\tval_loss: 4.0680\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1862,\tval_loss: 4.0739\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1907,\tval_loss: 4.0978\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1849,\tval_loss: 4.0821\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1801,\tval_loss: 4.0739\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1684,\tval_loss: 4.1082\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1555,\tval_loss: 4.0993\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0967,\tval_loss: 4.1085\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0756,\tval_loss: 4.1506\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.1061,\tval_loss: 4.1483\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0966,\tval_loss: 4.1799\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0663,\tval_loss: 4.1404\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0755,\tval_loss: 4.1474\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0592,\tval_loss: 4.2352\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 4.0229,\tval_loss: 4.2284\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9747,\tval_loss: 4.2139\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9603,\tval_loss: 4.2385\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9895,\tval_loss: 4.2044\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9602,\tval_loss: 4.2246\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9726,\tval_loss: 4.2733\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9830,\tval_loss: 4.2195\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8841,\tval_loss: 4.2774\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9407,\tval_loss: 4.2571\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.9410,\tval_loss: 4.2420\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8942,\tval_loss: 4.2931\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8402,\tval_loss: 4.2819\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8609,\tval_loss: 4.3757\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8767,\tval_loss: 4.2579\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8528,\tval_loss: 4.2939\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8580,\tval_loss: 4.3194\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.8448,\tval_loss: 4.2567\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7735,\tval_loss: 4.3384\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7602,\tval_loss: 4.2987\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7890,\tval_loss: 4.3335\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7832,\tval_loss: 4.3660\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7437,\tval_loss: 4.3382\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7314,\tval_loss: 4.4140\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6614,\tval_loss: 4.4207\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7234,\tval_loss: 4.3752\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6931,\tval_loss: 4.3569\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7052,\tval_loss: 4.4193\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6849,\tval_loss: 4.4232\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6870,\tval_loss: 4.4630\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7296,\tval_loss: 4.3354\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6891,\tval_loss: 4.4364\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6282,\tval_loss: 4.4757\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.6258,\tval_loss: 4.5232\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6211,\tval_loss: 4.4428\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6538,\tval_loss: 4.4557\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6396,\tval_loss: 4.4878\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6432,\tval_loss: 4.4827\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6652,\tval_loss: 4.4547\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6489,\tval_loss: 4.4562\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6208,\tval_loss: 4.4652\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5972,\tval_loss: 4.5118\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6153,\tval_loss: 4.4021\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6219,\tval_loss: 4.5107\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5912,\tval_loss: 4.4382\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6633,\tval_loss: 4.4169\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.6296,\tval_loss: 4.4618\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.6503,\tval_loss: 4.3922\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.5861,\tval_loss: 4.4886\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.5643,\tval_loss: 4.4878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3084,\tval_loss: 4.1775\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2077,\tval_loss: 4.0988\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1311,\tval_loss: 4.1422\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1488,\tval_loss: 4.1378\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1078,\tval_loss: 4.0907\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.0759,\tval_loss: 4.0901\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0367,\tval_loss: 4.1663\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0793,\tval_loss: 4.0933\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 3.9880,\tval_loss: 4.1239\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0309,\tval_loss: 4.1508\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0091,\tval_loss: 4.0983\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9784,\tval_loss: 4.1502\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.8780,\tval_loss: 4.1611\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9034,\tval_loss: 4.1747\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9590,\tval_loss: 4.1341\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.8988,\tval_loss: 4.2199\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.8207,\tval_loss: 4.1556\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8267,\tval_loss: 4.2285\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.8920,\tval_loss: 4.1606\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8269,\tval_loss: 4.2299\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.7607,\tval_loss: 4.3345\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8214,\tval_loss: 4.0833\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7549,\tval_loss: 4.3019\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7004,\tval_loss: 4.2393\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.6664,\tval_loss: 4.2795\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6955,\tval_loss: 4.2564\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6728,\tval_loss: 4.2864\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6295,\tval_loss: 4.3870\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 3.6270,\tval_loss: 4.2436\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.6149,\tval_loss: 4.1643\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.6157,\tval_loss: 4.3246\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.6306,\tval_loss: 4.3150\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.5417,\tval_loss: 4.2532\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.5766,\tval_loss: 4.2929\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.6211,\tval_loss: 4.2515\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.5297,\tval_loss: 4.4021\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.5532,\tval_loss: 4.2906\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.5557,\tval_loss: 4.3917\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.5672,\tval_loss: 4.3387\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.5752,\tval_loss: 4.3555\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5427,\tval_loss: 4.3302\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5343,\tval_loss: 4.3770\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5455,\tval_loss: 4.3501\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5172,\tval_loss: 4.2979\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5504,\tval_loss: 4.3197\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5070,\tval_loss: 4.4651\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5812,\tval_loss: 4.3199\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5517,\tval_loss: 4.3255\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.4922,\tval_loss: 4.3787\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.4654,\tval_loss: 4.4748\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.4506,\tval_loss: 4.4123\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.4539,\tval_loss: 4.3876\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.4203,\tval_loss: 4.4601\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.3910,\tval_loss: 4.4984\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.5054,\tval_loss: 4.3865\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.5407,\tval_loss: 4.4821\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.4801,\tval_loss: 4.5428\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.4482,\tval_loss: 4.3826\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.4930,\tval_loss: 4.4740\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5048,\tval_loss: 4.3975\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.4616,\tval_loss: 4.4730\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.3660,\tval_loss: 4.5796\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.4765,\tval_loss: 4.4117\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.4438,\tval_loss: 4.5133\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.4642,\tval_loss: 4.4003\n",
            "65:\t[0s / 3s],\t\n",
            "66:\t[0s / 3s],\t\n",
            "67:\t[0s / 4s],\t\n",
            "68:\t[0s / 4s],\t\n",
            "69:\t[0s / 4s],\t\n",
            "70:\t[0s / 4s],\t\n",
            "71:\t[0s / 4s],\t\n",
            "72:\t[0s / 4s],\t\n",
            "73:\t[0s / 4s],\t\n",
            "74:\t[0s / 4s],\t\n",
            "75:\t[0s / 4s],\t\n",
            "76:\t[0s / 4s],\t\n",
            "77:\t[0s / 4s],\t\n",
            "78:\t[0s / 4s],\t\n",
            "79:\t[0s / 4s],\t\n",
            "80:\t[0s / 4s],\t\n",
            "81:\t[0s / 5s],\t\n",
            "82:\t[0s / 5s],\t\n",
            "83:\t[0s / 5s],\t\n",
            "84:\t[0s / 5s],\t\n",
            "85:\t[0s / 5s],\t\n",
            "86:\t[0s / 5s],\t\n",
            "87:\t[0s / 5s],\t\n",
            "88:\t[0s / 5s],\t\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4723,\tval_loss: 4.0635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3922,\tval_loss: 4.0697\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3348,\tval_loss: 4.0523\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.3109,\tval_loss: 4.0452\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2787,\tval_loss: 4.0591\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2734,\tval_loss: 4.0608\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2704,\tval_loss: 4.0335\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2522,\tval_loss: 4.0342\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.2479,\tval_loss: 4.0302\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.2311,\tval_loss: 4.0318\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1904,\tval_loss: 4.0325\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1540,\tval_loss: 4.0607\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1885,\tval_loss: 4.0518\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1365,\tval_loss: 4.0881\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.1115,\tval_loss: 4.0735\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0705,\tval_loss: 4.1300\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 4.1033,\tval_loss: 4.0914\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 4.0166,\tval_loss: 4.1258\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9852,\tval_loss: 4.1622\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9860,\tval_loss: 4.1765\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9234,\tval_loss: 4.1381\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9697,\tval_loss: 4.2151\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9554,\tval_loss: 4.1682\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8155,\tval_loss: 4.1279\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8318,\tval_loss: 4.2983\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8500,\tval_loss: 4.1403\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8761,\tval_loss: 4.1672\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8594,\tval_loss: 4.1743\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8374,\tval_loss: 4.1469\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.7779,\tval_loss: 4.2018\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.7716,\tval_loss: 4.2662\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7523,\tval_loss: 4.1614\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7145,\tval_loss: 4.2655\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.7495,\tval_loss: 4.1737\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7306,\tval_loss: 4.2638\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7986,\tval_loss: 4.2655\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7255,\tval_loss: 4.2841\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7831,\tval_loss: 4.2113\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7352,\tval_loss: 4.2460\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7097,\tval_loss: 4.3191\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6650,\tval_loss: 4.2747\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6893,\tval_loss: 4.3285\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7534,\tval_loss: 4.2782\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7501,\tval_loss: 4.2229\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.6981,\tval_loss: 4.2557\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.6537,\tval_loss: 4.3359\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.6143,\tval_loss: 4.2502\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.5987,\tval_loss: 4.3611\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.6511,\tval_loss: 4.3849\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.6279,\tval_loss: 4.2703\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6701,\tval_loss: 4.2522\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.6372,\tval_loss: 4.3238\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.6470,\tval_loss: 4.3083\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.5597,\tval_loss: 4.2925\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6099,\tval_loss: 4.3754\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6266,\tval_loss: 4.3156\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5534,\tval_loss: 4.3363\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6049,\tval_loss: 4.2377\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5832,\tval_loss: 4.3463\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5607,\tval_loss: 4.3019\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5718,\tval_loss: 4.3977\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6205,\tval_loss: 4.2937\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.6270,\tval_loss: 4.2656\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.5156,\tval_loss: 4.3022\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.4922,\tval_loss: 4.4316\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.5790,\tval_loss: 4.3854\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.5714,\tval_loss: 4.3936\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.5460,\tval_loss: 4.3742\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.5912,\tval_loss: 4.3762\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.5536,\tval_loss: 4.3447\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.5878,\tval_loss: 4.3507\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.5753,\tval_loss: 4.3604\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.5345,\tval_loss: 4.4776\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.5801,\tval_loss: 4.3828\n",
            "74:\t[0s / 4s],\t\ttrain_loss: 3.5252,\tval_loss: 4.3746\n",
            "75:\t[0s / 4s],\t\ttrain_loss: 3.5303,\tval_loss: 4.3310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3833,\tval_loss: 4.1158\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2842,\tval_loss: 4.1100\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2184,\tval_loss: 4.1102\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1985,\tval_loss: 4.0892\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1743,\tval_loss: 4.1163\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1243,\tval_loss: 4.1066\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1407,\tval_loss: 4.1326\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1102,\tval_loss: 4.1229\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1085,\tval_loss: 4.1202\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0408,\tval_loss: 4.1437\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0095,\tval_loss: 4.1748\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9930,\tval_loss: 4.1481\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9934,\tval_loss: 4.1891\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9513,\tval_loss: 4.1574\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9358,\tval_loss: 4.2125\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.8785,\tval_loss: 4.2601\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9030,\tval_loss: 4.2728\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9182,\tval_loss: 4.2326\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8535,\tval_loss: 4.2661\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9564,\tval_loss: 4.2028\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8457,\tval_loss: 4.2591\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8217,\tval_loss: 4.2291\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8458,\tval_loss: 4.2477\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8521,\tval_loss: 4.2747\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7985,\tval_loss: 4.3081\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8180,\tval_loss: 4.3130\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7952,\tval_loss: 4.3576\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8631,\tval_loss: 4.2682\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7445,\tval_loss: 4.3649\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7091,\tval_loss: 4.3245\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6912,\tval_loss: 4.3087\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7675,\tval_loss: 4.3108\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7225,\tval_loss: 4.3495\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7512,\tval_loss: 4.3044\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7511,\tval_loss: 4.3422\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7380,\tval_loss: 4.3742\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7367,\tval_loss: 4.2794\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6485,\tval_loss: 4.3819\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7296,\tval_loss: 4.3658\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7353,\tval_loss: 4.2811\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7309,\tval_loss: 4.4274\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.6937,\tval_loss: 4.3711\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6878,\tval_loss: 4.2925\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7223,\tval_loss: 4.2998\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7825,\tval_loss: 4.2970\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7577,\tval_loss: 4.3570\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7248,\tval_loss: 4.3256\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6520,\tval_loss: 4.3887\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6586,\tval_loss: 4.3557\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7384,\tval_loss: 4.3571\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7827,\tval_loss: 4.3135\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6771,\tval_loss: 4.3152\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5942,\tval_loss: 4.4437\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6945,\tval_loss: 4.3331\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6227,\tval_loss: 4.3723\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6451,\tval_loss: 4.4091\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6133,\tval_loss: 4.4709\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6297,\tval_loss: 4.3902\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6691,\tval_loss: 4.4014\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6843,\tval_loss: 4.4107\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6608,\tval_loss: 4.3884\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6071,\tval_loss: 4.3568\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6739,\tval_loss: 4.3813\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 3.5814,\tval_loss: 4.4211\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5899,\tval_loss: 4.4253\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6580,\tval_loss: 4.3971\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6351,\tval_loss: 4.3384\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6415,\tval_loss: 4.4298\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6037,\tval_loss: 4.4024\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6629,\tval_loss: 4.3271\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6042,\tval_loss: 4.4709\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4239,\tval_loss: 4.0229\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2682,\tval_loss: 4.0227\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2069,\tval_loss: 4.0198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1888,\tval_loss: 4.0481\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1436,\tval_loss: 4.0417\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1314,\tval_loss: 4.0712\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0821,\tval_loss: 4.0983\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0163,\tval_loss: 4.0691\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 3.9931,\tval_loss: 4.1059\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0489,\tval_loss: 4.0697\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 3.9283,\tval_loss: 4.0931\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9338,\tval_loss: 4.0634\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0274,\tval_loss: 4.0835\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9393,\tval_loss: 4.1187\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.8868,\tval_loss: 4.1791\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9109,\tval_loss: 4.1348\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8725,\tval_loss: 4.1525\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8358,\tval_loss: 4.1520\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8353,\tval_loss: 4.2644\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.7766,\tval_loss: 4.1431\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.7076,\tval_loss: 4.2147\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7747,\tval_loss: 4.1941\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.6979,\tval_loss: 4.1956\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7090,\tval_loss: 4.1731\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.6959,\tval_loss: 4.2311\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6838,\tval_loss: 4.2356\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7002,\tval_loss: 4.2280\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6716,\tval_loss: 4.1626\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6466,\tval_loss: 4.2460\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.6229,\tval_loss: 4.2584\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.5660,\tval_loss: 4.2515\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.5964,\tval_loss: 4.2209\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.5691,\tval_loss: 4.2513\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.5284,\tval_loss: 4.2865\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6007,\tval_loss: 4.3273\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.5111,\tval_loss: 4.3031\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.5715,\tval_loss: 4.2779\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.5932,\tval_loss: 4.2782\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.5612,\tval_loss: 4.2404\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.5366,\tval_loss: 4.2462\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.5390,\tval_loss: 4.2632\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.5674,\tval_loss: 4.2495\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.4885,\tval_loss: 4.3597\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.4746,\tval_loss: 4.2884\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.4822,\tval_loss: 4.3090\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.4278,\tval_loss: 4.3230\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.4636,\tval_loss: 4.2656\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.4479,\tval_loss: 4.2230\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.4362,\tval_loss: 4.3915\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.3937,\tval_loss: 4.3001\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.4629,\tval_loss: 4.2789\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.3477,\tval_loss: 4.3438\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5215,\tval_loss: 4.2944\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.4902,\tval_loss: 4.3058\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.3706,\tval_loss: 4.3059\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.4358,\tval_loss: 4.3270\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.3604,\tval_loss: 4.3814\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.3267,\tval_loss: 4.3728\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.3377,\tval_loss: 4.3046\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.3437,\tval_loss: 4.2913\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.3784,\tval_loss: 4.3411\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.3331,\tval_loss: 4.4163\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.3222,\tval_loss: 4.4489\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.3449,\tval_loss: 4.3583\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.2554,\tval_loss: 4.4205\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.2899,\tval_loss: 4.3418\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4103,\tval_loss: 4.2807\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.3284,\tval_loss: 4.3419\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.1699,\tval_loss: 4.4428\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.3974,\tval_loss: 4.4153\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3553,\tval_loss: 4.1445\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2342,\tval_loss: 4.1464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1971,\tval_loss: 4.1302\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1778,\tval_loss: 4.1425\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1002,\tval_loss: 4.1547\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1576,\tval_loss: 4.1329\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1343,\tval_loss: 4.1595\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1023,\tval_loss: 4.1568\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0612,\tval_loss: 4.1657\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0647,\tval_loss: 4.1449\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0661,\tval_loss: 4.1697\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0065,\tval_loss: 4.1990\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0373,\tval_loss: 4.2184\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0145,\tval_loss: 4.2158\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9946,\tval_loss: 4.2473\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9010,\tval_loss: 4.2551\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8741,\tval_loss: 4.3655\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8811,\tval_loss: 4.3080\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8050,\tval_loss: 4.3735\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8250,\tval_loss: 4.3977\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.7962,\tval_loss: 4.4212\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8001,\tval_loss: 4.3383\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7239,\tval_loss: 4.4131\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7646,\tval_loss: 4.4386\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7211,\tval_loss: 4.4225\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6536,\tval_loss: 4.3940\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7232,\tval_loss: 4.4916\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6526,\tval_loss: 4.4369\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6569,\tval_loss: 4.5662\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.5885,\tval_loss: 4.5367\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.5884,\tval_loss: 4.4697\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6489,\tval_loss: 4.4936\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6022,\tval_loss: 4.4640\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.5573,\tval_loss: 4.5573\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.5887,\tval_loss: 4.4974\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.6719,\tval_loss: 4.4698\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.6151,\tval_loss: 4.4150\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.5666,\tval_loss: 4.4283\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.5073,\tval_loss: 4.5945\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.5538,\tval_loss: 4.4784\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.4985,\tval_loss: 4.4836\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5080,\tval_loss: 4.4850\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5259,\tval_loss: 4.4825\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.4928,\tval_loss: 4.5132\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.4701,\tval_loss: 4.5555\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.4980,\tval_loss: 4.5664\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.4841,\tval_loss: 4.5027\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.4762,\tval_loss: 4.6169\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.4581,\tval_loss: 4.5160\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.4783,\tval_loss: 4.5720\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.4420,\tval_loss: 4.5892\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.5403,\tval_loss: 4.5405\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.5051,\tval_loss: 4.5242\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.4296,\tval_loss: 4.5881\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.5017,\tval_loss: 4.4886\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.4922,\tval_loss: 4.5225\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.3958,\tval_loss: 4.5181\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.3972,\tval_loss: 4.6042\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.4054,\tval_loss: 4.5829\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.4405,\tval_loss: 4.5214\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5433,\tval_loss: 4.5439\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.4593,\tval_loss: 4.6148\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.4715,\tval_loss: 4.5418\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.4327,\tval_loss: 4.5703\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.4957,\tval_loss: 4.6238\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.3904,\tval_loss: 4.6131\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.3655,\tval_loss: 4.5913\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.4287,\tval_loss: 4.5667\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.4688,\tval_loss: 4.6288\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.2847,\tval_loss: 4.6063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4396,\tval_loss: 4.0323\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2746,\tval_loss: 4.0592\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2350,\tval_loss: 4.0676\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2393,\tval_loss: 4.0673\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1969,\tval_loss: 4.0774\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1614,\tval_loss: 4.0895\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1552,\tval_loss: 4.1171\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1015,\tval_loss: 4.1169\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0647,\tval_loss: 4.1416\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1114,\tval_loss: 4.1727\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0637,\tval_loss: 4.1528\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0033,\tval_loss: 4.1570\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0043,\tval_loss: 4.2663\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9757,\tval_loss: 4.2292\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0048,\tval_loss: 4.2896\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9854,\tval_loss: 4.2618\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9379,\tval_loss: 4.1898\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9227,\tval_loss: 4.3679\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.8788,\tval_loss: 4.2618\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9068,\tval_loss: 4.3139\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9449,\tval_loss: 4.3039\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9458,\tval_loss: 4.1881\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8548,\tval_loss: 4.2885\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7996,\tval_loss: 4.3480\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8111,\tval_loss: 4.2936\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8105,\tval_loss: 4.3552\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 3.8576,\tval_loss: 4.3060\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 3.7692,\tval_loss: 4.3218\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 3.7587,\tval_loss: 4.3063\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.7442,\tval_loss: 4.3158\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.7358,\tval_loss: 4.3640\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.8003,\tval_loss: 4.3472\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7418,\tval_loss: 4.3013\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.7374,\tval_loss: 4.3685\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.6826,\tval_loss: 4.3429\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.7057,\tval_loss: 4.4081\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.6940,\tval_loss: 4.3569\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.6745,\tval_loss: 4.3905\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.8033,\tval_loss: 4.2932\n",
            "39:\t[0s / 3s],\t\ttrain_loss: 3.6592,\tval_loss: 4.4731\n",
            "40:\t[0s / 3s],\t\ttrain_loss: 3.6323,\tval_loss: 4.3001\n",
            "41:\t[0s / 3s],\t\ttrain_loss: 3.6744,\tval_loss: 4.4120\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 3.5903,\tval_loss: 4.4453\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 3.5963,\tval_loss: 4.4528\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.6748,\tval_loss: 4.3763\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.6618,\tval_loss: 4.4031\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.5825,\tval_loss: 4.5256\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.6692,\tval_loss: 4.3265\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.5810,\tval_loss: 4.4694\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.5963,\tval_loss: 4.4015\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6046,\tval_loss: 4.4012\n",
            "51:\t[0s / 4s],\t\ttrain_loss: 3.6505,\tval_loss: 4.3894\n",
            "52:\t[0s / 4s],\t\ttrain_loss: 3.5902,\tval_loss: 4.3834\n",
            "53:\t[0s / 4s],\t\ttrain_loss: 3.5579,\tval_loss: 4.4583\n",
            "54:\t[0s / 4s],\t\ttrain_loss: 3.5820,\tval_loss: 4.3852\n",
            "55:\t[0s / 4s],\t\ttrain_loss: 3.5353,\tval_loss: 4.5536\n",
            "56:\t[0s / 4s],\t\ttrain_loss: 3.6693,\tval_loss: 4.3969\n",
            "57:\t[0s / 4s],\t\ttrain_loss: 3.6341,\tval_loss: 4.4411\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 3.5328,\tval_loss: 4.5032\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 3.5683,\tval_loss: 4.4469\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 3.5570,\tval_loss: 4.4546\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.6291,\tval_loss: 4.3803\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.5882,\tval_loss: 4.5470\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.6021,\tval_loss: 4.4111\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.5240,\tval_loss: 4.4724\n",
            "65:\t[0s / 5s],\t\ttrain_loss: 3.5051,\tval_loss: 4.4572\n",
            "66:\t[0s / 5s],\t\ttrain_loss: 3.5603,\tval_loss: 4.5153\n",
            "67:\t[0s / 5s],\t\ttrain_loss: 3.5591,\tval_loss: 4.4799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4360,\tval_loss: 4.1048\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2948,\tval_loss: 4.1230\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2641,\tval_loss: 4.1109\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2569,\tval_loss: 4.1051\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2289,\tval_loss: 4.1112\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2114,\tval_loss: 4.1181\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1764,\tval_loss: 4.1162\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1996,\tval_loss: 4.1171\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1749,\tval_loss: 4.1195\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1628,\tval_loss: 4.1441\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1579,\tval_loss: 4.1514\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1772,\tval_loss: 4.1862\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1741,\tval_loss: 4.1384\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 4.0827,\tval_loss: 4.2204\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.1120,\tval_loss: 4.2051\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0532,\tval_loss: 4.2118\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 4.0570,\tval_loss: 4.2510\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 4.0829,\tval_loss: 4.2847\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9957,\tval_loss: 4.2869\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 4.0321,\tval_loss: 4.3090\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 4.0155,\tval_loss: 4.3187\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9957,\tval_loss: 4.2922\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9816,\tval_loss: 4.3801\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9146,\tval_loss: 4.3700\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9135,\tval_loss: 4.3782\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9388,\tval_loss: 4.3568\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9359,\tval_loss: 4.3646\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9165,\tval_loss: 4.3223\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8453,\tval_loss: 4.4190\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8406,\tval_loss: 4.3840\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8831,\tval_loss: 4.3844\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8535,\tval_loss: 4.4148\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8452,\tval_loss: 4.3697\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8711,\tval_loss: 4.3842\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8422,\tval_loss: 4.4287\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.8353,\tval_loss: 4.3294\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.8198,\tval_loss: 4.3829\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.8311,\tval_loss: 4.3894\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7255,\tval_loss: 4.4586\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7417,\tval_loss: 4.4627\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7312,\tval_loss: 4.4618\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7220,\tval_loss: 4.4182\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7449,\tval_loss: 4.5041\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7724,\tval_loss: 4.4933\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7032,\tval_loss: 4.5110\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6807,\tval_loss: 4.5235\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6492,\tval_loss: 4.5527\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7453,\tval_loss: 4.4677\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6898,\tval_loss: 4.5989\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6167,\tval_loss: 4.6052\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6174,\tval_loss: 4.6283\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5832,\tval_loss: 4.5785\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7180,\tval_loss: 4.5385\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6147,\tval_loss: 4.4422\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5653,\tval_loss: 4.5387\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5425,\tval_loss: 4.6495\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5735,\tval_loss: 4.5162\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5974,\tval_loss: 4.5713\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5993,\tval_loss: 4.5708\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5514,\tval_loss: 4.5495\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5767,\tval_loss: 4.5443\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5858,\tval_loss: 4.5245\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6118,\tval_loss: 4.5926\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5877,\tval_loss: 4.6006\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5476,\tval_loss: 4.5762\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5569,\tval_loss: 4.5465\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5440,\tval_loss: 4.5830\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5174,\tval_loss: 4.6039\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3974,\tval_loss: 4.0834\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2844,\tval_loss: 4.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2090,\tval_loss: 4.0555\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1840,\tval_loss: 4.0495\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1436,\tval_loss: 4.0859\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1539,\tval_loss: 4.0820\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1125,\tval_loss: 4.1193\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0968,\tval_loss: 4.0899\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0726,\tval_loss: 4.1295\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0564,\tval_loss: 4.1434\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0398,\tval_loss: 4.1462\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0161,\tval_loss: 4.1526\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9753,\tval_loss: 4.1769\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9612,\tval_loss: 4.1780\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9784,\tval_loss: 4.2130\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9700,\tval_loss: 4.1949\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9468,\tval_loss: 4.2533\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9089,\tval_loss: 4.2652\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8837,\tval_loss: 4.1980\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9338,\tval_loss: 4.2736\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8902,\tval_loss: 4.1758\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9007,\tval_loss: 4.2171\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9085,\tval_loss: 4.1937\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8624,\tval_loss: 4.1579\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7756,\tval_loss: 4.2507\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7502,\tval_loss: 4.2538\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8680,\tval_loss: 4.1763\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8155,\tval_loss: 4.2475\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7650,\tval_loss: 4.2011\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7877,\tval_loss: 4.2388\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7308,\tval_loss: 4.1776\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7416,\tval_loss: 4.2041\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7625,\tval_loss: 4.2420\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6769,\tval_loss: 4.2800\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7170,\tval_loss: 4.1442\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7310,\tval_loss: 4.1707\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7157,\tval_loss: 4.2188\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7122,\tval_loss: 4.2680\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.8295,\tval_loss: 4.1636\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7182,\tval_loss: 4.2252\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6706,\tval_loss: 4.2536\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7791,\tval_loss: 4.1466\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.8276,\tval_loss: 4.1533\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.8262,\tval_loss: 4.2167\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7299,\tval_loss: 4.1686\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6607,\tval_loss: 4.1873\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6282,\tval_loss: 4.2782\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7991,\tval_loss: 4.1984\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7478,\tval_loss: 4.1438\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7428,\tval_loss: 4.2071\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6344,\tval_loss: 4.2694\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6835,\tval_loss: 4.2134\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6902,\tval_loss: 4.2452\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6520,\tval_loss: 4.2042\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6852,\tval_loss: 4.2077\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6933,\tval_loss: 4.2624\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6254,\tval_loss: 4.2396\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6124,\tval_loss: 4.2253\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6348,\tval_loss: 4.2649\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5499,\tval_loss: 4.3296\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6151,\tval_loss: 4.2967\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5824,\tval_loss: 4.2628\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6588,\tval_loss: 4.3139\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5695,\tval_loss: 4.3196\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6648,\tval_loss: 4.3380\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.7165,\tval_loss: 4.2134\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.7449,\tval_loss: 4.2388\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6641,\tval_loss: 4.1715\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6715,\tval_loss: 4.2841\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5901,\tval_loss: 4.4655\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5926,\tval_loss: 4.2101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.5027,\tval_loss: 4.0343\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3240,\tval_loss: 4.0466\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3095,\tval_loss: 4.0323\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.3008,\tval_loss: 4.0322\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2985,\tval_loss: 4.0407\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2891,\tval_loss: 4.0404\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2470,\tval_loss: 4.0310\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2035,\tval_loss: 4.0328\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.2385,\tval_loss: 4.0396\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1815,\tval_loss: 4.0448\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1714,\tval_loss: 4.0196\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1539,\tval_loss: 4.0556\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1183,\tval_loss: 4.0985\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1265,\tval_loss: 4.0639\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0574,\tval_loss: 4.1317\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0175,\tval_loss: 4.1186\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0049,\tval_loss: 4.1959\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0288,\tval_loss: 4.1482\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9834,\tval_loss: 4.2230\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9624,\tval_loss: 4.1922\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9525,\tval_loss: 4.1752\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9190,\tval_loss: 4.2055\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8798,\tval_loss: 4.2090\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8242,\tval_loss: 4.2544\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8914,\tval_loss: 4.2238\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8513,\tval_loss: 4.3254\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8147,\tval_loss: 4.3475\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7684,\tval_loss: 4.2768\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8521,\tval_loss: 4.2837\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7692,\tval_loss: 4.3127\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7526,\tval_loss: 4.2746\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7237,\tval_loss: 4.3387\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7763,\tval_loss: 4.3027\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7046,\tval_loss: 4.3320\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7097,\tval_loss: 4.3088\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7280,\tval_loss: 4.3451\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7497,\tval_loss: 4.3916\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7671,\tval_loss: 4.2747\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7797,\tval_loss: 4.2871\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6821,\tval_loss: 4.3387\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7312,\tval_loss: 4.3689\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7173,\tval_loss: 4.3887\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7057,\tval_loss: 4.3095\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7353,\tval_loss: 4.3182\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6983,\tval_loss: 4.2673\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5843,\tval_loss: 4.3383\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6922,\tval_loss: 4.3459\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6368,\tval_loss: 4.3627\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7073,\tval_loss: 4.3827\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6027,\tval_loss: 4.4073\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6244,\tval_loss: 4.4137\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6794,\tval_loss: 4.3571\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6864,\tval_loss: 4.3106\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6276,\tval_loss: 4.3151\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6415,\tval_loss: 4.4226\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6951,\tval_loss: 4.2783\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6379,\tval_loss: 4.3562\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6107,\tval_loss: 4.3738\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6052,\tval_loss: 4.4246\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6338,\tval_loss: 4.3437\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5622,\tval_loss: 4.5008\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6355,\tval_loss: 4.3654\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6043,\tval_loss: 4.3242\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6066,\tval_loss: 4.4277\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5702,\tval_loss: 4.4150\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.4809,\tval_loss: 4.5433\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5579,\tval_loss: 4.4405\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5677,\tval_loss: 4.4887\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5459,\tval_loss: 4.5332\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6113,\tval_loss: 4.3347\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6196,\tval_loss: 4.4121\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.6731,\tval_loss: 4.3849\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.5687,\tval_loss: 4.3818\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.5349,\tval_loss: 4.4745\n",
            "74:\t[0s / 3s],\t\ttrain_loss: 3.5585,\tval_loss: 4.3922\n",
            "75:\t[0s / 3s],\t\ttrain_loss: 3.6163,\tval_loss: 4.4133\n",
            "76:\t[0s / 3s],\t\ttrain_loss: 3.5589,\tval_loss: 4.3880\n",
            "77:\t[0s / 3s],\t\ttrain_loss: 3.5072,\tval_loss: 4.4316\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4265,\tval_loss: 4.0550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3188,\tval_loss: 4.0262\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2767,\tval_loss: 4.0206\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2524,\tval_loss: 4.0126\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2702,\tval_loss: 3.9985\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2493,\tval_loss: 4.0039\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1930,\tval_loss: 4.0078\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1898,\tval_loss: 3.9969\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1509,\tval_loss: 4.0149\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1522,\tval_loss: 4.0264\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1776,\tval_loss: 3.9927\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0950,\tval_loss: 4.0291\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0792,\tval_loss: 4.0261\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0809,\tval_loss: 4.0101\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0400,\tval_loss: 4.0222\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0937,\tval_loss: 4.0126\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 4.0199,\tval_loss: 4.0274\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 4.0290,\tval_loss: 4.0299\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 4.0280,\tval_loss: 4.0024\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9197,\tval_loss: 4.0460\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 4.0513,\tval_loss: 4.0648\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 4.0192,\tval_loss: 4.0230\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8856,\tval_loss: 4.0508\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9067,\tval_loss: 4.0773\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8683,\tval_loss: 4.1451\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9881,\tval_loss: 4.0610\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8980,\tval_loss: 4.1126\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9290,\tval_loss: 4.0853\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.9136,\tval_loss: 4.1048\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8863,\tval_loss: 4.0750\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.8701,\tval_loss: 4.1167\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.8565,\tval_loss: 4.0995\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.8564,\tval_loss: 4.0542\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.8850,\tval_loss: 4.0776\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.8032,\tval_loss: 4.0778\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.8731,\tval_loss: 4.1052\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.8687,\tval_loss: 4.1153\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.8322,\tval_loss: 4.1251\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7874,\tval_loss: 4.1477\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7515,\tval_loss: 4.1485\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.8415,\tval_loss: 4.2204\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.8058,\tval_loss: 4.1324\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7583,\tval_loss: 4.1294\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7591,\tval_loss: 4.1915\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7946,\tval_loss: 4.1161\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.7703,\tval_loss: 4.1549\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.7830,\tval_loss: 4.1369\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.8168,\tval_loss: 4.1516\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.7897,\tval_loss: 4.1668\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.8133,\tval_loss: 4.1704\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.7683,\tval_loss: 4.1526\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.7918,\tval_loss: 4.1501\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.7708,\tval_loss: 4.1769\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.8147,\tval_loss: 4.1578\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.7919,\tval_loss: 4.1888\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.7798,\tval_loss: 4.1124\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.7636,\tval_loss: 4.1646\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.7741,\tval_loss: 4.2110\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.7045,\tval_loss: 4.1829\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.7313,\tval_loss: 4.1935\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 3.7258,\tval_loss: 4.1501\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.7311,\tval_loss: 4.1774\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.7224,\tval_loss: 4.1899\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.7241,\tval_loss: 4.2071\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.6845,\tval_loss: 4.2281\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.7377,\tval_loss: 4.2611\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.7891,\tval_loss: 4.1941\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.7438,\tval_loss: 4.2340\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.7384,\tval_loss: 4.2416\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.6787,\tval_loss: 4.2164\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.6807,\tval_loss: 4.2209\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.7062,\tval_loss: 4.2298\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.7608,\tval_loss: 4.1827\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.7079,\tval_loss: 4.2167\n",
            "74:\t[0s / 4s],\t\ttrain_loss: 3.6607,\tval_loss: 4.2489\n",
            "75:\t[0s / 4s],\t\ttrain_loss: 3.6650,\tval_loss: 4.2494\n",
            "76:\t[0s / 5s],\t\ttrain_loss: 3.6992,\tval_loss: 4.2636\n",
            "77:\t[0s / 5s],\t\ttrain_loss: 3.6716,\tval_loss: 4.1539\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3806,\tval_loss: 4.0849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2018,\tval_loss: 4.1217\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1918,\tval_loss: 4.1089\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1578,\tval_loss: 4.0789\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.0796,\tval_loss: 4.1068\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.0687,\tval_loss: 4.1085\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0137,\tval_loss: 4.1321\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0460,\tval_loss: 4.1145\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0377,\tval_loss: 4.1328\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 3.9883,\tval_loss: 4.1126\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 3.9085,\tval_loss: 4.1624\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9541,\tval_loss: 4.1612\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9311,\tval_loss: 4.1742\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.8625,\tval_loss: 4.2187\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.8568,\tval_loss: 4.2804\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9293,\tval_loss: 4.2739\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.8458,\tval_loss: 4.2498\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8008,\tval_loss: 4.3247\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.7979,\tval_loss: 4.2665\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.7510,\tval_loss: 4.3388\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.7035,\tval_loss: 4.3166\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.6595,\tval_loss: 4.3588\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.6303,\tval_loss: 4.3025\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.5553,\tval_loss: 4.3803\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.5956,\tval_loss: 4.3213\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.5830,\tval_loss: 4.4115\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6792,\tval_loss: 4.3075\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.5867,\tval_loss: 4.3437\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6023,\tval_loss: 4.4006\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.4933,\tval_loss: 4.3317\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.5657,\tval_loss: 4.3742\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.4555,\tval_loss: 4.3583\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.5410,\tval_loss: 4.3260\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.4936,\tval_loss: 4.3037\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.5125,\tval_loss: 4.3246\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.5310,\tval_loss: 4.3769\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.5322,\tval_loss: 4.3833\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.5145,\tval_loss: 4.3338\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.5210,\tval_loss: 4.3568\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.5432,\tval_loss: 4.3605\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5060,\tval_loss: 4.3858\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5313,\tval_loss: 4.3883\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5737,\tval_loss: 4.3108\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.3851,\tval_loss: 4.3638\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.4517,\tval_loss: 4.3690\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.4166,\tval_loss: 4.4377\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5155,\tval_loss: 4.3524\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.4297,\tval_loss: 4.4626\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.4779,\tval_loss: 4.3264\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.4902,\tval_loss: 4.3337\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.4355,\tval_loss: 4.4149\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.3383,\tval_loss: 4.4301\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.3632,\tval_loss: 4.4414\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.4324,\tval_loss: 4.4193\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.3577,\tval_loss: 4.5709\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.4230,\tval_loss: 4.4928\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.4077,\tval_loss: 4.6145\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.4631,\tval_loss: 4.4139\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.4413,\tval_loss: 4.4973\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.4493,\tval_loss: 4.3791\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.3965,\tval_loss: 4.4845\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.3890,\tval_loss: 4.4546\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.3955,\tval_loss: 4.4758\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.4050,\tval_loss: 4.5160\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.3780,\tval_loss: 4.6390\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.3823,\tval_loss: 4.5056\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4174,\tval_loss: 4.5683\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.2927,\tval_loss: 4.6636\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.4001,\tval_loss: 4.4403\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.3394,\tval_loss: 4.5301\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.3997,\tval_loss: 4.4821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4649,\tval_loss: 4.0785\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3378,\tval_loss: 4.0613\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3302,\tval_loss: 4.0641\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2901,\tval_loss: 4.0573\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2761,\tval_loss: 4.0692\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2134,\tval_loss: 4.0801\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2259,\tval_loss: 4.0887\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2603,\tval_loss: 4.0864\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.2429,\tval_loss: 4.0591\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1978,\tval_loss: 4.0760\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1065,\tval_loss: 4.0927\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1502,\tval_loss: 4.0856\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1236,\tval_loss: 4.0789\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1133,\tval_loss: 4.1372\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0655,\tval_loss: 4.1058\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0371,\tval_loss: 4.0890\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9771,\tval_loss: 4.1377\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9618,\tval_loss: 4.1537\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9838,\tval_loss: 4.1691\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9913,\tval_loss: 4.0890\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9321,\tval_loss: 4.1519\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9158,\tval_loss: 4.1626\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8623,\tval_loss: 4.1326\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9297,\tval_loss: 4.1677\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8514,\tval_loss: 4.1588\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8609,\tval_loss: 4.1536\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8948,\tval_loss: 4.2685\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7920,\tval_loss: 4.1938\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7583,\tval_loss: 4.2433\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8548,\tval_loss: 4.1779\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8527,\tval_loss: 4.2285\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8057,\tval_loss: 4.2441\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7763,\tval_loss: 4.2907\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7049,\tval_loss: 4.2624\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7853,\tval_loss: 4.2015\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7236,\tval_loss: 4.2473\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7447,\tval_loss: 4.2470\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7522,\tval_loss: 4.2267\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6771,\tval_loss: 4.3403\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6811,\tval_loss: 4.3321\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7127,\tval_loss: 4.2568\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7276,\tval_loss: 4.3056\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6756,\tval_loss: 4.3674\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7164,\tval_loss: 4.2690\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6405,\tval_loss: 4.3139\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5997,\tval_loss: 4.3284\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7221,\tval_loss: 4.2823\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6782,\tval_loss: 4.3130\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6495,\tval_loss: 4.2438\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6617,\tval_loss: 4.2519\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6247,\tval_loss: 4.2988\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6496,\tval_loss: 4.2869\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6111,\tval_loss: 4.3558\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5884,\tval_loss: 4.4246\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6455,\tval_loss: 4.3280\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6249,\tval_loss: 4.3693\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5797,\tval_loss: 4.3913\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5701,\tval_loss: 4.4283\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5803,\tval_loss: 4.3988\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6143,\tval_loss: 4.4097\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5329,\tval_loss: 4.3812\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6059,\tval_loss: 4.3734\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5746,\tval_loss: 4.3372\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5599,\tval_loss: 4.3218\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5703,\tval_loss: 4.4017\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5383,\tval_loss: 4.3995\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5177,\tval_loss: 4.4851\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5282,\tval_loss: 4.3832\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5609,\tval_loss: 4.4840\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.5574,\tval_loss: 4.3439\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5072,\tval_loss: 4.3885\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.5659,\tval_loss: 4.1104\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3378,\tval_loss: 4.0894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3024,\tval_loss: 4.0872\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2423,\tval_loss: 4.1162\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2479,\tval_loss: 4.0848\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1885,\tval_loss: 4.1071\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1947,\tval_loss: 4.1112\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1686,\tval_loss: 4.1079\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1273,\tval_loss: 4.1149\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1218,\tval_loss: 4.1365\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1111,\tval_loss: 4.1295\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0905,\tval_loss: 4.1445\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0669,\tval_loss: 4.1510\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 4.0259,\tval_loss: 4.1726\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0384,\tval_loss: 4.1503\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0089,\tval_loss: 4.1687\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9861,\tval_loss: 4.1483\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9775,\tval_loss: 4.1955\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9546,\tval_loss: 4.1812\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9030,\tval_loss: 4.2112\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9213,\tval_loss: 4.2211\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8979,\tval_loss: 4.2321\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9346,\tval_loss: 4.2171\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9085,\tval_loss: 4.2779\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8999,\tval_loss: 4.2474\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8723,\tval_loss: 4.2608\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8195,\tval_loss: 4.2488\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8962,\tval_loss: 4.1906\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8963,\tval_loss: 4.2570\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8628,\tval_loss: 4.2447\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7864,\tval_loss: 4.2372\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7556,\tval_loss: 4.3090\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8173,\tval_loss: 4.2200\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.7881,\tval_loss: 4.2978\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7465,\tval_loss: 4.3230\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.8040,\tval_loss: 4.2538\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.8517,\tval_loss: 4.2692\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.8036,\tval_loss: 4.4073\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.7950,\tval_loss: 4.2587\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7623,\tval_loss: 4.2871\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7665,\tval_loss: 4.3559\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7524,\tval_loss: 4.3099\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7623,\tval_loss: 4.3005\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7684,\tval_loss: 4.3101\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7331,\tval_loss: 4.2838\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7283,\tval_loss: 4.3143\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7603,\tval_loss: 4.3173\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.8249,\tval_loss: 4.3509\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7706,\tval_loss: 4.3050\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7102,\tval_loss: 4.2125\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6831,\tval_loss: 4.3504\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7307,\tval_loss: 4.2884\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7047,\tval_loss: 4.2963\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7033,\tval_loss: 4.2815\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6264,\tval_loss: 4.3382\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6533,\tval_loss: 4.2619\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6627,\tval_loss: 4.3496\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6839,\tval_loss: 4.3136\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6883,\tval_loss: 4.3784\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6785,\tval_loss: 4.3547\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6682,\tval_loss: 4.3245\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6177,\tval_loss: 4.3292\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5334,\tval_loss: 4.4301\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5684,\tval_loss: 4.3217\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6192,\tval_loss: 4.3333\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6429,\tval_loss: 4.3862\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6887,\tval_loss: 4.2905\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6395,\tval_loss: 4.3502\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6402,\tval_loss: 4.3155\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6459,\tval_loss: 4.3518\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5853,\tval_loss: 4.3066\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.6454,\tval_loss: 4.3260\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3781,\tval_loss: 4.0989\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2786,\tval_loss: 4.1126\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2520,\tval_loss: 4.1006\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2163,\tval_loss: 4.1359\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2174,\tval_loss: 4.0708\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2189,\tval_loss: 4.0815\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2084,\tval_loss: 4.0750\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1962,\tval_loss: 4.0707\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1714,\tval_loss: 4.0465\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1902,\tval_loss: 4.0634\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1542,\tval_loss: 4.0649\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1623,\tval_loss: 4.0532\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0903,\tval_loss: 4.0196\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 4.1216,\tval_loss: 4.0936\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0851,\tval_loss: 4.0454\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0587,\tval_loss: 4.0768\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9984,\tval_loss: 4.1272\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9957,\tval_loss: 4.0982\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 4.0748,\tval_loss: 4.1477\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 4.0492,\tval_loss: 4.0950\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9463,\tval_loss: 4.1739\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9749,\tval_loss: 4.1458\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9691,\tval_loss: 4.1774\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9923,\tval_loss: 4.1138\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9386,\tval_loss: 4.1375\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8437,\tval_loss: 4.1936\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8653,\tval_loss: 4.1489\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 3.8542,\tval_loss: 4.1815\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 3.9338,\tval_loss: 4.1616\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.9010,\tval_loss: 4.1607\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.8917,\tval_loss: 4.1989\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.8321,\tval_loss: 4.1652\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.8361,\tval_loss: 4.2351\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.8030,\tval_loss: 4.2009\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7334,\tval_loss: 4.2812\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.8418,\tval_loss: 4.2059\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.7172,\tval_loss: 4.2484\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.8086,\tval_loss: 4.2919\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.8662,\tval_loss: 4.2144\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.8719,\tval_loss: 4.2693\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7962,\tval_loss: 4.2260\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7295,\tval_loss: 4.3061\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 3.7787,\tval_loss: 4.3322\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 3.7836,\tval_loss: 4.2954\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.8203,\tval_loss: 4.2525\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.7759,\tval_loss: 4.2622\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.7618,\tval_loss: 4.2611\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.7370,\tval_loss: 4.3130\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.7166,\tval_loss: 4.3844\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.7405,\tval_loss: 4.2809\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6642,\tval_loss: 4.3489\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.6634,\tval_loss: 4.2964\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.7868,\tval_loss: 4.2455\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.7192,\tval_loss: 4.3456\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.7789,\tval_loss: 4.2583\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.7206,\tval_loss: 4.3271\n",
            "56:\t[0s / 4s],\t\ttrain_loss: 3.6917,\tval_loss: 4.2957\n",
            "57:\t[0s / 4s],\t\ttrain_loss: 3.7265,\tval_loss: 4.2820\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 3.7908,\tval_loss: 4.2111\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 3.6832,\tval_loss: 4.3212\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 3.6115,\tval_loss: 4.2815\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.7431,\tval_loss: 4.2659\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.6987,\tval_loss: 4.3180\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.7281,\tval_loss: 4.3089\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.7657,\tval_loss: 4.3371\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.6694,\tval_loss: 4.3546\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.6943,\tval_loss: 4.3118\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.7353,\tval_loss: 4.2802\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.7052,\tval_loss: 4.2858\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.7603,\tval_loss: 4.2537\n",
            "70:\t[0s / 5s],\t\ttrain_loss: 3.6443,\tval_loss: 4.3956\n",
            "71:\t[0s / 5s],\t\ttrain_loss: 3.7409,\tval_loss: 4.2930\n",
            "72:\t[0s / 5s],\t\ttrain_loss: 3.6984,\tval_loss: 4.2948\n",
            "73:\t[0s / 5s],\t\ttrain_loss: 3.7412,\tval_loss: 4.2940\n",
            "74:\t[0s / 5s],\t\ttrain_loss: 3.6637,\tval_loss: 4.3212\n",
            "75:\t[0s / 5s],\t\ttrain_loss: 3.6983,\tval_loss: 4.3467\n",
            "76:\t[0s / 5s],\t\ttrain_loss: 3.6504,\tval_loss: 4.3637\n",
            "77:\t[0s / 5s],\t\ttrain_loss: 3.6223,\tval_loss: 4.3997\n",
            "78:\t[0s / 5s],\t\ttrain_loss: 3.6032,\tval_loss: 4.4106\n",
            "79:\t[0s / 5s],\t\ttrain_loss: 3.6687,\tval_loss: 4.4014\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4524,\tval_loss: 4.0541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3291,\tval_loss: 4.0429\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2705,\tval_loss: 4.0433\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2662,\tval_loss: 4.0388\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2463,\tval_loss: 4.0414\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2286,\tval_loss: 4.0492\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2146,\tval_loss: 4.0488\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.2165,\tval_loss: 4.0473\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1979,\tval_loss: 4.0567\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1731,\tval_loss: 4.0592\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1807,\tval_loss: 4.0508\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1880,\tval_loss: 4.0381\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.1689,\tval_loss: 4.0651\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.1565,\tval_loss: 4.0635\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.1234,\tval_loss: 4.0961\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.1113,\tval_loss: 4.0751\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0820,\tval_loss: 4.1030\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0741,\tval_loss: 4.0830\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.0648,\tval_loss: 4.1265\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 4.0800,\tval_loss: 4.1001\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 4.0231,\tval_loss: 4.1305\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 4.0033,\tval_loss: 4.1458\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9849,\tval_loss: 4.1577\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9288,\tval_loss: 4.1637\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9430,\tval_loss: 4.1866\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.9462,\tval_loss: 4.1945\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.9231,\tval_loss: 4.2054\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9337,\tval_loss: 4.2213\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.9616,\tval_loss: 4.1012\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.9597,\tval_loss: 4.1613\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8562,\tval_loss: 4.2243\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8703,\tval_loss: 4.2321\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8394,\tval_loss: 4.3281\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.8136,\tval_loss: 4.2539\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8107,\tval_loss: 4.1974\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.8065,\tval_loss: 4.2324\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7663,\tval_loss: 4.2576\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.8014,\tval_loss: 4.1997\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.8097,\tval_loss: 4.2087\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.8068,\tval_loss: 4.1989\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.8379,\tval_loss: 4.1673\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 3.7574,\tval_loss: 4.2578\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7548,\tval_loss: 4.2646\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7683,\tval_loss: 4.2299\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7506,\tval_loss: 4.2965\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7018,\tval_loss: 4.2840\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7195,\tval_loss: 4.2433\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6677,\tval_loss: 4.2977\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6615,\tval_loss: 4.2351\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6835,\tval_loss: 4.2809\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6880,\tval_loss: 4.2447\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6899,\tval_loss: 4.2876\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7346,\tval_loss: 4.2553\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7038,\tval_loss: 4.2707\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6386,\tval_loss: 4.2527\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5738,\tval_loss: 4.3306\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6592,\tval_loss: 4.2738\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6482,\tval_loss: 4.2507\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.7286,\tval_loss: 4.2591\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6723,\tval_loss: 4.2399\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6831,\tval_loss: 4.2786\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6830,\tval_loss: 4.1731\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6179,\tval_loss: 4.1781\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6489,\tval_loss: 4.3317\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.7028,\tval_loss: 4.1844\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6162,\tval_loss: 4.2003\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.7068,\tval_loss: 4.2695\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6271,\tval_loss: 4.2710\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6403,\tval_loss: 4.2340\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6705,\tval_loss: 4.2615\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.5453,\tval_loss: 4.2178\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.5838,\tval_loss: 4.2970\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.5404,\tval_loss: 4.2276\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 3.6423,\tval_loss: 4.1758\n",
            "74:\t[0s / 3s],\t\ttrain_loss: 3.6211,\tval_loss: 4.2882\n",
            "75:\t[0s / 3s],\t\ttrain_loss: 3.6162,\tval_loss: 4.1899\n",
            "76:\t[0s / 3s],\t\ttrain_loss: 3.6077,\tval_loss: 4.2630\n",
            "77:\t[0s / 3s],\t\ttrain_loss: 3.5982,\tval_loss: 4.2563\n",
            "78:\t[0s / 3s],\t\ttrain_loss: 3.5783,\tval_loss: 4.3284\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4536,\tval_loss: 4.0858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2990,\tval_loss: 4.1298\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2567,\tval_loss: 4.1346\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2141,\tval_loss: 4.1225\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1834,\tval_loss: 4.1280\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1752,\tval_loss: 4.1156\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1459,\tval_loss: 4.1482\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1292,\tval_loss: 4.1402\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1264,\tval_loss: 4.1389\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0977,\tval_loss: 4.1753\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1207,\tval_loss: 4.1369\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0584,\tval_loss: 4.1664\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0433,\tval_loss: 4.1457\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9843,\tval_loss: 4.2288\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9802,\tval_loss: 4.2274\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9663,\tval_loss: 4.2482\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9643,\tval_loss: 4.1807\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9486,\tval_loss: 4.2749\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9169,\tval_loss: 4.2657\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9104,\tval_loss: 4.2494\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8389,\tval_loss: 4.3373\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8900,\tval_loss: 4.3012\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8388,\tval_loss: 4.3374\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8408,\tval_loss: 4.2889\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8470,\tval_loss: 4.3609\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8074,\tval_loss: 4.3089\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8200,\tval_loss: 4.2836\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7438,\tval_loss: 4.3242\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8046,\tval_loss: 4.2619\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7315,\tval_loss: 4.3673\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7440,\tval_loss: 4.3712\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6702,\tval_loss: 4.3979\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6797,\tval_loss: 4.3602\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6633,\tval_loss: 4.3982\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7260,\tval_loss: 4.3210\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6906,\tval_loss: 4.3845\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6907,\tval_loss: 4.4219\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6766,\tval_loss: 4.3389\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6609,\tval_loss: 4.4820\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.6836,\tval_loss: 4.4052\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6357,\tval_loss: 4.4003\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7159,\tval_loss: 4.3482\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6461,\tval_loss: 4.4014\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6790,\tval_loss: 4.3587\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5837,\tval_loss: 4.4116\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6615,\tval_loss: 4.3305\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6887,\tval_loss: 4.4707\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6350,\tval_loss: 4.4272\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6198,\tval_loss: 4.4068\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6966,\tval_loss: 4.3293\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7785,\tval_loss: 4.3221\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6185,\tval_loss: 4.4376\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6162,\tval_loss: 4.4079\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5584,\tval_loss: 4.5378\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5996,\tval_loss: 4.4919\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5896,\tval_loss: 4.3546\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6243,\tval_loss: 4.4332\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6171,\tval_loss: 4.4055\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.6459,\tval_loss: 4.4021\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5931,\tval_loss: 4.4128\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6054,\tval_loss: 4.4297\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6144,\tval_loss: 4.4669\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5910,\tval_loss: 4.5123\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5672,\tval_loss: 4.4274\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5297,\tval_loss: 4.5152\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5414,\tval_loss: 4.5497\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5170,\tval_loss: 4.5459\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5989,\tval_loss: 4.3940\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4093,\tval_loss: 4.0111\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3041,\tval_loss: 3.9917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2618,\tval_loss: 3.9839\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2026,\tval_loss: 3.9789\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1779,\tval_loss: 3.9862\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1188,\tval_loss: 4.0040\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0999,\tval_loss: 4.0410\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1195,\tval_loss: 4.0502\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0945,\tval_loss: 4.0257\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0799,\tval_loss: 4.0609\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0824,\tval_loss: 4.1120\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0100,\tval_loss: 4.1070\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0393,\tval_loss: 4.1423\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9611,\tval_loss: 4.1662\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0047,\tval_loss: 4.1584\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9640,\tval_loss: 4.1794\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9436,\tval_loss: 4.1606\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9715,\tval_loss: 4.2114\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9683,\tval_loss: 4.1669\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9513,\tval_loss: 4.1943\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9174,\tval_loss: 4.1915\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9017,\tval_loss: 4.2720\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9156,\tval_loss: 4.2757\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9349,\tval_loss: 4.2198\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8981,\tval_loss: 4.2275\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8982,\tval_loss: 4.2859\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8918,\tval_loss: 4.2049\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8715,\tval_loss: 4.2518\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8577,\tval_loss: 4.1978\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8923,\tval_loss: 4.2322\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8081,\tval_loss: 4.2160\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8138,\tval_loss: 4.2902\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8394,\tval_loss: 4.2010\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7998,\tval_loss: 4.2239\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.8119,\tval_loss: 4.3111\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7939,\tval_loss: 4.2962\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7781,\tval_loss: 4.2482\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.8062,\tval_loss: 4.2383\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7822,\tval_loss: 4.2850\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7710,\tval_loss: 4.2991\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7494,\tval_loss: 4.2542\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7977,\tval_loss: 4.3158\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.8035,\tval_loss: 4.3005\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.7826,\tval_loss: 4.2830\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6624,\tval_loss: 4.2797\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.7148,\tval_loss: 4.3105\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6811,\tval_loss: 4.2877\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7373,\tval_loss: 4.2788\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.7140,\tval_loss: 4.3032\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.7062,\tval_loss: 4.3424\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.7137,\tval_loss: 4.3135\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.7454,\tval_loss: 4.2878\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.6257,\tval_loss: 4.3362\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6813,\tval_loss: 4.3051\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.6789,\tval_loss: 4.2959\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.7066,\tval_loss: 4.2650\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6963,\tval_loss: 4.3510\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.7556,\tval_loss: 4.2562\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.7788,\tval_loss: 4.2584\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6436,\tval_loss: 4.2878\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6442,\tval_loss: 4.3461\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.7354,\tval_loss: 4.3173\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.6718,\tval_loss: 4.3479\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.6576,\tval_loss: 4.2758\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.7056,\tval_loss: 4.3804\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6945,\tval_loss: 4.2520\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6155,\tval_loss: 4.3485\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6663,\tval_loss: 4.3224\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.5728,\tval_loss: 4.4171\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6357,\tval_loss: 4.3665\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6170,\tval_loss: 4.3369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.5202,\tval_loss: 4.0717\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2808,\tval_loss: 4.0458\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2646,\tval_loss: 4.0531\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2340,\tval_loss: 4.0249\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2407,\tval_loss: 4.0307\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2161,\tval_loss: 4.0402\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2003,\tval_loss: 4.0156\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1716,\tval_loss: 4.0023\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1245,\tval_loss: 4.0518\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1044,\tval_loss: 4.0385\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0970,\tval_loss: 4.0358\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0711,\tval_loss: 3.9841\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 4.0342,\tval_loss: 4.1062\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 4.0363,\tval_loss: 4.0390\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0309,\tval_loss: 4.0424\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0143,\tval_loss: 4.0704\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 4.0167,\tval_loss: 4.0676\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 4.0416,\tval_loss: 4.1255\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.9999,\tval_loss: 4.0844\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9686,\tval_loss: 4.1143\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9899,\tval_loss: 4.1412\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8899,\tval_loss: 4.1482\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8859,\tval_loss: 4.0831\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8866,\tval_loss: 4.0929\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8896,\tval_loss: 4.1600\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8594,\tval_loss: 4.1698\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 3.8823,\tval_loss: 4.1083\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 3.8478,\tval_loss: 4.1238\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 3.8508,\tval_loss: 4.0830\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.8931,\tval_loss: 4.1051\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.9013,\tval_loss: 4.1868\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.7975,\tval_loss: 4.2099\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7911,\tval_loss: 4.2648\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.8813,\tval_loss: 4.1270\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.7860,\tval_loss: 4.1669\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.8135,\tval_loss: 4.2092\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.8194,\tval_loss: 4.0903\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.8183,\tval_loss: 4.2100\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.8178,\tval_loss: 4.1732\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7988,\tval_loss: 4.1641\n",
            "40:\t[0s / 3s],\t\ttrain_loss: 3.8068,\tval_loss: 4.1677\n",
            "41:\t[0s / 3s],\t\ttrain_loss: 3.7942,\tval_loss: 4.2020\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 3.7689,\tval_loss: 4.1850\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 3.7295,\tval_loss: 4.2007\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.7802,\tval_loss: 4.1058\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.8357,\tval_loss: 4.1798\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.7535,\tval_loss: 4.2482\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.7405,\tval_loss: 4.3028\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.7493,\tval_loss: 4.1741\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.7866,\tval_loss: 4.1739\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.7772,\tval_loss: 4.1864\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.7547,\tval_loss: 4.1738\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.8635,\tval_loss: 4.1158\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.7344,\tval_loss: 4.2463\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.8087,\tval_loss: 4.1397\n",
            "55:\t[0s / 4s],\t\ttrain_loss: 3.7521,\tval_loss: 4.2028\n",
            "56:\t[0s / 4s],\t\ttrain_loss: 3.7845,\tval_loss: 4.2168\n",
            "57:\t[0s / 4s],\t\ttrain_loss: 3.7824,\tval_loss: 4.1707\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 3.7315,\tval_loss: 4.1401\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 3.7799,\tval_loss: 4.2164\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 3.7456,\tval_loss: 4.1896\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 3.7872,\tval_loss: 4.2936\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 3.7281,\tval_loss: 4.2149\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 3.6836,\tval_loss: 4.2504\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 3.7127,\tval_loss: 4.1880\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.7561,\tval_loss: 4.1740\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.7111,\tval_loss: 4.2545\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.7049,\tval_loss: 4.2456\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.6486,\tval_loss: 4.4163\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.7747,\tval_loss: 4.1638\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.7390,\tval_loss: 4.2971\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.6939,\tval_loss: 4.2013\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.6783,\tval_loss: 4.1997\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 3.7059,\tval_loss: 4.2479\n",
            "74:\t[0s / 4s],\t\ttrain_loss: 3.6706,\tval_loss: 4.3799\n",
            "75:\t[0s / 4s],\t\ttrain_loss: 3.7752,\tval_loss: 4.0924\n",
            "76:\t[0s / 5s],\t\ttrain_loss: 3.6918,\tval_loss: 4.2213\n",
            "77:\t[0s / 5s],\t\ttrain_loss: 3.7704,\tval_loss: 4.1146\n",
            "78:\t[0s / 5s],\t\ttrain_loss: 3.7451,\tval_loss: 4.2580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4127,\tval_loss: 4.1066\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3289,\tval_loss: 4.0652\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2700,\tval_loss: 4.0858\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2520,\tval_loss: 4.0686\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2312,\tval_loss: 4.0676\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1968,\tval_loss: 4.0806\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1522,\tval_loss: 4.0807\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1422,\tval_loss: 4.0945\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0794,\tval_loss: 4.2134\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0397,\tval_loss: 4.1465\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0285,\tval_loss: 4.2302\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.9924,\tval_loss: 4.1785\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9711,\tval_loss: 4.2702\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9433,\tval_loss: 4.3018\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9418,\tval_loss: 4.2550\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9368,\tval_loss: 4.2116\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.7981,\tval_loss: 4.3468\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8110,\tval_loss: 4.2949\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.7788,\tval_loss: 4.2956\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.7864,\tval_loss: 4.3327\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.7793,\tval_loss: 4.3106\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7883,\tval_loss: 4.3198\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7852,\tval_loss: 4.4106\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8143,\tval_loss: 4.2465\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7121,\tval_loss: 4.3059\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6835,\tval_loss: 4.4759\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6316,\tval_loss: 4.4203\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7102,\tval_loss: 4.2849\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6807,\tval_loss: 4.3585\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.6696,\tval_loss: 4.4050\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6670,\tval_loss: 4.3388\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6253,\tval_loss: 4.3501\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.5945,\tval_loss: 4.4918\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6952,\tval_loss: 4.3776\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6490,\tval_loss: 4.3226\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6336,\tval_loss: 4.3881\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6310,\tval_loss: 4.4415\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.5498,\tval_loss: 4.4835\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.5748,\tval_loss: 4.4715\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.5765,\tval_loss: 4.4808\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.5592,\tval_loss: 4.4296\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5813,\tval_loss: 4.4439\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6265,\tval_loss: 4.3555\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5410,\tval_loss: 4.4073\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5018,\tval_loss: 4.4524\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5226,\tval_loss: 4.4864\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5356,\tval_loss: 4.4069\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.4882,\tval_loss: 4.4396\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5069,\tval_loss: 4.4211\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.4664,\tval_loss: 4.4955\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5725,\tval_loss: 4.4035\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.4559,\tval_loss: 4.4214\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5264,\tval_loss: 4.4185\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.5452,\tval_loss: 4.4733\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.4245,\tval_loss: 4.4299\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.4351,\tval_loss: 4.4810\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.4416,\tval_loss: 4.3679\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.4702,\tval_loss: 4.4664\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5142,\tval_loss: 4.5020\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5434,\tval_loss: 4.4189\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.4663,\tval_loss: 4.5315\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5070,\tval_loss: 4.4276\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.5039,\tval_loss: 4.4024\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.4635,\tval_loss: 4.5955\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5225,\tval_loss: 4.4550\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.4907,\tval_loss: 4.4744\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4076,\tval_loss: 4.4773\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4609,\tval_loss: 4.4723\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.4514,\tval_loss: 4.4388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3871,\tval_loss: 4.1085\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2211,\tval_loss: 4.0991\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.1968,\tval_loss: 4.0996\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1649,\tval_loss: 4.0917\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2013,\tval_loss: 4.0897\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1305,\tval_loss: 4.1050\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0869,\tval_loss: 4.1382\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.0781,\tval_loss: 4.1140\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.0925,\tval_loss: 4.1677\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0546,\tval_loss: 4.1397\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 3.9817,\tval_loss: 4.1471\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0338,\tval_loss: 4.1710\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.9574,\tval_loss: 4.2073\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9253,\tval_loss: 4.2712\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9209,\tval_loss: 4.2358\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.8610,\tval_loss: 4.2864\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.8940,\tval_loss: 4.3211\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.8709,\tval_loss: 4.3567\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8843,\tval_loss: 4.3075\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8263,\tval_loss: 4.3331\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8048,\tval_loss: 4.3148\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8502,\tval_loss: 4.3983\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7502,\tval_loss: 4.4278\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8447,\tval_loss: 4.3991\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7752,\tval_loss: 4.4035\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8122,\tval_loss: 4.3404\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7784,\tval_loss: 4.4517\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6840,\tval_loss: 4.4244\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7620,\tval_loss: 4.3453\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7118,\tval_loss: 4.4786\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6262,\tval_loss: 4.4250\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6558,\tval_loss: 4.3627\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6454,\tval_loss: 4.4944\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6339,\tval_loss: 4.4608\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.5752,\tval_loss: 4.4588\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6403,\tval_loss: 4.3930\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6336,\tval_loss: 4.4229\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.5861,\tval_loss: 4.4338\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.5884,\tval_loss: 4.4548\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.5894,\tval_loss: 4.5149\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.5520,\tval_loss: 4.4620\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5907,\tval_loss: 4.5283\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5658,\tval_loss: 4.4822\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6098,\tval_loss: 4.5137\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.5840,\tval_loss: 4.4519\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5848,\tval_loss: 4.4898\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5761,\tval_loss: 4.4164\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5594,\tval_loss: 4.5275\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5293,\tval_loss: 4.6053\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5374,\tval_loss: 4.5720\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5367,\tval_loss: 4.5059\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5144,\tval_loss: 4.4661\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5290,\tval_loss: 4.5070\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.4612,\tval_loss: 4.5811\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5467,\tval_loss: 4.6259\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5188,\tval_loss: 4.5050\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5058,\tval_loss: 4.4898\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.4699,\tval_loss: 4.4945\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.4534,\tval_loss: 4.5435\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.4823,\tval_loss: 4.5725\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.4894,\tval_loss: 4.4754\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.4831,\tval_loss: 4.4723\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.4361,\tval_loss: 4.5906\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.4341,\tval_loss: 4.5818\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.4175,\tval_loss: 4.5086\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.4222,\tval_loss: 4.5587\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5027,\tval_loss: 4.5794\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.4985,\tval_loss: 4.5786\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.4371,\tval_loss: 4.5533\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.4218,\tval_loss: 4.4748\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.4017,\tval_loss: 4.6158\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.4019,\tval_loss: 4.6535\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.3459,\tval_loss: 4.0814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2530,\tval_loss: 4.0841\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2051,\tval_loss: 4.0862\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2053,\tval_loss: 4.0721\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1668,\tval_loss: 4.0768\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1570,\tval_loss: 4.0767\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1526,\tval_loss: 4.0962\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1717,\tval_loss: 4.0996\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1237,\tval_loss: 4.1242\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1201,\tval_loss: 4.1227\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0959,\tval_loss: 4.1366\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0829,\tval_loss: 4.1415\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0461,\tval_loss: 4.1798\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0239,\tval_loss: 4.1941\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0144,\tval_loss: 4.2508\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9841,\tval_loss: 4.2289\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9654,\tval_loss: 4.3026\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9921,\tval_loss: 4.1794\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9711,\tval_loss: 4.3202\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8355,\tval_loss: 4.2715\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8959,\tval_loss: 4.3785\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8532,\tval_loss: 4.3004\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8220,\tval_loss: 4.3633\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.7895,\tval_loss: 4.3632\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8576,\tval_loss: 4.3144\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7704,\tval_loss: 4.4032\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7820,\tval_loss: 4.2981\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7722,\tval_loss: 4.3799\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8283,\tval_loss: 4.3074\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7467,\tval_loss: 4.3788\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.6954,\tval_loss: 4.3574\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.6964,\tval_loss: 4.3496\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7013,\tval_loss: 4.3378\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6594,\tval_loss: 4.3990\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7006,\tval_loss: 4.4140\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6879,\tval_loss: 4.4716\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6714,\tval_loss: 4.4162\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.5734,\tval_loss: 4.4285\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6755,\tval_loss: 4.4599\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6553,\tval_loss: 4.4767\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6988,\tval_loss: 4.5418\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6296,\tval_loss: 4.4277\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6811,\tval_loss: 4.5670\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6473,\tval_loss: 4.5147\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6296,\tval_loss: 4.4937\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6908,\tval_loss: 4.5288\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6033,\tval_loss: 4.4918\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6101,\tval_loss: 4.6184\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5869,\tval_loss: 4.4664\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6036,\tval_loss: 4.5558\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6526,\tval_loss: 4.5007\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5726,\tval_loss: 4.5479\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.5923,\tval_loss: 4.4771\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6244,\tval_loss: 4.4998\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.5411,\tval_loss: 4.5480\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.5030,\tval_loss: 4.5837\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5149,\tval_loss: 4.5411\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5437,\tval_loss: 4.5700\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.5912,\tval_loss: 4.4379\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.5422,\tval_loss: 4.5231\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5307,\tval_loss: 4.5372\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5573,\tval_loss: 4.5742\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.4930,\tval_loss: 4.5621\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5960,\tval_loss: 4.4497\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.4986,\tval_loss: 4.6286\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5052,\tval_loss: 4.5789\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.5536,\tval_loss: 4.5517\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.4694,\tval_loss: 4.5216\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.5449,\tval_loss: 4.5436\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.5769,\tval_loss: 4.4650\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.5862,\tval_loss: 4.4899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4461,\tval_loss: 4.0947\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3369,\tval_loss: 4.1006\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2977,\tval_loss: 4.1031\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2611,\tval_loss: 4.1307\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2628,\tval_loss: 4.0702\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2280,\tval_loss: 4.0549\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2154,\tval_loss: 4.0993\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1788,\tval_loss: 4.0809\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1189,\tval_loss: 4.1317\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1121,\tval_loss: 4.1005\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1724,\tval_loss: 4.1302\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0872,\tval_loss: 4.1794\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0156,\tval_loss: 4.2347\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0010,\tval_loss: 4.1996\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.9684,\tval_loss: 4.2442\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.9267,\tval_loss: 4.2444\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.9138,\tval_loss: 4.3104\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.8745,\tval_loss: 4.2935\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.8347,\tval_loss: 4.4011\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.8599,\tval_loss: 4.3829\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.7978,\tval_loss: 4.4996\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.7858,\tval_loss: 4.4240\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.7917,\tval_loss: 4.5173\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.6516,\tval_loss: 4.5583\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7562,\tval_loss: 4.4744\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6717,\tval_loss: 4.5343\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6908,\tval_loss: 4.5328\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.6454,\tval_loss: 4.5891\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.6490,\tval_loss: 4.4862\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.6367,\tval_loss: 4.5784\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.6519,\tval_loss: 4.6911\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.6230,\tval_loss: 4.5281\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.6480,\tval_loss: 4.5635\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.5949,\tval_loss: 4.5229\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.5647,\tval_loss: 4.6279\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.5539,\tval_loss: 4.5632\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.5837,\tval_loss: 4.6323\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.5635,\tval_loss: 4.5795\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.5887,\tval_loss: 4.6066\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.5300,\tval_loss: 4.5505\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.4832,\tval_loss: 4.6061\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.5094,\tval_loss: 4.6441\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.5151,\tval_loss: 4.5877\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.5306,\tval_loss: 4.7010\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.5956,\tval_loss: 4.5436\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.4758,\tval_loss: 4.6385\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.4884,\tval_loss: 4.6611\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.4988,\tval_loss: 4.6586\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.4975,\tval_loss: 4.5448\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.4787,\tval_loss: 4.5982\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.5220,\tval_loss: 4.7327\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.4662,\tval_loss: 4.5735\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.5297,\tval_loss: 4.5862\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.5455,\tval_loss: 4.5238\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.5007,\tval_loss: 4.6041\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.4935,\tval_loss: 4.5352\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5148,\tval_loss: 4.6262\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.4418,\tval_loss: 4.6700\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.4371,\tval_loss: 4.6440\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.4899,\tval_loss: 4.6554\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.4302,\tval_loss: 4.6386\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5216,\tval_loss: 4.5929\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.3772,\tval_loss: 4.6798\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.3873,\tval_loss: 4.6425\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.4383,\tval_loss: 4.5686\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.4144,\tval_loss: 4.7196\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.4290,\tval_loss: 4.5940\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.4070,\tval_loss: 4.6179\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.4138,\tval_loss: 4.7085\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.4055,\tval_loss: 4.6266\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.4733,\tval_loss: 4.7722\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.4535,\tval_loss: 4.6756\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.3606,\tval_loss: 4.7027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4827,\tval_loss: 4.0522\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3224,\tval_loss: 4.0578\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.3007,\tval_loss: 4.0608\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2617,\tval_loss: 4.0507\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2450,\tval_loss: 4.0648\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1893,\tval_loss: 4.0437\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1863,\tval_loss: 4.0676\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1491,\tval_loss: 4.1041\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1281,\tval_loss: 4.0818\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.0658,\tval_loss: 4.1507\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0208,\tval_loss: 4.1320\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0777,\tval_loss: 4.1592\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0084,\tval_loss: 4.2186\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0175,\tval_loss: 4.2017\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9710,\tval_loss: 4.2042\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0202,\tval_loss: 4.2412\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9669,\tval_loss: 4.2153\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9111,\tval_loss: 4.2401\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9489,\tval_loss: 4.2113\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9069,\tval_loss: 4.2157\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9361,\tval_loss: 4.2355\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8642,\tval_loss: 4.1987\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8572,\tval_loss: 4.2749\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8428,\tval_loss: 4.2286\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7989,\tval_loss: 4.2451\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8955,\tval_loss: 4.3136\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8701,\tval_loss: 4.1970\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8444,\tval_loss: 4.2027\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.8531,\tval_loss: 4.2392\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.8129,\tval_loss: 4.2491\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8472,\tval_loss: 4.2816\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.8454,\tval_loss: 4.2193\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.8048,\tval_loss: 4.2117\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7913,\tval_loss: 4.3404\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7671,\tval_loss: 4.2564\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.7325,\tval_loss: 4.3044\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.7954,\tval_loss: 4.1994\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.7899,\tval_loss: 4.2559\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.7690,\tval_loss: 4.2467\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7795,\tval_loss: 4.2942\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.7521,\tval_loss: 4.3224\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.7514,\tval_loss: 4.3130\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7520,\tval_loss: 4.3263\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6932,\tval_loss: 4.2990\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.7245,\tval_loss: 4.2915\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6247,\tval_loss: 4.3427\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.7003,\tval_loss: 4.2947\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.7335,\tval_loss: 4.3567\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.6812,\tval_loss: 4.3374\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6831,\tval_loss: 4.3270\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.6784,\tval_loss: 4.3208\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5880,\tval_loss: 4.4171\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.7287,\tval_loss: 4.3474\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.7530,\tval_loss: 4.2033\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.7115,\tval_loss: 4.3434\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.6790,\tval_loss: 4.2943\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.6572,\tval_loss: 4.4145\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.6587,\tval_loss: 4.3157\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5601,\tval_loss: 4.3685\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.6623,\tval_loss: 4.3156\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.6538,\tval_loss: 4.3190\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.6606,\tval_loss: 4.3800\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 3.6322,\tval_loss: 4.3478\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5980,\tval_loss: 4.3158\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6726,\tval_loss: 4.3656\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.6306,\tval_loss: 4.3498\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.6235,\tval_loss: 4.3698\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.6261,\tval_loss: 4.4552\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 3.6780,\tval_loss: 4.3040\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 3.6293,\tval_loss: 4.3362\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 3.6172,\tval_loss: 4.2871\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 3.5948,\tval_loss: 4.3212\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 3.6761,\tval_loss: 4.3290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4554,\tval_loss: 4.0909\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.2662,\tval_loss: 4.1118\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2245,\tval_loss: 4.1269\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.1979,\tval_loss: 4.1338\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.1783,\tval_loss: 4.1333\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1598,\tval_loss: 4.1589\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1582,\tval_loss: 4.1302\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1295,\tval_loss: 4.1646\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1284,\tval_loss: 4.1445\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1385,\tval_loss: 4.1610\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0922,\tval_loss: 4.1447\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.0847,\tval_loss: 4.1610\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0827,\tval_loss: 4.1517\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.0325,\tval_loss: 4.1619\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.0529,\tval_loss: 4.1581\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.0044,\tval_loss: 4.1976\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.0185,\tval_loss: 4.2331\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.0221,\tval_loss: 4.1763\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.9895,\tval_loss: 4.2591\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.9289,\tval_loss: 4.2541\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 4.0260,\tval_loss: 4.2416\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9638,\tval_loss: 4.2906\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9349,\tval_loss: 4.2865\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.9634,\tval_loss: 4.2828\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.9233,\tval_loss: 4.3111\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8480,\tval_loss: 4.3995\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8316,\tval_loss: 4.3780\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.8040,\tval_loss: 4.3805\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7386,\tval_loss: 4.4565\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.7703,\tval_loss: 4.4129\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.8263,\tval_loss: 4.3899\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7795,\tval_loss: 4.4391\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.7688,\tval_loss: 4.4078\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.7328,\tval_loss: 4.3591\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.6785,\tval_loss: 4.4733\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6536,\tval_loss: 4.4008\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6728,\tval_loss: 4.4308\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6728,\tval_loss: 4.4767\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 3.6880,\tval_loss: 4.4445\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 3.7055,\tval_loss: 4.4573\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 3.6734,\tval_loss: 4.4752\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6843,\tval_loss: 4.4633\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6996,\tval_loss: 4.4499\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6449,\tval_loss: 4.4405\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6701,\tval_loss: 4.4642\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.6521,\tval_loss: 4.4515\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.6479,\tval_loss: 4.3850\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.6782,\tval_loss: 4.4012\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5379,\tval_loss: 4.4724\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.6279,\tval_loss: 4.4800\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5244,\tval_loss: 4.3858\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.6135,\tval_loss: 4.3928\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 3.5935,\tval_loss: 4.4807\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 3.6044,\tval_loss: 4.4599\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 3.5608,\tval_loss: 4.4578\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 3.5531,\tval_loss: 4.4768\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 3.5690,\tval_loss: 4.5327\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 3.5930,\tval_loss: 4.4816\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 3.5702,\tval_loss: 4.3834\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 3.5635,\tval_loss: 4.4787\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 3.5643,\tval_loss: 4.4588\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 3.5291,\tval_loss: 4.4445\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.4167,\tval_loss: 4.4401\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5117,\tval_loss: 4.4525\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.5726,\tval_loss: 4.4038\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.5908,\tval_loss: 4.4321\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.5715,\tval_loss: 4.4410\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 3.5169,\tval_loss: 4.3876\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4475,\tval_loss: 4.0112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3179,\tval_loss: 4.0237\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2653,\tval_loss: 4.0007\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2347,\tval_loss: 4.0048\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2306,\tval_loss: 3.9941\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1971,\tval_loss: 3.9931\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.2147,\tval_loss: 3.9986\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1454,\tval_loss: 4.0472\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1036,\tval_loss: 4.0977\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1055,\tval_loss: 4.0959\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.0494,\tval_loss: 4.1246\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1033,\tval_loss: 4.1079\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0474,\tval_loss: 4.1207\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.9746,\tval_loss: 4.1722\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.9959,\tval_loss: 4.1818\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.9393,\tval_loss: 4.1858\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.9239,\tval_loss: 4.2409\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.9146,\tval_loss: 4.1763\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.8817,\tval_loss: 4.2836\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.8692,\tval_loss: 4.2878\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.8417,\tval_loss: 4.2803\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.8385,\tval_loss: 4.2596\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.8424,\tval_loss: 4.3177\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8625,\tval_loss: 4.2268\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7852,\tval_loss: 4.2981\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.7690,\tval_loss: 4.2956\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.7640,\tval_loss: 4.3415\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.7434,\tval_loss: 4.3112\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 3.7126,\tval_loss: 4.3247\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 3.6364,\tval_loss: 4.4221\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 3.7543,\tval_loss: 4.3508\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 3.7049,\tval_loss: 4.3076\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 3.6999,\tval_loss: 4.3733\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 3.6716,\tval_loss: 4.3220\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 3.7308,\tval_loss: 4.3133\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 3.6946,\tval_loss: 4.3469\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 3.6203,\tval_loss: 4.3024\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 3.6287,\tval_loss: 4.3586\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.6334,\tval_loss: 4.3658\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.6234,\tval_loss: 4.3553\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.6895,\tval_loss: 4.3652\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.6281,\tval_loss: 4.3136\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.6185,\tval_loss: 4.3672\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 3.6142,\tval_loss: 4.3440\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 3.6241,\tval_loss: 4.3650\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 3.5333,\tval_loss: 4.4304\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 3.5847,\tval_loss: 4.3845\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 3.5911,\tval_loss: 4.3437\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 3.5833,\tval_loss: 4.3234\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 3.5433,\tval_loss: 4.4154\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 3.5209,\tval_loss: 4.4254\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 3.5723,\tval_loss: 4.4783\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.5834,\tval_loss: 4.4063\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.6056,\tval_loss: 4.4159\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.4809,\tval_loss: 4.4731\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.5119,\tval_loss: 4.4722\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.5189,\tval_loss: 4.4978\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.5152,\tval_loss: 4.5264\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.4265,\tval_loss: 4.4532\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.4731,\tval_loss: 4.4340\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.5330,\tval_loss: 4.4440\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.5504,\tval_loss: 4.4023\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.4698,\tval_loss: 4.4812\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5360,\tval_loss: 4.5416\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.4512,\tval_loss: 4.4596\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 3.4738,\tval_loss: 4.4924\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 3.4954,\tval_loss: 4.4563\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.5625,\tval_loss: 4.4313\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.4601,\tval_loss: 4.4663\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.6226,\tval_loss: 4.3708\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.4954,\tval_loss: 4.4680\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.4347,\tval_loss: 4.5555\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.4972,\tval_loss: 4.4266\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 4.4482,\tval_loss: 4.0660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 4.3247,\tval_loss: 4.0659\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.2754,\tval_loss: 4.0680\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2785,\tval_loss: 4.0491\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2383,\tval_loss: 4.0249\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2508,\tval_loss: 4.0192\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.1920,\tval_loss: 4.0276\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 4.1941,\tval_loss: 4.0384\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.1755,\tval_loss: 4.0314\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.1746,\tval_loss: 4.0449\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.1337,\tval_loss: 4.0627\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.1293,\tval_loss: 4.0826\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.0589,\tval_loss: 4.0891\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 4.0967,\tval_loss: 4.0930\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 4.0536,\tval_loss: 4.1294\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.0422,\tval_loss: 4.1384\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 4.0745,\tval_loss: 4.1177\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.9687,\tval_loss: 4.1921\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 4.0129,\tval_loss: 4.1718\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.9921,\tval_loss: 4.2444\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.9571,\tval_loss: 4.1936\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.9312,\tval_loss: 4.2106\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.9043,\tval_loss: 4.2753\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.8700,\tval_loss: 4.2907\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.8514,\tval_loss: 4.3218\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.8629,\tval_loss: 4.3084\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.8762,\tval_loss: 4.3054\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 3.9232,\tval_loss: 4.3015\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 3.8668,\tval_loss: 4.2473\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 3.8410,\tval_loss: 4.3303\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 3.8477,\tval_loss: 4.3435\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 3.8982,\tval_loss: 4.2844\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 3.7604,\tval_loss: 4.4010\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 3.7823,\tval_loss: 4.3564\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 3.8292,\tval_loss: 4.3242\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 3.8775,\tval_loss: 4.3297\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 3.8164,\tval_loss: 4.3414\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 3.7125,\tval_loss: 4.3579\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 3.8054,\tval_loss: 4.3797\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 3.7853,\tval_loss: 4.3373\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 3.7822,\tval_loss: 4.3953\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 3.8305,\tval_loss: 4.3252\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 3.7518,\tval_loss: 4.3482\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 3.7441,\tval_loss: 4.3735\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 3.7124,\tval_loss: 4.4182\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 3.6922,\tval_loss: 4.4087\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 3.7431,\tval_loss: 4.3179\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 3.7427,\tval_loss: 4.3459\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 3.6356,\tval_loss: 4.4048\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 3.5915,\tval_loss: 4.3996\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 3.6734,\tval_loss: 4.3691\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 3.6849,\tval_loss: 4.3578\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 3.7023,\tval_loss: 4.3923\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 3.7398,\tval_loss: 4.3339\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 3.6669,\tval_loss: 4.3587\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 3.6611,\tval_loss: 4.3668\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 3.6896,\tval_loss: 4.3314\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 3.6985,\tval_loss: 4.3737\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 3.6435,\tval_loss: 4.3314\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 3.6960,\tval_loss: 4.3804\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 3.6194,\tval_loss: 4.3948\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 3.6824,\tval_loss: 4.3884\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 3.5367,\tval_loss: 4.3615\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 3.5405,\tval_loss: 4.5011\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 3.6900,\tval_loss: 4.3511\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 3.6689,\tval_loss: 4.4256\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 3.6124,\tval_loss: 4.4178\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 3.6807,\tval_loss: 4.4100\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 3.6881,\tval_loss: 4.3509\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 3.6325,\tval_loss: 4.3545\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 3.6335,\tval_loss: 4.4725\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 3.5977,\tval_loss: 4.3401\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 3.6269,\tval_loss: 4.4095\n",
            "Bootstrap 95% confidence interval for the C-index: (0.55, 0.68)\n",
            "Bootstrap 95% confidence interval for the IBS: (0.08, 0.09)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils import resample\n",
        "import numpy as np\n",
        "import torchtuples as tt\n",
        "from pycox.models import CoxPH\n",
        "from pycox.evaluation import EvalSurv\n",
        "\n",
        "\n",
        "# Number of bootstrap iterations\n",
        "n_bootstrap_iterations = 200\n",
        "\n",
        "# Arrays to store bootstrap C-indices and IBS scores\n",
        "c_indices_deepsurv = np.zeros(n_bootstrap_iterations)\n",
        "ibs_scores_deepsurv = np.zeros(n_bootstrap_iterations)\n",
        "\n",
        "for i in range(n_bootstrap_iterations):\n",
        "    # Generate a bootstrap sample of indices\n",
        "    bootstrap_indices = resample(np.arange(len(x_train)), replace=True)\n",
        "\n",
        "     # Use these indices to create bootstrap samples\n",
        "    bootstrap_train_x = x_train[bootstrap_indices]\n",
        "    bootstrap_train_y_time = y_train[0][bootstrap_indices]\n",
        "    bootstrap_train_y_event = y_train[1][bootstrap_indices]\n",
        "    bootstrap_train_y = (bootstrap_train_y_time, bootstrap_train_y_event)\n",
        "\n",
        "    # Define the network architecture and the model\n",
        "    in_features = bootstrap_train_x.shape[1]\n",
        "    out_features = 1\n",
        "    output_bias = False\n",
        "    net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout, output_bias=output_bias)\n",
        "    bootstrap_model = CoxPH(net, tt.optim.Adam(learning_rate, weight_decay = weight_decay))\n",
        "\n",
        "    # Set up the training parameters and train the model\n",
        "    bootstrap_model.optimizer.set_lr(learning_rate)\n",
        "    callbacks = [tt.callbacks.EarlyStopping(patience=patience)]\n",
        "    verbose = True\n",
        "\n",
        "    # Fit the model using the resampled training data\n",
        "    log = bootstrap_model.fit(bootstrap_train_x, bootstrap_train_y, batch_size, epochs, callbacks, verbose, val_data=val, val_batch_size=batch_size)\n",
        "\n",
        "    bootstrap_model.compute_baseline_hazards()\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    surv = bootstrap_model.predict_surv_df(x_test)\n",
        "    ev_test = EvalSurv(surv, y_test_surv, y_test_event, censor_surv='km')\n",
        "    c_index_test = ev_test.concordance_td('antolini')\n",
        "    c_indices_deepsurv[i] = c_index_test\n",
        "\n",
        "    # Calculate the integrated Brier score\n",
        "    ibs = ev_test.integrated_brier_score(time_grid=np.linspace(0, y_test_surv.max(), 100))\n",
        "    ibs_scores_deepsurv[i] = ibs\n",
        "\n",
        "# Compute the lower and upper percentiles for C-index\n",
        "lower_percentile_c_index = np.percentile(c_indices_deepsurv, 2.5)\n",
        "upper_percentile_c_index = np.percentile(c_indices_deepsurv, 97.5)\n",
        "\n",
        "# Compute the lower and upper percentiles for IBS\n",
        "lower_percentile_ibs = np.percentile(ibs_scores_deepsurv, 2.5)\n",
        "upper_percentile_ibs = np.percentile(ibs_scores_deepsurv, 97.5)\n",
        "\n",
        "print('Bootstrap 95% confidence interval for the C-index: ({:.2f}, {:.2f})'.format(lower_percentile_c_index, upper_percentile_c_index))\n",
        "print('Bootstrap 95% confidence interval for the IBS: ({:.2f}, {:.2f})'.format(lower_percentile_ibs, upper_percentile_ibs))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "dlHVGJCc0xJD",
        "outputId": "c9064c75-c76f-46ad-b8d4-b93cbbef24cd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the style for seaborn\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create a figure\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Subplot for C-index\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot(y=c_indices_deepsurv)\n",
        "plt.title(\"Boxplot of Bootstrap C-Indices\")\n",
        "plt.ylabel(\"C-Index\")\n",
        "\n",
        "# Subplot for IBS\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(y=ibs_scores_deepsurv)\n",
        "plt.title(\"Boxplot of Bootstrap IBS Scores\")\n",
        "plt.ylabel(\"IBS Score\")\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Mj-kMlFyTRB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# save the numpy arrays to the specified directory\n",
        "np.save('/content/drive/MyDrive/MSc_summer_project/Clinical_trial_data/Breast/Confidence_intervals_breast_IBS_cindex/c_indices_deepsurv.npy', c_indices_deepsurv)\n",
        "np.save('/content/drive/MyDrive/MSc_summer_project/Clinical_trial_data/Breast/Confidence_intervals_breast_IBS_cindex/ibs_scores_deepsurv.npy', ibs_scores_deepsurv)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWChz5AKyUfu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yuGWk_s5BKf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FiFHuEwyBKci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "djA8AcPABKZY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1mBR_1hLbB8Whs-io85gIEDFynLRQ-Ntv",
      "authorship_tag": "ABX9TyPei88cttIMDNZ54I+wq27C",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}