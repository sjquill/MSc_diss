{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sjquill/MSc_diss/blob/main/BREAST_Data/Breast_DeepHit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIs_FbLalC5y",
        "outputId": "dfba1482-2d25-4b53-8c09-bed5397693f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lifelines\n",
            "  Downloading lifelines-0.27.7-py3-none-any.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.4/409.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.10.1)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (3.7.1)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.6.2)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines)\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting formulaic>=0.2.2 (from lifelines)\n",
            "  Downloading formulaic-0.6.4-py3-none-any.whl (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.9/88.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd>=1.5->lifelines) (0.18.3)\n",
            "Collecting astor>=0.8 (from formulaic>=0.2.2->lifelines)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines) (4.7.1)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines) (1.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->lifelines) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.16.0)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=7d4121447bd41c2eb9e0b54427a80d919d292886bf3414b2f681b5fcfd504c30\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/cc/e0/ef2969164144c899fedb22b338f6703e2b9cf46eeebf254991\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: interface-meta, astor, autograd-gamma, formulaic, lifelines\n",
            "Successfully installed astor-0.8.1 autograd-gamma-0.5.0 formulaic-0.6.4 interface-meta-1.3.0 lifelines-0.27.7\n",
            "Collecting pycox\n",
            "  Downloading pycox-0.2.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtuples>=0.2.0 (from pycox)\n",
            "  Downloading torchtuples-0.2.2-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting feather-format>=0.4.0 (from pycox)\n",
            "  Downloading feather-format-0.4.1.tar.gz (3.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from pycox) (3.9.0)\n",
            "Requirement already satisfied: numba>=0.44 in /usr/local/lib/python3.10/dist-packages (from pycox) (0.56.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from pycox) (1.2.2)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pycox) (2.31.0)\n",
            "Collecting py7zr>=0.11.3 (from pycox)\n",
            "  Downloading py7zr-0.20.6-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from feather-format>=0.4.0->pycox) (9.0.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py>=2.9.0->pycox) (1.23.5)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.44->pycox) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.44->pycox) (67.7.2)\n",
            "Collecting texttable (from py7zr>=0.11.3->pycox)\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pycryptodomex>=3.6.6 (from py7zr>=0.11.3->pycox)\n",
            "  Downloading pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzstd>=0.14.4 (from py7zr>=0.11.3->pycox)\n",
            "  Downloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyppmd<1.1.0,>=0.18.1 (from py7zr>=0.11.3->pycox)\n",
            "  Downloading pyppmd-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybcj>=0.6.0 (from py7zr>=0.11.3->pycox)\n",
            "  Downloading pybcj-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3 (from py7zr>=0.11.3->pycox)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting brotli>=1.0.9 (from py7zr>=0.11.3->pycox)\n",
            "  Downloading Brotli-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting inflate64>=0.3.1 (from py7zr>=0.11.3->pycox)\n",
            "  Downloading inflate64-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from py7zr>=0.11.3->pycox) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pycox) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pycox) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pycox) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pycox) (2023.7.22)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.2->pycox) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.2->pycox) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.2->pycox) (3.2.0)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from torchtuples>=0.2.0->pycox) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from torchtuples>=0.2.0->pycox) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->torchtuples>=0.2.0->pycox) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (1.16.0)\n",
            "Building wheels for collected packages: feather-format\n",
            "  Building wheel for feather-format (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feather-format: filename=feather_format-0.4.1-py3-none-any.whl size=2436 sha256=3c781fcba0604124929c9af8592d08552d4b1dde64f0bc347b70065581106a8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/ff/5d/4f10de26fe5ddef243c97f13c6cf579d7353d659e41a05c3a6\n",
            "Successfully built feather-format\n",
            "Installing collected packages: texttable, brotli, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, py7zr, feather-format, torchtuples, pycox\n",
            "Successfully installed brotli-1.0.9 feather-format-0.4.1 inflate64-0.3.1 multivolumefile-0.2.3 py7zr-0.20.6 pybcj-1.0.1 pycox-0.2.3 pycryptodomex-3.18.0 pyppmd-1.0.0 pyzstd-0.15.9 texttable-1.6.7 torchtuples-0.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install lifelines\n",
        "!pip install pycox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qf4pgYmBlNPB"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import lifelines\n",
        "import numpy as np\n",
        "from pycox.models import CoxPH\n",
        "from pycox.evaluation import EvalSurv\n",
        "\n",
        "import torch\n",
        "import torchtuples as tt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1nxR9kklRVn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "breast_train_data_imputed1 = pd.read_csv(\"/content/drive/MyDrive/MSc_summer_project/Clinical_trial_data/Breast/breast_train_data_imputed1.csv\")\n",
        "breast_test_data_imputed1 = pd.read_csv(\"/content/drive/MyDrive/MSc_summer_project/Clinical_trial_data/Breast/breast_test_data_imputed1.csv\")\n",
        "train_data = breast_train_data_imputed1.copy()\n",
        "test_data = breast_test_data_imputed1.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edNgqB21lVBb"
      },
      "outputs": [],
      "source": [
        "column_names = [\n",
        "    'mask_id',\n",
        "    'disease_free_survival_status',\n",
        "    'disease_free_survival_months',\n",
        "    'race_asian',\n",
        "    'race_black',\n",
        "    'race_other',\n",
        "    'Treatment_CA_6',\n",
        "    'Treatment_T_4',\n",
        "    'Treatment_T_6',\n",
        "    'post_menopausal',\n",
        "    'tumor_side_right',\n",
        "    'tumor_side_bilateral',\n",
        "    'receptor_status_er_pos',\n",
        "    'receptor_status_pgrn_pos',\n",
        "    'histologic_grade_inter',\n",
        "    'histologic_grade_high',\n",
        "    'her2_status_pos',\n",
        "    'prior_hormonal_therapy_yes',\n",
        "    'most_extensive_primary_surgery_mast_NOS',\n",
        "    'tumor_size_2_to_5cm',\n",
        "    'tumor_size_over_5cm',\n",
        "    'num_pos_nodes_1',\n",
        "    'num_pos_nodes_2+',\n",
        "    'age_over_fifty'\n",
        "]\n",
        "# Set the new column names\n",
        "train_data.columns = column_names\n",
        "test_data.columns = column_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYt-U0E8lXre"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_data, val_data = train_test_split(\n",
        "    train_data, test_size=0.2, stratify=train_data['disease_free_survival_status'], random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaS9A3djlZlU",
        "outputId": "7d2ce987-b7d3-4333-84d6-e79adc6afbf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 2000\n",
            "Validation set size: 500\n",
            "Test set size: 624\n"
          ]
        }
      ],
      "source": [
        "print(\"Train set size:\", len(train_data))\n",
        "print(\"Validation set size:\", len(val_data))\n",
        "print(\"Test set size:\", len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfxi928lldCw",
        "outputId": "37712c1a-5034-4fa2-e71e-aa422e6544fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "train_data = train_data.drop(columns=['mask_id'])\n",
        "val_data = val_data.drop(columns=['mask_id'])\n",
        "test_data = test_data.drop(columns=['mask_id'])\n",
        "\n",
        "x_train = train_data.drop(columns=['disease_free_survival_status', 'disease_free_survival_months'])\n",
        "x_val = val_data.drop(columns=['disease_free_survival_status', 'disease_free_survival_months'])\n",
        "x_test = test_data.drop(columns=['disease_free_survival_status', 'disease_free_survival_months'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_val = x_val.astype('float32')\n",
        "x_test= x_test.astype('float32')\n",
        "\n",
        "x_train = x_train.values\n",
        "print(type(x_train))\n",
        "\n",
        "x_test = x_test.values\n",
        "print(type(x_test))\n",
        "\n",
        "x_val = x_val.values\n",
        "print(type(x_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOvkNFWIlh-M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn_pandas import DataFrameMapper\n",
        "\n",
        "import torch\n",
        "import torchtuples as tt\n",
        "\n",
        "from pycox.models import DeepHitSingle\n",
        "from pycox.evaluation import EvalSurv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbL5T5tjmCDZ"
      },
      "outputs": [],
      "source": [
        "labtrans = DeepHitSingle.label_transform(num_durations)\n",
        "get_target = lambda df: (df['disease_free_survival_months'].values, df['disease_free_survival_status'].values)\n",
        "y_train = labtrans.fit_transform(*get_target(train_data))\n",
        "y_val = labtrans.transform(*get_target(val_data))\n",
        "\n",
        "train = (x_train, y_train)\n",
        "val = (x_val, y_val)\n",
        "\n",
        "durations_train, events_train = get_target(train_data)\n",
        "durations_val, events_val = get_target(val_data)\n",
        "durations_test, events_test = get_target(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09-HtAXUluAW"
      },
      "outputs": [],
      "source": [
        "best_val_ci = 0\n",
        "best_hyperparameters = None\n",
        "RS_ITERATION = 100\n",
        "in_features = x_train.shape[1]\n",
        "get_target = lambda df: (df['disease_free_survival_months'].values, df['disease_free_survival_status'].values)\n",
        "num_durations = 10\n",
        "labtrans = DeepHitSingle.label_transform(num_durations)\n",
        "y_train = labtrans.fit_transform(*get_target(train_data))\n",
        "y_val = labtrans.transform(*get_target(val_data))\n",
        "out_features = labtrans.out_features\n",
        "batch_norm = True\n",
        "batch_size = 256\n",
        "epochs = 100\n",
        "callbacks = [tt.callbacks.EarlyStopping()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FR-_Ci99PGCQ",
        "outputId": "363abc0a-2514-42f6-e116-157fc0af5de2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random search... itr: 0\n",
            "{'batch_size': 256, 'layers': 2, 'nodes': 75, 'activation_fn': 'elu', 'alpha': 1.0, 'sigma': 0.1, 'lr': 0.1, 'dropout': 0.8, 'patience': 25}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 1.0143,\tval_loss: 0.5803\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.7177,\tval_loss: 0.4894\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5868,\tval_loss: 0.4911\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5443,\tval_loss: 0.4966\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5207,\tval_loss: 0.4935\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5286,\tval_loss: 0.4892\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.5097,\tval_loss: 0.4884\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.5157,\tval_loss: 0.4901\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.5083,\tval_loss: 0.4878\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.5100,\tval_loss: 0.4861\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.5090,\tval_loss: 0.4865\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.5066,\tval_loss: 0.4870\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.5047,\tval_loss: 0.4862\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.5036,\tval_loss: 0.4861\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.5043,\tval_loss: 0.4858\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.5044,\tval_loss: 0.4853\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 0.5069,\tval_loss: 0.4858\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 0.5058,\tval_loss: 0.4859\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 0.5042,\tval_loss: 0.4864\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 0.5086,\tval_loss: 0.4869\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 0.5056,\tval_loss: 0.4853\n",
            "21:\t[0s / 0s],\t\ttrain_loss: 0.5074,\tval_loss: 0.4869\n",
            "22:\t[0s / 0s],\t\ttrain_loss: 0.5065,\tval_loss: 0.4845\n",
            "23:\t[0s / 0s],\t\ttrain_loss: 0.5055,\tval_loss: 0.4846\n",
            "24:\t[0s / 0s],\t\ttrain_loss: 0.5055,\tval_loss: 0.4860\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.5060,\tval_loss: 0.4860\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.5049,\tval_loss: 0.4861\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.5047,\tval_loss: 0.4851\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.5073,\tval_loss: 0.4867\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 0.5025,\tval_loss: 0.4858\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 0.5025,\tval_loss: 0.4861\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 0.5014,\tval_loss: 0.4849\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 0.5469,\tval_loss: 0.4854\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 0.5029,\tval_loss: 0.4858\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 0.5039,\tval_loss: 0.4863\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 0.5040,\tval_loss: 0.4867\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 0.5053,\tval_loss: 0.4854\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 0.5051,\tval_loss: 0.4846\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 0.5047,\tval_loss: 0.4848\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 0.5023,\tval_loss: 0.4861\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 0.5049,\tval_loss: 0.4859\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 0.5053,\tval_loss: 0.4854\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 0.5036,\tval_loss: 0.4849\n",
            "43:\t[0s / 1s],\t\ttrain_loss: 0.5013,\tval_loss: 0.4853\n",
            "44:\t[0s / 1s],\t\ttrain_loss: 0.5041,\tval_loss: 0.4857\n",
            "45:\t[0s / 1s],\t\ttrain_loss: 0.5037,\tval_loss: 0.4861\n",
            "46:\t[0s / 1s],\t\ttrain_loss: 0.5023,\tval_loss: 0.4848\n",
            "47:\t[0s / 1s],\t\ttrain_loss: 0.5051,\tval_loss: 0.4844\n",
            "48:\t[0s / 1s],\t\ttrain_loss: 0.5013,\tval_loss: 0.4857\n",
            "49:\t[0s / 1s],\t\ttrain_loss: 0.5034,\tval_loss: 0.4868\n",
            "50:\t[0s / 1s],\t\ttrain_loss: 0.5038,\tval_loss: 0.4862\n",
            "51:\t[0s / 1s],\t\ttrain_loss: 0.5076,\tval_loss: 0.4855\n",
            "52:\t[0s / 1s],\t\ttrain_loss: 0.5058,\tval_loss: 0.4844\n",
            "53:\t[0s / 1s],\t\ttrain_loss: 0.5084,\tval_loss: 0.4867\n",
            "54:\t[0s / 1s],\t\ttrain_loss: 0.5087,\tval_loss: 0.4873\n",
            "55:\t[0s / 1s],\t\ttrain_loss: 0.5024,\tval_loss: 0.4853\n",
            "56:\t[0s / 1s],\t\ttrain_loss: 0.5037,\tval_loss: 0.4840\n",
            "57:\t[0s / 1s],\t\ttrain_loss: 0.5042,\tval_loss: 0.4834\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 0.5043,\tval_loss: 0.4857\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 0.5054,\tval_loss: 0.4867\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 0.5022,\tval_loss: 0.4852\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 0.5048,\tval_loss: 0.4864\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 0.5049,\tval_loss: 0.4849\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 0.5078,\tval_loss: 0.4853\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 0.5038,\tval_loss: 0.4854\n",
            "65:\t[0s / 2s],\t\ttrain_loss: 0.5005,\tval_loss: 0.4839\n",
            "66:\t[0s / 2s],\t\ttrain_loss: 0.5026,\tval_loss: 0.4858\n",
            "67:\t[0s / 2s],\t\ttrain_loss: 0.5017,\tval_loss: 0.4856\n",
            "68:\t[0s / 2s],\t\ttrain_loss: 0.5035,\tval_loss: 0.4856\n",
            "69:\t[0s / 2s],\t\ttrain_loss: 0.5057,\tval_loss: 0.4862\n",
            "70:\t[0s / 2s],\t\ttrain_loss: 0.5053,\tval_loss: 0.4863\n",
            "71:\t[0s / 2s],\t\ttrain_loss: 0.5028,\tval_loss: 0.4872\n",
            "72:\t[0s / 2s],\t\ttrain_loss: 0.5044,\tval_loss: 0.4840\n",
            "73:\t[0s / 2s],\t\ttrain_loss: 0.5060,\tval_loss: 0.4847\n",
            "74:\t[0s / 2s],\t\ttrain_loss: 0.5033,\tval_loss: 0.4843\n",
            "75:\t[0s / 2s],\t\ttrain_loss: 0.5052,\tval_loss: 0.4864\n",
            "76:\t[0s / 2s],\t\ttrain_loss: 0.5115,\tval_loss: 0.4869\n",
            "77:\t[0s / 2s],\t\ttrain_loss: 0.5051,\tval_loss: 0.4858\n",
            "78:\t[0s / 2s],\t\ttrain_loss: 0.5049,\tval_loss: 0.4847\n",
            "79:\t[0s / 2s],\t\ttrain_loss: 0.5066,\tval_loss: 0.4866\n",
            "80:\t[0s / 2s],\t\ttrain_loss: 0.5044,\tval_loss: 0.4856\n",
            "81:\t[0s / 2s],\t\ttrain_loss: 0.5048,\tval_loss: 0.4844\n",
            "82:\t[0s / 2s],\t\ttrain_loss: 0.5031,\tval_loss: 0.4853\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current best c-index: 0.0010208248264597796\n",
            "Random search... itr: 1\n",
            "{'batch_size': 32, 'layers': 5, 'nodes': 75, 'activation_fn': 'tanh', 'alpha': 1.0, 'sigma': 1.0, 'lr': 0.01, 'dropout': 0.05, 'patience': 75}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.5648,\tval_loss: 0.5047\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5312,\tval_loss: 0.5112\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5149,\tval_loss: 0.4828\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5134,\tval_loss: 0.5109\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5008,\tval_loss: 0.4856\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4998,\tval_loss: 0.5131\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.4926,\tval_loss: 0.5042\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.4834,\tval_loss: 0.5533\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.4878,\tval_loss: 0.5282\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.4736,\tval_loss: 0.5490\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.4707,\tval_loss: 0.5741\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.4633,\tval_loss: 0.5451\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 0.4644,\tval_loss: 0.6573\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.4561,\tval_loss: 0.6141\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.4505,\tval_loss: 0.6807\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.4482,\tval_loss: 0.9056\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.4504,\tval_loss: 0.6598\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.4444,\tval_loss: 0.7989\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.4467,\tval_loss: 0.8331\n",
            "19:\t[0s / 3s],\t\ttrain_loss: 0.4288,\tval_loss: 0.6683\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.4377,\tval_loss: 0.7583\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.4206,\tval_loss: 0.7947\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.4202,\tval_loss: 0.6489\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.4269,\tval_loss: 0.8761\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.4136,\tval_loss: 0.7479\n",
            "25:\t[0s / 4s],\t\ttrain_loss: 0.4237,\tval_loss: 0.6072\n",
            "26:\t[0s / 4s],\t\ttrain_loss: 0.3951,\tval_loss: 0.7808\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.3924,\tval_loss: 1.0551\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.4014,\tval_loss: 0.7458\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.3913,\tval_loss: 0.8434\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.3848,\tval_loss: 0.6726\n",
            "31:\t[0s / 5s],\t\ttrain_loss: 0.4024,\tval_loss: 0.8589\n",
            "32:\t[0s / 5s],\t\ttrain_loss: 0.3743,\tval_loss: 1.3449\n",
            "33:\t[0s / 5s],\t\ttrain_loss: 0.3865,\tval_loss: 1.1446\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.3733,\tval_loss: 1.0576\n",
            "35:\t[0s / 6s],\t\ttrain_loss: 0.3641,\tval_loss: 1.2400\n",
            "36:\t[0s / 6s],\t\ttrain_loss: 0.3679,\tval_loss: 0.7882\n",
            "37:\t[0s / 6s],\t\ttrain_loss: 0.3668,\tval_loss: 1.2545\n",
            "38:\t[0s / 6s],\t\ttrain_loss: 0.3595,\tval_loss: 1.3578\n",
            "39:\t[0s / 6s],\t\ttrain_loss: 0.3556,\tval_loss: 1.5921\n",
            "40:\t[0s / 7s],\t\ttrain_loss: 0.3568,\tval_loss: 1.2898\n",
            "41:\t[0s / 7s],\t\ttrain_loss: 0.3401,\tval_loss: 1.2176\n",
            "42:\t[0s / 7s],\t\ttrain_loss: 0.3944,\tval_loss: 1.3757\n",
            "43:\t[0s / 7s],\t\ttrain_loss: 0.3850,\tval_loss: 1.0100\n",
            "44:\t[0s / 7s],\t\ttrain_loss: 0.3808,\tval_loss: 0.9821\n",
            "45:\t[0s / 8s],\t\ttrain_loss: 0.3915,\tval_loss: 1.3117\n",
            "46:\t[0s / 8s],\t\ttrain_loss: 0.3741,\tval_loss: 1.0372\n",
            "47:\t[0s / 8s],\t\ttrain_loss: 0.3527,\tval_loss: 1.2152\n",
            "48:\t[0s / 8s],\t\ttrain_loss: 0.3376,\tval_loss: 1.3999\n",
            "49:\t[0s / 8s],\t\ttrain_loss: 0.3480,\tval_loss: 1.0910\n",
            "50:\t[0s / 8s],\t\ttrain_loss: 0.3492,\tval_loss: 1.1467\n",
            "51:\t[0s / 8s],\t\ttrain_loss: 0.3472,\tval_loss: 1.1600\n",
            "52:\t[0s / 9s],\t\ttrain_loss: 0.3550,\tval_loss: 1.2583\n",
            "53:\t[0s / 9s],\t\ttrain_loss: 0.3631,\tval_loss: 0.9165\n",
            "54:\t[0s / 9s],\t\ttrain_loss: 0.3615,\tval_loss: 0.9981\n",
            "55:\t[0s / 9s],\t\ttrain_loss: 0.3327,\tval_loss: 1.1369\n",
            "56:\t[0s / 9s],\t\ttrain_loss: 0.3065,\tval_loss: 1.0321\n",
            "57:\t[0s / 9s],\t\ttrain_loss: 0.3083,\tval_loss: 1.4772\n",
            "58:\t[0s / 10s],\t\ttrain_loss: 0.3177,\tval_loss: 1.4794\n",
            "59:\t[0s / 10s],\t\ttrain_loss: 0.3050,\tval_loss: 1.5064\n",
            "60:\t[0s / 10s],\t\ttrain_loss: 0.3185,\tval_loss: 1.9011\n",
            "61:\t[0s / 10s],\t\ttrain_loss: 0.3134,\tval_loss: 1.5808\n",
            "62:\t[0s / 10s],\t\ttrain_loss: 0.3054,\tval_loss: 1.3211\n",
            "63:\t[0s / 10s],\t\ttrain_loss: 0.3398,\tval_loss: 1.4303\n",
            "64:\t[0s / 10s],\t\ttrain_loss: 0.3170,\tval_loss: 1.3128\n",
            "65:\t[0s / 11s],\t\ttrain_loss: 0.3029,\tval_loss: 1.4213\n",
            "66:\t[0s / 11s],\t\ttrain_loss: 0.3132,\tval_loss: 1.1536\n",
            "67:\t[0s / 11s],\t\ttrain_loss: 0.3191,\tval_loss: 0.9893\n",
            "68:\t[0s / 11s],\t\ttrain_loss: 0.3061,\tval_loss: 1.5097\n",
            "69:\t[0s / 11s],\t\ttrain_loss: 0.3169,\tval_loss: 1.1211\n",
            "70:\t[0s / 11s],\t\ttrain_loss: 0.2863,\tval_loss: 1.6611\n",
            "71:\t[0s / 12s],\t\ttrain_loss: 0.2810,\tval_loss: 1.5634\n",
            "72:\t[0s / 12s],\t\ttrain_loss: 0.2618,\tval_loss: 1.8711\n",
            "73:\t[0s / 12s],\t\ttrain_loss: 0.2639,\tval_loss: 1.6653\n",
            "74:\t[0s / 12s],\t\ttrain_loss: 0.2728,\tval_loss: 2.4100\n",
            "75:\t[0s / 12s],\t\ttrain_loss: 0.3360,\tval_loss: 1.7772\n",
            "76:\t[0s / 12s],\t\ttrain_loss: 0.3033,\tval_loss: 1.9035\n",
            "77:\t[0s / 12s],\t\ttrain_loss: 0.2986,\tval_loss: 2.1102\n",
            "Current best c-index: 0.6027970600244998\n",
            "Random search... itr: 2\n",
            "{'batch_size': 32, 'layers': 3, 'nodes': 50, 'activation_fn': 'elu', 'alpha': 1.0, 'sigma': 1.0, 'lr': 0.01, 'dropout': 0.3, 'patience': 25}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6117,\tval_loss: 0.4979\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5571,\tval_loss: 0.5126\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5251,\tval_loss: 0.4880\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5247,\tval_loss: 0.5016\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5049,\tval_loss: 0.4914\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5097,\tval_loss: 0.4874\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.5065,\tval_loss: 0.4922\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.4921,\tval_loss: 0.4784\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.4903,\tval_loss: 0.4803\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.4893,\tval_loss: 0.4891\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.4958,\tval_loss: 0.4891\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.4897,\tval_loss: 0.4903\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.4832,\tval_loss: 0.4932\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.4825,\tval_loss: 0.4952\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.4860,\tval_loss: 0.5147\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.4775,\tval_loss: 0.5331\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.4754,\tval_loss: 0.5066\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.4687,\tval_loss: 0.5260\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.4757,\tval_loss: 0.5220\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.4746,\tval_loss: 0.5336\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.4777,\tval_loss: 0.5327\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.4686,\tval_loss: 0.5312\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.4653,\tval_loss: 0.5308\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.4665,\tval_loss: 0.5190\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.4637,\tval_loss: 0.5816\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.4589,\tval_loss: 0.5979\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.4717,\tval_loss: 0.5930\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.4704,\tval_loss: 0.5773\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.4586,\tval_loss: 0.5338\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.4582,\tval_loss: 0.5624\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.4636,\tval_loss: 0.6123\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.4517,\tval_loss: 0.6065\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.4622,\tval_loss: 0.5696\n",
            "Current best c-index: 0.6027970600244998\n",
            "Random search... itr: 3\n",
            "{'batch_size': 256, 'layers': 1, 'nodes': 50, 'activation_fn': 'tanh', 'alpha': 0.5, 'sigma': 0.1, 'lr': 0.01, 'dropout': 0.6, 'patience': 75}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.4526,\tval_loss: 0.3055\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.3373,\tval_loss: 0.3011\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.3305,\tval_loss: 0.2818\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 0.3134,\tval_loss: 0.2767\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.3128,\tval_loss: 0.2776\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.2980,\tval_loss: 0.2814\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.3025,\tval_loss: 0.2785\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.2906,\tval_loss: 0.2782\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.2900,\tval_loss: 0.2786\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.2861,\tval_loss: 0.2788\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.2872,\tval_loss: 0.2782\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.2878,\tval_loss: 0.2776\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.2819,\tval_loss: 0.2785\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.2852,\tval_loss: 0.2786\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.2815,\tval_loss: 0.2789\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.2795,\tval_loss: 0.2791\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.2822,\tval_loss: 0.2797\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.2731,\tval_loss: 0.2818\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.2762,\tval_loss: 0.2825\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.2691,\tval_loss: 0.2829\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.2741,\tval_loss: 0.2810\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.2753,\tval_loss: 0.2825\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.2663,\tval_loss: 0.2831\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.2658,\tval_loss: 0.2849\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.2709,\tval_loss: 0.2828\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.2622,\tval_loss: 0.2814\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.2609,\tval_loss: 0.2839\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.2678,\tval_loss: 0.2865\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.2633,\tval_loss: 0.2862\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.2628,\tval_loss: 0.2844\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.2613,\tval_loss: 0.2839\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.2605,\tval_loss: 0.2843\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.2569,\tval_loss: 0.2834\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.2659,\tval_loss: 0.2853\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.2570,\tval_loss: 0.2846\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.2557,\tval_loss: 0.2865\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.2575,\tval_loss: 0.2886\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.2598,\tval_loss: 0.2856\n",
            "38:\t[0s / 3s],\t\ttrain_loss: 0.2551,\tval_loss: 0.2843\n",
            "39:\t[0s / 3s],\t\ttrain_loss: 0.2572,\tval_loss: 0.2848\n",
            "40:\t[0s / 3s],\t\ttrain_loss: 0.2545,\tval_loss: 0.2857\n",
            "41:\t[0s / 3s],\t\ttrain_loss: 0.2537,\tval_loss: 0.2848\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.2517,\tval_loss: 0.2836\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.2534,\tval_loss: 0.2839\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.2522,\tval_loss: 0.2842\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.2539,\tval_loss: 0.2857\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.2519,\tval_loss: 0.2880\n",
            "47:\t[0s / 4s],\t\ttrain_loss: 0.2431,\tval_loss: 0.2901\n",
            "48:\t[0s / 4s],\t\ttrain_loss: 0.2465,\tval_loss: 0.2908\n",
            "49:\t[0s / 4s],\t\ttrain_loss: 0.2464,\tval_loss: 0.2905\n",
            "50:\t[0s / 4s],\t\ttrain_loss: 0.2515,\tval_loss: 0.2885\n",
            "51:\t[0s / 4s],\t\ttrain_loss: 0.2509,\tval_loss: 0.2895\n",
            "52:\t[0s / 4s],\t\ttrain_loss: 0.2418,\tval_loss: 0.2950\n",
            "53:\t[0s / 4s],\t\ttrain_loss: 0.2470,\tval_loss: 0.2965\n",
            "54:\t[0s / 4s],\t\ttrain_loss: 0.2455,\tval_loss: 0.2931\n",
            "55:\t[0s / 4s],\t\ttrain_loss: 0.2464,\tval_loss: 0.2922\n",
            "56:\t[0s / 4s],\t\ttrain_loss: 0.2482,\tval_loss: 0.2940\n",
            "57:\t[0s / 4s],\t\ttrain_loss: 0.2455,\tval_loss: 0.2938\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 0.2458,\tval_loss: 0.2935\n",
            "59:\t[0s / 5s],\t\ttrain_loss: 0.2438,\tval_loss: 0.2929\n",
            "60:\t[0s / 5s],\t\ttrain_loss: 0.2420,\tval_loss: 0.2936\n",
            "61:\t[0s / 5s],\t\ttrain_loss: 0.2486,\tval_loss: 0.2935\n",
            "62:\t[0s / 5s],\t\ttrain_loss: 0.2427,\tval_loss: 0.2921\n",
            "63:\t[0s / 5s],\t\ttrain_loss: 0.2401,\tval_loss: 0.2896\n",
            "64:\t[0s / 5s],\t\ttrain_loss: 0.2388,\tval_loss: 0.2906\n",
            "65:\t[0s / 5s],\t\ttrain_loss: 0.2418,\tval_loss: 0.2955\n",
            "66:\t[0s / 5s],\t\ttrain_loss: 0.2350,\tval_loss: 0.2962\n",
            "67:\t[0s / 5s],\t\ttrain_loss: 0.2431,\tval_loss: 0.2950\n",
            "68:\t[0s / 5s],\t\ttrain_loss: 0.2430,\tval_loss: 0.2995\n",
            "69:\t[0s / 5s],\t\ttrain_loss: 0.2407,\tval_loss: 0.3004\n",
            "70:\t[0s / 5s],\t\ttrain_loss: 0.2372,\tval_loss: 0.2988\n",
            "71:\t[0s / 5s],\t\ttrain_loss: 0.2398,\tval_loss: 0.2970\n",
            "72:\t[0s / 5s],\t\ttrain_loss: 0.2334,\tval_loss: 0.2984\n",
            "73:\t[0s / 5s],\t\ttrain_loss: 0.2358,\tval_loss: 0.2996\n",
            "74:\t[0s / 5s],\t\ttrain_loss: 0.2402,\tval_loss: 0.2970\n",
            "75:\t[0s / 5s],\t\ttrain_loss: 0.2389,\tval_loss: 0.3002\n",
            "76:\t[0s / 5s],\t\ttrain_loss: 0.2371,\tval_loss: 0.3024\n",
            "77:\t[0s / 5s],\t\ttrain_loss: 0.2367,\tval_loss: 0.3003\n",
            "78:\t[0s / 5s],\t\ttrain_loss: 0.2383,\tval_loss: 0.2988\n",
            "Current best c-index: 0.6174458962841977\n",
            "Random search... itr: 4\n",
            "{'batch_size': 128, 'layers': 3, 'nodes': 100, 'activation_fn': 'elu', 'alpha': 1.0, 'sigma': 0.5, 'lr': 0.1, 'dropout': 0.95, 'patience': 75}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 30.9613,\tval_loss: 2.4534\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 14.0938,\tval_loss: 0.7293\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.4797,\tval_loss: 0.5938\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 3.8208,\tval_loss: 0.4883\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 1.2128,\tval_loss: 0.4834\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.7362,\tval_loss: 0.4839\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 1.1424,\tval_loss: 0.4887\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.7041,\tval_loss: 0.4830\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 8.6283,\tval_loss: 0.4873\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.5554,\tval_loss: 0.4874\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.5268,\tval_loss: 0.4838\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.5008,\tval_loss: 0.4872\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.8873,\tval_loss: 0.4877\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.5298,\tval_loss: 0.4888\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 1.5078,\tval_loss: 0.4913\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.9197,\tval_loss: 0.4893\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.5218,\tval_loss: 0.4882\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.5118,\tval_loss: 0.4859\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.5525,\tval_loss: 0.4833\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.5148,\tval_loss: 0.4880\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.5352,\tval_loss: 0.4861\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.6556,\tval_loss: 0.4840\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.6589,\tval_loss: 0.4878\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.5091,\tval_loss: 0.4841\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 2.0186,\tval_loss: 0.4899\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.7888,\tval_loss: 0.4865\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.5125,\tval_loss: 0.4856\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.5088,\tval_loss: 0.4869\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.5212,\tval_loss: 0.4846\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.5114,\tval_loss: 0.4842\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.5323,\tval_loss: 0.4879\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.6667,\tval_loss: 0.4794\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.5163,\tval_loss: 0.4889\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.5096,\tval_loss: 0.4835\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.5034,\tval_loss: 0.4851\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 8.5109,\tval_loss: 0.4849\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.6056,\tval_loss: 0.4862\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.5049,\tval_loss: 0.4846\n",
            "38:\t[0s / 3s],\t\ttrain_loss: 0.5118,\tval_loss: 0.4872\n",
            "39:\t[0s / 3s],\t\ttrain_loss: 0.5128,\tval_loss: 0.4869\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.5228,\tval_loss: 0.4912\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.8952,\tval_loss: 0.4862\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.5266,\tval_loss: 0.4850\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.5107,\tval_loss: 0.4864\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.5215,\tval_loss: 0.4843\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.5055,\tval_loss: 0.4862\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 2.1279,\tval_loss: 0.4859\n",
            "47:\t[0s / 4s],\t\ttrain_loss: 0.5103,\tval_loss: 0.4895\n",
            "48:\t[0s / 4s],\t\ttrain_loss: 0.5154,\tval_loss: 0.4852\n",
            "49:\t[0s / 4s],\t\ttrain_loss: 0.5168,\tval_loss: 0.4841\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.5047,\tval_loss: 0.4861\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.5005,\tval_loss: 0.4834\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.5119,\tval_loss: 0.4860\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.8278,\tval_loss: 0.4876\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.5055,\tval_loss: 0.4855\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.5121,\tval_loss: 0.4867\n",
            "56:\t[0s / 5s],\t\ttrain_loss: 0.5042,\tval_loss: 0.4850\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.5082,\tval_loss: 0.4870\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.5066,\tval_loss: 0.4857\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.5045,\tval_loss: 0.4854\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.5189,\tval_loss: 0.4859\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.5141,\tval_loss: 0.4854\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.5033,\tval_loss: 0.4849\n",
            "63:\t[0s / 6s],\t\ttrain_loss: 0.5095,\tval_loss: 0.4850\n",
            "64:\t[0s / 6s],\t\ttrain_loss: 0.5213,\tval_loss: 0.4878\n",
            "65:\t[0s / 6s],\t\ttrain_loss: 0.5273,\tval_loss: 0.4852\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.5043,\tval_loss: 0.4842\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.5071,\tval_loss: 0.4857\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.5064,\tval_loss: 0.4880\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.5333,\tval_loss: 0.4856\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.5075,\tval_loss: 0.4831\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.5200,\tval_loss: 0.4876\n",
            "72:\t[0s / 7s],\t\ttrain_loss: 0.5077,\tval_loss: 0.4857\n",
            "73:\t[0s / 7s],\t\ttrain_loss: 0.6013,\tval_loss: 0.4841\n",
            "74:\t[0s / 7s],\t\ttrain_loss: 0.5146,\tval_loss: 0.4857\n",
            "75:\t[0s / 7s],\t\ttrain_loss: 0.5116,\tval_loss: 0.4850\n",
            "76:\t[0s / 7s],\t\ttrain_loss: 0.5043,\tval_loss: 0.4856\n",
            "77:\t[0s / 7s],\t\ttrain_loss: 0.5080,\tval_loss: 0.6511\n",
            "78:\t[0s / 7s],\t\ttrain_loss: 0.5207,\tval_loss: 0.8480\n",
            "79:\t[0s / 7s],\t\ttrain_loss: 4.1706,\tval_loss: 0.5170\n",
            "80:\t[0s / 8s],\t\ttrain_loss: 0.5077,\tval_loss: 0.4865\n",
            "81:\t[0s / 8s],\t\ttrain_loss: 0.5067,\tval_loss: 0.4864\n",
            "82:\t[0s / 8s],\t\ttrain_loss: 0.5121,\tval_loss: 0.4864\n",
            "83:\t[0s / 8s],\t\ttrain_loss: 0.5054,\tval_loss: 0.4857\n",
            "84:\t[0s / 8s],\t\ttrain_loss: 0.5947,\tval_loss: 0.4878\n",
            "85:\t[0s / 8s],\t\ttrain_loss: 0.5001,\tval_loss: 0.4827\n",
            "86:\t[0s / 8s],\t\ttrain_loss: 0.5057,\tval_loss: 0.4849\n",
            "87:\t[0s / 8s],\t\ttrain_loss: 0.5032,\tval_loss: 0.4882\n",
            "88:\t[0s / 8s],\t\ttrain_loss: 0.5026,\tval_loss: 0.4871\n",
            "89:\t[0s / 8s],\t\ttrain_loss: 0.5048,\tval_loss: 0.4839\n",
            "90:\t[0s / 8s],\t\ttrain_loss: 3.7631,\tval_loss: 0.5041\n",
            "91:\t[0s / 8s],\t\ttrain_loss: 1.0642,\tval_loss: 0.9790\n",
            "92:\t[0s / 8s],\t\ttrain_loss: 0.9253,\tval_loss: 0.9022\n",
            "93:\t[0s / 8s],\t\ttrain_loss: 0.5124,\tval_loss: 0.8057\n",
            "94:\t[0s / 8s],\t\ttrain_loss: 0.6671,\tval_loss: 0.5947\n",
            "95:\t[0s / 9s],\t\ttrain_loss: 0.5021,\tval_loss: 0.5642\n",
            "96:\t[0s / 9s],\t\ttrain_loss: 0.5066,\tval_loss: 0.5645\n",
            "97:\t[0s / 9s],\t\ttrain_loss: 0.5055,\tval_loss: 0.5620\n",
            "98:\t[0s / 9s],\t\ttrain_loss: 0.5080,\tval_loss: 0.5665\n",
            "99:\t[0s / 9s],\t\ttrain_loss: 0.5064,\tval_loss: 0.5654\n",
            "Current best c-index: 0.6174458962841977\n",
            "Random search... itr: 5\n",
            "{'batch_size': 256, 'layers': 2, 'nodes': 75, 'activation_fn': 'relu', 'alpha': 0.5, 'sigma': 0.5, 'lr': 0.1, 'dropout': 0.3, 'patience': 50}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.4785,\tval_loss: 0.4412\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.3488,\tval_loss: 0.2976\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.3064,\tval_loss: 0.2977\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.2954,\tval_loss: 0.2895\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.2883,\tval_loss: 0.2931\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.2908,\tval_loss: 0.2909\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.2824,\tval_loss: 0.2983\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.2851,\tval_loss: 0.2959\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.2801,\tval_loss: 0.2959\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.2817,\tval_loss: 0.2930\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.2762,\tval_loss: 0.3034\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.2752,\tval_loss: 0.3065\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.2829,\tval_loss: 0.2999\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.2730,\tval_loss: 0.2955\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.2632,\tval_loss: 0.2949\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.2709,\tval_loss: 0.3106\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 0.2642,\tval_loss: 0.3018\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 0.2702,\tval_loss: 0.3197\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 0.2690,\tval_loss: 0.3246\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 0.2643,\tval_loss: 0.3172\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 0.2634,\tval_loss: 0.3175\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.2573,\tval_loss: 0.3254\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.2601,\tval_loss: 0.3407\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.2594,\tval_loss: 0.3094\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.2592,\tval_loss: 0.3588\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.2603,\tval_loss: 0.3179\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.2610,\tval_loss: 0.3237\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.2572,\tval_loss: 0.3295\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.2507,\tval_loss: 0.3471\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 0.2528,\tval_loss: 0.3581\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 0.2573,\tval_loss: 0.3522\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 0.2544,\tval_loss: 0.3745\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 0.2510,\tval_loss: 0.3757\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 0.2438,\tval_loss: 0.3754\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 0.2652,\tval_loss: 0.3768\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 0.2593,\tval_loss: 0.3785\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 0.2525,\tval_loss: 0.3793\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 0.2500,\tval_loss: 0.3933\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 0.2463,\tval_loss: 0.4036\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 0.2468,\tval_loss: 0.3705\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 0.2483,\tval_loss: 0.3425\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 0.2473,\tval_loss: 0.3584\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 0.2458,\tval_loss: 0.3543\n",
            "43:\t[0s / 1s],\t\ttrain_loss: 0.2422,\tval_loss: 0.3484\n",
            "44:\t[0s / 1s],\t\ttrain_loss: 0.2421,\tval_loss: 0.4504\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 0.2438,\tval_loss: 0.4382\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 0.2556,\tval_loss: 0.4172\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 0.2382,\tval_loss: 0.4242\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 0.2429,\tval_loss: 0.4569\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 0.2408,\tval_loss: 0.3910\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 0.2457,\tval_loss: 0.3929\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 0.2386,\tval_loss: 0.3885\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 0.2320,\tval_loss: 0.4094\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 0.2307,\tval_loss: 0.4296\n",
            "Current best c-index: 0.6174458962841977\n",
            "Random search... itr: 6\n",
            "{'batch_size': 32, 'layers': 5, 'nodes': 100, 'activation_fn': 'tanh', 'alpha': 1.0, 'sigma': 1.0, 'lr': 0.01, 'dropout': 0.5, 'patience': 75}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.7078,\tval_loss: 0.5735\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.6640,\tval_loss: 0.5597\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5855,\tval_loss: 0.5243\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5445,\tval_loss: 0.4864\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5284,\tval_loss: 0.5043\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5276,\tval_loss: 0.4866\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.5181,\tval_loss: 0.4876\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.5209,\tval_loss: 0.4840\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.5161,\tval_loss: 0.4855\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.5146,\tval_loss: 0.4851\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.5108,\tval_loss: 0.4930\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.5084,\tval_loss: 0.4842\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 0.5202,\tval_loss: 0.4832\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.5116,\tval_loss: 0.4855\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.5123,\tval_loss: 0.4895\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.5181,\tval_loss: 0.4877\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.5122,\tval_loss: 0.4863\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.5154,\tval_loss: 0.4886\n",
            "18:\t[0s / 3s],\t\ttrain_loss: 0.5117,\tval_loss: 0.4837\n",
            "19:\t[0s / 3s],\t\ttrain_loss: 0.5087,\tval_loss: 0.4846\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.5102,\tval_loss: 0.4849\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.5044,\tval_loss: 0.4847\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.5085,\tval_loss: 0.4848\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.5096,\tval_loss: 0.4849\n",
            "24:\t[0s / 4s],\t\ttrain_loss: 0.5118,\tval_loss: 0.4868\n",
            "25:\t[0s / 4s],\t\ttrain_loss: 0.5182,\tval_loss: 0.4842\n",
            "26:\t[0s / 4s],\t\ttrain_loss: 0.5047,\tval_loss: 0.4876\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.5111,\tval_loss: 0.4870\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.5066,\tval_loss: 0.4887\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.5092,\tval_loss: 0.4856\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.5081,\tval_loss: 0.4835\n",
            "31:\t[0s / 5s],\t\ttrain_loss: 0.5084,\tval_loss: 0.4874\n",
            "32:\t[0s / 5s],\t\ttrain_loss: 0.5018,\tval_loss: 0.4842\n",
            "33:\t[0s / 5s],\t\ttrain_loss: 0.5042,\tval_loss: 0.4854\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.5069,\tval_loss: 0.4859\n",
            "35:\t[0s / 5s],\t\ttrain_loss: 0.5081,\tval_loss: 0.4866\n",
            "36:\t[0s / 5s],\t\ttrain_loss: 0.5094,\tval_loss: 0.4873\n",
            "37:\t[0s / 6s],\t\ttrain_loss: 0.5084,\tval_loss: 0.4863\n",
            "38:\t[0s / 6s],\t\ttrain_loss: 0.5052,\tval_loss: 0.4844\n",
            "39:\t[0s / 6s],\t\ttrain_loss: 0.5026,\tval_loss: 0.4860\n",
            "40:\t[0s / 6s],\t\ttrain_loss: 0.5066,\tval_loss: 0.4845\n",
            "41:\t[0s / 6s],\t\ttrain_loss: 0.5069,\tval_loss: 0.4855\n",
            "42:\t[0s / 6s],\t\ttrain_loss: 0.5148,\tval_loss: 0.4860\n",
            "43:\t[0s / 7s],\t\ttrain_loss: 0.5057,\tval_loss: 0.4862\n",
            "44:\t[0s / 7s],\t\ttrain_loss: 0.5177,\tval_loss: 0.4846\n",
            "45:\t[0s / 7s],\t\ttrain_loss: 0.5078,\tval_loss: 0.4860\n",
            "46:\t[0s / 7s],\t\ttrain_loss: 0.5068,\tval_loss: 0.4858\n",
            "47:\t[0s / 7s],\t\ttrain_loss: 0.5101,\tval_loss: 0.4854\n",
            "48:\t[0s / 7s],\t\ttrain_loss: 0.5047,\tval_loss: 0.4857\n",
            "49:\t[0s / 8s],\t\ttrain_loss: 0.5084,\tval_loss: 0.4854\n",
            "50:\t[0s / 8s],\t\ttrain_loss: 0.5028,\tval_loss: 0.4860\n",
            "51:\t[0s / 8s],\t\ttrain_loss: 0.5038,\tval_loss: 0.4858\n",
            "52:\t[0s / 8s],\t\ttrain_loss: 0.5070,\tval_loss: 0.4849\n",
            "53:\t[0s / 8s],\t\ttrain_loss: 0.5038,\tval_loss: 0.4854\n",
            "54:\t[0s / 8s],\t\ttrain_loss: 0.5105,\tval_loss: 0.4859\n",
            "55:\t[0s / 8s],\t\ttrain_loss: 0.5041,\tval_loss: 0.4858\n",
            "56:\t[0s / 9s],\t\ttrain_loss: 0.5053,\tval_loss: 0.4864\n",
            "57:\t[0s / 9s],\t\ttrain_loss: 0.5050,\tval_loss: 0.4854\n",
            "58:\t[0s / 9s],\t\ttrain_loss: 0.5071,\tval_loss: 0.4856\n",
            "59:\t[0s / 9s],\t\ttrain_loss: 0.5037,\tval_loss: 0.4855\n",
            "60:\t[0s / 9s],\t\ttrain_loss: 0.5088,\tval_loss: 0.4852\n",
            "61:\t[0s / 10s],\t\ttrain_loss: 0.5074,\tval_loss: 0.4848\n",
            "62:\t[0s / 10s],\t\ttrain_loss: 0.5051,\tval_loss: 0.4858\n",
            "63:\t[0s / 10s],\t\ttrain_loss: 0.5042,\tval_loss: 0.4851\n",
            "64:\t[0s / 10s],\t\ttrain_loss: 0.5017,\tval_loss: 0.4852\n",
            "65:\t[0s / 11s],\t\ttrain_loss: 0.5028,\tval_loss: 0.4854\n",
            "66:\t[0s / 11s],\t\ttrain_loss: 0.5056,\tval_loss: 0.4846\n",
            "67:\t[0s / 11s],\t\ttrain_loss: 0.5012,\tval_loss: 0.4851\n",
            "68:\t[0s / 11s],\t\ttrain_loss: 0.5065,\tval_loss: 0.4848\n",
            "69:\t[0s / 11s],\t\ttrain_loss: 0.5019,\tval_loss: 0.4850\n",
            "70:\t[0s / 12s],\t\ttrain_loss: 0.5064,\tval_loss: 0.4848\n",
            "71:\t[0s / 12s],\t\ttrain_loss: 0.5033,\tval_loss: 0.4848\n",
            "72:\t[0s / 12s],\t\ttrain_loss: 0.5013,\tval_loss: 0.4852\n",
            "73:\t[0s / 12s],\t\ttrain_loss: 0.5088,\tval_loss: 0.4854\n",
            "74:\t[0s / 12s],\t\ttrain_loss: 0.5010,\tval_loss: 0.4860\n",
            "75:\t[0s / 12s],\t\ttrain_loss: 0.5053,\tval_loss: 0.4856\n",
            "76:\t[0s / 13s],\t\ttrain_loss: 0.5073,\tval_loss: 0.4850\n",
            "77:\t[0s / 13s],\t\ttrain_loss: 0.5132,\tval_loss: 0.4858\n",
            "78:\t[0s / 13s],\t\ttrain_loss: 0.5055,\tval_loss: 0.4851\n",
            "79:\t[0s / 13s],\t\ttrain_loss: 0.5074,\tval_loss: 0.4851\n",
            "80:\t[0s / 13s],\t\ttrain_loss: 0.5017,\tval_loss: 0.4848\n",
            "81:\t[0s / 13s],\t\ttrain_loss: 0.5035,\tval_loss: 0.4852\n",
            "82:\t[0s / 14s],\t\ttrain_loss: 0.5048,\tval_loss: 0.4856\n",
            "83:\t[0s / 14s],\t\ttrain_loss: 0.5066,\tval_loss: 0.4856\n",
            "84:\t[0s / 14s],\t\ttrain_loss: 0.5033,\tval_loss: 0.4850\n",
            "85:\t[0s / 14s],\t\ttrain_loss: 0.5059,\tval_loss: 0.4857\n",
            "86:\t[0s / 14s],\t\ttrain_loss: 0.5040,\tval_loss: 0.4859\n",
            "87:\t[0s / 14s],\t\ttrain_loss: 0.5097,\tval_loss: 0.4854\n",
            "Current best c-index: 0.6174458962841977\n",
            "Random search... itr: 7\n",
            "{'batch_size': 64, 'layers': 3, 'nodes': 100, 'activation_fn': 'elu', 'alpha': 0.1, 'sigma': 0.1, 'lr': 0.001, 'dropout': 0.0, 'patience': 75}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1455,\tval_loss: 0.1192\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1209,\tval_loss: 0.1133\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1147,\tval_loss: 0.1127\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1084,\tval_loss: 0.1129\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1076,\tval_loss: 0.1132\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1044,\tval_loss: 0.1128\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.0977,\tval_loss: 0.1167\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.0954,\tval_loss: 0.1170\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.0898,\tval_loss: 0.1262\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.0882,\tval_loss: 0.1178\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.0825,\tval_loss: 0.1225\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.0820,\tval_loss: 0.1269\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.0816,\tval_loss: 0.1333\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.0775,\tval_loss: 0.1439\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.0718,\tval_loss: 0.1488\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.0684,\tval_loss: 0.1479\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.0657,\tval_loss: 0.1425\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.0613,\tval_loss: 0.1534\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.0600,\tval_loss: 0.1604\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.0565,\tval_loss: 0.1851\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.0579,\tval_loss: 0.1733\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.0577,\tval_loss: 0.1813\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.0506,\tval_loss: 0.2086\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.0489,\tval_loss: 0.1679\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.0471,\tval_loss: 0.1816\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.0466,\tval_loss: 0.1726\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.0453,\tval_loss: 0.2846\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.0509,\tval_loss: 0.2451\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.0474,\tval_loss: 0.2224\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.0407,\tval_loss: 0.1952\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.0393,\tval_loss: 0.2350\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.0414,\tval_loss: 0.2381\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.0414,\tval_loss: 0.1838\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.0440,\tval_loss: 0.3111\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.0399,\tval_loss: 0.2662\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.0389,\tval_loss: 0.3014\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.0388,\tval_loss: 0.2207\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.0365,\tval_loss: 0.2103\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.0326,\tval_loss: 0.2430\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.0339,\tval_loss: 0.4144\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 0.0422,\tval_loss: 0.3363\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 0.0395,\tval_loss: 0.2017\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 0.0375,\tval_loss: 0.2567\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 0.0303,\tval_loss: 0.2274\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 0.0298,\tval_loss: 0.3536\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 0.0275,\tval_loss: 0.4268\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 0.0272,\tval_loss: 0.3454\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 0.0281,\tval_loss: 0.3875\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 0.0283,\tval_loss: 0.4679\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 0.0272,\tval_loss: 0.3423\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 0.0284,\tval_loss: 0.3308\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 0.0309,\tval_loss: 0.4015\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 0.0373,\tval_loss: 0.2831\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 0.0422,\tval_loss: 0.2994\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 0.0313,\tval_loss: 0.3202\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 0.0266,\tval_loss: 0.4349\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 0.0276,\tval_loss: 0.6857\n",
            "57:\t[0s / 4s],\t\ttrain_loss: 0.0265,\tval_loss: 0.4882\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 0.0245,\tval_loss: 0.6270\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 0.0256,\tval_loss: 0.3537\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 0.0270,\tval_loss: 0.9328\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 0.0263,\tval_loss: 0.5116\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 0.0265,\tval_loss: 1.4378\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 0.0236,\tval_loss: 0.9073\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 0.0238,\tval_loss: 0.7112\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 0.0232,\tval_loss: 0.8390\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 0.0248,\tval_loss: 0.4073\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 0.0348,\tval_loss: 0.4849\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 0.0311,\tval_loss: 0.9768\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 0.0598,\tval_loss: 0.1799\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 0.0658,\tval_loss: 0.3549\n",
            "71:\t[0s / 5s],\t\ttrain_loss: 0.0394,\tval_loss: 0.2793\n",
            "72:\t[0s / 5s],\t\ttrain_loss: 0.0305,\tval_loss: 0.2619\n",
            "73:\t[0s / 5s],\t\ttrain_loss: 0.0279,\tval_loss: 0.3688\n",
            "74:\t[0s / 5s],\t\ttrain_loss: 0.0250,\tval_loss: 0.4131\n",
            "75:\t[0s / 5s],\t\ttrain_loss: 0.0236,\tval_loss: 0.4633\n",
            "76:\t[0s / 5s],\t\ttrain_loss: 0.0224,\tval_loss: 0.4071\n",
            "77:\t[0s / 5s],\t\ttrain_loss: 0.0222,\tval_loss: 0.6231\n",
            "Current best c-index: 0.6174458962841977\n",
            "Random search... itr: 8\n",
            "{'batch_size': 32, 'layers': 3, 'nodes': 25, 'activation_fn': 'tanh', 'alpha': 0.1, 'sigma': 0.5, 'lr': 0.1, 'dropout': 0.3, 'patience': 50}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1327,\tval_loss: 0.1143\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1211,\tval_loss: 0.1138\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1186,\tval_loss: 0.1145\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1189,\tval_loss: 0.1146\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1190,\tval_loss: 0.1138\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1188,\tval_loss: 0.1137\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1182,\tval_loss: 0.1150\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1142\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1186,\tval_loss: 0.1144\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1191,\tval_loss: 0.1144\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1186,\tval_loss: 0.1147\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1144\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1188,\tval_loss: 0.1145\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1140\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1191,\tval_loss: 0.1143\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.1187,\tval_loss: 0.1148\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.1179,\tval_loss: 0.1142\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1142\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1190,\tval_loss: 0.1146\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1177,\tval_loss: 0.1150\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1188,\tval_loss: 0.1145\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.1178,\tval_loss: 0.1151\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.1193,\tval_loss: 0.1144\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1142\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1199,\tval_loss: 0.1141\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1188,\tval_loss: 0.1149\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1178,\tval_loss: 0.1143\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.1177,\tval_loss: 0.1142\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.1192,\tval_loss: 0.1153\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.1196,\tval_loss: 0.1137\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1140\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.1194,\tval_loss: 0.1141\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1189,\tval_loss: 0.1140\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.1177,\tval_loss: 0.1143\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.1192,\tval_loss: 0.1143\n",
            "35:\t[0s / 5s],\t\ttrain_loss: 0.1177,\tval_loss: 0.1141\n",
            "36:\t[0s / 5s],\t\ttrain_loss: 0.1183,\tval_loss: 0.1145\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.1202,\tval_loss: 0.1142\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.1179,\tval_loss: 0.1148\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.1188,\tval_loss: 0.1146\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.1193,\tval_loss: 0.1142\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1194,\tval_loss: 0.1139\n",
            "42:\t[0s / 6s],\t\ttrain_loss: 0.1171,\tval_loss: 0.1153\n",
            "43:\t[0s / 6s],\t\ttrain_loss: 0.1174,\tval_loss: 0.1145\n",
            "44:\t[0s / 6s],\t\ttrain_loss: 0.1195,\tval_loss: 0.1145\n",
            "45:\t[0s / 6s],\t\ttrain_loss: 0.1184,\tval_loss: 0.1149\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.1188,\tval_loss: 0.1136\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.1178,\tval_loss: 0.1149\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.1183,\tval_loss: 0.1143\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1186,\tval_loss: 0.1149\n",
            "50:\t[0s / 7s],\t\ttrain_loss: 0.1188,\tval_loss: 0.1141\n",
            "51:\t[0s / 7s],\t\ttrain_loss: 0.1179,\tval_loss: 0.1144\n",
            "52:\t[0s / 7s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1148\n",
            "53:\t[0s / 7s],\t\ttrain_loss: 0.1192,\tval_loss: 0.1150\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.1195,\tval_loss: 0.1140\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.1186,\tval_loss: 0.1143\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.1190,\tval_loss: 0.1147\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.1192,\tval_loss: 0.1142\n",
            "58:\t[0s / 8s],\t\ttrain_loss: 0.1184,\tval_loss: 0.1143\n",
            "59:\t[0s / 8s],\t\ttrain_loss: 0.1191,\tval_loss: 0.1146\n",
            "60:\t[0s / 8s],\t\ttrain_loss: 0.1178,\tval_loss: 0.1139\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.1187,\tval_loss: 0.1143\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1135\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.1174,\tval_loss: 0.1140\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1146\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.1191,\tval_loss: 0.1150\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1173,\tval_loss: 0.1139\n",
            "67:\t[0s / 9s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1142\n",
            "68:\t[0s / 9s],\t\ttrain_loss: 0.1186,\tval_loss: 0.1144\n",
            "69:\t[0s / 9s],\t\ttrain_loss: 0.1173,\tval_loss: 0.1148\n",
            "70:\t[0s / 9s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1140\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.1189,\tval_loss: 0.1153\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.1176,\tval_loss: 0.1145\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.1192,\tval_loss: 0.1147\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1187,\tval_loss: 0.1143\n",
            "75:\t[0s / 10s],\t\ttrain_loss: 0.1179,\tval_loss: 0.1148\n",
            "76:\t[0s / 10s],\t\ttrain_loss: 0.1196,\tval_loss: 0.1147\n",
            "77:\t[0s / 10s],\t\ttrain_loss: 0.1199,\tval_loss: 0.1145\n",
            "78:\t[0s / 10s],\t\ttrain_loss: 0.1188,\tval_loss: 0.1145\n",
            "79:\t[0s / 10s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1142\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.1185,\tval_loss: 0.1146\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.1176,\tval_loss: 0.1146\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.1177,\tval_loss: 0.1144\n",
            "83:\t[0s / 11s],\t\ttrain_loss: 0.1177,\tval_loss: 0.1144\n",
            "84:\t[0s / 11s],\t\ttrain_loss: 0.1182,\tval_loss: 0.1141\n",
            "85:\t[0s / 11s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1138\n",
            "86:\t[0s / 11s],\t\ttrain_loss: 0.1178,\tval_loss: 0.1143\n",
            "87:\t[0s / 11s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1142\n",
            "88:\t[0s / 11s],\t\ttrain_loss: 0.1187,\tval_loss: 0.1142\n",
            "89:\t[0s / 11s],\t\ttrain_loss: 0.1186,\tval_loss: 0.1140\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.1204,\tval_loss: 0.1140\n",
            "91:\t[0s / 12s],\t\ttrain_loss: 0.1186,\tval_loss: 0.1146\n",
            "92:\t[0s / 12s],\t\ttrain_loss: 0.1186,\tval_loss: 0.1142\n",
            "93:\t[0s / 12s],\t\ttrain_loss: 0.1176,\tval_loss: 0.1150\n",
            "94:\t[0s / 12s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1140\n",
            "95:\t[0s / 12s],\t\ttrain_loss: 0.1193,\tval_loss: 0.1148\n",
            "96:\t[0s / 12s],\t\ttrain_loss: 0.1189,\tval_loss: 0.1146\n",
            "97:\t[0s / 12s],\t\ttrain_loss: 0.1188,\tval_loss: 0.1143\n",
            "98:\t[0s / 12s],\t\ttrain_loss: 0.1177,\tval_loss: 0.1146\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.1196,\tval_loss: 0.1140\n",
            "Current best c-index: 0.6174458962841977\n",
            "Random search... itr: 9\n",
            "{'batch_size': 64, 'layers': 5, 'nodes': 25, 'activation_fn': 'tanh', 'alpha': 0.5, 'sigma': 1.0, 'lr': 0.01, 'dropout': 0.0, 'patience': 25}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.3383,\tval_loss: 0.2834\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2959,\tval_loss: 0.2820\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.2866,\tval_loss: 0.2801\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.2837,\tval_loss: 0.2838\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.2817,\tval_loss: 0.2875\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.2718,\tval_loss: 0.2865\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.2700,\tval_loss: 0.2875\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.2646,\tval_loss: 0.3183\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.2683,\tval_loss: 0.3047\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.2604,\tval_loss: 0.3029\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.2586,\tval_loss: 0.3052\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.2438,\tval_loss: 0.3091\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.2468,\tval_loss: 0.3680\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.2360,\tval_loss: 0.3741\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.2318,\tval_loss: 0.3812\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.2353,\tval_loss: 0.3654\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.2347,\tval_loss: 0.4246\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.2436,\tval_loss: 0.3783\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.2275,\tval_loss: 0.3706\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.2164,\tval_loss: 0.3813\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.2161,\tval_loss: 0.3782\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.2091,\tval_loss: 0.4160\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.2205,\tval_loss: 0.3835\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.2132,\tval_loss: 0.4084\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.2134,\tval_loss: 0.4090\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.2019,\tval_loss: 0.4072\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1961,\tval_loss: 0.4709\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1918,\tval_loss: 0.4608\n",
            "Current best c-index: 0.6174458962841977\n",
            "Random search... itr: 10\n",
            "{'batch_size': 32, 'layers': 3, 'nodes': 75, 'activation_fn': 'elu', 'alpha': 0.5, 'sigma': 0.5, 'lr': 0.001, 'dropout': 0.4, 'patience': 75}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.3677,\tval_loss: 0.2886\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.3199,\tval_loss: 0.2979\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.3144,\tval_loss: 0.2890\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.3037,\tval_loss: 0.2835\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.3068,\tval_loss: 0.2984\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.3014,\tval_loss: 0.2913\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.2995,\tval_loss: 0.2893\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.2990,\tval_loss: 0.2830\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.2940,\tval_loss: 0.2924\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.2939,\tval_loss: 0.2848\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.2892,\tval_loss: 0.2843\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 0.2945,\tval_loss: 0.2965\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 0.2907,\tval_loss: 0.2843\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.2957,\tval_loss: 0.2849\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.2897,\tval_loss: 0.2933\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.2907,\tval_loss: 0.2903\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.2876,\tval_loss: 0.2844\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.2868,\tval_loss: 0.2806\n",
            "18:\t[0s / 3s],\t\ttrain_loss: 0.2862,\tval_loss: 0.2897\n",
            "19:\t[0s / 3s],\t\ttrain_loss: 0.2811,\tval_loss: 0.2896\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.2845,\tval_loss: 0.2857\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.2864,\tval_loss: 0.2798\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.2817,\tval_loss: 0.2850\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.2754,\tval_loss: 0.2804\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.2787,\tval_loss: 0.2808\n",
            "25:\t[0s / 4s],\t\ttrain_loss: 0.2785,\tval_loss: 0.2802\n",
            "26:\t[0s / 4s],\t\ttrain_loss: 0.2759,\tval_loss: 0.2813\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.2784,\tval_loss: 0.2829\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.2755,\tval_loss: 0.2843\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.2759,\tval_loss: 0.2820\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.2740,\tval_loss: 0.2838\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.2849,\tval_loss: 0.2820\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.2735,\tval_loss: 0.2795\n",
            "33:\t[0s / 5s],\t\ttrain_loss: 0.2675,\tval_loss: 0.2806\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.2685,\tval_loss: 0.2835\n",
            "35:\t[0s / 5s],\t\ttrain_loss: 0.2688,\tval_loss: 0.2789\n",
            "36:\t[0s / 5s],\t\ttrain_loss: 0.2679,\tval_loss: 0.2833\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.2693,\tval_loss: 0.2810\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.2692,\tval_loss: 0.2800\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.2681,\tval_loss: 0.2848\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.2675,\tval_loss: 0.2807\n",
            "41:\t[0s / 6s],\t\ttrain_loss: 0.2622,\tval_loss: 0.2810\n",
            "42:\t[0s / 6s],\t\ttrain_loss: 0.2668,\tval_loss: 0.2826\n",
            "43:\t[0s / 6s],\t\ttrain_loss: 0.2662,\tval_loss: 0.2821\n",
            "44:\t[0s / 6s],\t\ttrain_loss: 0.2617,\tval_loss: 0.2825\n",
            "45:\t[0s / 6s],\t\ttrain_loss: 0.2647,\tval_loss: 0.2826\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.2600,\tval_loss: 0.2825\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.2605,\tval_loss: 0.2837\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.2595,\tval_loss: 0.2830\n",
            "49:\t[0s / 7s],\t\ttrain_loss: 0.2639,\tval_loss: 0.2837\n",
            "50:\t[0s / 7s],\t\ttrain_loss: 0.2627,\tval_loss: 0.2848\n",
            "51:\t[0s / 7s],\t\ttrain_loss: 0.2620,\tval_loss: 0.2838\n",
            "52:\t[0s / 7s],\t\ttrain_loss: 0.2561,\tval_loss: 0.2864\n",
            "53:\t[0s / 7s],\t\ttrain_loss: 0.2645,\tval_loss: 0.2844\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.2591,\tval_loss: 0.2851\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.2565,\tval_loss: 0.2837\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.2596,\tval_loss: 0.2853\n",
            "57:\t[0s / 8s],\t\ttrain_loss: 0.2517,\tval_loss: 0.2867\n",
            "58:\t[0s / 8s],\t\ttrain_loss: 0.2570,\tval_loss: 0.2865\n",
            "59:\t[0s / 8s],\t\ttrain_loss: 0.2549,\tval_loss: 0.2875\n",
            "60:\t[0s / 8s],\t\ttrain_loss: 0.2543,\tval_loss: 0.2887\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.2484,\tval_loss: 0.2888\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.2469,\tval_loss: 0.2892\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.2500,\tval_loss: 0.2914\n",
            "64:\t[0s / 9s],\t\ttrain_loss: 0.2432,\tval_loss: 0.2920\n",
            "65:\t[0s / 9s],\t\ttrain_loss: 0.2463,\tval_loss: 0.2916\n",
            "66:\t[0s / 9s],\t\ttrain_loss: 0.2524,\tval_loss: 0.2925\n",
            "67:\t[0s / 9s],\t\ttrain_loss: 0.2499,\tval_loss: 0.2912\n",
            "68:\t[0s / 9s],\t\ttrain_loss: 0.2426,\tval_loss: 0.2906\n",
            "69:\t[0s / 10s],\t\ttrain_loss: 0.2444,\tval_loss: 0.2938\n",
            "70:\t[0s / 10s],\t\ttrain_loss: 0.2442,\tval_loss: 0.2980\n",
            "71:\t[0s / 10s],\t\ttrain_loss: 0.2413,\tval_loss: 0.2980\n",
            "72:\t[0s / 10s],\t\ttrain_loss: 0.2459,\tval_loss: 0.2964\n",
            "73:\t[0s / 10s],\t\ttrain_loss: 0.2389,\tval_loss: 0.2962\n",
            "74:\t[0s / 10s],\t\ttrain_loss: 0.2412,\tval_loss: 0.3009\n",
            "75:\t[0s / 10s],\t\ttrain_loss: 0.2366,\tval_loss: 0.2964\n",
            "76:\t[0s / 10s],\t\ttrain_loss: 0.2396,\tval_loss: 0.3010\n",
            "77:\t[0s / 11s],\t\ttrain_loss: 0.2364,\tval_loss: 0.3018\n",
            "78:\t[0s / 11s],\t\ttrain_loss: 0.2370,\tval_loss: 0.3005\n",
            "79:\t[0s / 11s],\t\ttrain_loss: 0.2358,\tval_loss: 0.3014\n",
            "80:\t[0s / 11s],\t\ttrain_loss: 0.2343,\tval_loss: 0.3042\n",
            "81:\t[0s / 11s],\t\ttrain_loss: 0.2338,\tval_loss: 0.3005\n",
            "82:\t[0s / 11s],\t\ttrain_loss: 0.2316,\tval_loss: 0.3077\n",
            "83:\t[0s / 11s],\t\ttrain_loss: 0.2294,\tval_loss: 0.3031\n",
            "84:\t[0s / 11s],\t\ttrain_loss: 0.2381,\tval_loss: 0.3095\n",
            "85:\t[0s / 12s],\t\ttrain_loss: 0.2272,\tval_loss: 0.3068\n",
            "86:\t[0s / 12s],\t\ttrain_loss: 0.2401,\tval_loss: 0.3077\n",
            "87:\t[0s / 12s],\t\ttrain_loss: 0.2312,\tval_loss: 0.3085\n",
            "88:\t[0s / 12s],\t\ttrain_loss: 0.2267,\tval_loss: 0.3087\n",
            "89:\t[0s / 12s],\t\ttrain_loss: 0.2234,\tval_loss: 0.3190\n",
            "90:\t[0s / 12s],\t\ttrain_loss: 0.2261,\tval_loss: 0.3109\n",
            "91:\t[0s / 12s],\t\ttrain_loss: 0.2238,\tval_loss: 0.3208\n",
            "92:\t[0s / 13s],\t\ttrain_loss: 0.2239,\tval_loss: 0.3209\n",
            "93:\t[0s / 13s],\t\ttrain_loss: 0.2259,\tval_loss: 0.3186\n",
            "94:\t[0s / 13s],\t\ttrain_loss: 0.2252,\tval_loss: 0.3202\n",
            "95:\t[0s / 13s],\t\ttrain_loss: 0.2230,\tval_loss: 0.3219\n",
            "96:\t[0s / 13s],\t\ttrain_loss: 0.2237,\tval_loss: 0.3193\n",
            "97:\t[0s / 14s],\t\ttrain_loss: 0.2233,\tval_loss: 0.3207\n",
            "98:\t[0s / 14s],\t\ttrain_loss: 0.2232,\tval_loss: 0.3275\n",
            "99:\t[0s / 14s],\t\ttrain_loss: 0.2200,\tval_loss: 0.3219\n",
            "Current best c-index: 0.6174458962841977\n",
            "Random search... itr: 11\n",
            "{'batch_size': 32, 'layers': 2, 'nodes': 50, 'activation_fn': 'tanh', 'alpha': 0.1, 'sigma': 0.1, 'lr': 0.01, 'dropout': 0.1, 'patience': 50}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1341,\tval_loss: 0.1171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1206,\tval_loss: 0.1165\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1185,\tval_loss: 0.1180\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1145,\tval_loss: 0.1168\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1132,\tval_loss: 0.1220\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1108,\tval_loss: 0.1196\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1072,\tval_loss: 0.1271\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.1064,\tval_loss: 0.1181\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1017,\tval_loss: 0.1247\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.0987,\tval_loss: 0.1265\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.0943,\tval_loss: 0.1241\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.0950,\tval_loss: 0.1311\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.0965,\tval_loss: 0.1499\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.0937,\tval_loss: 0.1506\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.1266,\tval_loss: 0.1420\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.1105,\tval_loss: 0.1328\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.0974,\tval_loss: 0.1347\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.0982,\tval_loss: 0.1394\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.0950,\tval_loss: 0.1404\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.0897,\tval_loss: 0.1471\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.0938,\tval_loss: 0.1393\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.0871,\tval_loss: 0.1481\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.0815,\tval_loss: 0.1760\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.0851,\tval_loss: 0.1539\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1004,\tval_loss: 0.1638\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.0994,\tval_loss: 0.1501\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.0859,\tval_loss: 0.1596\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.0847,\tval_loss: 0.1566\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.0831,\tval_loss: 0.1687\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.0766,\tval_loss: 0.1689\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.0836,\tval_loss: 0.1995\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.0771,\tval_loss: 0.1704\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.0741,\tval_loss: 0.1986\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.0771,\tval_loss: 0.1734\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.0789,\tval_loss: 0.1819\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1184,\tval_loss: 0.1871\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1040,\tval_loss: 0.1661\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.0996,\tval_loss: 0.1806\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.0820,\tval_loss: 0.1711\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.0815,\tval_loss: 0.1732\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.0776,\tval_loss: 0.1732\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.0756,\tval_loss: 0.1694\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.0769,\tval_loss: 0.1816\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.0693,\tval_loss: 0.1864\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.0718,\tval_loss: 0.1788\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.0816,\tval_loss: 0.1912\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.0778,\tval_loss: 0.1880\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.0793,\tval_loss: 0.1869\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.0778,\tval_loss: 0.1967\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.0711,\tval_loss: 0.1876\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.0694,\tval_loss: 0.2130\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.0655,\tval_loss: 0.2044\n",
            "Current best c-index: 0.6174458962841977\n",
            "Random search... itr: 12\n",
            "{'batch_size': 64, 'layers': 3, 'nodes': 100, 'activation_fn': 'tanh', 'alpha': 1.0, 'sigma': 0.5, 'lr': 0.01, 'dropout': 0.3, 'patience': 75}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6024,\tval_loss: 0.5419\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5604,\tval_loss: 0.4747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5279,\tval_loss: 0.4823\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5257,\tval_loss: 0.4989\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5066,\tval_loss: 0.5044\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4948,\tval_loss: 0.4956\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.4955,\tval_loss: 0.4908\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.4782,\tval_loss: 0.4972\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.4858,\tval_loss: 0.5032\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.4760,\tval_loss: 0.5222\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.4597,\tval_loss: 0.5201\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.4541,\tval_loss: 0.5430\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.4801,\tval_loss: 0.4851\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.4438,\tval_loss: 0.5020\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.4504,\tval_loss: 0.5439\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.4392,\tval_loss: 0.5416\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.4402,\tval_loss: 0.5442\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.4406,\tval_loss: 0.6187\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.4411,\tval_loss: 0.5314\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.4207,\tval_loss: 0.5743\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.3998,\tval_loss: 0.5903\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.4187,\tval_loss: 0.6336\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.4116,\tval_loss: 0.6549\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.4180,\tval_loss: 0.6524\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.4008,\tval_loss: 0.6392\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.3980,\tval_loss: 0.6999\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.4153,\tval_loss: 0.6447\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.4191,\tval_loss: 0.6077\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.3955,\tval_loss: 0.6345\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.3888,\tval_loss: 0.6085\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.3845,\tval_loss: 0.6217\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.3742,\tval_loss: 0.7449\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.3944,\tval_loss: 0.8321\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.3808,\tval_loss: 0.7369\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.3758,\tval_loss: 0.7272\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.3784,\tval_loss: 0.8560\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.3774,\tval_loss: 0.7501\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.3526,\tval_loss: 0.8021\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.3653,\tval_loss: 0.8786\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.3731,\tval_loss: 0.8448\n",
            "40:\t[0s / 3s],\t\ttrain_loss: 0.3712,\tval_loss: 0.7800\n",
            "41:\t[0s / 3s],\t\ttrain_loss: 0.3451,\tval_loss: 0.8418\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 0.3690,\tval_loss: 0.7756\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 0.3470,\tval_loss: 0.8514\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 0.3352,\tval_loss: 0.9496\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 0.3508,\tval_loss: 0.9074\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 0.3466,\tval_loss: 0.9726\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 0.3731,\tval_loss: 0.8451\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 0.3509,\tval_loss: 0.9161\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 0.3614,\tval_loss: 1.0238\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 0.3511,\tval_loss: 1.1108\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 0.3428,\tval_loss: 1.0594\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 0.3357,\tval_loss: 1.0338\n",
            "53:\t[0s / 4s],\t\ttrain_loss: 0.3557,\tval_loss: 0.8521\n",
            "54:\t[0s / 4s],\t\ttrain_loss: 0.3614,\tval_loss: 0.8465\n",
            "55:\t[0s / 4s],\t\ttrain_loss: 0.3598,\tval_loss: 1.0106\n",
            "56:\t[0s / 4s],\t\ttrain_loss: 0.3280,\tval_loss: 1.1296\n",
            "57:\t[0s / 4s],\t\ttrain_loss: 0.3278,\tval_loss: 1.1225\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 0.3352,\tval_loss: 1.0820\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 0.3397,\tval_loss: 1.1754\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 0.3495,\tval_loss: 1.1822\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 0.3186,\tval_loss: 1.1659\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 0.3178,\tval_loss: 1.2322\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 0.3193,\tval_loss: 1.2051\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 0.3148,\tval_loss: 1.3648\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 0.3238,\tval_loss: 1.1076\n",
            "66:\t[0s / 5s],\t\ttrain_loss: 0.3654,\tval_loss: 1.0821\n",
            "67:\t[0s / 5s],\t\ttrain_loss: 0.3326,\tval_loss: 0.9790\n",
            "68:\t[0s / 5s],\t\ttrain_loss: 0.3272,\tval_loss: 1.1371\n",
            "69:\t[0s / 5s],\t\ttrain_loss: 0.3156,\tval_loss: 1.3456\n",
            "70:\t[0s / 5s],\t\ttrain_loss: 0.3145,\tval_loss: 1.3215\n",
            "71:\t[0s / 5s],\t\ttrain_loss: 0.3257,\tval_loss: 1.3579\n",
            "72:\t[0s / 5s],\t\ttrain_loss: 0.3306,\tval_loss: 1.2185\n",
            "73:\t[0s / 5s],\t\ttrain_loss: 0.3360,\tval_loss: 1.2258\n",
            "74:\t[0s / 5s],\t\ttrain_loss: 0.3131,\tval_loss: 1.4739\n",
            "75:\t[0s / 5s],\t\ttrain_loss: 0.3094,\tval_loss: 1.3817\n",
            "76:\t[0s / 6s],\t\ttrain_loss: 0.3079,\tval_loss: 1.3074\n",
            "Current best c-index: 0.6174458962841977\n",
            "Random search... itr: 13\n",
            "{'batch_size': 32, 'layers': 5, 'nodes': 25, 'activation_fn': 'elu', 'alpha': 0.5, 'sigma': 0.5, 'lr': 0.1, 'dropout': 0.1, 'patience': 75}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.3397,\tval_loss: 0.2786\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2963,\tval_loss: 0.2797\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.2950,\tval_loss: 0.2835\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.2951,\tval_loss: 0.2796\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.2958,\tval_loss: 0.2807\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.2913,\tval_loss: 0.2822\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.2932,\tval_loss: 0.2773\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.2919,\tval_loss: 0.2797\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.2927,\tval_loss: 0.2815\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.2930,\tval_loss: 0.2790\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.2912,\tval_loss: 0.2775\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 0.2914,\tval_loss: 0.2798\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 0.2921,\tval_loss: 0.2782\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.2947,\tval_loss: 0.2774\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.2917,\tval_loss: 0.2871\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.2951,\tval_loss: 0.2775\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.2932,\tval_loss: 0.2776\n",
            "17:\t[0s / 3s],\t\ttrain_loss: 0.2916,\tval_loss: 0.2824\n",
            "18:\t[0s / 3s],\t\ttrain_loss: 0.2940,\tval_loss: 0.2783\n",
            "19:\t[0s / 3s],\t\ttrain_loss: 0.2913,\tval_loss: 0.2798\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.2924,\tval_loss: 0.2823\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.2933,\tval_loss: 0.2798\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.2956,\tval_loss: 0.2784\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.2933,\tval_loss: 0.2772\n",
            "24:\t[0s / 4s],\t\ttrain_loss: 0.2929,\tval_loss: 0.2779\n",
            "25:\t[0s / 4s],\t\ttrain_loss: 0.2921,\tval_loss: 0.2782\n",
            "26:\t[0s / 4s],\t\ttrain_loss: 0.2940,\tval_loss: 0.2793\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.2920,\tval_loss: 0.2789\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.2962,\tval_loss: 0.2791\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.2923,\tval_loss: 0.2794\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.2921,\tval_loss: 0.2792\n",
            "31:\t[0s / 5s],\t\ttrain_loss: 0.2905,\tval_loss: 0.2784\n",
            "32:\t[0s / 5s],\t\ttrain_loss: 0.2895,\tval_loss: 0.2787\n",
            "33:\t[0s / 5s],\t\ttrain_loss: 0.2942,\tval_loss: 0.2763\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.2917,\tval_loss: 0.2794\n",
            "35:\t[0s / 5s],\t\ttrain_loss: 0.2928,\tval_loss: 0.2814\n",
            "36:\t[0s / 5s],\t\ttrain_loss: 0.2923,\tval_loss: 0.2804\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.2927,\tval_loss: 0.2835\n",
            "38:\t[0s / 6s],\t\ttrain_loss: 0.2919,\tval_loss: 0.2821\n",
            "39:\t[0s / 6s],\t\ttrain_loss: 0.2899,\tval_loss: 0.2850\n",
            "40:\t[0s / 6s],\t\ttrain_loss: 0.2931,\tval_loss: 0.2798\n",
            "41:\t[0s / 6s],\t\ttrain_loss: 0.2931,\tval_loss: 0.2791\n",
            "42:\t[0s / 6s],\t\ttrain_loss: 0.2905,\tval_loss: 0.2806\n",
            "43:\t[0s / 6s],\t\ttrain_loss: 0.2926,\tval_loss: 0.2811\n",
            "44:\t[0s / 6s],\t\ttrain_loss: 0.2931,\tval_loss: 0.2828\n",
            "45:\t[0s / 7s],\t\ttrain_loss: 0.2922,\tval_loss: 0.2785\n",
            "46:\t[0s / 7s],\t\ttrain_loss: 0.2916,\tval_loss: 0.2781\n",
            "47:\t[0s / 7s],\t\ttrain_loss: 0.2918,\tval_loss: 0.2781\n",
            "48:\t[0s / 7s],\t\ttrain_loss: 0.2907,\tval_loss: 0.2817\n",
            "49:\t[0s / 7s],\t\ttrain_loss: 0.2943,\tval_loss: 0.2794\n",
            "50:\t[0s / 7s],\t\ttrain_loss: 0.2932,\tval_loss: 0.2799\n",
            "51:\t[0s / 7s],\t\ttrain_loss: 0.2911,\tval_loss: 0.2834\n",
            "52:\t[0s / 8s],\t\ttrain_loss: 0.2921,\tval_loss: 0.2790\n",
            "53:\t[0s / 8s],\t\ttrain_loss: 0.2944,\tval_loss: 0.2771\n",
            "54:\t[0s / 8s],\t\ttrain_loss: 0.2905,\tval_loss: 0.2824\n",
            "55:\t[0s / 8s],\t\ttrain_loss: 0.2926,\tval_loss: 0.2816\n",
            "56:\t[0s / 8s],\t\ttrain_loss: 0.2909,\tval_loss: 0.2784\n",
            "57:\t[0s / 8s],\t\ttrain_loss: 0.2935,\tval_loss: 0.2817\n",
            "58:\t[0s / 8s],\t\ttrain_loss: 0.2932,\tval_loss: 0.2795\n",
            "59:\t[0s / 9s],\t\ttrain_loss: 0.2916,\tval_loss: 0.2799\n",
            "60:\t[0s / 9s],\t\ttrain_loss: 0.2936,\tval_loss: 0.2799\n",
            "61:\t[0s / 9s],\t\ttrain_loss: 0.2989,\tval_loss: 0.2791\n",
            "62:\t[0s / 9s],\t\ttrain_loss: 0.2914,\tval_loss: 0.2811\n",
            "63:\t[0s / 9s],\t\ttrain_loss: 0.2957,\tval_loss: 0.2827\n",
            "64:\t[0s / 9s],\t\ttrain_loss: 0.2914,\tval_loss: 0.2793\n",
            "65:\t[0s / 9s],\t\ttrain_loss: 0.2918,\tval_loss: 0.2774\n",
            "66:\t[0s / 10s],\t\ttrain_loss: 0.2942,\tval_loss: 0.2794\n",
            "67:\t[0s / 10s],\t\ttrain_loss: 0.2915,\tval_loss: 0.2780\n",
            "68:\t[0s / 10s],\t\ttrain_loss: 0.2887,\tval_loss: 0.2819\n",
            "69:\t[0s / 10s],\t\ttrain_loss: 0.2920,\tval_loss: 0.2795\n",
            "70:\t[0s / 10s],\t\ttrain_loss: 0.2911,\tval_loss: 0.2808\n",
            "71:\t[0s / 10s],\t\ttrain_loss: 0.2908,\tval_loss: 0.2799\n",
            "72:\t[0s / 10s],\t\ttrain_loss: 0.2919,\tval_loss: 0.2794\n",
            "73:\t[0s / 11s],\t\ttrain_loss: 0.2904,\tval_loss: 0.2789\n",
            "74:\t[0s / 11s],\t\ttrain_loss: 0.2897,\tval_loss: 0.2825\n",
            "75:\t[0s / 11s],\t\ttrain_loss: 0.2938,\tval_loss: 0.2788\n",
            "76:\t[0s / 11s],\t\ttrain_loss: 0.2926,\tval_loss: 0.2814\n",
            "77:\t[0s / 11s],\t\ttrain_loss: 0.2920,\tval_loss: 0.2788\n",
            "78:\t[0s / 11s],\t\ttrain_loss: 0.2893,\tval_loss: 0.2806\n",
            "79:\t[0s / 11s],\t\ttrain_loss: 0.2941,\tval_loss: 0.2808\n",
            "80:\t[0s / 12s],\t\ttrain_loss: 0.2953,\tval_loss: 0.2817\n",
            "81:\t[0s / 12s],\t\ttrain_loss: 0.2932,\tval_loss: 0.2831\n",
            "82:\t[0s / 12s],\t\ttrain_loss: 0.2943,\tval_loss: 0.2822\n",
            "83:\t[0s / 12s],\t\ttrain_loss: 0.3023,\tval_loss: 0.2785\n",
            "84:\t[0s / 12s],\t\ttrain_loss: 0.2908,\tval_loss: 0.2790\n",
            "85:\t[0s / 13s],\t\ttrain_loss: 0.2915,\tval_loss: 0.2838\n",
            "86:\t[0s / 13s],\t\ttrain_loss: 0.2922,\tval_loss: 0.2814\n",
            "87:\t[0s / 13s],\t\ttrain_loss: 0.2923,\tval_loss: 0.2792\n",
            "88:\t[0s / 13s],\t\ttrain_loss: 0.2906,\tval_loss: 0.2832\n",
            "89:\t[0s / 13s],\t\ttrain_loss: 0.2902,\tval_loss: 0.2789\n",
            "90:\t[0s / 14s],\t\ttrain_loss: 0.2930,\tval_loss: 0.2824\n",
            "91:\t[0s / 14s],\t\ttrain_loss: 0.2914,\tval_loss: 0.2813\n",
            "92:\t[0s / 14s],\t\ttrain_loss: 0.2916,\tval_loss: 0.2781\n",
            "93:\t[0s / 14s],\t\ttrain_loss: 0.2923,\tval_loss: 0.2807\n",
            "94:\t[0s / 14s],\t\ttrain_loss: 0.2899,\tval_loss: 0.2793\n",
            "95:\t[0s / 15s],\t\ttrain_loss: 0.2918,\tval_loss: 0.2827\n",
            "96:\t[0s / 15s],\t\ttrain_loss: 0.2909,\tval_loss: 0.2839\n",
            "97:\t[0s / 15s],\t\ttrain_loss: 0.2905,\tval_loss: 0.2818\n",
            "98:\t[0s / 15s],\t\ttrain_loss: 0.2901,\tval_loss: 0.2817\n",
            "99:\t[0s / 15s],\t\ttrain_loss: 0.2913,\tval_loss: 0.2808\n",
            "Current best c-index: 0.6174458962841977\n",
            "Random search... itr: 14\n",
            "{'batch_size': 256, 'layers': 1, 'nodes': 50, 'activation_fn': 'elu', 'alpha': 0.1, 'sigma': 1.0, 'lr': 0.1, 'dropout': 0.6, 'patience': 50}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1401,\tval_loss: 0.1150\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1278,\tval_loss: 0.1154\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1248,\tval_loss: 0.1154\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1224,\tval_loss: 0.1149\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1209,\tval_loss: 0.1142\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1192,\tval_loss: 0.1148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1142\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1186,\tval_loss: 0.1148\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1178,\tval_loss: 0.1142\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.1189,\tval_loss: 0.1163\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.1191,\tval_loss: 0.1158\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1156\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.1168,\tval_loss: 0.1171\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.1171,\tval_loss: 0.1185\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.1175,\tval_loss: 0.1170\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.1167,\tval_loss: 0.1183\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 0.1178,\tval_loss: 0.1185\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 0.1176,\tval_loss: 0.1155\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 0.1174,\tval_loss: 0.1140\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 0.1183,\tval_loss: 0.1149\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1150\n",
            "21:\t[0s / 0s],\t\ttrain_loss: 0.1167,\tval_loss: 0.1166\n",
            "22:\t[0s / 0s],\t\ttrain_loss: 0.1166,\tval_loss: 0.1156\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.1184,\tval_loss: 0.1154\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.1167,\tval_loss: 0.1154\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.1183,\tval_loss: 0.1176\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.1162,\tval_loss: 0.1167\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.1170,\tval_loss: 0.1166\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.1175,\tval_loss: 0.1162\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 0.1178,\tval_loss: 0.1171\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 0.1184,\tval_loss: 0.1181\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 0.1174,\tval_loss: 0.1188\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1195\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 0.1167,\tval_loss: 0.1181\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1168\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 0.1170,\tval_loss: 0.1178\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 0.1178,\tval_loss: 0.1207\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 0.1161,\tval_loss: 0.1203\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 0.1172,\tval_loss: 0.1178\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 0.1169,\tval_loss: 0.1164\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1162\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 0.1177,\tval_loss: 0.1166\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 0.1177,\tval_loss: 0.1171\n",
            "43:\t[0s / 1s],\t\ttrain_loss: 0.1158,\tval_loss: 0.1181\n",
            "44:\t[0s / 1s],\t\ttrain_loss: 0.1173,\tval_loss: 0.1194\n",
            "45:\t[0s / 1s],\t\ttrain_loss: 0.1169,\tval_loss: 0.1186\n",
            "46:\t[0s / 1s],\t\ttrain_loss: 0.1160,\tval_loss: 0.1199\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 0.1156,\tval_loss: 0.1193\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 0.1158,\tval_loss: 0.1164\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 0.1183,\tval_loss: 0.1157\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 0.1162,\tval_loss: 0.1151\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 0.1168,\tval_loss: 0.1156\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 0.1154,\tval_loss: 0.1153\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 0.1162,\tval_loss: 0.1168\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 0.1157,\tval_loss: 0.1172\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 0.1164,\tval_loss: 0.1176\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1196\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 0.1161,\tval_loss: 0.1201\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 0.1164,\tval_loss: 0.1205\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 0.1171,\tval_loss: 0.1184\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 0.1175,\tval_loss: 0.1155\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 0.1162,\tval_loss: 0.1162\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 0.1151,\tval_loss: 0.1161\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 0.1164,\tval_loss: 0.1153\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 0.1162,\tval_loss: 0.1146\n",
            "65:\t[0s / 2s],\t\ttrain_loss: 0.1170,\tval_loss: 0.1156\n",
            "66:\t[0s / 2s],\t\ttrain_loss: 0.1164,\tval_loss: 0.1146\n",
            "67:\t[0s / 2s],\t\ttrain_loss: 0.1168,\tval_loss: 0.1151\n",
            "68:\t[0s / 2s],\t\ttrain_loss: 0.1169,\tval_loss: 0.1158\n",
            "Current best c-index: 0.6174458962841977\n",
            "Random search... itr: 15\n",
            "{'batch_size': 32, 'layers': 2, 'nodes': 100, 'activation_fn': 'relu', 'alpha': 1.0, 'sigma': 0.1, 'lr': 0.1, 'dropout': 0.3, 'patience': 25}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.9468,\tval_loss: 0.6179\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.6269,\tval_loss: 0.5759\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.6365,\tval_loss: 0.5199\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5751,\tval_loss: 0.5809\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5904,\tval_loss: 0.5580\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5877,\tval_loss: 0.5610\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.5975,\tval_loss: 0.6107\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.6796,\tval_loss: 0.6827\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.7094,\tval_loss: 0.6664\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.7506,\tval_loss: 0.7313\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.7533,\tval_loss: 0.7815\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.7034,\tval_loss: 0.6139\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.6457,\tval_loss: 0.7088\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.6743,\tval_loss: 0.5960\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.6294,\tval_loss: 0.5504\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.6110,\tval_loss: 0.6427\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.6071,\tval_loss: 0.5630\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.6327,\tval_loss: 0.6257\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.7102,\tval_loss: 0.6256\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.6654,\tval_loss: 0.5937\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.6491,\tval_loss: 0.6169\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.6152,\tval_loss: 0.5802\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.6068,\tval_loss: 0.6395\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.6258,\tval_loss: 0.6301\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.5994,\tval_loss: 0.6261\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.6176,\tval_loss: 0.5774\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.6050,\tval_loss: 0.6307\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.6210,\tval_loss: 0.5944\n",
            "Current best c-index: 0.6174458962841977\n",
            "Random search... itr: 16\n",
            "{'batch_size': 32, 'layers': 3, 'nodes': 100, 'activation_fn': 'tanh', 'alpha': 0.5, 'sigma': 0.5, 'lr': 0.001, 'dropout': 0.5, 'patience': 75}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.3575,\tval_loss: 0.3080\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.3283,\tval_loss: 0.3164\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.3229,\tval_loss: 0.3108\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.3218,\tval_loss: 0.3119\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.3111,\tval_loss: 0.3193\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.3011,\tval_loss: 0.3125\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.3074,\tval_loss: 0.3277\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.2990,\tval_loss: 0.3119\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.3030,\tval_loss: 0.3055\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.3029,\tval_loss: 0.3101\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.2955,\tval_loss: 0.3078\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.2964,\tval_loss: 0.3093\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.2948,\tval_loss: 0.3093\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.2954,\tval_loss: 0.3146\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.2907,\tval_loss: 0.3059\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.2946,\tval_loss: 0.2989\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.2929,\tval_loss: 0.2981\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.2930,\tval_loss: 0.3026\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.2900,\tval_loss: 0.3008\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.2869,\tval_loss: 0.2985\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.2859,\tval_loss: 0.2961\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.2928,\tval_loss: 0.2902\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.2836,\tval_loss: 0.2873\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.2827,\tval_loss: 0.2913\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.2867,\tval_loss: 0.2866\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.2883,\tval_loss: 0.2940\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.2848,\tval_loss: 0.2931\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.2875,\tval_loss: 0.2869\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.2804,\tval_loss: 0.2836\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.2845,\tval_loss: 0.2826\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.2774,\tval_loss: 0.2866\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.2826,\tval_loss: 0.2897\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.2751,\tval_loss: 0.2852\n",
            "33:\t[0s / 5s],\t\ttrain_loss: 0.2781,\tval_loss: 0.2849\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.2785,\tval_loss: 0.2810\n",
            "35:\t[0s / 5s],\t\ttrain_loss: 0.2744,\tval_loss: 0.2820\n",
            "36:\t[0s / 5s],\t\ttrain_loss: 0.2696,\tval_loss: 0.2817\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.2746,\tval_loss: 0.2850\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.2762,\tval_loss: 0.2865\n",
            "39:\t[0s / 6s],\t\ttrain_loss: 0.2791,\tval_loss: 0.2859\n",
            "40:\t[0s / 6s],\t\ttrain_loss: 0.2777,\tval_loss: 0.2841\n",
            "41:\t[0s / 6s],\t\ttrain_loss: 0.2750,\tval_loss: 0.2841\n",
            "42:\t[0s / 6s],\t\ttrain_loss: 0.2724,\tval_loss: 0.2827\n",
            "43:\t[0s / 6s],\t\ttrain_loss: 0.2711,\tval_loss: 0.2843\n",
            "44:\t[0s / 6s],\t\ttrain_loss: 0.2726,\tval_loss: 0.2817\n",
            "45:\t[0s / 6s],\t\ttrain_loss: 0.2705,\tval_loss: 0.2810\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.2723,\tval_loss: 0.2870\n",
            "47:\t[0s / 7s],\t\ttrain_loss: 0.2687,\tval_loss: 0.2817\n",
            "48:\t[0s / 7s],\t\ttrain_loss: 0.2709,\tval_loss: 0.2827\n",
            "49:\t[0s / 7s],\t\ttrain_loss: 0.2650,\tval_loss: 0.2814\n",
            "50:\t[0s / 7s],\t\ttrain_loss: 0.2616,\tval_loss: 0.2815\n",
            "51:\t[0s / 7s],\t\ttrain_loss: 0.2607,\tval_loss: 0.2834\n",
            "52:\t[0s / 7s],\t\ttrain_loss: 0.2656,\tval_loss: 0.2839\n",
            "53:\t[0s / 7s],\t\ttrain_loss: 0.2650,\tval_loss: 0.2826\n",
            "54:\t[0s / 8s],\t\ttrain_loss: 0.2622,\tval_loss: 0.2830\n",
            "55:\t[0s / 8s],\t\ttrain_loss: 0.2624,\tval_loss: 0.2819\n",
            "56:\t[0s / 8s],\t\ttrain_loss: 0.2611,\tval_loss: 0.2838\n",
            "57:\t[0s / 8s],\t\ttrain_loss: 0.2601,\tval_loss: 0.2814\n",
            "58:\t[0s / 8s],\t\ttrain_loss: 0.2613,\tval_loss: 0.2852\n",
            "59:\t[0s / 8s],\t\ttrain_loss: 0.2639,\tval_loss: 0.2840\n",
            "60:\t[0s / 8s],\t\ttrain_loss: 0.2580,\tval_loss: 0.2819\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.2598,\tval_loss: 0.2850\n",
            "62:\t[0s / 9s],\t\ttrain_loss: 0.2572,\tval_loss: 0.2848\n",
            "63:\t[0s / 9s],\t\ttrain_loss: 0.2591,\tval_loss: 0.2844\n",
            "64:\t[0s / 9s],\t\ttrain_loss: 0.2517,\tval_loss: 0.2880\n",
            "65:\t[0s / 9s],\t\ttrain_loss: 0.2562,\tval_loss: 0.2890\n",
            "66:\t[0s / 9s],\t\ttrain_loss: 0.2507,\tval_loss: 0.2880\n",
            "67:\t[0s / 9s],\t\ttrain_loss: 0.2533,\tval_loss: 0.2864\n",
            "68:\t[0s / 9s],\t\ttrain_loss: 0.2511,\tval_loss: 0.2857\n",
            "69:\t[0s / 9s],\t\ttrain_loss: 0.2506,\tval_loss: 0.2857\n",
            "70:\t[0s / 10s],\t\ttrain_loss: 0.2519,\tval_loss: 0.2873\n",
            "71:\t[0s / 10s],\t\ttrain_loss: 0.2493,\tval_loss: 0.2874\n",
            "72:\t[0s / 10s],\t\ttrain_loss: 0.2518,\tval_loss: 0.2898\n",
            "73:\t[0s / 10s],\t\ttrain_loss: 0.2489,\tval_loss: 0.2878\n",
            "74:\t[0s / 10s],\t\ttrain_loss: 0.2507,\tval_loss: 0.2876\n",
            "75:\t[0s / 10s],\t\ttrain_loss: 0.2511,\tval_loss: 0.2879\n",
            "76:\t[0s / 10s],\t\ttrain_loss: 0.2492,\tval_loss: 0.2866\n",
            "77:\t[0s / 11s],\t\ttrain_loss: 0.2499,\tval_loss: 0.2879\n",
            "78:\t[0s / 11s],\t\ttrain_loss: 0.2493,\tval_loss: 0.2888\n",
            "79:\t[0s / 11s],\t\ttrain_loss: 0.2476,\tval_loss: 0.2890\n",
            "80:\t[0s / 11s],\t\ttrain_loss: 0.2455,\tval_loss: 0.2932\n",
            "81:\t[0s / 11s],\t\ttrain_loss: 0.2459,\tval_loss: 0.2935\n",
            "82:\t[0s / 11s],\t\ttrain_loss: 0.2388,\tval_loss: 0.2939\n",
            "83:\t[0s / 11s],\t\ttrain_loss: 0.2464,\tval_loss: 0.2955\n",
            "84:\t[0s / 11s],\t\ttrain_loss: 0.2446,\tval_loss: 0.2945\n",
            "85:\t[0s / 12s],\t\ttrain_loss: 0.2374,\tval_loss: 0.2978\n",
            "86:\t[0s / 12s],\t\ttrain_loss: 0.2465,\tval_loss: 0.2946\n",
            "87:\t[0s / 12s],\t\ttrain_loss: 0.2388,\tval_loss: 0.2962\n",
            "88:\t[0s / 12s],\t\ttrain_loss: 0.2404,\tval_loss: 0.2988\n",
            "89:\t[0s / 12s],\t\ttrain_loss: 0.2368,\tval_loss: 0.3003\n",
            "90:\t[0s / 12s],\t\ttrain_loss: 0.2396,\tval_loss: 0.2983\n",
            "91:\t[0s / 12s],\t\ttrain_loss: 0.2376,\tval_loss: 0.3009\n",
            "92:\t[0s / 13s],\t\ttrain_loss: 0.2349,\tval_loss: 0.2990\n",
            "93:\t[0s / 13s],\t\ttrain_loss: 0.2364,\tval_loss: 0.3018\n",
            "94:\t[0s / 13s],\t\ttrain_loss: 0.2419,\tval_loss: 0.3008\n",
            "95:\t[0s / 13s],\t\ttrain_loss: 0.2350,\tval_loss: 0.3032\n",
            "96:\t[0s / 13s],\t\ttrain_loss: 0.2308,\tval_loss: 0.3071\n",
            "97:\t[0s / 13s],\t\ttrain_loss: 0.2352,\tval_loss: 0.3043\n",
            "98:\t[0s / 13s],\t\ttrain_loss: 0.2279,\tval_loss: 0.3078\n",
            "99:\t[0s / 13s],\t\ttrain_loss: 0.2286,\tval_loss: 0.3138\n",
            "Current best c-index: 0.6174458962841977\n",
            "Random search... itr: 17\n",
            "{'batch_size': 256, 'layers': 2, 'nodes': 100, 'activation_fn': 'tanh', 'alpha': 0.1, 'sigma': 1.0, 'lr': 0.001, 'dropout': 0.6, 'patience': 75}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1481,\tval_loss: 0.1283\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1376,\tval_loss: 0.1204\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1293,\tval_loss: 0.1174\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1308,\tval_loss: 0.1163\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1285,\tval_loss: 0.1159\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1282,\tval_loss: 0.1160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1283,\tval_loss: 0.1161\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1271,\tval_loss: 0.1160\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1265,\tval_loss: 0.1158\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.1265,\tval_loss: 0.1153\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.1240,\tval_loss: 0.1150\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.1262,\tval_loss: 0.1150\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.1233,\tval_loss: 0.1152\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.1251,\tval_loss: 0.1150\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.1239,\tval_loss: 0.1150\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.1225,\tval_loss: 0.1149\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 0.1242,\tval_loss: 0.1149\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 0.1241,\tval_loss: 0.1148\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 0.1231,\tval_loss: 0.1149\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 0.1243,\tval_loss: 0.1150\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 0.1234,\tval_loss: 0.1147\n",
            "21:\t[0s / 0s],\t\ttrain_loss: 0.1224,\tval_loss: 0.1148\n",
            "22:\t[0s / 0s],\t\ttrain_loss: 0.1232,\tval_loss: 0.1145\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.1236,\tval_loss: 0.1142\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.1227,\tval_loss: 0.1145\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.1214,\tval_loss: 0.1146\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.1205,\tval_loss: 0.1144\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.1213,\tval_loss: 0.1142\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.1218,\tval_loss: 0.1143\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 0.1222,\tval_loss: 0.1142\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 0.1210,\tval_loss: 0.1142\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 0.1191,\tval_loss: 0.1142\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 0.1218,\tval_loss: 0.1143\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 0.1211,\tval_loss: 0.1142\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 0.1211,\tval_loss: 0.1145\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 0.1208,\tval_loss: 0.1144\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 0.1199,\tval_loss: 0.1144\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 0.1204,\tval_loss: 0.1142\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 0.1209,\tval_loss: 0.1141\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 0.1215,\tval_loss: 0.1142\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 0.1194,\tval_loss: 0.1144\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 0.1214,\tval_loss: 0.1142\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 0.1197,\tval_loss: 0.1143\n",
            "43:\t[0s / 1s],\t\ttrain_loss: 0.1191,\tval_loss: 0.1146\n",
            "44:\t[0s / 1s],\t\ttrain_loss: 0.1206,\tval_loss: 0.1143\n",
            "45:\t[0s / 1s],\t\ttrain_loss: 0.1204,\tval_loss: 0.1145\n",
            "46:\t[0s / 1s],\t\ttrain_loss: 0.1187,\tval_loss: 0.1142\n",
            "47:\t[0s / 1s],\t\ttrain_loss: 0.1190,\tval_loss: 0.1140\n",
            "48:\t[0s / 1s],\t\ttrain_loss: 0.1202,\tval_loss: 0.1140\n",
            "49:\t[0s / 1s],\t\ttrain_loss: 0.1201,\tval_loss: 0.1140\n",
            "50:\t[0s / 1s],\t\ttrain_loss: 0.1196,\tval_loss: 0.1142\n",
            "51:\t[0s / 1s],\t\ttrain_loss: 0.1193,\tval_loss: 0.1141\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 0.1194,\tval_loss: 0.1140\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 0.1192,\tval_loss: 0.1140\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1141\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 0.1184,\tval_loss: 0.1142\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 0.1197,\tval_loss: 0.1142\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 0.1186,\tval_loss: 0.1141\n",
            "58:\t[0s / 2s],\t\ttrain_loss: 0.1194,\tval_loss: 0.1142\n",
            "59:\t[0s / 2s],\t\ttrain_loss: 0.1174,\tval_loss: 0.1141\n",
            "60:\t[0s / 2s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1138\n",
            "61:\t[0s / 2s],\t\ttrain_loss: 0.1173,\tval_loss: 0.1138\n",
            "62:\t[0s / 2s],\t\ttrain_loss: 0.1177,\tval_loss: 0.1138\n",
            "63:\t[0s / 2s],\t\ttrain_loss: 0.1171,\tval_loss: 0.1140\n",
            "64:\t[0s / 2s],\t\ttrain_loss: 0.1178,\tval_loss: 0.1140\n",
            "65:\t[0s / 2s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1141\n",
            "66:\t[0s / 2s],\t\ttrain_loss: 0.1188,\tval_loss: 0.1139\n",
            "67:\t[0s / 2s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1139\n",
            "68:\t[0s / 2s],\t\ttrain_loss: 0.1188,\tval_loss: 0.1142\n",
            "69:\t[0s / 2s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1142\n",
            "70:\t[0s / 2s],\t\ttrain_loss: 0.1186,\tval_loss: 0.1140\n",
            "71:\t[0s / 2s],\t\ttrain_loss: 0.1167,\tval_loss: 0.1143\n",
            "72:\t[0s / 2s],\t\ttrain_loss: 0.1167,\tval_loss: 0.1143\n",
            "73:\t[0s / 2s],\t\ttrain_loss: 0.1166,\tval_loss: 0.1141\n",
            "74:\t[0s / 2s],\t\ttrain_loss: 0.1179,\tval_loss: 0.1141\n",
            "75:\t[0s / 2s],\t\ttrain_loss: 0.1192,\tval_loss: 0.1142\n",
            "76:\t[0s / 3s],\t\ttrain_loss: 0.1161,\tval_loss: 0.1143\n",
            "77:\t[0s / 3s],\t\ttrain_loss: 0.1171,\tval_loss: 0.1142\n",
            "78:\t[0s / 3s],\t\ttrain_loss: 0.1172,\tval_loss: 0.1141\n",
            "79:\t[0s / 3s],\t\ttrain_loss: 0.1159,\tval_loss: 0.1141\n",
            "80:\t[0s / 3s],\t\ttrain_loss: 0.1166,\tval_loss: 0.1141\n",
            "81:\t[0s / 3s],\t\ttrain_loss: 0.1165,\tval_loss: 0.1140\n",
            "82:\t[0s / 3s],\t\ttrain_loss: 0.1175,\tval_loss: 0.1141\n",
            "83:\t[0s / 3s],\t\ttrain_loss: 0.1177,\tval_loss: 0.1139\n",
            "84:\t[0s / 3s],\t\ttrain_loss: 0.1173,\tval_loss: 0.1138\n",
            "85:\t[0s / 3s],\t\ttrain_loss: 0.1170,\tval_loss: 0.1138\n",
            "86:\t[0s / 3s],\t\ttrain_loss: 0.1170,\tval_loss: 0.1137\n",
            "87:\t[0s / 3s],\t\ttrain_loss: 0.1168,\tval_loss: 0.1136\n",
            "88:\t[0s / 3s],\t\ttrain_loss: 0.1172,\tval_loss: 0.1136\n",
            "89:\t[0s / 3s],\t\ttrain_loss: 0.1182,\tval_loss: 0.1136\n",
            "90:\t[0s / 3s],\t\ttrain_loss: 0.1167,\tval_loss: 0.1137\n",
            "91:\t[0s / 3s],\t\ttrain_loss: 0.1156,\tval_loss: 0.1138\n",
            "92:\t[0s / 3s],\t\ttrain_loss: 0.1163,\tval_loss: 0.1140\n",
            "93:\t[0s / 3s],\t\ttrain_loss: 0.1163,\tval_loss: 0.1140\n",
            "94:\t[0s / 3s],\t\ttrain_loss: 0.1152,\tval_loss: 0.1141\n",
            "95:\t[0s / 3s],\t\ttrain_loss: 0.1140,\tval_loss: 0.1141\n",
            "96:\t[0s / 3s],\t\ttrain_loss: 0.1154,\tval_loss: 0.1140\n",
            "97:\t[0s / 3s],\t\ttrain_loss: 0.1172,\tval_loss: 0.1140\n",
            "98:\t[0s / 3s],\t\ttrain_loss: 0.1147,\tval_loss: 0.1141\n",
            "99:\t[0s / 4s],\t\ttrain_loss: 0.1163,\tval_loss: 0.1140\n",
            "Current best c-index: 0.6174458962841977\n",
            "Random search... itr: 18\n",
            "{'batch_size': 32, 'layers': 5, 'nodes': 75, 'activation_fn': 'tanh', 'alpha': 0.1, 'sigma': 1.0, 'lr': 0.01, 'dropout': 0.6, 'patience': 75}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1363\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1342,\tval_loss: 0.1256\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1261,\tval_loss: 0.1203\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1222,\tval_loss: 0.1184\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1216,\tval_loss: 0.1152\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1218,\tval_loss: 0.1153\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1197,\tval_loss: 0.1148\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.1178,\tval_loss: 0.1144\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1200,\tval_loss: 0.1140\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1193,\tval_loss: 0.1141\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1197,\tval_loss: 0.1141\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 0.1189,\tval_loss: 0.1142\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 0.1182,\tval_loss: 0.1141\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.1199,\tval_loss: 0.1145\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.1188,\tval_loss: 0.1140\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.1197,\tval_loss: 0.1142\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.1195,\tval_loss: 0.1144\n",
            "17:\t[0s / 3s],\t\ttrain_loss: 0.1197,\tval_loss: 0.1139\n",
            "18:\t[0s / 3s],\t\ttrain_loss: 0.1184,\tval_loss: 0.1141\n",
            "19:\t[0s / 3s],\t\ttrain_loss: 0.1197,\tval_loss: 0.1143\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.1184,\tval_loss: 0.1141\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.1203,\tval_loss: 0.1141\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.1195,\tval_loss: 0.1141\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1176,\tval_loss: 0.1140\n",
            "24:\t[0s / 4s],\t\ttrain_loss: 0.1211,\tval_loss: 0.1139\n",
            "25:\t[0s / 4s],\t\ttrain_loss: 0.1172,\tval_loss: 0.1141\n",
            "26:\t[0s / 4s],\t\ttrain_loss: 0.1188,\tval_loss: 0.1141\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.1188,\tval_loss: 0.1141\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.1162,\tval_loss: 0.1141\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.1202,\tval_loss: 0.1141\n",
            "30:\t[0s / 5s],\t\ttrain_loss: 0.1203,\tval_loss: 0.1142\n",
            "31:\t[0s / 5s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1144\n",
            "32:\t[0s / 5s],\t\ttrain_loss: 0.1183,\tval_loss: 0.1143\n",
            "33:\t[0s / 5s],\t\ttrain_loss: 0.1183,\tval_loss: 0.1140\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.1172,\tval_loss: 0.1141\n",
            "35:\t[0s / 5s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1140\n",
            "36:\t[0s / 6s],\t\ttrain_loss: 0.1190,\tval_loss: 0.1140\n",
            "37:\t[0s / 6s],\t\ttrain_loss: 0.1162,\tval_loss: 0.1140\n",
            "38:\t[0s / 6s],\t\ttrain_loss: 0.1188,\tval_loss: 0.1140\n",
            "39:\t[0s / 6s],\t\ttrain_loss: 0.1168,\tval_loss: 0.1140\n",
            "40:\t[0s / 6s],\t\ttrain_loss: 0.1187,\tval_loss: 0.1141\n",
            "41:\t[0s / 6s],\t\ttrain_loss: 0.1194,\tval_loss: 0.1140\n",
            "42:\t[0s / 7s],\t\ttrain_loss: 0.1168,\tval_loss: 0.1140\n",
            "43:\t[0s / 7s],\t\ttrain_loss: 0.1189,\tval_loss: 0.1140\n",
            "44:\t[0s / 7s],\t\ttrain_loss: 0.1198,\tval_loss: 0.1141\n",
            "45:\t[0s / 7s],\t\ttrain_loss: 0.1189,\tval_loss: 0.1140\n",
            "46:\t[0s / 7s],\t\ttrain_loss: 0.1187,\tval_loss: 0.1140\n",
            "47:\t[0s / 7s],\t\ttrain_loss: 0.1200,\tval_loss: 0.1140\n",
            "48:\t[0s / 7s],\t\ttrain_loss: 0.1176,\tval_loss: 0.1140\n",
            "49:\t[0s / 8s],\t\ttrain_loss: 0.1190,\tval_loss: 0.1141\n",
            "50:\t[0s / 8s],\t\ttrain_loss: 0.1190,\tval_loss: 0.1140\n",
            "51:\t[0s / 8s],\t\ttrain_loss: 0.1175,\tval_loss: 0.1141\n",
            "52:\t[0s / 8s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1141\n",
            "53:\t[0s / 8s],\t\ttrain_loss: 0.1173,\tval_loss: 0.1140\n",
            "54:\t[0s / 8s],\t\ttrain_loss: 0.1191,\tval_loss: 0.1141\n",
            "55:\t[0s / 9s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1141\n",
            "56:\t[0s / 9s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1141\n",
            "57:\t[0s / 9s],\t\ttrain_loss: 0.1182,\tval_loss: 0.1140\n",
            "58:\t[0s / 9s],\t\ttrain_loss: 0.1183,\tval_loss: 0.1140\n",
            "59:\t[0s / 9s],\t\ttrain_loss: 0.1173,\tval_loss: 0.1142\n",
            "60:\t[0s / 9s],\t\ttrain_loss: 0.1196,\tval_loss: 0.1141\n",
            "61:\t[0s / 9s],\t\ttrain_loss: 0.1183,\tval_loss: 0.1140\n",
            "62:\t[0s / 10s],\t\ttrain_loss: 0.1194,\tval_loss: 0.1140\n",
            "63:\t[0s / 10s],\t\ttrain_loss: 0.1182,\tval_loss: 0.1140\n",
            "64:\t[0s / 10s],\t\ttrain_loss: 0.1205,\tval_loss: 0.1141\n",
            "65:\t[0s / 10s],\t\ttrain_loss: 0.1168,\tval_loss: 0.1140\n",
            "66:\t[0s / 10s],\t\ttrain_loss: 0.1183,\tval_loss: 0.1141\n",
            "67:\t[0s / 10s],\t\ttrain_loss: 0.1193,\tval_loss: 0.1141\n",
            "68:\t[0s / 11s],\t\ttrain_loss: 0.1169,\tval_loss: 0.1141\n",
            "69:\t[0s / 11s],\t\ttrain_loss: 0.1193,\tval_loss: 0.1140\n",
            "70:\t[0s / 11s],\t\ttrain_loss: 0.1177,\tval_loss: 0.1141\n",
            "71:\t[0s / 11s],\t\ttrain_loss: 0.1188,\tval_loss: 0.1141\n",
            "72:\t[0s / 12s],\t\ttrain_loss: 0.1182,\tval_loss: 0.1141\n",
            "73:\t[0s / 12s],\t\ttrain_loss: 0.1188,\tval_loss: 0.1141\n",
            "74:\t[0s / 12s],\t\ttrain_loss: 0.1191,\tval_loss: 0.1140\n",
            "75:\t[0s / 12s],\t\ttrain_loss: 0.1176,\tval_loss: 0.1140\n",
            "76:\t[0s / 12s],\t\ttrain_loss: 0.1193,\tval_loss: 0.1141\n",
            "77:\t[0s / 13s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1140\n",
            "78:\t[0s / 13s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1140\n",
            "79:\t[0s / 13s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1141\n",
            "80:\t[0s / 13s],\t\ttrain_loss: 0.1198,\tval_loss: 0.1140\n",
            "81:\t[0s / 13s],\t\ttrain_loss: 0.1186,\tval_loss: 0.1141\n",
            "82:\t[0s / 13s],\t\ttrain_loss: 0.1211,\tval_loss: 0.1141\n",
            "83:\t[0s / 14s],\t\ttrain_loss: 0.1178,\tval_loss: 0.1140\n",
            "84:\t[0s / 14s],\t\ttrain_loss: 0.1206,\tval_loss: 0.1141\n",
            "85:\t[0s / 14s],\t\ttrain_loss: 0.1184,\tval_loss: 0.1140\n",
            "86:\t[0s / 14s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1141\n",
            "87:\t[0s / 14s],\t\ttrain_loss: 0.1193,\tval_loss: 0.1140\n",
            "88:\t[0s / 14s],\t\ttrain_loss: 0.1187,\tval_loss: 0.1141\n",
            "89:\t[0s / 15s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1141\n",
            "90:\t[0s / 15s],\t\ttrain_loss: 0.1175,\tval_loss: 0.1140\n",
            "91:\t[0s / 15s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1141\n",
            "92:\t[0s / 15s],\t\ttrain_loss: 0.1178,\tval_loss: 0.1140\n",
            "93:\t[0s / 15s],\t\ttrain_loss: 0.1192,\tval_loss: 0.1140\n",
            "94:\t[0s / 15s],\t\ttrain_loss: 0.1184,\tval_loss: 0.1140\n",
            "95:\t[0s / 15s],\t\ttrain_loss: 0.1170,\tval_loss: 0.1141\n",
            "96:\t[0s / 16s],\t\ttrain_loss: 0.1178,\tval_loss: 0.1141\n",
            "97:\t[0s / 16s],\t\ttrain_loss: 0.1179,\tval_loss: 0.1141\n",
            "98:\t[0s / 16s],\t\ttrain_loss: 0.1183,\tval_loss: 0.1141\n",
            "99:\t[0s / 16s],\t\ttrain_loss: 0.1196,\tval_loss: 0.1141\n",
            "Current best c-index: 0.6174458962841977\n",
            "Random search... itr: 19\n",
            "{'batch_size': 256, 'layers': 3, 'nodes': 25, 'activation_fn': 'elu', 'alpha': 0.5, 'sigma': 1.0, 'lr': 0.1, 'dropout': 0.6, 'patience': 75}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.4207,\tval_loss: 0.2920\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.3286,\tval_loss: 0.2810\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.3081,\tval_loss: 0.2840\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.2977,\tval_loss: 0.2789\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.2974,\tval_loss: 0.2829\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.2960,\tval_loss: 0.2825\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6:\t[0s / 0s],\t\ttrain_loss: 0.2949,\tval_loss: 0.2807\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.2919,\tval_loss: 0.2792\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.2914,\tval_loss: 0.2781\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.2931,\tval_loss: 0.2791\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.2944,\tval_loss: 0.2816\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.2922,\tval_loss: 0.2792\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.2905,\tval_loss: 0.2797\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.2926,\tval_loss: 0.2793\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.2933,\tval_loss: 0.2795\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.2932,\tval_loss: 0.2809\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 0.2931,\tval_loss: 0.2797\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 0.2945,\tval_loss: 0.2792\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 0.2926,\tval_loss: 0.2798\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 0.2928,\tval_loss: 0.2792\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 0.2923,\tval_loss: 0.2802\n",
            "21:\t[0s / 0s],\t\ttrain_loss: 0.2944,\tval_loss: 0.2795\n",
            "22:\t[0s / 0s],\t\ttrain_loss: 0.2920,\tval_loss: 0.2786\n",
            "23:\t[0s / 0s],\t\ttrain_loss: 0.2922,\tval_loss: 0.2795\n",
            "24:\t[0s / 0s],\t\ttrain_loss: 0.2934,\tval_loss: 0.2795\n",
            "25:\t[0s / 0s],\t\ttrain_loss: 0.2931,\tval_loss: 0.2795\n",
            "26:\t[0s / 0s],\t\ttrain_loss: 0.2922,\tval_loss: 0.2813\n",
            "27:\t[0s / 0s],\t\ttrain_loss: 0.2928,\tval_loss: 0.2794\n",
            "28:\t[0s / 0s],\t\ttrain_loss: 0.2910,\tval_loss: 0.2794\n",
            "29:\t[0s / 0s],\t\ttrain_loss: 0.2931,\tval_loss: 0.2792\n",
            "30:\t[0s / 0s],\t\ttrain_loss: 0.2900,\tval_loss: 0.2789\n",
            "31:\t[0s / 0s],\t\ttrain_loss: 0.2929,\tval_loss: 0.2798\n",
            "32:\t[0s / 0s],\t\ttrain_loss: 0.2926,\tval_loss: 0.2796\n",
            "33:\t[0s / 0s],\t\ttrain_loss: 0.2912,\tval_loss: 0.2793\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 0.2895,\tval_loss: 0.2789\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 0.2896,\tval_loss: 0.2790\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 0.2918,\tval_loss: 0.2788\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 0.2921,\tval_loss: 0.2800\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 0.2895,\tval_loss: 0.2805\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 0.2906,\tval_loss: 0.2791\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 0.2918,\tval_loss: 0.2782\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 0.2918,\tval_loss: 0.2795\n",
            "42:\t[0s / 1s],\t\ttrain_loss: 0.2935,\tval_loss: 0.2791\n",
            "43:\t[0s / 1s],\t\ttrain_loss: 0.2906,\tval_loss: 0.2797\n",
            "44:\t[0s / 1s],\t\ttrain_loss: 0.2910,\tval_loss: 0.2795\n",
            "45:\t[0s / 1s],\t\ttrain_loss: 0.2917,\tval_loss: 0.2795\n",
            "46:\t[0s / 1s],\t\ttrain_loss: 0.3000,\tval_loss: 0.2788\n",
            "47:\t[0s / 1s],\t\ttrain_loss: 0.3621,\tval_loss: 0.2796\n",
            "48:\t[0s / 1s],\t\ttrain_loss: 0.2918,\tval_loss: 0.2786\n",
            "49:\t[0s / 1s],\t\ttrain_loss: 0.2929,\tval_loss: 0.2788\n",
            "50:\t[0s / 1s],\t\ttrain_loss: 0.2921,\tval_loss: 0.2791\n",
            "51:\t[0s / 1s],\t\ttrain_loss: 0.2915,\tval_loss: 0.2794\n",
            "52:\t[0s / 1s],\t\ttrain_loss: 0.2908,\tval_loss: 0.2798\n",
            "53:\t[0s / 1s],\t\ttrain_loss: 0.2905,\tval_loss: 0.2795\n",
            "54:\t[0s / 1s],\t\ttrain_loss: 0.2902,\tval_loss: 0.2792\n",
            "55:\t[0s / 1s],\t\ttrain_loss: 0.2910,\tval_loss: 0.2786\n",
            "56:\t[0s / 1s],\t\ttrain_loss: 0.2912,\tval_loss: 0.2791\n",
            "57:\t[0s / 1s],\t\ttrain_loss: 0.2907,\tval_loss: 0.2790\n",
            "58:\t[0s / 1s],\t\ttrain_loss: 0.2902,\tval_loss: 0.2797\n",
            "59:\t[0s / 1s],\t\ttrain_loss: 0.2917,\tval_loss: 0.2793\n",
            "60:\t[0s / 1s],\t\ttrain_loss: 0.2916,\tval_loss: 0.2788\n",
            "61:\t[0s / 1s],\t\ttrain_loss: 0.2906,\tval_loss: 0.2795\n",
            "62:\t[0s / 1s],\t\ttrain_loss: 0.2901,\tval_loss: 0.2791\n",
            "63:\t[0s / 1s],\t\ttrain_loss: 0.2910,\tval_loss: 0.2793\n",
            "64:\t[0s / 1s],\t\ttrain_loss: 0.2908,\tval_loss: 0.2790\n",
            "65:\t[0s / 1s],\t\ttrain_loss: 0.2920,\tval_loss: 0.2792\n",
            "66:\t[0s / 2s],\t\ttrain_loss: 0.2921,\tval_loss: 0.2793\n",
            "67:\t[0s / 2s],\t\ttrain_loss: 0.2914,\tval_loss: 0.2789\n",
            "68:\t[0s / 2s],\t\ttrain_loss: 0.2909,\tval_loss: 0.2793\n",
            "69:\t[0s / 2s],\t\ttrain_loss: 0.2931,\tval_loss: 0.2790\n",
            "70:\t[0s / 2s],\t\ttrain_loss: 0.2899,\tval_loss: 0.2790\n",
            "71:\t[0s / 2s],\t\ttrain_loss: 0.2896,\tval_loss: 0.2791\n",
            "72:\t[0s / 2s],\t\ttrain_loss: 0.2883,\tval_loss: 0.2796\n",
            "73:\t[0s / 2s],\t\ttrain_loss: 0.2911,\tval_loss: 0.2794\n",
            "74:\t[0s / 2s],\t\ttrain_loss: 0.2893,\tval_loss: 0.2787\n",
            "75:\t[0s / 2s],\t\ttrain_loss: 0.2891,\tval_loss: 0.2786\n",
            "76:\t[0s / 2s],\t\ttrain_loss: 0.2913,\tval_loss: 0.2797\n",
            "77:\t[0s / 2s],\t\ttrain_loss: 0.2918,\tval_loss: 0.2790\n",
            "78:\t[0s / 2s],\t\ttrain_loss: 0.2901,\tval_loss: 0.2800\n",
            "79:\t[0s / 2s],\t\ttrain_loss: 0.2883,\tval_loss: 0.2800\n",
            "80:\t[0s / 2s],\t\ttrain_loss: 0.2914,\tval_loss: 0.2791\n",
            "81:\t[0s / 2s],\t\ttrain_loss: 0.2902,\tval_loss: 0.2787\n",
            "82:\t[0s / 2s],\t\ttrain_loss: 0.2899,\tval_loss: 0.2791\n",
            "83:\t[0s / 2s],\t\ttrain_loss: 0.2895,\tval_loss: 0.2790\n",
            "Current best c-index: 0.6174458962841977\n",
            "Best hyperparameters: {'batch_size': 256, 'layers': 1, 'nodes': 50, 'activation_fn': 'tanh', 'alpha': 0.5, 'sigma': 0.1, 'lr': 0.01, 'dropout': 0.6, 'patience': 75}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from lifelines.utils import concordance_index\n",
        "def get_random_hyperparameters():\n",
        "    SET_BATCH_SIZE = [32, 64, 128, 256]\n",
        "    SET_LAYERS = [1,2,3,5]\n",
        "    SET_NODES = [25, 50, 75, 100]\n",
        "    SET_ACTIVATION_FN = ['relu', 'elu', 'tanh']\n",
        "    SET_ALPHA = [0.1, 0.5, 1.0]\n",
        "    SET_SIGMA = [0.1, 0.5, 1.0]\n",
        "    SET_LR = [0.001, 0.01, 0.1]\n",
        "    SET_DROPOUT = [0.0, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
        "    SET_PATIENCE = [25, 50, 75]\n",
        "\n",
        "    return {\n",
        "        'batch_size': SET_BATCH_SIZE[np.random.randint(len(SET_BATCH_SIZE))],\n",
        "        'layers': SET_LAYERS[np.random.randint(len(SET_LAYERS))],\n",
        "        'nodes': SET_NODES[np.random.randint(len(SET_NODES))],\n",
        "        'activation_fn': SET_ACTIVATION_FN[np.random.randint(len(SET_ACTIVATION_FN))],\n",
        "        'alpha': SET_ALPHA[np.random.randint(len(SET_ALPHA))],\n",
        "        'sigma': SET_SIGMA[np.random.randint(len(SET_SIGMA))],\n",
        "        'lr': SET_LR[np.random.randint(len(SET_LR))],\n",
        "        'dropout': SET_DROPOUT[np.random.randint(len(SET_DROPOUT))],\n",
        "        'patience': SET_PATIENCE[np.random.randint(len(SET_PATIENCE))],\n",
        "    }\n",
        "\n",
        "\n",
        "# Main loop\n",
        "max_valid = 0.0\n",
        "best_model = None\n",
        "best_hyperparameters = None\n",
        "\n",
        "for r_itr in range(RS_ITERATION):\n",
        "    print(f'Random search... itr: {r_itr}')\n",
        "    hyperparameters = get_random_hyperparameters()\n",
        "    print(hyperparameters)\n",
        "\n",
        "    # Use chosen hyperparameters\n",
        "    num_nodes = [hyperparameters['nodes']] * hyperparameters['layers']\n",
        "    batch_norm = True if hyperparameters['activation_fn'] == 'relu' else False\n",
        "    dropout = hyperparameters['dropout']\n",
        "\n",
        "    net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
        "\n",
        "    model = DeepHitSingle(net, tt.optim.Adam, alpha=hyperparameters['alpha'], sigma=hyperparameters['sigma'], duration_index=labtrans.cuts)\n",
        "\n",
        "    batch_size = hyperparameters['batch_size']\n",
        "    model.optimizer.set_lr(hyperparameters['lr'])\n",
        "\n",
        "    epochs = 100\n",
        "    callbacks = [tt.callbacks.EarlyStopping(patience=hyperparameters['patience'])]\n",
        "    log = model.fit(x_train, y_train, batch_size, epochs, callbacks, val_data=val)\n",
        "\n",
        "    # Validate the model\n",
        "    surv = model.predict_surv_df(x_val)\n",
        "    ev = EvalSurv(surv, durations_val, events_val, censor_surv='km')\n",
        "    c_index = ev.concordance_td('antolini')\n",
        "\n",
        "    # If this model is better, save it\n",
        "    if c_index > max_valid:\n",
        "        max_valid = c_index\n",
        "        best_model = model\n",
        "        best_hyperparameters = hyperparameters\n",
        "\n",
        "    print(f'Current best c-index: {max_valid}')\n",
        "\n",
        "print(f'Best hyperparameters: {best_hyperparameters}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "izZJNH3MPPLv",
        "outputId": "4c502007-a4d1-4648-ac5f-6eb6b13582f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.4508,\tval_loss: 0.3510\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.3555,\tval_loss: 0.2968\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.3437,\tval_loss: 0.2838\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.3126,\tval_loss: 0.2732\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.3064,\tval_loss: 0.2721\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.2978,\tval_loss: 0.2729\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.2961,\tval_loss: 0.2713\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.2901,\tval_loss: 0.2713\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.2878,\tval_loss: 0.2717\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.2864,\tval_loss: 0.2714\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.2837,\tval_loss: 0.2721\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.2876,\tval_loss: 0.2736\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.2863,\tval_loss: 0.2740\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.2862,\tval_loss: 0.2742\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.2842,\tval_loss: 0.2736\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.2856,\tval_loss: 0.2692\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.2801,\tval_loss: 0.2704\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.2788,\tval_loss: 0.2725\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.2803,\tval_loss: 0.2749\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.2827,\tval_loss: 0.2749\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.2760,\tval_loss: 0.2731\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.2767,\tval_loss: 0.2736\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.2779,\tval_loss: 0.2754\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.2754,\tval_loss: 0.2757\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.2718,\tval_loss: 0.2757\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.2763,\tval_loss: 0.2759\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.2732,\tval_loss: 0.2741\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.2737,\tval_loss: 0.2743\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.2766,\tval_loss: 0.2732\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 0.2740,\tval_loss: 0.2739\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.2698,\tval_loss: 0.2749\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.2733,\tval_loss: 0.2789\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.2679,\tval_loss: 0.2768\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.2763,\tval_loss: 0.2758\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.2798,\tval_loss: 0.2732\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.2747,\tval_loss: 0.2718\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.2764,\tval_loss: 0.2740\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.2737,\tval_loss: 0.2770\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.2754,\tval_loss: 0.2765\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.2735,\tval_loss: 0.2736\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 0.2758,\tval_loss: 0.2727\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 0.2735,\tval_loss: 0.2730\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 0.2711,\tval_loss: 0.2743\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 0.2718,\tval_loss: 0.2756\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 0.2726,\tval_loss: 0.2761\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 0.2689,\tval_loss: 0.2773\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 0.2699,\tval_loss: 0.2783\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 0.2698,\tval_loss: 0.2781\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 0.2731,\tval_loss: 0.2753\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 0.2652,\tval_loss: 0.2822\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 0.2747,\tval_loss: 0.2826\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 0.2726,\tval_loss: 0.2857\n",
            "Concordance index on test set: 0.6519413238730749\n",
            "Integrated Brier Score on test set: 0.0820695514511368\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAGhCAYAAABlH26aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB8zUlEQVR4nO3deVzU1f7H8desDAMMiAIuiAgq4pb7koqWZmmL3bKyX4uV3axrddO895a3upXdMm2xtD27mt2ysm6LmWXlklrmvmUqm4oIAsKwDDPM8v39MTJGKDA6C+Dn+XjwQL7rmQMyb84533NUiqIoCCGEEEI0Y+pgF0AIIYQQwt8k8AghhBCi2ZPAI4QQQohmTwKPEEIIIZo9CTxCCCGEaPYk8AghhBCi2ZPAI4QQQohmTxvsAjQW27dvR1EUdDpdsIsihBBCiAay2+2oVCr69OlT53HSwnOSoij4Yw5GRVGoqqryy7WFm9Sxf0n9+pfUr/9JHftXsOu3oe/f0sJzUnXLTs+ePX16XYvFwr59++jUqRNGo9Gn1xZuUsf+JfXrX1K//id17F/Brt/du3c36Dhp4RFCCCFEsyeBRwghhBDNngQeIYQQQjR7EniEEEII0exJ4BFCCCFEsydPaQkhhGgynE4ndrvdq3NsNpvns1otf+f7mj/rV6fTodFofHItCTxCCCEaPUVRyMvLo6SkxOtzXS4XWq2W3NxcCTx+4O/6jYqKonXr1qhUqnO6jgQeIYQQjV512ImNjcVoNHr15ud0OrHZbISEhPistUCc4q/6VRQFi8XC8ePHAWjTps05XU8CjxBCiEbN6XR6wk7Lli3P6nwAg8EggccP/Fm/oaGhABw/fpzY2Nhzur607QkhhGjUqsfsyCzJ56fq77u3Y7f+SAKPEEKIJuFcx3CIpslX33evA09GRga33347vXv3ZujQocyZM4eqqiqvrrFo0SJSUlKYMmVKje2bNm0iJSWl1se0adNqXeOHH37gqquuomfPnlx66aV88skn3r4UIYQQQpwnvBrDYzabmTRpEomJicyfP5/8/Hxmz56N1Wrlsccea9A1CgoKeOWVV+rsh33mmWdISkryfN2iRYsa+7ds2cK9997LhAkTmDlzJj///DP//Oc/CQsL47LLLvPmJQkhhBDiPOBV4Fm6dCkVFRUsWLCAqKgowD1Y6YknnmDKlCnExcXVe425c+dy8cUXk5ube8ZjOnfuXOeq5a+99hq9evXiySefBGDw4MEcOXKEl19+uVEGnoYsWy+EEKL5++6778jPz+emm27y2TUvvvhiRo4c2eCGh4b49NNPefjhh/npp5+Ijo722XWDyasurXXr1jFkyBBP2AEYO3YsLpeLDRs21Hv+li1b+O6773jwwQe9Lmi1qqoqNm3aVCvYjBs3joyMDHJycs762v7w/rcHee5/xyguswW7KEIIIYLsu+++44MPPvDpNRcsWMAdd9zh02s2R14FnszMzBpdTQAmk4mYmBgyMzPrPNfpdDJr1izuvvtuYmNj6zz2rrvuIjU1lbS0NJ599lmsVqtn3+HDh7Hb7bXKkZyc7CljY7I3q5gKq4v0HHOwiyKEEKIJUBTFq7Gx3bp1Iz4+3o8lah686tIqLS3FZDLV2h4ZGYnZXPcb+vvvv09lZSW33XbbGY+JiIjgzjvvZMCAAYSEhPDzzz/zzjvvkJmZyRtvvAHguc8fy1H9dX3lqEv1JEe+FKJ1jy4vLa/0+bWFW2VlZY3Pwrekfv1L6rd+NpsNl8uF0+n0zPnijephBYqinNX5vjJz5kw+++wzAFJSUgC4+uqrAdizZw8PPvgg8+bNIyMjg7lz5zJ8+HBeeOEFNm7cSF5eHtHR0QwbNowHH3yQiIgIz3VHjx7NyJEjeeSRRzz32bNnD4888gizZ8/m0KFDdOrUiccee4zu3bs3qKwul8vzubrOSkpKmDt3LqtXr6ayspLU1FSmT59Ov379AHf9bt68mRdffJH9+/fjcrlo164dt99+u+d1btu2rc79p+N0OnG5XFRWVnrK9XuKojToSa6ATDxYVFTEyy+/zLPPPoterz/jcd26daNbt26er4cMGUJsbCxPPvkku3btolevXn4tp91uZ9++fT69ptPhbp06euw4+/ZJ4PGn7OzsYBehWZP69S+p37pptVrPmk3VFEXBZq/9Bngm1iof/0GrU3v1yPTtt99OYWEh2dnZPPXUU4D7oZy3336b48eP8+9//5s777yT1q1b07p1a8xmM1VVVfzlL3+hRYsW5OXlsXDhQqZOncqbb77pua6iKDgcDk9viNPppLCwkKeeeorbb7+d8PBw5s+fz3333cfnn3+OTqert6zVc95YrVasVitOp5O77rqLnJwc7r//fqKjo1m6dCmTJ0/mP//5D926daOoqIi7776b3r178/TTT6PT6cjKyuLEiRNYrVbKy8vr3H8mNpsNh8NRZw9OXdmimleBx2QyUVZWVmu72WwmMjLyjOe99NJLpKSk0L9/f0pLSwFwOBw4HA5KS0sxGo1otacvytixY3nyySfZs2cPvXr18tznj+Wovm5d5aiPTqejU6dOZ33+6bTcvRNyrISFR5Ga2tmn1xZulZWVZGdnk5iY6JmVU/iO1K9/Sf3Wz2azkZubS0hICAaDAXC/yT/86kZ+O1QctHKlJrbg6XsubHDo6dy5M61atSIvL4+BAwd6tms0GkpLS3njjTe44IILapxT/XAOuN83O3bsyM0330xeXh6JiYmAe54arVbrqRuNRoPZbGbx4sV07ux+34mMjOS2227jwIEDnhaZulSHIoPBgMFg4IcffmDPnj28+eabDBs2DICLLrqIyy67jEWLFjFnzhyOHTtGeXk5M2bMoEuXLgCMGDHCc8309PQ699dFq9WSkJBASEhIrX3p6ekNu0aDjjopKSmpVsIqKyujoKCg1pia38vKymLz5s0MGDCg1r4BAwbw1ltvkZaW1qAyJCQkoNPpyMzMZPjw4Z7t1eWqqxz1UalUPp/JM9zo/ubYXb6/tqgpNDRU6tiPpH79S+r3zNRqNWq1Go1G41laoKHdGP6lQqPReFUOlUqFSqWqsUSCSqUiKiqKvn371jr+s88+Y9GiRRw6dKjGsIjDhw97xq7+8ZoqlYrY2Fi6du3qOb46YBQUFDRoeYbqRUCr633btm2Eh4fXCCgajYYxY8awfPlywP3+HB4ezpNPPsktt9zC4MGDazzhlZiYWOf+M9FoNKjVakJDQz2h7vcaWv9eBZ60tDRef/31GmN5Vq5ciVqtZujQoWc8b+bMmZ4WmGpPP/00BoOB6dOne/oyT+err74C8DymrtfrGTRoEN988w2TJk3yHLdixQqSk5Mb3cAtg979g2W1OYJcEiGEaD5UKhXP3jsMW1X9Y3KcLidWqw2DIQSN2ndrPYXovQs7dWnVqlWtbatWreIf//gHN9xwA9OmTSMqKoqCggKmTp1aq3vvj/44zrW6xaa+886ktLT0tPPntWrVyjN2NjIykv/85z+8/PLL/P3vf8fpdNK/f38eeeQRUlJS6t3vb14FnokTJ7JkyRKmTp3KlClTyM/PZ86cOUycOLHGHDyTJk0iNzeXVatWAZCamlrrWiaTCaPRyKBBgzzbZsyYQYcOHejWrZtn0PKiRYsYPXp0jXl57rnnHm699VYef/xxxo4dy6ZNm1i+fDkvvvii1xXgb6Eh7iqubMB/SiGEEA2nUqkwhNT/NuZ0qsDlwKDXNtrFQ08XnFauXElqamqNbq1ffvklkMXyiIyMpKioqNb2wsLCGkNJevXqxdtvv43VamXTpk08++yzTJ06le+++65B+/3Jq8fSIyMjWbx4MRqNhqlTp/L8888zYcIEHnrooRrH/X5Utzc6d+7MN998w4wZM7j77rtZtWoVd999d60g079/f+bPn8/WrVuZPHkyy5cv56mnnmLs2LFe39PfQkPc/7kqpYVHCCHOezqdrsGtLFartdYA4y+//NIfxapXv379KC8vZ/369Z5tDoeD77777rRdcQaDgREjRnDjjTeSk5NT6zXXt98fvH5KKzk5mUWLFtV5zJIlS+q9zumOmTJlSq31tc5k1KhRjBo1qkHHBlN1C4/VJi08QghxvktOTuaTTz5h+fLldOjQodbSSb934YUX8uSTT/LKK6/Qp08f1q5dy08//RTA0p4ycuRIevXqxd/+9jcefPBBWrVqxZIlSzh+/Djz5s0DYO3atXz66aeMHj2atm3bUlhYyHvvvUffvn0JCQlhzZo1LFu27Iz7/S0gj6Wfz6rH8FRWSQuPEEKc7yZMmMCuXbuYNWsWJSUl/OlPfzrjsRMnTiQnJ4f33nuPhQsXMmzYMJ5//nmuv/76AJbYTaPR8OabbzJnzhzmzp2LxWKhe/fuvPPOO3Tv3h2r1UpCQgJqtZp58+ZRVFREVFQUw4YNY/r06QD17vc3lSILPQGwe/dugDrX8DobP+86wr8XbyMhLpxX/t74W6SaIovFwr59+0hNTZWnXPxA6te/pH7rZ7VaycrKomPHjqd9Sqc+TqcTq9WKwWBotGN4mjJ/12993/+Gvn97NYZHeM8gY3iEEEKIoJMuLT8L1Z98SkvG8AghhGgEXC7XaZdoqObt3EJNhQQeP/M8pSVjeIQQQjQCr7zyCgsWLDjj/meeeYZrrrkmgCUKDAk8flb9lJbTqWB3ONFppf9YCCFE8Fx//fWMHDnyjPsb2wS+viKBx8+qn9ICsFgdRIZL4BFCCBE8cXFxNSYLPl/IoGU/02jUaDXuvlAZuCyEEEIEhwSeAAjRSeARQgghgkkCTwDotRJ4hBBCiGCSwBMAITp3NUvgEUIIIYJDAk8AVLfwWKwSeIQQQohgkMATANLCI4QQQgSXBJ4AkDE8QgghfGnTpk2kpKR41pGqz6effkpKSgonTpzwc8kaLwk8ASAtPEIIIURwSeAJAM9j6TKGRwghhAgKCTwBIF1aQgjhe4qi4KqyNuhDsdsafGyDr6koXpf5008/pVu3bhQWFtbYXlJSQo8ePVi6dCnbt2/n7rvvZtiwYfTu3Zvx48fz2Wef+ajWat7z4YcfZtCgQfTq1YuJEyeyefPmGsds3bqVm266iX79+tGnTx+uvPJK/ve//9XYf8stt5CWlkb//v1r7W9MZGmJAJAuLSGE8C1FUch995/YcvYHrQwh8V1pe+tTXq0sfskll/Cvf/2LlStXcvPNN3u2f/vttwBcdtllbNiwgb59+3LjjTei1+vZtm0bjzzyCIqi8Kc//cknZXc6nfz5z3/myJEjzJgxg1atWrFkyRJuv/12li5dSo8ePSgvL2fKlCn069ePF154Ab1eT3p6OqWlpQCe/X379uXpp58mLCyMrKwsz/7GRgJPAOhlpmUhhPCDhgeNxiIiIoIRI0awfPnyGoFn+fLlDB06lKioKC6//HLPdkVRGDBgAPn5+Xz44Yc+Czxr1qxh165dvP322wwfPhyAYcOGMWbMGN544w3mz59PVlYWZWVlTJ8+nZSUFACGDBniuUb1/mnTppGQkIDBYGDYsGE+KZ8/SOAJgBCtu4VH5uERQgjfUKlUtL31KRS7rd5jnU4nNpuNkJAQNBrfLeCs0oV41bpT7fLLL2fatGnk5ubStm1bjh8/zubNm3n22WcBMJvNzJ8/n++//578/HycTicAUVFRPiv7li1bCA8P94QdAJ1OxyWXXMLy5csBSEhIIDw8nMcff5xbbrmFwYMHEx0d7Tm+ev+TTz7J9ddfz7Bhw4iJifFZGX1NxvAEwKkWHnuQSyKEEM2HSqVCrTc06EOlC2nwsQ2+5lmEHYCLLrqI0NBQvvrqKwC+/vprQkJCGD16NAAPPfQQy5cv54477mDhwoUsW7aMa6+9lqqqKp/VXWlpKS1btqy1vVWrVpjNZgAiIyP5z3/+Q1hYGH//+98ZOnQot9xyC/v376+x32g08uijj5KWllZjf2MjgScAqlt4pEtLCCGEwWBg9OjRrFixAoAVK1Zw0UUXYTQasdlsrFmzhnvuuYdbbrmFIUOG0LNnz7MaIF2XyMhIioqKam0vLCwkMjLS83WvXr14++232bJlC6+//jpFRUVMnTq1xv4333yTtWvX8sorr9Ta35hI4AkAWS1dCCHE711xxRX8+uuv/Pjjj+zYscMzbqeqqgqXy4VOp/McW15ezg8//ODT+/fr14/y8nLWr1/v2eZwOPjuu+/o169freMNBgMjRozgxhtvJCcnB5vN5tX+xkDG8ASAXp7SEkII8TsXXnghUVFRzJw5E5PJRFpaGuAe1NyzZ0/eeustoqOj0Wq1vPnmm4SHh/t0luSRI0fSq1cv/va3v/Hggw96ntI6fvw4L7/8MuAe2Lxs2TJGjx5N27ZtKSws5L333qNv376EhIR49o8aNYqWLVtSWlpaY39jI4EnAEI88/A4cbkU1Oqm92SBEEII39HpdFx66aV8+OGHTJgwAb1e79n3/PPP89hjj/HQQw8RFRXFLbfcgsVi4Z133vHZ/TUaDW+++SZz5sxh7ty5WCwWunfvzjvvvEOPHj0A96BktVrNvHnzKCoqIioqimHDhjF9+vRa+0+cOFFrf2OjUnzdMdhEVa9H0rNnT59e12KxsHP3Xp7+KBeAD/89DqNBV89ZwhsWi4V9+/aRmpqK0WgMdnGaHalf/5L6rZ/VaiUrK4uOHTtiMBi8Pt/pdGK1WjEYDD59Sku4+bt+6/v+N/T9W8bwBIBOo6J6ML90awkhhBCBJ11aAaBSqQgN0WKxOiTwCCGE8CmXy4XL5Trjfo1Gc9aP0DcnEngCJFSvwWJ1yOSDQgghfOqVV15hwYIFZ9z/zDPPcM011wSwRI2TBJ4AMYRoAZu08AghhPCp66+/npEjR55xf3x8fOAK04hJ4AmQ0BD3QC4JPEIIIXwpLi6OuLi4YBej0ZNBywESGuLOlhJ4hBDi7MhDxecnX33fJfAEiEEvgUcIIc5G9azDFoslyCURwVD9ff/97NNnw+surYyMDJ566im2b99OWFgY48eP54EHHqgxaVJ9Fi1axDPPPMPIkSN54403PNs3btzIxx9/zM6dOykqKqJdu3Zcc801TJo0qcYLfeihh/jf//5X67pvvfWWZ7bKxsbTpSWDloUQwisajYaoqCiOHz8OgNFo9Oqpo+rV0quvJXzLX/WrKAoWi4Xjx48TFRV1ztf2KvCYzWYmTZpEYmIi8+fPJz8/n9mzZ2O1WnnssccadI2CggJeeeWV067SunTpUqxWK/fffz9t2rRh586dzJ8/n4yMDJ555pkax7Zv357nnnuuxrbk5GRvXk5ASZeWEEKcvdatWwN4Qo83XC4XDocDrVaLWi0dG77m7/qNioryfP/PhVeBZ+nSpVRUVLBgwQKioqIAd7J74oknmDJlSoMGTc2dO5eLL76Y3NzcWvsef/xxoqOjPV8PGjQIl8vFvHnz+Nvf/lZjn8FgoHfv3t4UP6gMehm0LIQQZ0ulUtGmTRtiY2Ox2+1enVtZWUlmZiYJCQmEhob6qYTnL3/Wr06n81mrkVeBZ926dQwZMsQTdgDGjh3Lv/71LzZs2FDvc/5btmzhu+++Y+XKlTz44IO19v8+0FRLTU1FURQKCgpOu7+pqG7hkXl4hBDi7Gk0Gq/fAKsn5QsJCTmrpSlE3ZpK/XoVeDIzM7n22mtrbDOZTMTExJCZmVnnuU6nk1mzZnH33XcTGxvb4Htu27YNvV5fax6BQ4cO0a9fP2w2G126dOEvf/kLo0ePbviLOY3q/kJfqqysBECjcv9AlFmsMvDOx6rruPqz8C2pX/+S+vU/qWP/Cnb9KorSoDFdXgWe0tJSTCZTre2RkZGYzeY6z33//feprKzktttua/D9srOzeffdd5k4cSJhYWGe7ampqfTs2ZNOnTpRVlbGBx98wNSpU3nppZe47LLLGnz9P7Lb7ezbt++sz69LeVkxAIUnzH67x/kuOzs72EVo1qR+/Uvq1/+kjv0rmPXbkAenAjLxYFFRES+//DLPPvtsg5/mKi8v57777iM+Pp5p06bV2Ddp0qQaX1988cVMnDiRl19++ZwCj06no1OnTmd9/ulUVlaSnZ1N+7ZxQDEanYHU1FSf3uN8V13HiYmJ0j/vB1K//iX1639Sx/4V7PpNT09v0HFeBR6TyURZWVmt7WazmcjIyDOe99JLL5GSkkL//v0pLS0FwOFw4HA4KC0txWg0otWeKkpVVRVTp07FbDbz4YcfYjQa6yyXWq1mzJgxzJ0717NE/dlQqVT13utsRUa4r1tlV/x2j/NdaGio1K0fSf36l9Sv/0kd+1ew6rehUxR4FXiSkpJqjdUpKyujoKCApKSkM56XlZXF5s2bGTBgQK19AwYMqDF/jsvlYsaMGezdu5f//ve/tGnTxpsiNlqGk/PwWOQpLSGEECLgvAo8aWlpvP766zXG8qxcuRK1Ws3QoUPPeN7MmTM9LTvVnn76aQwGA9OnTyclJcWz/YknnmD16tUsXLiwxva6uFwuVq5cSefOnRvtCPHQ6pmW5SktIYQQIuC8CjwTJ05kyZIlTJ06lSlTppCfn8+cOXOYOHFijTl4Jk2aRG5uLqtWrQI47ZgVk8mE0Whk0KBBnm2vv/46S5cuZfLkyej1enbs2OHZ16lTJ8LDwzl69CgPPfQQl19+OR06dMBsNvPBBx+wZ88e5s+f7+3rDxhZPFQIIYQIHq8CT2RkJIsXL2bWrFlMnTqVsLAwJkyYUGtQscvlwul0el2YDRs2ALBw4UIWLlxYY9+7777LoEGDCAsLIzw8nNdee42ioiJ0Oh09evTgrbfeYvjw4V7fM1AMJ+fhcThd2B1OdFqZ3lwIIYQIFK+f0kpOTmbRokV1HrNkyZJ6r3O6YxpyXlRUFK+99lq9xzU2ofpTAcdidRAZLoFHCCGECBRZVCRANBo1eq27uqVbSwghhAgsCTwBZDS4V3yXwCOEEEIElgSeAJIV04UQQojgkMATQBJ4hBBCiOCQwBNAoQYJPEIIIUQwSOAJIE8Lj0w+KIQQQgSUBJ4Aqg48sryEEEIIEVgSeAJIxvAIIYQQwSGBJ4CkS0sIIYQIDgk8ASQtPEIIIURwSOAJIKM8pSWEEEIEhQSeAJIWHiGEECI4JPAEkAQeIYQQIjgk8ARQ9cSD8li6EEIIEVgSeAJIntISQgghgkMCTwCd6tKyB7kkQgghxPlFAk8AGWUMjxBCCBEUEngC6FQLjxOXSwlyaYQQQojzhwSeAKoetAxgrZJWHiGEECJQJPAEUIhOg1rl/rd0awkhhBCBI4EngFQqlczFI4QQQgSBBJ4Ak8AjhBBCBJ4EngALlfW0hBBCiICTwBNg1S08Fpl8UAghhAgYCTwBJl1aQgghROBJ4AkwCTxCCCFE4EngCTCjQQfIelpCCCFEIEngCTBp4RFCCCECTwJPgEngEUIIIQJPAk+ASeARQgghAk8CT4B5HkuXwCOEEEIEjASeAPO08MigZSGEECJgvA48GRkZ3H777fTu3ZuhQ4cyZ84cqqqqvLrGokWLSElJYcqUKbX25efnc99999GnTx8GDhzIP//5T8rLy2sd98MPP3DVVVfRs2dPLr30Uj755BNvX0pQyEzLQgghROB5FXjMZjOTJk3Cbrczf/58pk2bxkcffcTs2bMbfI2CggJeeeUVWrZsWWuf3W7nzjvvJDs7m+eff57HH3+c9evX8+CDD9Y4bsuWLdx777307t2bt956i7Fjx/LPf/6TlStXevNygkLG8AghhBCBp/Xm4KVLl1JRUcGCBQuIiooCwOl08sQTTzBlyhTi4uLqvcbcuXO5+OKLyc3NrbXvm2++4eDBg6xYsYKkpCQATCYTkydPZteuXfTq1QuA1157jV69evHkk08CMHjwYI4cOcLLL7/MZZdd5s1LCjijjOERQgghAs6rFp5169YxZMgQT9gBGDt2LC6Xiw0bNtR7/pYtW/juu+9qtdj8/vopKSmesAMwdOhQoqKiWLt2LQBVVVVs2rSpVrAZN24cGRkZ5OTkePOSAs7TpSVjeIQQQoiA8aqFJzMzk2uvvbbGNpPJRExMDJmZmXWe63Q6mTVrFnfffTexsbFnvP7vww6ASqWiY8eOnusfPnwYu91e67jk5GTPNeLj4715WR6KomCxWM7q3DOprKys8Vnlsru/ttl9fq/z1R/rWPiW1K9/Sf36n9SxfwW7fhVFQaVS1XucV4GntLQUk8lUa3tkZCRms7nOc99//30qKyu57bbb6rx+REREndev/vzHclR/XV856mK329m3b99Zn1+X7OxsACqrXAA4nAq79/yKVlP/N0k0THUdC/+Q+vUvqV//kzr2r2DWr16vr/cYrwLP2SoqKuLll1/m2WefbVChgkWn09GpUyefXrOyspLs7GwSExMJDQ3F6XTBMvf4pcSkTkQYG299NBV/rGPhW1K//iX1639Sx/4V7PpNT09v0HFeBR6TyURZWVmt7WazmcjIyDOe99JLL5GSkkL//v0pLS0FwOFw4HA4KC0txWg0otVqMZlMp30E3Ww206ZNGwDPff5Yjurr1lWO+qhUKoxG41mfX5fQ0FDPtfVaNVUOF4pK57f7nY9+X8fC96R+/Uvq1/+kjv0rWPXbkO4s8DLwJCUl1RqrU1ZWRkFBQa0xNb+XlZXF5s2bGTBgQK19AwYM4K233iItLY2kpCQOHDhQY7+iKGRlZTF06FAAEhIS0Ol0ZGZmMnz4cM9x1eWqqxyNRahBS1V5lTyaLoQQQgSIV4EnLS2N119/vcZYnpUrV6JWqz2B5HRmzpzpaYGp9vTTT2MwGJg+fTopKSme63/xxReepjGAn376iZKSEkaMGAG4++kGDRrEN998w6RJkzzXW7FiBcnJyWc9YDmQQkO0mCXwCCGEEAHjVeCZOHEiS5YsYerUqUyZMoX8/HzmzJnDxIkTa8zBM2nSJHJzc1m1ahUAqampta5lMpkwGo0MGjTIs+3SSy/ljTfe4L777mP69OlUVlYyZ84cRo4c6ZmDB+Cee+7h1ltv5fHHH2fs2LFs2rSJ5cuX8+KLL3pdAcEgkw8KIYQQgeVV4ImMjGTx4sXMmjWLqVOnEhYWxoQJE5g2bVqN41wuF06n0+vC6HQ63n77bZ566immT5+OVqvlkksuYebMmTWO69+/P/Pnz2fevHksW7aMtm3b8tRTTzF27Fiv7xkMRoMOkMAjhBBCBIrXT2klJyezaNGiOo9ZsmRJvdc50zFxcXHMnz+/3vNHjRrFqFGj6j2uMZIFRIUQQojAktXSg0C6tIQQQojAksATBBJ4hBBCiMCSwBMEEniEEEKIwJLAEwTVgcciY3iEEEKIgJDAEwTSwiOEEEIElgSeIAg1SOARQgghAkkCTxBIC48QQggRWBJ4gsB4soXHIoFHCCGECAgJPEEgEw8KIYQQgSWBJwikS0sIIYQILAk8QWCUwCOEEEIElASeIPh9C4/LpQS5NEIIIUTzJ4EnCKoDD4C1Slp5hBBCCH+TwBMEIXoNapX739KtJYQQQvifBJ4gUKlUGGQcjxBCCBEwEniCRAYuCyGEEIEjgSdIZHkJIYQQInAk8ASJTD4ohBBCBI4EniCRyQeFEEKIwJHAEyTVgUfW0xJCCCH8TwJPkEiXlhBCCBE4EniCRLq0hBBCiMCRwBMkEniEEEKIwJHAEyRGgw6QwCOEEEIEggSeIJFBy0IIIUTgSOAJEunSEkIIIQJHAk+QeGZalqe0hBBCCL+TwBMk0sIjhBBCBI4EniAxyhgeIYQQImAk8ASJTDwohBBCBI4EniCRLi0hhBAicCTwBEn1oGWH04Xd4QpyaYQQQojmzevAk5GRwe23307v3r0ZOnQoc+bMoaqqqt7zZsyYwZgxY+jduzcDBgzgpptuYv369TWOmT9/PikpKaf9eOyxx+o97oMPPvD25QRNdQsPSCuPEEII4W/a+g85xWw2M2nSJBITE5k/fz75+fnMnj0bq9VaI5Ccjt1u57bbbiMxMRGbzcayZcu46667ePfdd+nfvz8A1113HcOHD69x3ubNm3nuuedIS0ursd1gMLB48eIa29q3b+/NywkqrUaNXqumyuGi0ubAFKYPdpGEEEKIZsurwLN06VIqKipYsGABUVFRADidTp544gmmTJlCXFzcGc996aWXanydlpbGqFGj+Pzzzz2Bp3Xr1rRu3brWPSMjI2sFHrVaTe/evb0pfqMTatBSVV4lLTxCCCGEn3nVpbVu3TqGDBniCTsAY8eOxeVysWHDBq9urNFoiIiIwG63n/EYm83GqlWruPTSS9Hrm18LiDypJYQQQgSGVy08mZmZXHvttTW2mUwmYmJiyMzMrPd8RVFwOp2UlZXx6aefcujQIZ588skzHr969WrKy8u54oorau2zWq0MHjyY0tJSEhMTue2227j++uu9eTmnLZ/FYjmna/xRZWVljc+/F6Jz583i0nIsFoNP73s+qauOxbmT+vUvqV//kzr2r2DXr6IoqFSqeo/zKvCUlpZiMplqbY+MjMRsNtd7/rJly3jkkUcAMBqNvPjii/Tp0+eMxy9fvpy4uDgGDBhQY3tCQgIzZsygW7du2Gw2vvzySx599FHKysqYPHmyNy+pBrvdzr59+876/LpkZ2fX2qY43YO90zMPEeIo8Mt9zyenq2PhO1K//iX1639Sx/4VzPptSC+QV4HnXI0aNYquXbtSXFzMypUreeCBB1iwYAEjRoyodWxpaSlr167l5ptvRq2u2fM2fvz4Gl+PHDkSu93Oa6+9xq233opOpzur8ul0Ojp16nRW555JZWUl2dnZJCYmEhoaWmNf9OZKDhcU0bJVa1JT2/n0vueTuupYnDupX/+S+vU/qWP/Cnb9pqenN+g4rwKPyWSirKys1naz2UxkZGS950dHRxMdHQ24By2bzWbmzp172sDzzTffUFVVxZVXXtmgso0dO5ZvvvmGw4cPk5yc3KBz/kilUmE0Gs/q3PqEhobWuna4MQQAp6L2233PJ6erY+E7Ur/+JfXrf1LH/hWs+m1IdxZ4OWg5KSmp1lidsrIyCgoKSEpK8uZSAHTv3p1Dhw6ddt/y5ctJSkqiW7duXl+3qTAa3C1R8pSWEEII4V9eBZ60tDQ2btxIaWmpZ9vKlStRq9UMHTrU65tv3br1tHPnHD9+nF9++eW0g5XPZMWKFZhMJhISErwuR7DI8hJCCCFEYHjVpTVx4kSWLFnC1KlTmTJlCvn5+cyZM4eJEyfWmINn0qRJ5ObmsmrVKgDWrFnDZ599xsiRI2nTpg1ms5nly5ezfv16XnjhhVr3WbFiBS6X64zdWddccw1XX301SUlJWK1WvvzyS7799ltmzpx51uN3giFUVkwXQgghAsKrwBMZGcnixYuZNWsWU6dOJSwsjAkTJjBt2rQax7lcLpxOp+fr9u3bU1VVxfPPP09xcTEtWrQgJSWFJUuWMHDgwFr3+fLLL+nVq9cZW2sSEhJYtGgRhYWFqFQqunTpwty5c7nqqqu8eTlBJy08QgghRGB4/ZRWcnIyixYtqvOYJUuW1Drn1VdfbfA9Pvnkkzr3z5s3r8HXasyqFxCViQeFEEII/5LV0oNIWniEEEKIwJDAE0RGGcMjhBBCBIQEniCStbSEEEKIwJDAE0TSpSWEEEIEhgSeIDIaJPAIIYQQgSCBJ4iqW3isVQ4URQlyaYQQQojmSwJPEFUHHkUBa5WznqOFEEIIcbYk8ARRiF6D+uSaZxarPbiFEUIIIZoxCTxBpFKpMMjAZSGEEMLvJPAEmTypJYQQQvifBJ4gk8AjhBBC+J8EniCTyQeFEEII/5PAE2QyF48QQgjhfxJ4gky6tIQQQgj/k8ATZBJ4hBBCCP+TwBNk1YHHImN4hBBCCL+RwBNk0sIjhBBC+J8EniALlUHLQgghhN9J4AkyT5eWBB4hhBDCbyTwBJlRurSEEEIIv5PAE2ShBh0gEw8KIYQQ/iSBJ8hk0LIQQgjhfxJ4gky6tIQQQgj/k8ATZNLCI4QQQvifBJ4gk4kHhRBCCP+TwBNk1fPwOJwu7A5XkEsjhBBCNE8SeIKsuoUHpFtLCCGE8BcJPEGm1agJDdEAkFtQHuTSCCGEEM2TBJ5GYFCPNgCs/Dk7uAURQgghmikJPI3A5Rd2BODH7UcpragKcmmEEEKI5kcCTyOQ0qEFSW0jqXK4+H7z4WAXRwghhGh2JPA0AiqVinFDEwH4emM2LpcS3AIJIYQQzYzXgScjI4Pbb7+d3r17M3ToUObMmUNVVf3dMDNmzGDMmDH07t2bAQMGcNNNN7F+/foax+Tk5JCSklLr4/rrr691vW3btnHDDTfQq1cvLrroIt58800UpekGhRF94jEatBwrqmDHgYJgF0cIIYRoVrT1H3KK2Wxm0qRJJCYmMn/+fPLz85k9ezZWq5XHHnusznPtdju33XYbiYmJ2Gw2li1bxl133cW7775L//79axw7ffp0Bg0a5Pk6LCysxv5Dhw4xefJkhg4dygMPPMD+/ft57rnn0Gg0TJ482ZuX1GgYQrSMGpDAlz9msmJjFn27xga7SEIIIUSz4VXgWbp0KRUVFSxYsICoqCgAnE4nTzzxBFOmTCEuLu6M57700ks1vk5LS2PUqFF8/vnntQJPhw4d6N279xmvtXDhQlq0aMELL7yAXq9nyJAhnDhxgtdff51bbrkFvV7vzcvyK1dlGZriI0BqvceOHZLIlz9msvnXPI6fsBAbbfR/AYUQQojzgFddWuvWrWPIkCGesAMwduxYXC4XGzZs8OrGGo2GiIgI7Ha7V+dVl2PUqFE1gs24ceMoLS1l+/btXl/Pn8zfvIlp0xLs+Vn1Hts+LoJenVrhUuQRdSGEEMKXvAo8mZmZJCUl1dhmMpmIiYkhMzOz3vMVRcHhcFBcXMzChQs5dOgQN9xwQ63jHn/8cVJTUxkyZAiPPPIIJSUlnn0Wi4Vjx47VKkdSUhIqlapB5QgkxeEOdI4TuQ06ftxQ9yPqqzYdxu5w+q1cQgghxPnEqy6t0tJSTCZTre2RkZGYzeZ6z1+2bBmPPPIIAEajkRdffJE+ffp49uv1em688UaGDRuGyWRi586dvP766+zZs4ePP/4YnU5HWVkZQK1y6PV6QkNDG1SOM1EUBYvFctbnn/aaIe7xRzZzYYOu3bOjiRYRIRSX2VizJZuhvdr4tDzNUWVlZY3Pwrekfv1L6tf/pI79K9j1qygKKpWq3uO8CjznatSoUXTt2pXi4mJWrlzJAw88wIIFCxgxYgQAsbGxPP74457jBw4cSOfOnZkyZQqrVq1i3Lhxfi2f3W5n3759Pr1mqB0MQEleDscaeO0LEkNYs9vGZ2sOEK0r8Wl5mrPs7OxgF6FZk/r1L6lf/5M69q9g1m9Dxu56FXhMJpOnheX3zGYzkZGR9Z4fHR1NdHQ04B60bDabmTt3rifwnM6IESMwGo3s3buXcePGERERAVCrHFVVVVRWVjaoHGei0+no1KnTWZ9/OiXFv2E99AsROhWJqfUPXAaIa2dl3d71HC6owtging6tI3xapuamsrKS7OxsEhMTCQ0NDXZxmh2pX/+S+vU/qWP/Cnb9pqenN+g4rwJPUlJSrTEyZWVlFBQU1BpT0xDdu3dn3bp1Xp1jNBpp06ZNrXJkZWWhKMpZlaOaSqXCaPTtk1GWyJZYAZWtvMHXNhqNDOnRhg27clm9LY+/TDjz02/ilNDQUJ9//8QpUr/+JfXrf1LH/hWs+m1IdxZ4OWg5LS2NjRs3Ulpa6tm2cuVK1Go1Q4cO9a6EwNatW2nfvn2dx6xevRqLxULPnj1rlOP777+v8YTXihUrMJlMNcYENQYao7vFyWUprefImqpnXl6z7QgWq/dPsgkhhBDiFK9aeCZOnMiSJUuYOnUqU6ZMIT8/nzlz5jBx4sQac/BMmjSJ3NxcVq1aBcCaNWv47LPPGDlyJG3atMFsNrN8+XLWr1/PCy+84Dlv9uzZqFQqevfujclkYteuXbzxxhv06NGD0aNHe46bPHkyX375JQ8++CA33ngjBw4cYOHChUybNq1RzcEDoK4OPBUlXp3XM7kV8bHh5BwvZ/XWHC4/+fSWEEIIIbznVeCJjIxk8eLFzJo1i6lTpxIWFsaECROYNm1ajeNcLhdO56lHqtu3b09VVRXPP/88xcXFtGjRgpSUFJYsWcLAgQM9xyUnJ/PBBx/w0UcfYbVaiYuLY8KECdx///1otaeK2qFDBxYuXMjs2bO56667iI6O5v777+eOO+4423rwG3WY+2kyV2UZiuJCpWpYo5pKpWLchR1587PdrNiYxbgLExvcbCeEEEKImrx+Sis5OZlFixbVecySJUtqnfPqq6/We+3rrruO6667rkHl6Nu3Lx999FGDjg0mdejJx+cVFy5LGZqwhg+qvrh/exav+JXDeWXszSyiR3IrP5VSCCGEaN5ktXQ/U2m0uHTuUevOCu/mCAoL1TGybzwAKzZm+7poQgghxHlDAk8AVE8+6PRyHA/AuAvdY3c27sqluNTqy2IJIYQQ5w0JPAHg0lcHHu9ngU5qF0lqYjROl8K3mw75umhCCCHEeUECTwAoJwOP4yxaeADGXZgIwDcSeIQQQoizIoEnAFzn0KUFMLiHez2tguJKzOU2XxVLCCGEOG9I4AkA5Ry6tAAMIVpiW7gHPuccL/dZuYQQQojzhQSeADjXFh6A+Fj3eloSeIQQQgjvSeAJgHMZtFwtPjYcgJzjtRdvFUIIIUTdJPAEwLk8ll7tVOCRFh4hhBDCWxJ4AuBUC08piqKc1TWqu7SOSuARQgghvCaBJwCUEKP7Hy4HLuvZBZbqFp78ExVU2Z31HC2EEEKI35PAEwhqLaqToedsx/FERYQQZtDiUuBYYYUvSyeEEEI0exJ4AkRtdC8a6iwvPqvzVSoV8XHubq0jMnBZCCGE8IoEngBRG92rpvvmSS0ZxyOEEEJ4QwJPgGiqW3h8MRdPvgQeIYQQwhsSeAJEHVYdeHzQwlMgXVpCCCGENyTwBMipLq2Ss77G77u0XK6ze7xdCCGEOB9J4AkQtTEKOLcWntYtw9CoVdiqnBSZrT4qmRBCCNH8SeAJEF+08Gg1atq0ck9iKEtMCCGEEA0ngSdAqsfwOM6hhQegfZwsIiqEEEJ4SwJPgPz+Ka2zXV4CTo3jkbl4hBBCiIaTwBMg1V1aOB24bJazvk514JE1tYQQQoiGk8ATICqt/nfLS5Sc9XU8c/FIC48QQgjRYBJ4Akgbdu6TD7aLcbfwnCi1UVFp90WxhBBCiGZPAk8AacKigHN7ND0sVEe0KQSAowXSrSWEEEI0hASeANJUt/CUl5zTdaRbSwghhPCOBJ4A8kULD0A7WURUCCGE8IoEngDS+GAMD0D7ky08R/KlhUcIIYRoCAk8AXSqhafknK4TLy08QgghhFck8ASQxgcrpsOpMTzHCitwOF3nXC4hhBCiuZPAE0C+auFpGWnAoNfgdCnkFVWce8GEEEKIZk4CTwD9voXnXJaXUKtVMnBZCCGE8IIEngCqbuFRHFUoVZXndK34GFlEVAghhGgorbcnZGRk8NRTT7F9+3bCwsIYP348DzzwAHq9vs7zZsyYwa5duzh+/Dg6nY4uXbpwzz33MGzYMM8xu3bt4oMPPmDLli0cP36cuLg4Lr30Uu655x6MRqPnuPnz57NgwYJa93j88ce58cYbvX1JAaPWG1DpDShVVpwVJahDjPWfdAbxcdUtPPKklhBCCFEfrwKP2Wxm0qRJJCYmMn/+fPLz85k9ezZWq5XHHnusznPtdju33XYbiYmJ2Gw2li1bxl133cW7775L//79Afj66685dOgQd955J4mJiaSnp/Pyyy+zc+dO3n333RrXMxgMLF68uMa29u3be/NygkITFoWjKg9nhRlddNuzvo48qSWEEEI0nFeBZ+nSpVRUVLBgwQKioqIAcDqdPPHEE0yZMoW4uLgznvvSSy/V+DotLY1Ro0bx+eefewLPn//8Z6Kjoz3HDBo0CJPJxIwZM9izZw89evTw7FOr1fTu3dub4jcKmrBIHMV5OHw0F09OfhmKoqBSqXxQOiGEEKJ58moMz7p16xgyZIgn7ACMHTsWl8vFhg0bvLqxRqMhIiICu/3UApi/DzvVunXrBsDx48e9un5j5XlSq/zcHk1v0yoMtQoqrA5Kymw+KJkQQgjRfHnVwpOZmcm1115bY5vJZCImJobMzMx6z1cUBafTSVlZGZ9++imHDh3iySefrPOcrVu3ApCUlFRju9VqZfDgwZSWlpKYmMhtt93G9ddf783LOW35LBbLOV3jjyorK2t8VkLCALCWFKA7x3vFtAgl/0Ql6UcK6d6xdlg8X/yxjoVvSf36l9Sv/0kd+1ew67ehvRxeBZ7S0lJMJlOt7ZGRkZjN9bdYLFu2jEceeQQAo9HIiy++SJ8+fc54/IkTJ5g/fz6jRo0iMTHRsz0hIYEZM2bQrVs3bDYbX375JY8++ihlZWVMnjzZm5dUg91uZ9++fWd9fl2ys7MBMFRUEQqcyD1Ezjney2RQyAe27s5Abc0/5zI2ddV1LPxD6te/pH79T+rYv4JZv/U9OAVn8ZTWuRg1ahRdu3aluLiYlStX8sADD7BgwQJGjBhR61i73c706dMB99NXvzd+/PgaX48cORK73c5rr73Grbfeik6nO6vy6XQ6OnXqdFbnnkllZSXZ2dkkJiYSGhqKpeoopRnrMenVdEhNPadrpxw6wMHcQ7i0JlJTU3xU4qbnj3UsfEvq17+kfv1P6ti/gl2/6enpDTrOq8BjMpkoK6v9GLTZbCYyMrLe86Ojoz3jdNLS0jCbzcydO7dW4FEUhZkzZ7Jr1y7ef/99YmNj67322LFj+eabbzh8+DDJyckNfEU1qVSqGo+/+1JoaChGoxGlRSylANbyc75XYtsWwCHyT1j9Vu6mpLqOhX9I/fqX1K//SR37V7Dqt6EP7Xg1aDkpKanWWJ2ysjIKCgpqjbFpiO7du3Po0KFa25999lm+/vprXnnlFbp27er1dRszXy0vAb9/NF3m4hFCCCHq4lXgSUtLY+PGjZSWlnq2rVy5ErVazdChQ72++datW2vNnfPmm2+yaNEiZs+ezZAhQxp8rRUrVmAymUhISPC6HIF0anmJknO+Vvs496Ppx4srsVY5zvl6QgghRHPlVZfWxIkTWbJkCVOnTmXKlCnk5+czZ84cJk6cWGMOnkmTJpGbm8uqVasAWLNmDZ999hkjR46kTZs2mM1mli9fzvr163nhhRc853355Zc8//zzXHXVVcTHx7Njxw7PvoSEBE932DXXXMPVV19NUlISVquVL7/8km+//ZaZM2ee9fidQPEsL2G34aqqRK0/+/5OU5geU5ie0ooqjh4vJzk+yjeFFEIIIZoZrwJPZGQkixcvZtasWUydOpWwsDAmTJjAtGnTahzncrlwOp2er9u3b09VVRXPP/88xcXFtGjRgpSUFJYsWcLAgQM9x1XP5fPFF1/wxRdf1LjmM888wzXXXAO4w8+iRYsoLCxEpVLRpUsX5s6dy1VXXeXdqw8Cld6ASqtHcVThrDCfU+ABd7fWr1knyJHAI4QQQpyR109pJScns2jRojqPWbJkSa1zXn311XqvPXv2bGbPnl3vcfPmzav3mMZKpVK5l5cwH8dZUYKuRetzul58bIQn8AghhBDi9GS19CDwjOM5x9mWQQYuCyGEEA0hgScI/POklrTwCCGEEGcigScINOFRADgrfNHC435SK7egHKdLOefrCSGEEM2RBJ4g8OWj6bHRRnRaNVUOFwXFvl0HTAghhGguJPAEQXWXlsMHgUejVtEuRrq1hBBCiLpI4AmCU2N4zr1LC6CdDFwWQggh6iSBJwh82aUFMnBZCCGEqI8EniDwdQtP9cBlCTxCCCHE6UngCQLtyRYepaoSl912zteTuXiEEEKIukngCQJViBGVxr3mly9aeaoHLZvLqyitqDrn6wkhhBDNjQSeIHAvL+G7cTyhIVpaRbnX5Doq3VpCCCFELRJ4gsQzjqe8xCfXk24tIYQQ4swk8ASJr5/Uah/nHrh8RFp4hBBCiFok8ASJ75/UcrfwHM4r9cn1hBBCiOZEAk+Q+LqFp3P7KAC2/nacX37N88k1hRBCiOZCAk+Q+HIBUYDO7Vtw+dCOADz/360cLZCuLSGEEKKaBJ4gOdWlVeKza06+qgepidFYrA7+/Z9fsFjtPru2EEII0ZRJ4AkSX4/hAdBp1Tw8aQDRJgNH8st46cPtKIris+sLIYQQTZUEniDx9Rieai1MBh6eNACtRsXGXcdY9sNBn15fCCGEaIok8ARJdQuPy2bB5fDt7MhdE6O560+9AHjv631s23/cp9cXQgghmhoJPEGiNoSBRguAy4fdWtUuG9yBMYM64FJg7pIt5BVV+PweQgghRFMhgSdIVCoVGqO7W8vhh8CjUqm4+5qedEmIorzSztOLfsFa5fD5fYQQQoimQAJPEPnjSa3f02k1PDxpIFHhIWTllrLgo50yiFkIIcR5SQJPEPlr4PLvtYoK5R+39kejVrF2ew6fr8v0272EEEKIxkoCTxD549H00+mR3Io7ruoOwH+W72V3eqFf7yeEEEI0NhJ4gkgb7v8WnmpXDkvion7xuFwKCz7egd3h8vs9hRBCiMZCAk8QeVp4ykv8fi/3IOZeRIWHkFtYwdcbs/x+TyGEEKKxkMATRKfG8Pi3S6ua0aDjpsu6AvDBt/sps/h2/h8hhBCisZLAE0T+fkrrdC4Z1IHENibKK+188O3+gN1XCCGECCYJPEEU6BYeAI1axeSTA5hXbMgi53hZwO4thBBCBIsEniDyLC9hLUdxBm5l895dYhnQLQ6nS+E/X/4asPsKIYQQwSKBJ4jUoeGgcn8LnBWlAb337Vd0R6NW8cuveew8UBDQewshhBCB5nXgycjI4Pbbb6d3794MHTqUOXPmUFVV/+DXGTNmMGbMGHr37s2AAQO46aabWL9+fa3jysrKmDlzJgMHDqRPnz7cf//9HD9ee/HLbdu2ccMNN9CrVy8uuugi3nzzzSY3i7BKpQ7I5IOn0z4ugrEXJgLw9hd7cLqaVt0JIYQQ3vAq8JjNZiZNmoTdbmf+/PlMmzaNjz76iNmzZ9d7rt1u57bbbuPVV19lzpw5REVFcdddd7Fly5Yaxz3wwANs2LCBxx9/nOeee46srCz+/Oc/43CcWgfq0KFDTJ48mZiYGN544w0mTZrEyy+/zDvvvOPNy2kUgjFwudqNY7oSHqoj+1gp3/1yOOD3F0IIIQJF683BS5cupaKiggULFhAVFQWA0+nkiSeeYMqUKcTFxZ3x3JdeeqnG12lpaYwaNYrPP/+c/v37A7B9+3bWr1/PwoULGTZsGAAdO3Zk3LhxfPvtt4wbNw6AhQsX0qJFC1544QX0ej1DhgzhxIkTvP7669xyyy3o9XpvXlZQBWq25dMxhemZOCaFtz/fw3sr9zG8d1uMBl3AyyGEEEL4m1ctPOvWrWPIkCGesAMwduxYXC4XGzZs8OrGGo2GiIgI7PZTg3XXrVuHyWRi6NChnm1JSUmkpqaybt26GseNGjWqRrAZN24cpaWlbN++3atyBJsmgLMtn864CzvStlUYJWU2lv1wMChlEEIIIfzNqxaezMxMrr322hrbTCYTMTExZGbWvyiloig4nU7Kysr49NNPOXToEE8++WSN63fs2BGVSlXjvKSkJM/1LRYLx44dIykpqdYxKpWKzMxMBg0a5M3LqlE+i8VyVueeSWVlZY3Pte6pDwPAWlLo83s31P+N6cRz7+/ks7UZpF0QR2yL0KCU42zVV8fi3Ej9+pfUr/9JHftXsOtXUZRaueF0vAo8paWlmEymWtsjIyMxm+vvklm2bBmPPPIIAEajkRdffJE+ffrUuH5ERMRpr79nzx7APagZqFUOvV5PaGhog8pxJna7nX379p31+XXJzs4+7faQMitGoCTvCEf9dO/6hCkKiXEhZOfbeOOTrUwY2jIo5ThXZ6pj4RtSv/4l9et/Usf+Fcz6bchQFq8Cz7kaNWoUXbt2pbi4mJUrV/LAAw+wYMECRowYEchinJFOp6NTp04+vWZlZSXZ2dkkJiYSGlq75aSSE5j3f0+4FhJSU316b2/c06KMh177mT2HKrlhTBu6JEQFrSzeqq+OxbmR+vUvqV//kzr2r2DXb3p6eoOO8yrwmEwmTwvL75nNZiIjI+s9Pzo6mujoaMA9aNlsNjN37lxP4DGZTOTl5dV5/eoWoD+Wo6qqisrKygaV40xUKhVGo/Gsz69LaGjo6a8dHYsZUKxlfrt3Q3RLNjJ6QAKrfjnMe9+kM+e+4ajV9TcRNiZnrGPhE1K//iX1639Sx/4VrPptSHcWeDlo+fdjaaqVlZVRUFBQa0xNQ3Tv3p1Dhw7VuH5WVlat+XSysrI81zcajbRp06ZWOarPO5tyBJM2iE9p/dHNY1Mx6DXsP1zMY29u5Icth7FYAzcDtBBCCOEvXgWetLQ0Nm7cSGnpqVmBV65ciVqtrvFkVUNt3bqV9u3b17i+2Wzmp59+8mzLysri119/JS0trcZx33//fY0nvFasWIHJZKoxJqgp8CwvYSlFcTrqPtjPok0GbrvCvc7WzoOFvPjBdm7510qefXczm/Ycw+5wBbV8QgghxNnyqktr4sSJLFmyhKlTpzJlyhTy8/OZM2cOEydOrDEHz6RJk8jNzWXVqlUArFmzhs8++4yRI0fSpk0bzGYzy5cvZ/369bzwwgue8/r06cOwYcOYOXMm//jHPwgJCeHFF18kJSWFMWPGeI6bPHkyX375JQ8++CA33ngjBw4cYOHChUybNq1JzcEDv1teQnHhKCtCF3XmuYwC4fKhHemTEsO67UdZszWHowXlrN+Zy/qduYSH6hh6QVtG9I2ne8eWTa7LSwghxPnLq8ATGRnJ4sWLmTVrFlOnTiUsLIwJEyYwbdq0Gse5XC6cTqfn6/bt21NVVcXzzz9PcXExLVq0ICUlhSVLljBw4MAa586bN49nnnmGxx57DIfDwbBhw3jkkUfQak8VtUOHDixcuJDZs2dz1113ER0dzf33388dd9xxNnUQVCq1hpB2XbDl/EbFvp+IGnJ1sItE21bhTLwkhRtGdyHjqJm123JYtz2HE6U2vvn5EN/8fIjWLY08escgElrXfmpPCCGEaGxUSlNbgMpPdu/eDUDPnj19el2LxcK+fftITU0942Cu0u3fUbjiNXSt4om/a16DB2AFktOlsCejkLXbcti4K5cKq4PWLY08/9cRmMKC26rWkDoWZ0/q17+kfv1P6ti/gl2/DX3/ltXSG4Hw1CGotHrshTnYjmUEuzinpVGruKBzDPff0Ic3Hh5NXLSRvCILz767GYdTxvYIIYRo3CTwNAJqQxhhXQcDUL5rdZBLU7/I8BAeuWMQBr2GXemFLPxiT7CLJIQQQtRJAk8jEd5rJADle9fjclQFtzANkNjGxPT/6wfA8vVZfPNzdnALJIQQQtRBAk8jEdqhBxpTK1zWciwHtwS7OA0ypGcbbr6sKwCvf7qLvZlFQS6REEIIcXoSeBoJlVpDRE/3jNNlOxt/t1a160d3YegFbXE4FZ5Z/AvHTwRnAVQhhBCiLhJ4GpGIk91alZk7cJQVB7cwDaRSqXjghj4ktYvEXF7FU//ZhNUW3AkUhRBCiD+SwNOI6KLbEhLfFRQX5XvWBrs4DWYI0fLP2wcSFR5CVm4pLy7dhsslsx0IIYRoPCTwNDIRvS4CoGzX6lprijVmsS2MPHzbALQaFRt3HePD7w4Eu0hCCCGEhwSeRqYpzMlzJt06tuQv114AwPvf/MbGXblBLpEQQgjhJoGnkWlqc/L80SWDOnDVcPeK9XPf28qCj3dwtKA8yKUSQghxvpPA0widmpPnxyYxJ88f3XFld4b0bIPD6eKbnw9xz7Pf8/SiX9h/6ESwiyaEEOI85dXioSIwqufkcZYWYjmwmfBuQ4NdJK9oNGoenjSAX7NO8OnqdH75NY+fdh/jp93H6J7Ukmsv6kS/rnGy2roQQoiAkcDTCFXPyVOy4RPKdq1ucoEH3I+rd09qSfeklhzOK+V/azJYs+0IezOL2JtZRELrCK4Z2Ym0PvHotNLQKIQQwr/knaaROjUnz04cZU27KyihtYm/TuzD2/+8hGtGdiI0RMvhvDLmLd3OrY+vZO6SLfyw5TAlZTa/3P9YYQXvrviVH7cfxVzun3sIIYRo3KSFp5GqnpPHlvMb5XvWETXk6mAX6Zy1jAzl9iu7c/3oLqz8KZsvfszgRKmNdTuOsm7HUVQqSI6Pon/XOPqlxtK5fQs059jttWVfPs/9dysVlXYA9z3aRdInJZY+XWLpmhgtLUxCCHEekMDTiEX0ughbzm+U7VpN5ODxqFTNY8xLWKiOay/uzNUjktl/uJitvx1ny758Mo+aST9SQvqREpau2k+EUU/flFhGD2xP7y6xXt1DURSW/XCQJV/vQ1GgY1sTigLZx0pJzzGTnmPm4+8PYtBr6JHcij5dYujWsSV6nbpGPVf/U6VSoQIiwvREGPU+rA0hhBCBIIGnEQtPHULRtwvdc/LkpmNo1znYRfIpjUZNt44t6daxJbeMTeVEqZVtv+Wz5bfj7Nh/nDJLFWu357B2ew79U+O448rutI+LqPe6lTYHLy3dzoaT8wBdOrgDU/7UE51Ww4lSKzsOFLD9wHF2HCigpMzGln35bNmX36Ayq9UqBvdozRVDk+iR3LLZhFAhhPAnxeVEcVSh1ocGrQwSeBqx6jl5yveso3zX6mYXeP4o2mRg9MAOjB7YAYfTxf5Dxfy44ygrf8pmy758tu0/zrgLE7lxTFdMYadvZTlWWMG//7OJQ3llaDUqpvypF5cNSaxxj4v7t+fi/u1xuRQO5ZWyfb87AGXlmnG5ABSqJ7n2zHWtKCiAxepg465jbNx1jA6tI7h8WBIX9Y3HEFL3f6Uqu5O9mUVs/e04u9ILSOkQzd3X9DrnLjshhGjsKg5spnDlWyh2KwlTX0NtCAtKOSTwNHIRvS5yB55f1xN9yW2otedHd4pWo/Y85XXV8CTe+XIvm/bmsXx9Fmu25jBxTArjLuxYY/zNjoOFzP94D+WVdlpEhPDwpIGkdow+4z3UahUd20bSsW0k11zUqUHlOnSslK82ZPHD1iMcyivj1WU7Wbx8L6MHdmDc0ETatgr3HJtbWM7WfcfZtv84u9ILqbI7PfuyckvRqlXc9aee0kokhGiWHGUnKPp2IRW//QyArlU8aIIXOyTwNHKGxKY9J48vtI0J55E7BrHzYAFvf76H7GOlvP35Hr7emMUdV/age2IE638t4/udOSgKpHRowcOTBtAy0vdNpx3amPjLhAu49fJufL/5MF+tz+JYUQWfr8vgix8z6Nc1jrhoI9t+O86xoooa50abDPTrGktMVCgfrNrP8g1ZREcauG5UF5+XUwghgkVRXJRtW0XR6vdQbBZQqYkaMp6oYdeh1oUErVwSeBo5lUpNRM+RlGxYRtnOpjknj69c0DmGedNH8t0vh3jv6984WlDBrHc2EdsilOPFlQCMGdSBu69xj9fxp/BQHePTkrlyWBLb9h9n+fpMz+DralqNim4dW9I3JZa+XWNJbGPytOaEhep46/M9vLtiH9EmA6MGJPi1vEIIEQhVBYcpWPE6tpz9AIS06USry+8hJC4xuAVDAk+TENHLHXgqM3dgP5GLLrptsIsUNBq1iksHJzK8dzs++u4An6/L5HhxJWoV3HFFV64a0SWgXURqtYr+qXH0T40jt7Ccb38+hLXKSe8uMfTq1AqjQXfa865KS+ZEqZVPVqfz8kc7iAwPoX9qXMDKLYQQPuV0ULbxEyo2LweXA5XeQPTI/8PU7zJUav/+AdpQEniaAF10G4yd+mFJ30rJz18QM+7uYBcp6IwGHbdd0Z3LhiSyYn0GLQ3lXDKwfVDHw7RtFc5tV3Rv8PG3jutGUamVNVtzmP3uZp6+ZyhdElr4sYQ1VdocfL0xm0JzJbeMTSW0noHXQojzl6IoKHYrzsoyXJayGp+t5iJMu9dRYXFPkmvs3J9Wl/0ZralVkEtdk/yGayIih1yNJX0r5bvW0CLtBrThgXtjbMxatwxj4iWd2LdvX7CL4jW1WsX91/fBXGZj+4ECnlz4M3PuHU7bmPD6Tz4HFqud5euz+GxtBmUW9+K0FZV2pt3Y16/3FUI0PZb0bRR+uxBnaRGK037G4zSA2hhJq7F/JixlcKN8GEOmmG0iDO1TCWmXguK0U7p5RbCLI3xEp1Xz0KQBJMdHYi6v4rE3f6K4zOqXe5VX2vng2/1MfmoVS77eR5mlijYtw1Cr4IctR/hhyxG/3FcI0TTZzcc5/tmLOIrzToUdjRZNeDT62AQMHXoQ1nUIob0uxtLlIlpNepbwrkMaZdgBaeFpMlQqFVFDxpO/bA6l274h6sJrUIcEbwIn4TtGg45/3TmYv8//kbwiC0+8/TNP3zP0jON/vFVmqeKLdZl8+WMGFVYHAPGx4dxwSQrDe7fj4+8P8N+Vv/HaJzvp2qGF31uYhBCNn+JyUvD5y7hsFkLadSH26gfQGE2odIZagcZisZC7b1/Q5tdpKGnhaUKMXQagi26Ly1pB6Y5VwS6O8KEWEQae+PMQIsP1ZOSYmb14M3aH65yuefyEhXdX/Mrkp1axdNV+KqwOElpH8Peb+7Pgbxczsm88GrWK60Z1oWdyK6xVTua8twW7w1n/xYUQzVrJT59jPbIPld5A7Pi/oouKQ60PbbStNw0hgacJUanURA4eD4B50/I6+1NF09M2JpzHJg8mRK9h+4EC7nn2e15dtpMNu3I9Y23q4nQp/JZ9gndX/Mq9c39g8r9X8fH3B6m0OUhsY+KhSQOY/+BFDO/TrsYMzxq1igdv6kuE0R22Fn/V9MZDCd9wuhRWbz3CgcPFwS6KCCJbbjrF65YC0GrMZHQtWge5RL4hXVpNTETPERSv/QBnWRHle9cT0euiYBdJ+FCXBPekibMXbyb/hIWvf8rm65+yPSvJ9+4cQ+/OMaR2jEav01Bpc7B9/3F++TWPLfvyMZefCkZqFXRLaslVw5MZ1L016jqWsWgZGcoDE/sw651NfL4ugws6t2JAt+bxS040TEFxJc+/v5W9mUVoNWoemzyIPineLdormj5XlZXjn78ELidhXYcQ3ozeYyTwNDEqrY7IgVdwYvV7lPz8OeE9R6BSSUNdc9KvaxyL/3UpezKK2HGwgB0HCjiSX+ZZSX7ZDwfRa9UktI4g+1gZDueprq8wg5a+XeMY2C2OfqlxXq3sPrB7a64cnsSXP2Yyb+l2Xn5wpF9mqxbeURSF0q0rsezfRFjqhYT3GO7zBRh/2p3Lyx/uoLzS3WrscLr496JfeOLPQ+ie1NKn9xKNW9F3i7CfyEUTEU2rcVOadBfWH0ngaYIi+o6heMMn2AuOUJm+HWPnfsEukvAxo0HHwO6tGdjd3cpSZK5k58FCdp4MQCdKraTnmAFo0zKMAd3jGNitNd2TWqLVnH0Avv2KbuzNLCLzqJkX3t/Gk1Mu9MnrAXA6XWjOoWznI5fdRuHXb1K+ew0Aldm7KfphCRE9R2Lqdyn6VvHndH2b3cnCL/bw9cZsADq3j2LajX15+4s9bPvtOE8u/Jl/3zOUTvFR53Qf4RvOCjPWowew5R7ElpuOy2ZBpdOj0oag1oX87t96VFo9Kr2B0I4XYGjbsLUCK/b/Qtn2VYCK2KvuRxMa4d8XFGASeJogjSEMU98xmH/+nJKf/ieB5zzQMjLUs8q7oijkHC8n46iZ5HaRxMeG++yvMJ1Ww99v6c8DL6xhV3ohy344wJUXtj+ra1XaHPyaVcSug4XsSi8g86iZhNYm/u/Srgzu0bpZ/eXoD47SIvKXPYvtWAao1ET0GY01ezf2E8co3bKC0i0rMCT2xNTvUsI6D0Dl5aKMh46VMue9LRzOKwPg2os6cdNlqei0ah6eNIDH3/qZvZlFPPbGT8yeOpSE1iZ/vExxBorDji0/C9vRA1hzD2I7egBHyXGvr1O85n3Cuw8n+uKb65wI0FFWTMFXrwIQOfhKQhN7nnXZGyuvA09GRgZPPfUU27dvJywsjPHjx/PAAw+g15+56fz48eMsWrSIDRs2cPjwYSIiIhgwYADTp0+nXbt2nuMeeugh/ve//532Gg8++CB33XVXnce99dZbpKWlefuSmqTIAZdj/uUrrEf2Yc3ZjyE+JdhFEgGiUqloHxdB+zj//PXVLiacu6/pxbyl23n/m/10btew+1TZnfx26AS70gvZdbCQA4eLcbqUGsdkHyvl6UW/0Ck+kpsuS6Vf11gJPqdhPfIb+Z/MxVlRgjo0nLhrZhCa2BNFcVGZtdvdxXVwC9bs3Vizd6MJj8bU9xIiLhiF1lR3F5SiKKz8KZu3P99DlcNFVEQI027sS9/fjdcx6LU8NnkQj7y+kYNHSnj0jY3MnjqcNq1899ixo7wE66E9qA1haE0t0Ua0RBViPG9/HpwVZqw5v7k/jvyGLS8TnI5ax+laxRPStguGdp3RhLdAcVSh2G247Laa/7ZX4SgrwrL/F8r3/kjF/k1EDfkTkUPG11rAU1FcFCyfj6uyDH1cR6JH/F+gXnZAeRV4zGYzkyZNIjExkfnz55Ofn8/s2bOxWq089thjZzxv7969rFq1imuvvZYLLriA4uJiXnvtNa677jqWL19OdHQ0AH/5y1+YOHFijXNXrFjB4sWLawWZ9u3b89xzz9XYlpyc7M3LadK0ppaE90ijfNcPlPz8Oa0n/D3YRRLNyMX927PjQAFrtuUw/+PdTL7E/X9UURTM5VXkFVVwrKiCvCKL+9+FFaTnlNR6lD62RSgXdI6hZ6dWdIqPYvXWI3z5YybpOWaeePtnunZowc2XpdKrcyufvdE5nS5Kym1+H39UUFzJZ+vSadsqnDGDEny2YG3ptm8p/GYhuBzoYzsQd90/0EW511lTqdQYky7AmHQBDnMBpdtXUbbjO5zlJyhe9yHF6z5EGxVLSLsuGNp1IaRtZ0LiOqLSuud0KrNUMf+jHfy0+xgAfbvGMm1iX6Iiaq9gbTToePzPQ5j56noO5ZXxyOsbePbe4bSKqr9ezeU2Mo6aSUloQVhozfmkFJeT0m3fcmLN++6VtH9HpTOgNUWjiXAHIG1ENPqYBMJSh3jdgtWYKYqC/USu+w/WI/ux5fyG/URurePUoRHu72P197JtJzReznVjO5ZB0ar/YD2yj+IfP6R0x3e0vPgWwroP8/yfK928gsrMnai0emKvfsDz89LcqBRFUeo/zO2NN97g9ddfZ/Xq1URFRQHw4Ycf8sQTT7B69Wri4k6/+GFpaSlGoxGt9tQPbF5eHiNHjuTvf/87d9xxxxnvecstt3DixAm++uorz7aHHnqIPXv2sHz58oYWvV67d+8GoGdP3zbjWSwW9u3bR2pqKkaj0afXrirMIeeNvwIq4u9+CX3LdvWe0xz5s47PZxarnQdeXMuxwgpambQYQw0UlFRSaTvzPD0tIkLo1SmGXp1b0atTK1q3rP3L2Vxu45PV6Xy1PpOqkwGpR3JLbr60K6ntw8HlRFEUUBRQXDX+7f7ahWKvcv8166jC9bt/l5eV89XaA+QWVxHTcxA3XT3Qq4HbDWGzO/l0dTrLfjhIld1dF7HRRv5vTAoj+7Wv8ch/Q1T//Hbt0hnL+g8o2/YtAGGpQ4i54l7UekOd5ysOOxX7f6Z06zdYj5xmSgGNlpDWSWjjkvlgu51fTrSgUm1k0uXduGp4cp1P7wEUl1p56JX15BZW0C4mnNlTh502IFmrHPyyN4/VW3PYtv84LpeCKUzPTZd15dJBHdBo1NiOZVL49RvYjqUDoGvZFpVGi6P0BC5r+RnLoGsVT8tL7sCYdEGdZT2Tg4cKOHIok8H9ewbkd4SiKLisFThKC3GUFuI8+dlRWoTDXEBV0VFcltJa5+laxWNon4ohviuG+BS0LXzT9asoChW//cSJ79/FYS4AIKRdF1pecgdqnZ6j7/wDxWmn5aV3Etl/rNfXD/bv4Ia+f3sVmdetW8eQIUM8YQdg7Nix/Otf/2LDhg1cc801pz3PZKrd99u6dWuio6M5fvzMfZL5+fls2bKFv/71r94U87yhbxWPsfMALAc3Y/75C2IuvyfYRRLNiNGg4+8392fG/HUUljqg1P2GpFK5xxS1bmmkTcswWrcMo3VLIx3bnnk8kS0vi4p9G3GUncBVVcnYqkpGda7AXGzGYbUQUmQn5AM72T5o5LkIIBycmT+x/vl4Wva9mH6XjEFTT3Coj6IobNx1jHe+3MPx4koAUhJaUFBi4fgJC/OWbueT1encMrYrg3u08eqNSmUr58Qns7Ef3Q+oaDHyRqIuvKZB11BpdYR3H0549+E4rRXYctPdg1qPHsB69ACuyjJsRw9gO3qAq4BxUWo03UaR2H9EvWEHoIXJwKy7L+ShV9ZztKCcx97cyNP3DCXcqMfpUtiTUcjqrUfYuOsYlbZTXTARRh2lFVW89skuvvlxP1MSMzBkrAHFhSrESPTImzD1vcSzkrbLbsNZVuQOBWUnsJYUcOzQEQy526Ewh7wPnsTYZQAtR9/WoHlhFEVh18FCPvzuALszClGpYGgW3Hhpqs/HIzkrzFRm76YyaxfWo/txlBaiVNW9RIxKqyekTbIn4ITEd/HbIGGVSkV46oUYO/XD/MtySjZ8iu3oAXIXPYQ6NALFaSc0uS+mfpf55f6NhVeBJzMzk2uvvbbGNpPJRExMDJmZmV7dOCsri6Kiojq7oZYvX47L5eLyyy+vte/QoUP069cPm81Gly5d+Mtf/sLo0aO9KsMfKYqCxWKp/0AvVFZW1vjsa4Y+l2E5uJmy3WswDBiPJjzKL/dpzPxdx02RoriwZWzDlrkdxVX3zMlqQziGzgPRte1c6w22bUs9f7+xBzv2HaFrclsSWkfRKsqAXnf67pvffw9clWVU/raRyr0/4ig4dNrjw6Fh05+qVKBSn/xQuZ9A0epOftZTpWg4XGDF4lCj0ulJMtkJKTtKiuoI7FjMwR0foO/Unxa9R6CP7+r1VA6H8spYtGI/v2a5J+RraQrhpku7cGHPOKrsLlZuOsLnP2ZxJL+MpxdtplO8iYmjO9Ez+czjaVzWcuz5WVhyDmDa9QN2aykqfSiRY+8hJKnPWf48q6B1Z0Jadyak7zgiFAWn+TiF6b+y/ruNJGryidcWw75VHE5fh7HvZYT1HVvvkgDhIfDPSX3419tbyMot5bE3N9K1QxQbduVxotTmOS4mysDwC9ow7II2xEWH8v3mHPau/YFxVT9hSHf/bnV26E/rMZPQhEdRabXVuI9TZ2JPqZP1Oyv55VcD1qokQlXtuCx0F2mG/VgObMaSvp2wfmMJG3jVaVu/FEVh+4FCPl2bxcEj7icZ1SpwKbB+Vx4bducxMDWWa0Ymkdjm7AKGYrdRdXQ/tsN7qTq8B0fB4dMepwqNQBPREk1E9MnPLVFHRKOJjEUX06FGN51NAXz8/nM6IX3G0qrzYMo3fEzlrz/iqixDHRpB+Kg7zvp3aHmFhbJKZ9B+ByuK0rA/Drzp0urevTt//etfPYOHq11xxRX06dOHWbNmNbhwd955JwcOHOCbb745YxPYn/70J0JCQli6dGmN7YsXL0ar1dKpUyfKysr44IMPWL9+PS+99BKXXXZ2CXX37t1UVdU/m21jFPHzu2hLcqjsOARrSvOZJCooFAWcdlSOKlTOKs9nqj8DLoMJV6gJJSTc/QbcmCgudMf2EZq5AU15oVenOo0tqGrbg6q2PXEZo87u/i4X2sJMQo7uRHf8ICrF3WWlqDTY4zrjMLVB0YaAVo+iDUHR6FFO/rvYpubrHRYO5tlRUJEaH8oVg6IJDal7bMzhAhvvrynEaleIjdRy80UxmIwaFHMBBXu2EWP+jWh1xanXGRKBvW0P7C0T3a0NLge4nKf9bFWHsiHPxA/ZITgVNVoNDE2NYGi3CPTamt/7yioXG/eV8fP+cuwO96/VjnEhjLrARHwUaEvz0JiPoTUfQ2M+hqay5A/1H0153wm4ws/8JM3Z+mBdIftzrCTF6bm9VznGg2vRlrrH8bh0Bqwdh2Dr0B80dY/dyC+xs+i7AiqrTo3VMuhUdO9gpFeikfYxetQn33jUlhJC932LvsDdfVXoDOdjyyD2O9rRLzmMkb1MhBs0KIpC7gk7u7Mt7Dlkodx66tpRYRoijBqOFFQRpy7hT2GbSdW5y+3Qh2FLuZiqtj1ApcKlKPyWY2XdnlLyit3zCWk10Dc5nKGp4VTYXPy4t4x9R069KXdpayCtRwTxrWp30dXgcqEpPYauKBttUTba4hxUSs0/JBwRsThadsQe3QFXWAtcBlO99RlsGvMxQnJ2YGt3Ac6otmd9nU82nmB3toX4VnoGdQkntX0oWk1gB5/r9fp6u7SCEnhefvll3njjDd5++22GDBly2mMyMjIYN24cjz76KDfffHOd13O5XEycOJHy8nJWrDi7lcR3796Noih06tSw+QoaqrKykuzsbBITEwkN9c8gSmvGVkq+mIcqxEjM5Hnn3aKi9dWx4rBjP56Ny2LGVVl26sNShquyFFdlOa7KUhRrBYrdi5XK1RrU4S08f7lV/xWna9cV3TnOj+Itxemg8reNVPzyJc6SPABU+lBCe4xEExZZ57n2ohxsBzej2E/9ta2L70po6jAMnQdic3HG+lVcTlyWUpxlRdjSt1C5bwOuihLPfm1sIqHd0whNGYy6Ac31LpfCVxsP8cGqdJwuhZgoA/df15MuCVGnPX7b/gJe/HAXVXYXKQlR/P3m3oT/YZBs7vEylv/vB1qd2ElvfTZGtfdLstgULeaQ1sR26UZUYld0rZPRRET/oS5cOMuKMOflsGPLrxQcOUxLVSmxGvfH6X79a6LiULdKwKyNpPWQKzBG+X6Svx0HC3nm3e1o1CrmTB1MfGw4iqJgy9hK+YZlOE4cBUBtjCRs0HiMPS+qc4Bweo6ZNz77lbjoUIZf0Ia+KTHofhf+HOYCLDu+xbLrB3BUgVpD2IArqOg0mv9+f4hffnUPYwgN0TKsV2v2ZJ7gWNGplo0Io47BPeIY1qsNKQmRqFQqcgsq+GHrUdZsP0oHexZXG7cQo3E/Tm+L7EBhx0tYtstFZqG7Sy1Er2HMgHiuGNqBqIiQGr8jCkqdfLYui42786h+9+uZHM01I5PoltgCcH8vHQWHqTqyl6qcfVQd3V+ri0od0ZKQhO7oE3qgT+iGxlj3/7PmKuOomZmv/1JjW1S4ntED4hk9IJ4Wpxnv5Wvp6emoVCrfBp4hQ4YwYcIEHnzwwRrbhw8fzvjx45kxY0a91/joo4949NFH+fe//82ECRPOeNy8efN46623+PHHHz1PcdXl7bffZu7cuezcuRODwfu++qY4aLmaorjIeeMB7EVHiegzhsj+l6GLaX/ezMB8ujp2lBVjydiK5eBWKrN2eRdkAFChCglFrTOgDjG4F83TG8DlOjnGoAjO1FWk1hBz+V+I6DXynF5XQygOO2U7f6Dkp/95BiOqQ8OJHHglpv5jG/xEh6vKSsX+nynftYbK7D2A+9eCSqsnpFN/TqjCiTGForaW4ygvxln9UWH2HFtNbTQR3iONiF4XERKXeFav68DhYua+t4W8IgtqtYqbLu3KtRd3rjEgePXWI8xbuh2XS6F/ahz/uLU/Bv3p36gVReG7Xw7z7pc76eDIpn9IJgmhFuyKmiqXmkqHCrtLjR0NDkWNAw1ORU20poJEXREh1G791YRHE9K2E7ic2IvzsJfkn/Yx4mrl6ghaJqVijO9MSNtkQlonowkNr/d3hKIofP1TNrvSC7nt8m6nHQh+JnaHi/ueW83RgnLGpyVz5/geNa/tclK+90eK133omeNFGxmLacA4wjr3RxfdpsH3sh49gHnTF1T8tsk9wBwwJHSn1di7akyQuCejkIVf7PFMnAmg12kY3L01I/rF06dLbI0AVfP1OPl5dx6rfk4nOmc9Y0J3YVCdqvNiVxhKVDztUroS0S4JfWwHdC3bUmm11arjowXlfPrdPn7enoVOqSJMZWNwawsDWxQTciIdl7Wixr3VhnAMHboTmtiT0I4XoIv2bpxWY+R0uvjtUDGd20edsZu6Pv966ye2/Xac1Pah9Ojchu+3HPV0c2o1Ki7s1ZYrhyWR0qGF3+qroe/fXgWem266iaioKF555RXPtrKyMgYMGMDTTz99xkHL1VatWsVf//pXpk6dytSpU+s89pJLLqFDhw68/fbbDSrb+Rx4AEp3fE/hyUmjANSGMPdI//ZdMbRPJaRNp1qPGiouJ/YTx6gqOEzV8cNUFRzGXnAYR3kxoQndCUu9kLAuA+rt3w82i8XCvl9/pVO0AWfOXiwHt1KVl1HjGE1YFNqoWDShEaiNkWjCTGhCI9AYTaiNJjRGE5rQcFR6I+qQUPfYkDr+cyouJ87yEs9TGA5zAY7SQqrysz1PykSPupWok4u9+pqrykrZju8o+elznOUnPK8xcvBVmPqOOaelBxylhZTtXkf57tXYi2o/KluLSo0mLIqQNslE9LoIY+e+qHzQlG+x2nl12S7Wbs8B4ILOrZj+f/2INhn4Yl0Gb32+B4CR/eL56w19GjTDdEmZjbc/3+O55h9FGPW0jDQQHWmgpclAt47RjOwXj+tELrbcg1iPHsSWe5Cq44c8b+o1aLToouLQRbdB16I12hZtyCjV8/J3RRTZ9LSPi+CxyYNqhJa6fkcUl1mZt3Q7235zh5G2rcKYc99wIsMb9lfzZ2vTWfjFXqLCQ3j9oVG1HhGvpjjtlO34nuL1y3CWn1o4VNeyLcZO/TB26oehfWqtlh/F5aRi/y+YN32J7eh+z/bQjhcQOfAKQpP7nPb/kculsGZbDnsyCumR3JLBPdpgNHj3M5NbWM6a9XvR7f6CZFUOUarTP+Wl0ujQRLel0uEiVKsGuxVXVSUum6XOgOrSGghL7E5oYg9CO/RAH5d4Tn9EulwKBSWVHM4rRaVS0Scl1usn+nzpSH4Z85Zu48DhEvp1jeVfdw72OpDszSzioVfWo1GrmHp5HEMH9kSnN/DT7lyWr89iX/YJz7Gd4iO5fnQXhvQ8+66zM/FL4Kl+LH3t2rWeJ68+/vhj/vWvf9X5WDrApk2buPPOO7nmmmt44okn6rzPzp07uf7663n22We5+uqr6y2Xy+Xi+uuvx2q1nvWj6k098HjW2znwC9acA7VaNFQaHSFtOxHSJhlnhdkdcoqO1vkfHgCNFmNS71PhJyT4j30rLieOkuNUFR3FXpSLJTcDS8Z21FU1/yILadvZ/cu6cz/0cR0D8teYorg48f0SzJu+ACBy0FVEj7rFZ61tjrIT7ll2t63yPMariYgmasifiOg9qtaEYudCURRsuQcp2fEDJbmHiGzdHkNUDJqIFmjDW6AJb4EmPBqNMcLzpI2vKYrC95uP8Pr/dmGrchIZrqd/ahzfbz4CwFVpSUy+skeDnjb6vb2ZRWTklNDCZHAHHJP7o6F/5bqqrNjyMrAdy0St1aGNboOuRRu0ppanrYv0nBJmLdzEiVIrkeF6Hrl9EF0T3S3XZ/odsfnXPF76cDvm8ip0WjURRh0nSm10ah/F0/cMJTSk7mdOikutTJn9PZU2B/df35tLBnWo/3XZbZTt+J6KA79gPfxrjVZMVYjRPQfQyfBjObgF8y9f4TCffNJWoyW8expRg65AH1v/vXzNaa2g6vihkx+H3Z8LDtX7tBS45/9BZ6BQ1ZKfi6L4zRZHjjOajvEtuGF0FwZ1b9PgnzGXS+F4sYXDeWUczi/jSH4Zh/NKOXK8HFvVqfrs3TmG6Tf1pUXEuT096C2nS+GzNen895vfasyb9feb+zO8T8OnNlEUhZmvbWBPRhGj+rdjeBdVrZ/h9JwSvlqfxdrtOZ57vfuvS2lh8u1r9kvgMZvNXH755XTs2JEpU6Z4Jh688sora0w8OGnSJHJzc1m1ahXgHo9zww030KZNG5544gnU6lO//KOjo0lISKhxn6eeeoqPP/6YjRs3EhZWs3Xh6NGjPPTQQ1x++eV06NABs9nMBx98wKZNm5g/fz6XXHJJQ19ODU098Pye4nJSlZd1csbOfViP/Ibzd+Mqfk+lN6Bv1R59TAL62AR0Me3RGCKwHNxC+b4N2At/95ewRosxqQ9h3S7EmNQHlVYLiuKeJ8VVPUfKqTlTXHYbLosZZ4UZp6X05Gdzjc/gbirWhIajDg1HYwhHHRpxapshDGdFCfai3JMB5yj2E3ngqh3UVDoDxuTeGDv1IzS5L9ogPrFW8vPnnPj+XQDCe6QRc8XUc5o4zZaXhfmXLynfu8Hz2rUtWhM1eDwRvS7y60RhwZ5jA9x/jc59z/2EULVbxqZy3ajaT5Y1VkXmSp5cuInMo2Z0WjXTJvZleJ92terXZnfyny/38tWGLAAS25iYcXM/tBo1f5//I6UVVfTpEsOjkwefsesH4KWl2/lu82E6tY/i+fvTvA6FLmsFlqxdWNK3YEnfdtp5Y8A9OZ6p36WY+l2GNryFV/fwN0Vx4TAXUHbkIDmHs2nfsROhphaoQ0JRhxg9XdW/D6nFZVY+W5PBio1ZWE8GlA6tI7hhdAoXXtAWjVqF06VQVFLJsZOTbh4rrPD8O7ewwjM/0x9pNWraxYRxrMhCld1JVEQIM/6vHxd0iQlIfRzJL+OlpdvZf9jditevayxtY8L58sdMWkSE8No/ztwK+Ec7DxTwyBsb0WrUvDRtKAW5WWf8HWEut/H95iM4XS6uuaizz1u2/BJ4wB1eZs2aVWNpiWnTptVYWuKWW27h6NGj/PDDDwB8+umnPPzww6e93p/+9Cdmz57t+drpdDJixAj69+/PvHnzah1fUlLCww8/zK+//kpRURE6nY4ePXpw1113MXz4cG9eSg3NKfD8kaIoOIrzsB7Zhy0/C214C3QxCehjEtBGtqqz9aGq4DDlv26kYt9G7EVHA1jquqm0ene3Qcu2YIojzxlKpwvHEBbReNb7Kdu9hoLlr4LLSWhSb+KuneFVV5OiuKjM2E7Jpi+xZu/2bDe0TyVy0FUYO/fzW8vK7zWGn2FwL12x+KtfWbf9KDeP7cqlgxODVpazVWlz8Px/t7Jpr3tg+c2XdeWKC+P57bffSE1NJb/Eztz3tnIk3z0g96q0JCaN6+ZpeTpwuJiZr23AVuVkZN94pt3Y97RBZv+hE8x4+UcA5t4/nK4d6h8HWRdFcWHLTceSvhVL+jaq8jLRtWxH5MArCO85wqcti/5wNj/D5nIbX/yYyfL1mVis7j8yWrc0otWoySuy4HCepkvzJJ1WTXxsOO3jIkiIiyChtXspmDYtw9Bo1BzOK+XZJe51zFQquH50F268JMVvi+s6XQqfr83gvZX7sDtcGA1a7ryqB6MHJuBwVo/zquCKoR2Zck2veq+nKAp/m/8j+w8Vc+XwJG4ek9wkJh70OvA0V8058PiCoijYC45Qvm/DyfBzprEdKs+cKSqtDk1YJJrqMTPGSPdYmbBINGGRqI0mVCo1zspyXNZyXJXlOKs/V5ad3FaBOjQcfct26Fq2RdeyHbqW7WoEtcZcx5b0beR/+hyK3UZIm060vmFmnU9NKYqCoySfyswdmLd8faqFTaUmLHUIkYOuavDKx77SmOu3KXK6FBYt38tna93jzIZf0Ia0rmqOlIbx/rfpOJzu9a0emNiHfl1rDxPY+ls+sxZuwulSuHpEMpOvqjkQ2eVSmPHyOg4eKeHi/u2ZdmNfn78Gl91W7zi3xuRcfobLK+18+WMmX6zLoLzy1BN+Wo2KuOgw2rQKo20r9+fqj7josHpbMaxVDt76bA/fbnLPUdU9qSV/u7mfz5dEyTnubtX57ZC7VadvSiz3XtebmBan7rPzYAGPvL4RlQqeuz+NLgl1t9Rt/jWPJxduQq/T8PbM0YRoXU0i8DSfxUmEX6lUKvSxCUTHJhA94kZcJx9hVp2cCM4TcprIL8BAMXbqS5ubHifvw6exHUsn991HaH3jo+ii3As1Kk4HtvxsbGfoflSFGDH1Hk3kgHFoIwPT7C38S6NWMfmqHrRtFcbr/9vNjzuPsfU3NRabu8VgQLc4/npDnzMOTO7XNY77b+jDix9s47O1GbSIMHDNRadC8A9bDnPwSAmhIVpuu7ybX15DY2/R8aXwUB03jklhfFoS2/cXEBaqpU2rcFpFhZ5T14xBr+W+63vTs1MrXl22g72ZRdz//Bqm/1/f0wZdcP9BVFBcSXpOCRlHzVRU2tFoVGjUarS//6xRo1GrKLNU8fnaDKocLkJDtNw5vgeXDEyo9Xv6gs4xjOwXz5qtObyybCcv/DXtjK1NLpfCeyt/A+DKYR1pYTL4fMJef5HAI87K+fQL71wZ2nWh7a1PkffBLOwncsldPJOIXhdhPXoAW+7BGvPfAKDWEtImibDUCzH1HtUoBooL3xt7YUfiWoYxe/FmLDYHOq2aO8f3YOyQxHr/cLi4f3tKymz8Z/le/rN8L1ERIVzcvz0VlXYWf+V+SvDGMSk+Hxx6PjMadAy9wPdPGI3sG0/n9lHMeXcLmblmHn/rZ669qBM3j02lsKSSjBwz6Tkl7pCTY6bM4v0Eub27xHDf9b2JbXHm3yV3XNmdzb/mk3nUzFcbs7hq+OlXQfhpzzEyj5oJDdFyzUWdvS5LMEngESIA9K3iaTvpaY4tfQp7wWFKNn7q2Vc9hUBIfFcM7VMIadNJAuV5om9KLE/dNYBPv9/DNaN60CUxtsHnXnNRJ/cA27UZvPzhdkxhenYeLKCk3Ea7mHCuGJbkx5ILX2oXE87c+4fzzsnB6p+sTueLHzNrPEVVTatRkdDaRKf4KFqYQnA6FRxOF06XgvPkZ4fThdOp4HIp9O0ay8X929cboltEGLjt8m68smwn7339G0N7ta3VveZ0Kfz3ZOvO+LRkTGG+XZjX3yTwCBEgWlNL2t4yi6LvFoHi8syTpGsVf95MEilqi48N55Le7oVXvXX7Fd0pKbOxZlsOs9/djOPkG+Sfr+5R5xNcovHR6zTcfU0venZqxfwPt1NhdaDVqEhsYyI5Pork+Cg6xUeS2MaETuufhxXGDOrAd5sPs/9QMW99toeHJg2osf/H7TkcyS8jPFTH+BFnXgezsZLAI0QAaULDib3y3mAXQzQTarWK+2/oQ2lFFdv2u+fDGdS99RnHgIjGb2ivtvTuHENBSSXtYsIDGlzVahVTJ1zAAy+uZcOuXLbsy6d/qvtnyeF08f637sklr7moU60lXJoC+RNACCGaMJ1WzUOTBtCtYzQRRl2tp7ZE0xMWqjvZkhP4t+iObSO5ari7O/T1T3dhrXI/kv/DliMcK6wgMlzfZLtLpYVHCCGauNAQLc/8ZRguRWnQEhtC1OX/Lu3K+p255J+w8NF3B7hxTApLV7lbdyZc3KXeWb4bK/mfIYQQzYBarZKwI3wiNETLlD+557T5dLV7PbaC4kqiTQbGXpgY3MKdA/nfIYQQQogaBvdow6DurXG6FM8yJzdc0oWQs1xVvTGQwCOEEEKIWu66uichenfAiW0RyiUDA78orC9J4BFCCCFELbHRRu68yj3FweSrmv5UB01z5JEQQggh/O6yIYlcNiQx2MXwiaYd14QQQgghGkACjxBCCCGaPQk8QgghhGj2JPAIIYQQotmTwCOEEEKIZk8CjxBCCCGaPQk8QgghhGj2JPAIIYQQotmTwCOEEEKIZk8CjxBCCCGaPQk8QgghhGj2JPAIIYQQotmTwCOEEEKIZk8CjxBCCCGaPZWiKEqwC9EYbNu2DUVR0Ov1Pr2uoijY7XZ0Oh0qlcqn1xZuUsf+JfXrX1K//id17F/Brt+qqipUKhV9+/at8zhtgMrT6Pnrm6RSqXweokRNUsf+JfXrX1K//id17F/Brl+VStWg93Bp4RFCCCFEsydjeIQQQgjR7EngEUIIIUSzJ4FHCCGEEM2eBB4hhBBCNHsSeIQQQgjR7EngEUIIIUSzJ4FHCCGEEM2eBB4hhBBCNHsSeIQQQgjR7EngEUIIIUSzJ4FHCCGEEM2eBB4hhBBCNHsSePwkIyOD22+/nd69ezN06FDmzJlDVVVVsIvVZB06dIjHHnuM8ePH061bN6644orTHvfxxx9z6aWX0rNnT6666ipWr14d4JI2TV9//TX33HMPaWlp9O7dm/Hjx7Ns2TL+uLaw1O/ZWbt2LTfffDODBw+mR48ejBo1imeeeYaysrIax/3www9cddVV9OzZk0svvZRPPvkkSCVu2ioqKkhLSyMlJYXdu3fX2Cc/w2fn008/JSUlpdbHc889V+O4xly/2mAXoDkym81MmjSJxMRE5s+fT35+PrNnz8ZqtfLYY48Fu3hN0sGDB1m7di0XXHABLper1hsxwFdffcWjjz7K3XffzeDBg1mxYgX33nsv//3vf+ndu3fgC92ELFq0iHbt2vHQQw/RokULNm7cyKOPPkpeXh733nsvIPV7LkpKSujVqxe33HILUVFRHDx4kPnz53Pw4EHeeecdALZs2cK9997LhAkTmDlzJj///DP//Oc/CQsL47LLLgvyK2haXn31VZxOZ63t8jN87t5++20iIiI8X8fFxXn+3ejrVxE+9/rrryu9e/dWiouLPduWLl2qpKamKnl5ecErWBPmdDo9//7HP/6hXH755bWOGTNmjDJ9+vQa22644Qblzjvv9Hv5mrqioqJa2x555BGlb9++nrqX+vWtDz/8UOnSpYvnd8Idd9yh3HDDDTWOmT59ujJ27NhgFK/JSk9PV3r37q188MEHSpcuXZRdu3Z59snP8Nn75JNPlC5dupz2d0W1xl6/0qXlB+vWrWPIkCFERUV5to0dOxaXy8WGDRuCV7AmTK2u+0f1yJEjZGdnM3bs2Brbx40bx08//STdifWIjo6utS01NZXy8nIsFovUrx9U/36w2+1UVVWxadOmWi0548aNIyMjg5ycnCCUsGl66qmnmDhxIh07dqyxXX6G/asp1K8EHj/IzMwkKSmpxjaTyURMTAyZmZlBKlXzVl2vf/wll5ycjN1u58iRI8EoVpO2detW4uLiCA8Pl/r1EafTic1mY+/evbzyyitcfPHFxMfHc/jwYex2e63fG8nJyQDye6OBVq5cyYEDB5g6dWqtffIz7BtXXHEFqampjBo1ijfeeMPTddgU6lfG8PhBaWkpJpOp1vbIyEjMZnMQStT8VdfrH+u9+mupd+9s2bKFFStW8I9//AOQ+vWViy66iPz8fACGDx/O888/D0j9+kJlZSWzZ89m2rRphIeH19ovdXxuYmJiuO+++7jgggtQqVT88MMPzJs3j/z8fB577LEmUb8SeIQQNeTl5TFt2jQGDRrErbfeGuziNCtvvvkmlZWVpKen89prr3H33Xfzn//8J9jFahZee+01WrZsybXXXhvsojRLw4cPZ/jw4Z6vhw0bRkhICIsXL+buu+8OYskaTrq0/MBkMtV63BTcCTcyMjIIJWr+quv1j/VeWlpaY7+oW2lpKX/+85+Jiopi/vz5nrFTUr++0bVrV/r06cN1113Hq6++yqZNm1i1apXU7zk6evQo77zzDvfffz9lZWWUlpZisVgAsFgsVFRUSB37wdixY3E6nezbt69J1K8EHj9ISkqq1edeVlZGQUFBrT564RvV9frHes/MzESn09G+fftgFKtJsVqtTJkyhbKyslqPnkr9+l5KSgo6nY7Dhw+TkJCATqc7bf0C8nujHjk5Odjtdu666y4GDBjAgAEDPK0Ot956K7fffrv8DPtZU6hfCTx+kJaWxsaNGz3JFtyD6dRqNUOHDg1iyZqv9u3bk5iYyMqVK2tsX7FiBUOGDEGv1wepZE2Dw+HggQceIDMzk7fffrvG3Bog9esPO3fuxG63Ex8fj16vZ9CgQXzzzTc1jlmxYgXJycnEx8cHqZRNQ2pqKu+++26Nj4cffhiAJ554gn/961/yM+wHK1asQKPR0K1btyZRvzKGxw8mTpzIkiVLmDp1KlOmTCE/P585c+YwceLEWm8komEqKytZu3Yt4G6+Li8v9/zHGjhwINHR0dx3333MmDGDhIQEBg0axIoVK9i1axfvvfdeMIveJDzxxBOsXr2ahx56iPLycnbs2OHZ161bN/R6vdTvObj33nvp0aMHKSkpGAwGfvvtNxYuXEhKSgqjR48G4J577uHWW2/l8ccfZ+zYsWzatInly5fz4osvBrn0jZ/JZGLQoEGn3de9e3e6d+8OID/D52Dy5MkMGjSIlJQUAL7//ns++ugjbr31VmJiYoDGX78qRTnNlLXinGVkZDBr1iy2b99OWFgY48ePZ9q0aY0i5TZFOTk5jBo16rT73n33Xc8vu48//pi33nqL3NxcOnbsyPTp07nooosCWdQm6eKLL+bo0aOn3ff99997Whikfs/Om2++yYoVKzh8+DCKotCuXTsuueQSJk+eXOOJou+//5558+aRlZVF27Ztueuuu5gwYUIQS950bdq0iVtvvZVly5bRs2dPz3b5GT47Tz31FD/++CN5eXm4XC4SExO57rrruOWWW1CpVJ7jGnP9SuARQgghRLMnY3iEEEII0exJ4BFCCCFEsyeBRwghhBDNngQeIYQQQjR7EniEEEII0exJ4BFCCCFEsyeBRwghhBDNngQeIYQQQjR7EniEEEII0exJ4BFCCCFEsyeBRwghhBDN3v8Dzn5sEnyv5EAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "num_nodes = [best_hyperparameters['nodes']] * best_hyperparameters['layers']\n",
        "batch_norm = True if best_hyperparameters['activation_fn'] == 'relu' else False\n",
        "dropout = [best_hyperparameters['dropout']]\n",
        "\n",
        "best_net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
        "\n",
        "best_model = DeepHitSingle(best_net, tt.optim.Adam, alpha=best_hyperparameters['alpha'], sigma=best_hyperparameters['sigma'], duration_index=labtrans.cuts)\n",
        "\n",
        "batch_size = best_hyperparameters['batch_size']\n",
        "best_model.optimizer.set_lr(best_hyperparameters['lr'])\n",
        "\n",
        "# Train on the entire training set\n",
        "epochs = 100\n",
        "callbacks = [tt.callbacks.EarlyStopping(patience =best_hyperparameters['patience'])]\n",
        "log = best_model.fit(x_train, y_train, batch_size, epochs, callbacks, val_data=val)\n",
        "_ = log.plot()\n",
        "\n",
        "# Evaluate on the test set\n",
        "surv = best_model.predict_surv_df(x_test)\n",
        "ev_test = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
        "c_index_test = ev_test.concordance_td('antolini')\n",
        "\n",
        "print(f'Concordance index on test set: {c_index_test}')\n",
        "\n",
        "# Calculate the integrated Brier score\n",
        "ibs = ev_test.integrated_brier_score(time_grid=np.linspace(0, durations_test.max(), 100))\n",
        "\n",
        "print(f'Integrated Brier Score on test set: {ibs}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wito7vM9d9h_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPA67Lind_wN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8sDxUdFllxG",
        "outputId": "e5193f39-e8c3-4add-ce5a-c6d3e4276876"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random search... itr: 0\n",
            "{'batch_size': 209, 'layers': 1, 'nodes': 73, 'activation_fn': 'tanh', 'alpha': 0.45238118840431807, 'sigma': 0.17585827835328768, 'lr': 0.08638568518622398, 'dropout': 0.2178335761246409, 'patience': 42, 'batch_norm': False}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.4708,\tval_loss: 0.2927\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.3335,\tval_loss: 0.3025\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.2808,\tval_loss: 0.3058\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.2766,\tval_loss: 0.2939\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.2685,\tval_loss: 0.2894\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.2477,\tval_loss: 0.2898\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.2566,\tval_loss: 0.2911\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.2383,\tval_loss: 0.3190\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.2343,\tval_loss: 0.3036\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.2225,\tval_loss: 0.3026\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.2218,\tval_loss: 0.3204\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.2150,\tval_loss: 0.3272\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.2169,\tval_loss: 0.3360\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.2213,\tval_loss: 0.3415\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.2078,\tval_loss: 0.3404\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.2214,\tval_loss: 0.3585\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 0.2102,\tval_loss: 0.3570\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 0.2189,\tval_loss: 0.3481\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 0.2268,\tval_loss: 0.3657\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 0.2411,\tval_loss: 0.3783\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.2183,\tval_loss: 0.3919\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.2449,\tval_loss: 0.3720\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.2142,\tval_loss: 0.3867\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.2159,\tval_loss: 0.3898\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.2132,\tval_loss: 0.3957\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.1991,\tval_loss: 0.3722\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.1865,\tval_loss: 0.3803\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.1845,\tval_loss: 0.4141\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.1894,\tval_loss: 0.4373\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 0.1923,\tval_loss: 0.4400\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 0.1849,\tval_loss: 0.4483\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 0.1957,\tval_loss: 0.4439\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 0.1914,\tval_loss: 0.4281\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 0.1831,\tval_loss: 0.4505\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 0.1764,\tval_loss: 0.4559\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 0.2019,\tval_loss: 0.4332\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 0.2062,\tval_loss: 0.4375\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 0.1960,\tval_loss: 0.4413\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 0.1775,\tval_loss: 0.4588\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 0.1941,\tval_loss: 0.4550\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 0.1761,\tval_loss: 0.4538\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 0.1758,\tval_loss: 0.4691\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 0.1796,\tval_loss: 0.4647\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 0.1685,\tval_loss: 0.4991\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 0.1761,\tval_loss: 0.5044\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 0.1770,\tval_loss: 0.5335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46:\t[0s / 2s],\t\ttrain_loss: 0.1781,\tval_loss: 0.4948\n",
            "Current best c-index: 0.5582380563495304\n",
            "Random search... itr: 1\n",
            "{'batch_size': 212, 'layers': 2, 'nodes': 86, 'activation_fn': 'relu', 'alpha': 0.7529739194472821, 'sigma': 0.3109878673115315, 'lr': 0.09057204713662542, 'dropout': 0.7010333150120399, 'patience': 38, 'batch_norm': True}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.7689,\tval_loss: 0.5518\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5874,\tval_loss: 0.3926\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.4899,\tval_loss: 0.3839\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.4602,\tval_loss: 0.3971\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.4459,\tval_loss: 0.3817\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4317,\tval_loss: 0.3859\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.4269,\tval_loss: 0.3864\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.4370,\tval_loss: 0.3869\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.4290,\tval_loss: 0.3867\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.4125,\tval_loss: 0.3835\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.4210,\tval_loss: 0.3768\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.4182,\tval_loss: 0.3768\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.4126,\tval_loss: 0.3837\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.4193,\tval_loss: 0.3942\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.4251,\tval_loss: 0.3830\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.4399,\tval_loss: 0.3820\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.4225,\tval_loss: 0.3797\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.4160,\tval_loss: 0.3886\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.4205,\tval_loss: 0.3774\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.4262,\tval_loss: 0.3807\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.4414,\tval_loss: 0.3944\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.4380,\tval_loss: 0.3814\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.4223,\tval_loss: 0.3957\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.4390,\tval_loss: 0.3966\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.4419,\tval_loss: 0.4017\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.4093,\tval_loss: 0.4110\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.4478,\tval_loss: 0.3766\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.4127,\tval_loss: 0.3915\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.4287,\tval_loss: 0.3785\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.4198,\tval_loss: 0.3799\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.4305,\tval_loss: 0.3809\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.4394,\tval_loss: 0.3880\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.4114,\tval_loss: 0.3949\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.4214,\tval_loss: 0.3783\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.4205,\tval_loss: 0.3864\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.4145,\tval_loss: 0.3876\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.4117,\tval_loss: 0.3693\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.4110,\tval_loss: 0.3850\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.4159,\tval_loss: 0.3786\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.4048,\tval_loss: 0.3774\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 0.4156,\tval_loss: 0.3847\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 0.4229,\tval_loss: 0.3854\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 0.4402,\tval_loss: 0.3797\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 0.4130,\tval_loss: 0.3790\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 0.4304,\tval_loss: 0.3892\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 0.4424,\tval_loss: 0.3794\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 0.4289,\tval_loss: 0.3759\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 0.4274,\tval_loss: 0.3709\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 0.4243,\tval_loss: 0.3790\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 0.4256,\tval_loss: 0.3905\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 0.4285,\tval_loss: 0.3812\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 0.4287,\tval_loss: 0.3898\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 0.4262,\tval_loss: 0.3872\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 0.4307,\tval_loss: 0.3859\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 0.4344,\tval_loss: 0.3907\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 0.4485,\tval_loss: 0.3796\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 0.4302,\tval_loss: 0.3781\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 0.4626,\tval_loss: 0.3931\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 0.4247,\tval_loss: 0.3906\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 0.4687,\tval_loss: 0.3948\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 0.4446,\tval_loss: 0.3876\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 0.4493,\tval_loss: 0.3773\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 0.4343,\tval_loss: 0.3842\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 0.4457,\tval_loss: 0.4021\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 0.4343,\tval_loss: 0.3793\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 0.4495,\tval_loss: 0.3845\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 0.4484,\tval_loss: 0.3869\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 0.4633,\tval_loss: 0.3981\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 0.4294,\tval_loss: 0.3935\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 0.4554,\tval_loss: 0.3886\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 0.4532,\tval_loss: 0.3835\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 0.4555,\tval_loss: 0.3875\n",
            "72:\t[0s / 5s],\t\ttrain_loss: 0.4572,\tval_loss: 0.4015\n",
            "73:\t[0s / 5s],\t\ttrain_loss: 0.4759,\tval_loss: 0.3885\n",
            "74:\t[0s / 5s],\t\ttrain_loss: 0.4332,\tval_loss: 0.3849\n",
            "Current best c-index: 0.6262249897917518\n",
            "Random search... itr: 2\n",
            "{'batch_size': 99, 'layers': 4, 'nodes': 65, 'activation_fn': 'relu', 'alpha': 0.18935439395849107, 'sigma': 0.11435810864489403, 'lr': 0.09370263956822572, 'dropout': 0.038517845428792795, 'patience': 70, 'batch_norm': False}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 9.6001,\tval_loss: 6.0176\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 8.1382,\tval_loss: 5.0680\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 8.8272,\tval_loss: 1.5206\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 2.2910,\tval_loss: 0.5841\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 1.2370,\tval_loss: 0.2321\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5006,\tval_loss: 0.2585\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.4391,\tval_loss: 0.2193\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.2344,\tval_loss: 0.2020\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.2152,\tval_loss: 0.1875\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.2010,\tval_loss: 0.1756\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1900,\tval_loss: 0.1685\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 0.2646,\tval_loss: 0.1630\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 0.1821,\tval_loss: 0.1601\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.1709,\tval_loss: 0.1583\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.4989,\tval_loss: 0.1568\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.1851,\tval_loss: 0.1569\n",
            "16:\t[0s / 3s],\t\ttrain_loss: 0.1679,\tval_loss: 0.1546\n",
            "17:\t[0s / 3s],\t\ttrain_loss: 0.1668,\tval_loss: 0.1518\n",
            "18:\t[0s / 3s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1510\n",
            "19:\t[0s / 3s],\t\ttrain_loss: 0.1762,\tval_loss: 0.1673\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.1709,\tval_loss: 0.1563\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1545\n",
            "22:\t[0s / 4s],\t\ttrain_loss: 0.1574,\tval_loss: 0.1536\n",
            "23:\t[0s / 4s],\t\ttrain_loss: 0.1655,\tval_loss: 0.1531\n",
            "24:\t[0s / 4s],\t\ttrain_loss: 0.1591,\tval_loss: 0.1528\n",
            "25:\t[0s / 4s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1526\n",
            "26:\t[0s / 4s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1525\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.1692,\tval_loss: 0.1525\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.2167,\tval_loss: 0.1525\n",
            "29:\t[0s / 5s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1523\n",
            "30:\t[0s / 5s],\t\ttrain_loss: 0.1636,\tval_loss: 0.1523\n",
            "31:\t[0s / 5s],\t\ttrain_loss: 0.1607,\tval_loss: 0.1523\n",
            "32:\t[0s / 5s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1520\n",
            "33:\t[0s / 5s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1519\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.1869,\tval_loss: 0.1707\n",
            "35:\t[0s / 5s],\t\ttrain_loss: 0.1684,\tval_loss: 0.1537\n",
            "36:\t[0s / 5s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1520\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.1710,\tval_loss: 0.1533\n",
            "38:\t[0s / 6s],\t\ttrain_loss: 0.1790,\tval_loss: 0.1541\n",
            "39:\t[0s / 6s],\t\ttrain_loss: 0.1791,\tval_loss: 0.1512\n",
            "40:\t[0s / 6s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1512\n",
            "41:\t[0s / 6s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1511\n",
            "42:\t[0s / 6s],\t\ttrain_loss: 0.1582,\tval_loss: 0.1512\n",
            "43:\t[0s / 6s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1512\n",
            "44:\t[0s / 6s],\t\ttrain_loss: 0.1602,\tval_loss: 0.1513\n",
            "45:\t[0s / 6s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1514\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1515\n",
            "47:\t[0s / 7s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1512\n",
            "48:\t[0s / 7s],\t\ttrain_loss: 0.1656,\tval_loss: 0.1512\n",
            "49:\t[0s / 7s],\t\ttrain_loss: 0.1736,\tval_loss: 0.1513\n",
            "50:\t[0s / 7s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1513\n",
            "51:\t[0s / 7s],\t\ttrain_loss: 0.1931,\tval_loss: 0.1513\n",
            "52:\t[0s / 7s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1512\n",
            "53:\t[0s / 7s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1515\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.1753,\tval_loss: 0.1514\n",
            "55:\t[0s / 8s],\t\ttrain_loss: 0.1566,\tval_loss: 0.1515\n",
            "56:\t[0s / 8s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1514\n",
            "57:\t[0s / 8s],\t\ttrain_loss: 0.1566,\tval_loss: 0.1514\n",
            "58:\t[0s / 8s],\t\ttrain_loss: 0.1636,\tval_loss: 0.1512\n",
            "59:\t[0s / 8s],\t\ttrain_loss: 0.1574,\tval_loss: 0.1511\n",
            "60:\t[0s / 8s],\t\ttrain_loss: 0.1597,\tval_loss: 0.1513\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1514\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1511\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1511\n",
            "64:\t[0s / 9s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1511\n",
            "65:\t[0s / 9s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1514\n",
            "66:\t[0s / 9s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1511\n",
            "67:\t[0s / 9s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1511\n",
            "68:\t[0s / 9s],\t\ttrain_loss: 0.1537,\tval_loss: 0.1509\n",
            "69:\t[0s / 9s],\t\ttrain_loss: 0.1695,\tval_loss: 0.1549\n",
            "70:\t[0s / 9s],\t\ttrain_loss: 0.1685,\tval_loss: 0.1508\n",
            "71:\t[0s / 10s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1507\n",
            "72:\t[0s / 10s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1508\n",
            "73:\t[0s / 10s],\t\ttrain_loss: 0.1771,\tval_loss: 0.1509\n",
            "74:\t[0s / 10s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1510\n",
            "75:\t[0s / 10s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1509\n",
            "76:\t[0s / 10s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1510\n",
            "77:\t[0s / 10s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1509\n",
            "78:\t[0s / 11s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1509\n",
            "79:\t[0s / 11s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1508\n",
            "80:\t[0s / 11s],\t\ttrain_loss: 0.1592,\tval_loss: 0.1509\n",
            "81:\t[0s / 11s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1507\n",
            "82:\t[0s / 11s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1510\n",
            "83:\t[0s / 11s],\t\ttrain_loss: 0.1655,\tval_loss: 0.1509\n",
            "84:\t[0s / 11s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1511\n",
            "85:\t[0s / 12s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1509\n",
            "86:\t[0s / 12s],\t\ttrain_loss: 0.1678,\tval_loss: 0.1509\n",
            "87:\t[0s / 12s],\t\ttrain_loss: 0.1565,\tval_loss: 0.1511\n",
            "88:\t[0s / 12s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1510\n",
            "89:\t[0s / 13s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1511\n",
            "90:\t[0s / 13s],\t\ttrain_loss: 0.1586,\tval_loss: 0.1511\n",
            "91:\t[0s / 13s],\t\ttrain_loss: 0.1571,\tval_loss: 0.1511\n",
            "92:\t[0s / 13s],\t\ttrain_loss: 0.1633,\tval_loss: 0.1513\n",
            "93:\t[0s / 13s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1512\n",
            "94:\t[0s / 14s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1509\n",
            "95:\t[0s / 14s],\t\ttrain_loss: 0.1587,\tval_loss: 0.1510\n",
            "96:\t[0s / 14s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1512\n",
            "97:\t[0s / 14s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1512\n",
            "98:\t[0s / 14s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1510\n",
            "99:\t[0s / 15s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1511\n",
            "Current best c-index: 0.6262249897917518\n",
            "Random search... itr: 3\n",
            "{'batch_size': 94, 'layers': 3, 'nodes': 44, 'activation_fn': 'elu', 'alpha': 0.6743831432267504, 'sigma': 0.6402317649695441, 'lr': 0.08203312736598635, 'dropout': 0.838356724824819, 'patience': 45, 'batch_norm': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6931,\tval_loss: 0.3577\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.4894,\tval_loss: 0.3589\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.4153,\tval_loss: 0.3537\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.3887,\tval_loss: 0.3518\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.3904,\tval_loss: 0.3550\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.3917,\tval_loss: 0.3587\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.3749,\tval_loss: 0.3541\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.3859,\tval_loss: 0.3502\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.3832,\tval_loss: 0.3609\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.4144,\tval_loss: 0.3535\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.3933,\tval_loss: 0.3559\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 0.4093,\tval_loss: 0.3542\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.4134,\tval_loss: 0.3605\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.4023,\tval_loss: 0.3562\n",
            "14:\t[0s / 3s],\t\ttrain_loss: 0.4067,\tval_loss: 0.3502\n",
            "15:\t[0s / 3s],\t\ttrain_loss: 0.3876,\tval_loss: 0.3522\n",
            "16:\t[0s / 3s],\t\ttrain_loss: 0.3983,\tval_loss: 0.3565\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.3994,\tval_loss: 0.3510\n",
            "18:\t[0s / 4s],\t\ttrain_loss: 0.4136,\tval_loss: 0.3538\n",
            "19:\t[0s / 4s],\t\ttrain_loss: 0.4040,\tval_loss: 0.3604\n",
            "20:\t[0s / 4s],\t\ttrain_loss: 0.4367,\tval_loss: 0.3643\n",
            "21:\t[0s / 4s],\t\ttrain_loss: 0.4078,\tval_loss: 0.3549\n",
            "22:\t[0s / 5s],\t\ttrain_loss: 0.4046,\tval_loss: 0.3514\n",
            "23:\t[0s / 5s],\t\ttrain_loss: 0.3969,\tval_loss: 0.3526\n",
            "24:\t[0s / 5s],\t\ttrain_loss: 0.4010,\tval_loss: 0.3680\n",
            "25:\t[0s / 5s],\t\ttrain_loss: 0.4092,\tval_loss: 0.3564\n",
            "26:\t[0s / 5s],\t\ttrain_loss: 0.4102,\tval_loss: 0.3609\n",
            "27:\t[0s / 5s],\t\ttrain_loss: 0.4112,\tval_loss: 0.3661\n",
            "28:\t[0s / 5s],\t\ttrain_loss: 0.4384,\tval_loss: 0.3572\n",
            "29:\t[0s / 6s],\t\ttrain_loss: 0.4658,\tval_loss: 0.3661\n",
            "30:\t[0s / 6s],\t\ttrain_loss: 0.4506,\tval_loss: 0.3586\n",
            "31:\t[0s / 6s],\t\ttrain_loss: 0.4245,\tval_loss: 0.3537\n",
            "32:\t[0s / 6s],\t\ttrain_loss: 0.4208,\tval_loss: 0.3557\n",
            "33:\t[0s / 6s],\t\ttrain_loss: 0.4167,\tval_loss: 0.3623\n",
            "34:\t[0s / 6s],\t\ttrain_loss: 0.4275,\tval_loss: 0.3544\n",
            "35:\t[0s / 6s],\t\ttrain_loss: 0.4254,\tval_loss: 0.3616\n",
            "36:\t[0s / 7s],\t\ttrain_loss: 0.4199,\tval_loss: 0.3496\n",
            "37:\t[0s / 7s],\t\ttrain_loss: 0.4153,\tval_loss: 0.3512\n",
            "38:\t[0s / 7s],\t\ttrain_loss: 0.4302,\tval_loss: 0.3555\n",
            "39:\t[0s / 7s],\t\ttrain_loss: 0.4202,\tval_loss: 0.3585\n",
            "40:\t[0s / 7s],\t\ttrain_loss: 0.4448,\tval_loss: 0.3522\n",
            "41:\t[0s / 7s],\t\ttrain_loss: 0.4012,\tval_loss: 0.3562\n",
            "42:\t[0s / 7s],\t\ttrain_loss: 0.4050,\tval_loss: 0.3637\n",
            "43:\t[0s / 8s],\t\ttrain_loss: 0.4166,\tval_loss: 0.3581\n",
            "44:\t[0s / 8s],\t\ttrain_loss: 0.3972,\tval_loss: 0.3578\n",
            "45:\t[0s / 8s],\t\ttrain_loss: 0.4193,\tval_loss: 0.3551\n",
            "46:\t[0s / 8s],\t\ttrain_loss: 0.4025,\tval_loss: 0.3655\n",
            "47:\t[0s / 8s],\t\ttrain_loss: 0.3979,\tval_loss: 0.3529\n",
            "48:\t[0s / 8s],\t\ttrain_loss: 0.3998,\tval_loss: 0.3566\n",
            "49:\t[0s / 8s],\t\ttrain_loss: 0.4687,\tval_loss: 0.3534\n",
            "50:\t[0s / 9s],\t\ttrain_loss: 0.4070,\tval_loss: 0.3546\n",
            "51:\t[0s / 9s],\t\ttrain_loss: 0.4040,\tval_loss: 0.3564\n",
            "52:\t[0s / 9s],\t\ttrain_loss: 0.4305,\tval_loss: 0.3549\n",
            "53:\t[0s / 9s],\t\ttrain_loss: 0.4385,\tval_loss: 0.3583\n",
            "54:\t[0s / 9s],\t\ttrain_loss: 0.4591,\tval_loss: 0.3542\n",
            "55:\t[0s / 9s],\t\ttrain_loss: 0.5349,\tval_loss: 0.3585\n",
            "56:\t[0s / 9s],\t\ttrain_loss: 0.4879,\tval_loss: 0.3559\n",
            "57:\t[0s / 10s],\t\ttrain_loss: 0.4769,\tval_loss: 0.3576\n",
            "58:\t[0s / 10s],\t\ttrain_loss: 0.4431,\tval_loss: 0.3579\n",
            "59:\t[0s / 10s],\t\ttrain_loss: 0.4667,\tval_loss: 0.3601\n",
            "60:\t[0s / 10s],\t\ttrain_loss: 0.4383,\tval_loss: 0.3565\n",
            "61:\t[0s / 10s],\t\ttrain_loss: 0.4614,\tval_loss: 0.3679\n",
            "62:\t[0s / 10s],\t\ttrain_loss: 0.4464,\tval_loss: 0.3731\n",
            "63:\t[0s / 10s],\t\ttrain_loss: 0.4581,\tval_loss: 0.3590\n",
            "64:\t[0s / 10s],\t\ttrain_loss: 0.4144,\tval_loss: 0.3611\n",
            "65:\t[0s / 11s],\t\ttrain_loss: 0.4898,\tval_loss: 0.3592\n",
            "66:\t[0s / 11s],\t\ttrain_loss: 0.4949,\tval_loss: 0.3641\n",
            "67:\t[0s / 11s],\t\ttrain_loss: 0.4460,\tval_loss: 0.3624\n",
            "68:\t[0s / 11s],\t\ttrain_loss: 0.5098,\tval_loss: 0.3595\n",
            "69:\t[0s / 11s],\t\ttrain_loss: 0.4802,\tval_loss: 0.3638\n",
            "70:\t[0s / 11s],\t\ttrain_loss: 0.5041,\tval_loss: 0.3670\n",
            "71:\t[0s / 11s],\t\ttrain_loss: 0.5215,\tval_loss: 0.3618\n",
            "72:\t[0s / 12s],\t\ttrain_loss: 0.4907,\tval_loss: 0.3761\n",
            "73:\t[0s / 12s],\t\ttrain_loss: 0.4939,\tval_loss: 0.3639\n",
            "74:\t[0s / 12s],\t\ttrain_loss: 0.5302,\tval_loss: 0.3780\n",
            "75:\t[0s / 12s],\t\ttrain_loss: 0.4776,\tval_loss: 0.3826\n",
            "76:\t[0s / 12s],\t\ttrain_loss: 0.4526,\tval_loss: 0.3718\n",
            "77:\t[0s / 12s],\t\ttrain_loss: 0.4419,\tval_loss: 0.3721\n",
            "78:\t[0s / 12s],\t\ttrain_loss: 0.4284,\tval_loss: 0.3651\n",
            "79:\t[0s / 13s],\t\ttrain_loss: 0.4541,\tval_loss: 0.3687\n",
            "80:\t[0s / 13s],\t\ttrain_loss: 0.4642,\tval_loss: 0.3706\n",
            "81:\t[0s / 13s],\t\ttrain_loss: 0.4265,\tval_loss: 0.3729\n",
            "Current best c-index: 0.6262249897917518\n",
            "Random search... itr: 4\n",
            "{'batch_size': 236, 'layers': 1, 'nodes': 98, 'activation_fn': 'relu', 'alpha': 0.587695012244284, 'sigma': 0.12628810969837895, 'lr': 0.004600486138676481, 'dropout': 0.05796355400551068, 'patience': 40, 'batch_norm': True}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.5838,\tval_loss: 0.5143\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.4663,\tval_loss: 0.4427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 0.3857,\tval_loss: 0.3995\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.3634,\tval_loss: 0.3856\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.3324,\tval_loss: 0.3742\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.3192,\tval_loss: 0.3597\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.3060,\tval_loss: 0.3487\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.2923,\tval_loss: 0.3448\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.2831,\tval_loss: 0.3435\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.2788,\tval_loss: 0.3440\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.2647,\tval_loss: 0.3401\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.2673,\tval_loss: 0.3389\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.2611,\tval_loss: 0.3361\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.2609,\tval_loss: 0.3418\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.2575,\tval_loss: 0.3427\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.2509,\tval_loss: 0.3443\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.2458,\tval_loss: 0.3405\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.2456,\tval_loss: 0.3403\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.2403,\tval_loss: 0.3443\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.2443,\tval_loss: 0.3474\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.2316,\tval_loss: 0.3502\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.2320,\tval_loss: 0.3495\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.2205,\tval_loss: 0.3513\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.2271,\tval_loss: 0.3603\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.2207,\tval_loss: 0.3660\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.2195,\tval_loss: 0.3590\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.2154,\tval_loss: 0.3651\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.2096,\tval_loss: 0.3683\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.1983,\tval_loss: 0.3848\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.2092,\tval_loss: 0.3880\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.2052,\tval_loss: 0.3842\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.2023,\tval_loss: 0.3974\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.1991,\tval_loss: 0.4141\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.2018,\tval_loss: 0.4001\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.1978,\tval_loss: 0.3995\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.1942,\tval_loss: 0.3995\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.1909,\tval_loss: 0.4075\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.1958,\tval_loss: 0.4137\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.1879,\tval_loss: 0.4125\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.1869,\tval_loss: 0.4162\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 0.1787,\tval_loss: 0.4328\n",
            "41:\t[0s / 3s],\t\ttrain_loss: 0.1872,\tval_loss: 0.4447\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 0.1828,\tval_loss: 0.4399\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 0.1815,\tval_loss: 0.4349\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 0.1897,\tval_loss: 0.4345\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 0.1732,\tval_loss: 0.4423\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 0.1812,\tval_loss: 0.4552\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 0.1702,\tval_loss: 0.4573\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 0.1732,\tval_loss: 0.4482\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 0.1638,\tval_loss: 0.4505\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 0.1599,\tval_loss: 0.4522\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 0.1713,\tval_loss: 0.4530\n",
            "52:\t[0s / 4s],\t\ttrain_loss: 0.1693,\tval_loss: 0.4684\n",
            "Current best c-index: 0.6262249897917518\n",
            "Random search... itr: 5\n",
            "{'batch_size': 122, 'layers': 2, 'nodes': 25, 'activation_fn': 'relu', 'alpha': 0.9665295494041317, 'sigma': 0.3987515249606032, 'lr': 0.06420548161882556, 'dropout': 0.3910043392786522, 'patience': 45, 'batch_norm': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6886,\tval_loss: 0.5202\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5310,\tval_loss: 0.4737\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.4928,\tval_loss: 0.4735\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5038,\tval_loss: 0.4779\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.5018,\tval_loss: 0.4679\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.4881,\tval_loss: 0.4685\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.4862,\tval_loss: 0.4663\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.4917,\tval_loss: 0.4681\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.4850,\tval_loss: 0.4631\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.4806,\tval_loss: 0.4673\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.4864,\tval_loss: 0.4725\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.4806,\tval_loss: 0.4770\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.4883,\tval_loss: 0.4774\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.4770,\tval_loss: 0.4809\n",
            "14:\t[0s / 3s],\t\ttrain_loss: 0.4871,\tval_loss: 0.4750\n",
            "15:\t[0s / 3s],\t\ttrain_loss: 0.4847,\tval_loss: 0.4732\n",
            "16:\t[0s / 3s],\t\ttrain_loss: 0.4750,\tval_loss: 0.4810\n",
            "17:\t[0s / 3s],\t\ttrain_loss: 0.4784,\tval_loss: 0.4824\n",
            "18:\t[0s / 4s],\t\ttrain_loss: 0.4779,\tval_loss: 0.4714\n",
            "19:\t[0s / 4s],\t\ttrain_loss: 0.4690,\tval_loss: 0.4813\n",
            "20:\t[0s / 4s],\t\ttrain_loss: 0.4781,\tval_loss: 0.4818\n",
            "21:\t[0s / 4s],\t\ttrain_loss: 0.4675,\tval_loss: 0.4767\n",
            "22:\t[0s / 4s],\t\ttrain_loss: 0.4726,\tval_loss: 0.4772\n",
            "23:\t[0s / 4s],\t\ttrain_loss: 0.4726,\tval_loss: 0.4884\n",
            "24:\t[0s / 5s],\t\ttrain_loss: 0.4656,\tval_loss: 0.4752\n",
            "25:\t[0s / 5s],\t\ttrain_loss: 0.4717,\tval_loss: 0.4720\n",
            "26:\t[0s / 5s],\t\ttrain_loss: 0.4691,\tval_loss: 0.4763\n",
            "27:\t[0s / 5s],\t\ttrain_loss: 0.4566,\tval_loss: 0.4754\n",
            "28:\t[0s / 5s],\t\ttrain_loss: 0.4833,\tval_loss: 0.4767\n",
            "29:\t[0s / 5s],\t\ttrain_loss: 0.4718,\tval_loss: 0.4748\n",
            "30:\t[0s / 6s],\t\ttrain_loss: 0.4711,\tval_loss: 0.4848\n",
            "31:\t[0s / 6s],\t\ttrain_loss: 0.4673,\tval_loss: 0.4889\n",
            "32:\t[0s / 6s],\t\ttrain_loss: 0.4547,\tval_loss: 0.4856\n",
            "33:\t[0s / 6s],\t\ttrain_loss: 0.4730,\tval_loss: 0.4637\n",
            "34:\t[0s / 7s],\t\ttrain_loss: 0.4735,\tval_loss: 0.4706\n",
            "35:\t[0s / 7s],\t\ttrain_loss: 0.4686,\tval_loss: 0.4733\n",
            "36:\t[0s / 7s],\t\ttrain_loss: 0.4706,\tval_loss: 0.4749\n",
            "37:\t[0s / 7s],\t\ttrain_loss: 0.4622,\tval_loss: 0.4752\n",
            "38:\t[0s / 7s],\t\ttrain_loss: 0.4685,\tval_loss: 0.4880\n",
            "39:\t[0s / 7s],\t\ttrain_loss: 0.4753,\tval_loss: 0.4797\n",
            "40:\t[0s / 7s],\t\ttrain_loss: 0.4677,\tval_loss: 0.4841\n",
            "41:\t[0s / 7s],\t\ttrain_loss: 0.4659,\tval_loss: 0.5002\n",
            "42:\t[0s / 7s],\t\ttrain_loss: 0.4651,\tval_loss: 0.4746\n",
            "43:\t[0s / 7s],\t\ttrain_loss: 0.4687,\tval_loss: 0.4825\n",
            "44:\t[0s / 7s],\t\ttrain_loss: 0.4632,\tval_loss: 0.4822\n",
            "45:\t[0s / 8s],\t\ttrain_loss: 0.4644,\tval_loss: 0.4710\n",
            "46:\t[0s / 8s],\t\ttrain_loss: 0.4651,\tval_loss: 0.4821\n",
            "47:\t[0s / 8s],\t\ttrain_loss: 0.4501,\tval_loss: 0.4917\n",
            "48:\t[0s / 8s],\t\ttrain_loss: 0.4585,\tval_loss: 0.4826\n",
            "49:\t[0s / 8s],\t\ttrain_loss: 0.4669,\tval_loss: 0.4814\n",
            "50:\t[0s / 8s],\t\ttrain_loss: 0.4596,\tval_loss: 0.4903\n",
            "51:\t[0s / 8s],\t\ttrain_loss: 0.4763,\tval_loss: 0.4846\n",
            "52:\t[0s / 8s],\t\ttrain_loss: 0.4724,\tval_loss: 0.4778\n",
            "53:\t[0s / 8s],\t\ttrain_loss: 0.4548,\tval_loss: 0.4794\n",
            "Current best c-index: 0.6262249897917518\n",
            "Random search... itr: 6\n",
            "{'batch_size': 218, 'layers': 1, 'nodes': 65, 'activation_fn': 'relu', 'alpha': 0.32974913363080216, 'sigma': 0.45811638997588433, 'lr': 0.06700575720996706, 'dropout': 0.5617417728504804, 'patience': 27, 'batch_norm': True}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.3282,\tval_loss: 0.2449\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2495,\tval_loss: 0.2196\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.2380,\tval_loss: 0.2101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 0.2298,\tval_loss: 0.2060\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.2516,\tval_loss: 0.2058\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.2135,\tval_loss: 0.2069\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.2262,\tval_loss: 0.2104\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.2076,\tval_loss: 0.2077\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.2111,\tval_loss: 0.2072\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.2219,\tval_loss: 0.2087\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.2224,\tval_loss: 0.2092\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.2307,\tval_loss: 0.2085\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.2013,\tval_loss: 0.2171\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.2237,\tval_loss: 0.2051\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.2201,\tval_loss: 0.2117\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.2057,\tval_loss: 0.2088\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.2099,\tval_loss: 0.2088\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.2025,\tval_loss: 0.2092\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.2057,\tval_loss: 0.2092\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.2089,\tval_loss: 0.2084\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.2100,\tval_loss: 0.2124\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.2155,\tval_loss: 0.2146\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.2066,\tval_loss: 0.2131\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.2023,\tval_loss: 0.2115\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.2133,\tval_loss: 0.2086\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.2005,\tval_loss: 0.2113\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.2141,\tval_loss: 0.2069\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.2152,\tval_loss: 0.2088\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.2069,\tval_loss: 0.2140\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 0.2063,\tval_loss: 0.2135\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 0.2080,\tval_loss: 0.2103\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 0.2072,\tval_loss: 0.2110\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 0.2109,\tval_loss: 0.2101\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.2166,\tval_loss: 0.2098\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.2083,\tval_loss: 0.2313\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.2145,\tval_loss: 0.2126\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.1978,\tval_loss: 0.2123\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.2039,\tval_loss: 0.2170\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.1994,\tval_loss: 0.2132\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.2082,\tval_loss: 0.2156\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 0.2113,\tval_loss: 0.2182\n",
            "Current best c-index: 0.6262249897917518\n",
            "Random search... itr: 7\n",
            "{'batch_size': 117, 'layers': 4, 'nodes': 51, 'activation_fn': 'tanh', 'alpha': 0.1680330958309943, 'sigma': 0.7524657362668262, 'lr': 0.028815401038774884, 'dropout': 0.9232344702136619, 'patience': 33, 'batch_norm': False}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 1.6286,\tval_loss: 0.1942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 1.9952,\tval_loss: 0.1653\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 2.4434,\tval_loss: 0.1526\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 2.1733,\tval_loss: 0.1471\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 2.2278,\tval_loss: 0.1431\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 1.4827,\tval_loss: 0.1425\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 1.2462,\tval_loss: 0.1431\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 1.5047,\tval_loss: 0.1435\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.8979,\tval_loss: 0.1437\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.8833,\tval_loss: 0.1462\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.7054,\tval_loss: 0.1470\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 1.2424,\tval_loss: 0.1457\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.4438,\tval_loss: 0.1439\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.6501,\tval_loss: 0.1436\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.6523,\tval_loss: 0.1445\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 2.2080,\tval_loss: 0.1426\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 1.0612,\tval_loss: 0.1422\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 2.4202,\tval_loss: 0.1423\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.6326,\tval_loss: 0.1428\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.5817,\tval_loss: 0.1426\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 1.8125,\tval_loss: 0.1427\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 1.9289,\tval_loss: 0.1425\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.7081,\tval_loss: 0.1424\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 1.0010,\tval_loss: 0.1429\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 1.6311,\tval_loss: 0.1428\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 1.2153,\tval_loss: 0.1423\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.3018,\tval_loss: 0.1426\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 1.0643,\tval_loss: 0.1423\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 3.0666,\tval_loss: 0.1428\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.5574,\tval_loss: 0.1424\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 1.6078,\tval_loss: 0.1425\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.8391,\tval_loss: 0.1426\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 1.2956,\tval_loss: 0.1421\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 2.4748,\tval_loss: 0.1423\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.2599,\tval_loss: 0.1423\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 1.1323,\tval_loss: 0.1422\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 1.0809,\tval_loss: 0.1423\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.4105,\tval_loss: 0.1419\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.3695,\tval_loss: 0.1425\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.1981,\tval_loss: 0.1428\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.8472,\tval_loss: 0.1425\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.6647,\tval_loss: 0.1424\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.4361,\tval_loss: 0.1423\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.2547,\tval_loss: 0.1425\n",
            "44:\t[0s / 6s],\t\ttrain_loss: 0.1922,\tval_loss: 0.1425\n",
            "45:\t[0s / 6s],\t\ttrain_loss: 0.3661,\tval_loss: 0.1421\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.2469,\tval_loss: 0.1419\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.6475,\tval_loss: 0.1422\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.2521,\tval_loss: 0.1422\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.2363,\tval_loss: 0.1424\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.4227,\tval_loss: 0.1423\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1714,\tval_loss: 0.1420\n",
            "52:\t[0s / 7s],\t\ttrain_loss: 1.2292,\tval_loss: 0.1421\n",
            "53:\t[0s / 7s],\t\ttrain_loss: 0.2977,\tval_loss: 0.1422\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.1927,\tval_loss: 0.1423\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.1994,\tval_loss: 0.1423\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.1716,\tval_loss: 0.1424\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.1621,\tval_loss: 0.1424\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.7189,\tval_loss: 0.1426\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1654,\tval_loss: 0.1425\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.5462,\tval_loss: 0.1422\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.9346,\tval_loss: 0.1422\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.4299,\tval_loss: 0.1420\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.2376,\tval_loss: 0.1421\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.1703,\tval_loss: 0.1421\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.8936,\tval_loss: 0.1424\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1665,\tval_loss: 0.1425\n",
            "67:\t[0s / 9s],\t\ttrain_loss: 3.2532,\tval_loss: 0.1424\n",
            "68:\t[0s / 9s],\t\ttrain_loss: 0.1607,\tval_loss: 0.1423\n",
            "69:\t[0s / 9s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1422\n",
            "70:\t[0s / 9s],\t\ttrain_loss: 0.1701,\tval_loss: 0.1422\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 1.5854,\tval_loss: 0.1421\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.1758,\tval_loss: 0.1423\n",
            "73:\t[0s / 10s],\t\ttrain_loss: 0.1637,\tval_loss: 0.1423\n",
            "74:\t[0s / 10s],\t\ttrain_loss: 0.2582,\tval_loss: 0.1421\n",
            "75:\t[0s / 10s],\t\ttrain_loss: 0.1931,\tval_loss: 0.1421\n",
            "76:\t[0s / 10s],\t\ttrain_loss: 0.1785,\tval_loss: 0.1422\n",
            "77:\t[0s / 10s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1421\n",
            "78:\t[0s / 10s],\t\ttrain_loss: 0.1642,\tval_loss: 0.1421\n",
            "79:\t[0s / 10s],\t\ttrain_loss: 0.1525,\tval_loss: 0.1422\n",
            "Current best c-index: 0.6262249897917518\n",
            "Random search... itr: 8\n",
            "{'batch_size': 89, 'layers': 4, 'nodes': 87, 'activation_fn': 'tanh', 'alpha': 0.9548028408807531, 'sigma': 0.32527867245479797, 'lr': 0.0014819576065115225, 'dropout': 0.38367738226232845, 'patience': 44, 'batch_norm': True}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.9511,\tval_loss: 0.7634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.8463,\tval_loss: 0.6623\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.7651,\tval_loss: 0.5706\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.6756,\tval_loss: 0.5325\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.6249,\tval_loss: 0.5224\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5780,\tval_loss: 0.5175\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.5724,\tval_loss: 0.5087\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.5554,\tval_loss: 0.5026\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.5648,\tval_loss: 0.4974\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.5108,\tval_loss: 0.4939\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.5230,\tval_loss: 0.4892\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.5193,\tval_loss: 0.4881\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 0.5070,\tval_loss: 0.4817\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.5114,\tval_loss: 0.4762\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.4830,\tval_loss: 0.4778\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.4966,\tval_loss: 0.4779\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.4984,\tval_loss: 0.4789\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.4961,\tval_loss: 0.4774\n",
            "18:\t[0s / 3s],\t\ttrain_loss: 0.4955,\tval_loss: 0.4723\n",
            "19:\t[0s / 3s],\t\ttrain_loss: 0.4850,\tval_loss: 0.4746\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.4843,\tval_loss: 0.4746\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.4787,\tval_loss: 0.4730\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.4743,\tval_loss: 0.4724\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.4716,\tval_loss: 0.4758\n",
            "24:\t[0s / 4s],\t\ttrain_loss: 0.4881,\tval_loss: 0.4726\n",
            "25:\t[0s / 4s],\t\ttrain_loss: 0.4710,\tval_loss: 0.4700\n",
            "26:\t[0s / 4s],\t\ttrain_loss: 0.4708,\tval_loss: 0.4706\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.4780,\tval_loss: 0.4754\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.4696,\tval_loss: 0.4757\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.4678,\tval_loss: 0.4751\n",
            "30:\t[0s / 5s],\t\ttrain_loss: 0.4699,\tval_loss: 0.4719\n",
            "31:\t[0s / 5s],\t\ttrain_loss: 0.4668,\tval_loss: 0.4718\n",
            "32:\t[0s / 5s],\t\ttrain_loss: 0.4518,\tval_loss: 0.4761\n",
            "33:\t[0s / 5s],\t\ttrain_loss: 0.4649,\tval_loss: 0.4751\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.4667,\tval_loss: 0.4715\n",
            "35:\t[0s / 5s],\t\ttrain_loss: 0.4659,\tval_loss: 0.4722\n",
            "36:\t[0s / 6s],\t\ttrain_loss: 0.4714,\tval_loss: 0.4717\n",
            "37:\t[0s / 6s],\t\ttrain_loss: 0.4674,\tval_loss: 0.4682\n",
            "38:\t[0s / 6s],\t\ttrain_loss: 0.4667,\tval_loss: 0.4686\n",
            "39:\t[0s / 6s],\t\ttrain_loss: 0.4617,\tval_loss: 0.4722\n",
            "40:\t[0s / 7s],\t\ttrain_loss: 0.4536,\tval_loss: 0.4745\n",
            "41:\t[0s / 7s],\t\ttrain_loss: 0.4632,\tval_loss: 0.4733\n",
            "42:\t[0s / 7s],\t\ttrain_loss: 0.4661,\tval_loss: 0.4694\n",
            "43:\t[0s / 7s],\t\ttrain_loss: 0.4600,\tval_loss: 0.4740\n",
            "44:\t[0s / 8s],\t\ttrain_loss: 0.4564,\tval_loss: 0.4718\n",
            "45:\t[0s / 8s],\t\ttrain_loss: 0.4457,\tval_loss: 0.4755\n",
            "46:\t[0s / 8s],\t\ttrain_loss: 0.4541,\tval_loss: 0.4761\n",
            "47:\t[0s / 8s],\t\ttrain_loss: 0.4385,\tval_loss: 0.4704\n",
            "48:\t[0s / 8s],\t\ttrain_loss: 0.4568,\tval_loss: 0.4733\n",
            "49:\t[0s / 9s],\t\ttrain_loss: 0.4501,\tval_loss: 0.4752\n",
            "50:\t[0s / 9s],\t\ttrain_loss: 0.4565,\tval_loss: 0.4729\n",
            "51:\t[0s / 9s],\t\ttrain_loss: 0.4389,\tval_loss: 0.4770\n",
            "52:\t[0s / 9s],\t\ttrain_loss: 0.4402,\tval_loss: 0.4785\n",
            "53:\t[0s / 10s],\t\ttrain_loss: 0.4456,\tval_loss: 0.4768\n",
            "54:\t[0s / 10s],\t\ttrain_loss: 0.4358,\tval_loss: 0.4752\n",
            "55:\t[0s / 10s],\t\ttrain_loss: 0.4533,\tval_loss: 0.4761\n",
            "56:\t[0s / 10s],\t\ttrain_loss: 0.4337,\tval_loss: 0.4744\n",
            "57:\t[0s / 10s],\t\ttrain_loss: 0.4462,\tval_loss: 0.4781\n",
            "58:\t[0s / 11s],\t\ttrain_loss: 0.4362,\tval_loss: 0.4740\n",
            "59:\t[0s / 11s],\t\ttrain_loss: 0.4425,\tval_loss: 0.4798\n",
            "60:\t[0s / 11s],\t\ttrain_loss: 0.4552,\tval_loss: 0.4810\n",
            "61:\t[0s / 11s],\t\ttrain_loss: 0.4483,\tval_loss: 0.4791\n",
            "62:\t[0s / 11s],\t\ttrain_loss: 0.4407,\tval_loss: 0.4782\n",
            "63:\t[0s / 11s],\t\ttrain_loss: 0.4434,\tval_loss: 0.4815\n",
            "64:\t[0s / 12s],\t\ttrain_loss: 0.4360,\tval_loss: 0.4800\n",
            "65:\t[0s / 12s],\t\ttrain_loss: 0.4329,\tval_loss: 0.4823\n",
            "66:\t[0s / 12s],\t\ttrain_loss: 0.4371,\tval_loss: 0.4901\n",
            "67:\t[0s / 12s],\t\ttrain_loss: 0.4366,\tval_loss: 0.4782\n",
            "68:\t[0s / 12s],\t\ttrain_loss: 0.4230,\tval_loss: 0.4837\n",
            "69:\t[0s / 12s],\t\ttrain_loss: 0.4287,\tval_loss: 0.4879\n",
            "70:\t[0s / 13s],\t\ttrain_loss: 0.4363,\tval_loss: 0.4860\n",
            "71:\t[0s / 13s],\t\ttrain_loss: 0.4292,\tval_loss: 0.4867\n",
            "72:\t[0s / 13s],\t\ttrain_loss: 0.4223,\tval_loss: 0.4859\n",
            "73:\t[0s / 13s],\t\ttrain_loss: 0.4294,\tval_loss: 0.4819\n",
            "74:\t[0s / 13s],\t\ttrain_loss: 0.4321,\tval_loss: 0.4894\n",
            "75:\t[0s / 13s],\t\ttrain_loss: 0.4273,\tval_loss: 0.4846\n",
            "76:\t[0s / 13s],\t\ttrain_loss: 0.4395,\tval_loss: 0.4898\n",
            "77:\t[0s / 14s],\t\ttrain_loss: 0.4131,\tval_loss: 0.4911\n",
            "78:\t[0s / 14s],\t\ttrain_loss: 0.4173,\tval_loss: 0.4915\n",
            "79:\t[0s / 14s],\t\ttrain_loss: 0.4277,\tval_loss: 0.4907\n",
            "80:\t[0s / 14s],\t\ttrain_loss: 0.4235,\tval_loss: 0.4939\n",
            "81:\t[0s / 14s],\t\ttrain_loss: 0.4132,\tval_loss: 0.4998\n",
            "Current best c-index: 0.6262249897917518\n",
            "Random search... itr: 9\n",
            "{'batch_size': 51, 'layers': 3, 'nodes': 73, 'activation_fn': 'relu', 'alpha': 0.8552634684065544, 'sigma': 0.46868769266089705, 'lr': 0.036562411930865554, 'dropout': 0.4485973290307008, 'patience': 71, 'batch_norm': False}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.7508,\tval_loss: 0.4911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.6811,\tval_loss: 0.4591\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5627,\tval_loss: 0.4312\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.4667,\tval_loss: 0.4266\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.4710,\tval_loss: 0.4231\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.4541,\tval_loss: 0.4250\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.4512,\tval_loss: 0.4321\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.4512,\tval_loss: 0.4301\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.4638,\tval_loss: 0.4253\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.4502,\tval_loss: 0.4250\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.4472,\tval_loss: 0.4248\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 0.4379,\tval_loss: 0.4262\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 0.4378,\tval_loss: 0.4250\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.4479,\tval_loss: 0.4254\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.4407,\tval_loss: 0.4249\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.4467,\tval_loss: 0.4259\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.4387,\tval_loss: 0.4264\n",
            "17:\t[0s / 3s],\t\ttrain_loss: 0.4392,\tval_loss: 0.4263\n",
            "18:\t[0s / 3s],\t\ttrain_loss: 0.4548,\tval_loss: 0.4251\n",
            "19:\t[0s / 3s],\t\ttrain_loss: 0.4517,\tval_loss: 0.4284\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.4428,\tval_loss: 0.4259\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.4379,\tval_loss: 0.4251\n",
            "22:\t[0s / 4s],\t\ttrain_loss: 0.4461,\tval_loss: 0.4257\n",
            "23:\t[0s / 4s],\t\ttrain_loss: 0.4516,\tval_loss: 0.4265\n",
            "24:\t[0s / 4s],\t\ttrain_loss: 0.4367,\tval_loss: 0.4273\n",
            "25:\t[0s / 4s],\t\ttrain_loss: 0.4495,\tval_loss: 0.4265\n",
            "26:\t[0s / 4s],\t\ttrain_loss: 0.4378,\tval_loss: 0.4255\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.4545,\tval_loss: 0.4252\n",
            "28:\t[0s / 5s],\t\ttrain_loss: 0.4422,\tval_loss: 0.4292\n",
            "29:\t[0s / 5s],\t\ttrain_loss: 0.4560,\tval_loss: 0.4264\n",
            "30:\t[0s / 5s],\t\ttrain_loss: 0.4517,\tval_loss: 0.4254\n",
            "31:\t[0s / 5s],\t\ttrain_loss: 0.4475,\tval_loss: 0.4254\n",
            "32:\t[0s / 5s],\t\ttrain_loss: 0.4574,\tval_loss: 0.4253\n",
            "33:\t[0s / 6s],\t\ttrain_loss: 0.4481,\tval_loss: 0.4264\n",
            "34:\t[0s / 6s],\t\ttrain_loss: 0.4485,\tval_loss: 0.4268\n",
            "35:\t[0s / 6s],\t\ttrain_loss: 0.4487,\tval_loss: 0.4255\n",
            "36:\t[0s / 6s],\t\ttrain_loss: 0.4450,\tval_loss: 0.4260\n",
            "37:\t[0s / 7s],\t\ttrain_loss: 0.4456,\tval_loss: 0.4245\n",
            "38:\t[0s / 7s],\t\ttrain_loss: 0.4493,\tval_loss: 0.4270\n",
            "39:\t[0s / 7s],\t\ttrain_loss: 0.4424,\tval_loss: 0.4256\n",
            "40:\t[0s / 8s],\t\ttrain_loss: 0.4440,\tval_loss: 0.4251\n",
            "41:\t[0s / 9s],\t\ttrain_loss: 0.4428,\tval_loss: 0.4259\n",
            "42:\t[0s / 9s],\t\ttrain_loss: 0.4421,\tval_loss: 0.4243\n",
            "43:\t[0s / 10s],\t\ttrain_loss: 0.4386,\tval_loss: 0.4276\n",
            "44:\t[0s / 11s],\t\ttrain_loss: 0.4371,\tval_loss: 0.4265\n",
            "45:\t[0s / 11s],\t\ttrain_loss: 0.4362,\tval_loss: 0.4252\n",
            "46:\t[0s / 11s],\t\ttrain_loss: 0.4426,\tval_loss: 0.4248\n",
            "47:\t[0s / 12s],\t\ttrain_loss: 0.4370,\tval_loss: 0.4272\n",
            "48:\t[0s / 12s],\t\ttrain_loss: 0.4484,\tval_loss: 0.4253\n",
            "49:\t[0s / 13s],\t\ttrain_loss: 0.4362,\tval_loss: 0.4258\n",
            "50:\t[0s / 13s],\t\ttrain_loss: 0.4386,\tval_loss: 0.4268\n",
            "51:\t[0s / 13s],\t\ttrain_loss: 0.4423,\tval_loss: 0.4265\n",
            "52:\t[0s / 14s],\t\ttrain_loss: 0.4426,\tval_loss: 0.4251\n",
            "53:\t[0s / 14s],\t\ttrain_loss: 0.4490,\tval_loss: 0.4268\n",
            "54:\t[0s / 14s],\t\ttrain_loss: 0.4481,\tval_loss: 0.4260\n",
            "55:\t[0s / 15s],\t\ttrain_loss: 0.4427,\tval_loss: 0.4247\n",
            "56:\t[0s / 15s],\t\ttrain_loss: 0.4421,\tval_loss: 0.4269\n",
            "57:\t[0s / 16s],\t\ttrain_loss: 0.4548,\tval_loss: 0.4254\n",
            "58:\t[0s / 16s],\t\ttrain_loss: 0.4436,\tval_loss: 0.4259\n",
            "59:\t[0s / 16s],\t\ttrain_loss: 0.4438,\tval_loss: 0.4278\n",
            "60:\t[0s / 17s],\t\ttrain_loss: 0.4543,\tval_loss: 0.4253\n",
            "61:\t[0s / 17s],\t\ttrain_loss: 0.4421,\tval_loss: 0.4268\n",
            "62:\t[0s / 17s],\t\ttrain_loss: 0.4485,\tval_loss: 0.4264\n",
            "63:\t[0s / 17s],\t\ttrain_loss: 0.4367,\tval_loss: 0.4249\n",
            "64:\t[0s / 18s],\t\ttrain_loss: 0.4368,\tval_loss: 0.4251\n",
            "65:\t[0s / 18s],\t\ttrain_loss: 0.4538,\tval_loss: 0.4246\n",
            "66:\t[0s / 18s],\t\ttrain_loss: 0.4422,\tval_loss: 0.4258\n",
            "67:\t[0s / 18s],\t\ttrain_loss: 0.4470,\tval_loss: 0.4263\n",
            "68:\t[0s / 18s],\t\ttrain_loss: 0.4471,\tval_loss: 0.4259\n",
            "69:\t[0s / 19s],\t\ttrain_loss: 0.4544,\tval_loss: 0.4253\n",
            "70:\t[0s / 19s],\t\ttrain_loss: 0.4431,\tval_loss: 0.4247\n",
            "71:\t[0s / 19s],\t\ttrain_loss: 0.4563,\tval_loss: 0.4259\n",
            "72:\t[0s / 19s],\t\ttrain_loss: 0.4473,\tval_loss: 0.4251\n",
            "73:\t[0s / 19s],\t\ttrain_loss: 0.4404,\tval_loss: 0.4250\n",
            "74:\t[0s / 19s],\t\ttrain_loss: 0.4490,\tval_loss: 0.4273\n",
            "75:\t[0s / 20s],\t\ttrain_loss: 0.4491,\tval_loss: 0.4244\n",
            "Current best c-index: 0.6262249897917518\n",
            "Random search... itr: 10\n",
            "{'batch_size': 227, 'layers': 1, 'nodes': 53, 'activation_fn': 'elu', 'alpha': 0.4077749349508848, 'sigma': 0.84994626042999, 'lr': 0.01061896727741276, 'dropout': 0.45116368484738706, 'patience': 57, 'batch_norm': False}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.3351,\tval_loss: 0.2641\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2879,\tval_loss: 0.2501\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.2616,\tval_loss: 0.2473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 0.2577,\tval_loss: 0.2448\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.2496,\tval_loss: 0.2443\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.2427,\tval_loss: 0.2427\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.2408,\tval_loss: 0.2471\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.2408,\tval_loss: 0.2450\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.2362,\tval_loss: 0.2471\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.2420,\tval_loss: 0.2467\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.2340,\tval_loss: 0.2476\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.2365,\tval_loss: 0.2498\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.2275,\tval_loss: 0.2519\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.2284,\tval_loss: 0.2533\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.2303,\tval_loss: 0.2519\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.2242,\tval_loss: 0.2528\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 0.2244,\tval_loss: 0.2512\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 0.2271,\tval_loss: 0.2531\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 0.2282,\tval_loss: 0.2529\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 0.2238,\tval_loss: 0.2523\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.2193,\tval_loss: 0.2559\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.2222,\tval_loss: 0.2546\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.2174,\tval_loss: 0.2550\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.2149,\tval_loss: 0.2582\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.2157,\tval_loss: 0.2567\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.2172,\tval_loss: 0.2570\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.2162,\tval_loss: 0.2580\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.2184,\tval_loss: 0.2567\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.2142,\tval_loss: 0.2565\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 0.2092,\tval_loss: 0.2569\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 0.2111,\tval_loss: 0.2606\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 0.2182,\tval_loss: 0.2565\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 0.2069,\tval_loss: 0.2577\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 0.2082,\tval_loss: 0.2589\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.2052,\tval_loss: 0.2564\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.2019,\tval_loss: 0.2571\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.2091,\tval_loss: 0.2608\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.2046,\tval_loss: 0.2621\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.2027,\tval_loss: 0.2622\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.2067,\tval_loss: 0.2647\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 0.2034,\tval_loss: 0.2632\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 0.2057,\tval_loss: 0.2649\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 0.2046,\tval_loss: 0.2619\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 0.2031,\tval_loss: 0.2612\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 0.1998,\tval_loss: 0.2650\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 0.2002,\tval_loss: 0.2660\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 0.1998,\tval_loss: 0.2669\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 0.1987,\tval_loss: 0.2671\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 0.2019,\tval_loss: 0.2700\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 0.1970,\tval_loss: 0.2706\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 0.1980,\tval_loss: 0.2691\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 0.1984,\tval_loss: 0.2685\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 0.2013,\tval_loss: 0.2677\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 0.1991,\tval_loss: 0.2700\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 0.1987,\tval_loss: 0.2700\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 0.1962,\tval_loss: 0.2708\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 0.2002,\tval_loss: 0.2677\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 0.1937,\tval_loss: 0.2710\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 0.1950,\tval_loss: 0.2693\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 0.1889,\tval_loss: 0.2698\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 0.1910,\tval_loss: 0.2706\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 0.1971,\tval_loss: 0.2687\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 0.1929,\tval_loss: 0.2737\n",
            "Current best c-index: 0.6262249897917518\n",
            "Random search... itr: 11\n",
            "{'batch_size': 131, 'layers': 4, 'nodes': 40, 'activation_fn': 'elu', 'alpha': 0.8169927783134885, 'sigma': 0.24999556820334481, 'lr': 0.06573340893830315, 'dropout': 0.4934305481498846, 'patience': 54, 'batch_norm': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6873,\tval_loss: 0.5559\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5017,\tval_loss: 0.4150\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.4632,\tval_loss: 0.4122\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.4560,\tval_loss: 0.4135\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.4417,\tval_loss: 0.4108\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4523,\tval_loss: 0.4121\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.4472,\tval_loss: 0.4137\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.4255,\tval_loss: 0.4102\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.4363,\tval_loss: 0.4086\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.4292,\tval_loss: 0.4131\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.4315,\tval_loss: 0.4070\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.4364,\tval_loss: 0.4083\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 0.4439,\tval_loss: 0.4104\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.4332,\tval_loss: 0.4058\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.4388,\tval_loss: 0.4070\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.4194,\tval_loss: 0.4122\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.4409,\tval_loss: 0.4059\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.4299,\tval_loss: 0.4110\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.4388,\tval_loss: 0.4142\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.4399,\tval_loss: 0.4052\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.4436,\tval_loss: 0.4048\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.4367,\tval_loss: 0.3993\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.4538,\tval_loss: 0.4054\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.4333,\tval_loss: 0.4101\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.4283,\tval_loss: 0.3998\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.4370,\tval_loss: 0.4123\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.4351,\tval_loss: 0.4096\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.4350,\tval_loss: 0.4049\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.4336,\tval_loss: 0.4014\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.4449,\tval_loss: 0.4092\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.4272,\tval_loss: 0.4026\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.4390,\tval_loss: 0.4089\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.4428,\tval_loss: 0.4010\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.4274,\tval_loss: 0.4084\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.4236,\tval_loss: 0.4028\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.4139,\tval_loss: 0.4042\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.4299,\tval_loss: 0.4114\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.4406,\tval_loss: 0.4030\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.4207,\tval_loss: 0.4055\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.4515,\tval_loss: 0.4050\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.4313,\tval_loss: 0.4133\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.4479,\tval_loss: 0.4029\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.4284,\tval_loss: 0.4071\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.4213,\tval_loss: 0.4019\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.4199,\tval_loss: 0.4133\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.4294,\tval_loss: 0.4037\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.4170,\tval_loss: 0.4032\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.4374,\tval_loss: 0.4045\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.4304,\tval_loss: 0.4003\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.4518,\tval_loss: 0.4085\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.4248,\tval_loss: 0.4067\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.4232,\tval_loss: 0.3994\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.4317,\tval_loss: 0.4108\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.4218,\tval_loss: 0.4055\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.4327,\tval_loss: 0.4057\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.4314,\tval_loss: 0.4123\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.4145,\tval_loss: 0.4042\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.4283,\tval_loss: 0.4030\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.4218,\tval_loss: 0.4169\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.4367,\tval_loss: 0.4031\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.4354,\tval_loss: 0.4050\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.4277,\tval_loss: 0.4067\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.4213,\tval_loss: 0.4107\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.4236,\tval_loss: 0.4126\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.4281,\tval_loss: 0.4227\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.4480,\tval_loss: 0.4106\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.4378,\tval_loss: 0.4095\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.4283,\tval_loss: 0.4101\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.4289,\tval_loss: 0.4062\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.4331,\tval_loss: 0.4127\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.4221,\tval_loss: 0.4163\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.4218,\tval_loss: 0.4097\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.4284,\tval_loss: 0.4082\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.4343,\tval_loss: 0.4032\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.4328,\tval_loss: 0.4078\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.4209,\tval_loss: 0.4190\n",
            "Current best c-index: 0.6262249897917518\n",
            "Random search... itr: 12\n",
            "{'batch_size': 234, 'layers': 3, 'nodes': 36, 'activation_fn': 'relu', 'alpha': 0.9297094290868417, 'sigma': 0.3832552896698931, 'lr': 0.0014528625269429772, 'dropout': 0.680275037983291, 'patience': 39, 'batch_norm': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 1.0466,\tval_loss: 0.8527\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.9765,\tval_loss: 0.8204\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.9496,\tval_loss: 0.7903\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.9375,\tval_loss: 0.7688\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.8762,\tval_loss: 0.7513\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.8520,\tval_loss: 0.7337\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.8306,\tval_loss: 0.7135\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.8196,\tval_loss: 0.6978\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.7836,\tval_loss: 0.6827\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.7700,\tval_loss: 0.6692\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.7514,\tval_loss: 0.6538\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.7234,\tval_loss: 0.6369\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.7353,\tval_loss: 0.6237\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.6959,\tval_loss: 0.6075\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.7014,\tval_loss: 0.5933\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.6752,\tval_loss: 0.5813\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.6774,\tval_loss: 0.5742\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.6670,\tval_loss: 0.5624\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.6518,\tval_loss: 0.5555\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.6379,\tval_loss: 0.5486\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.6345,\tval_loss: 0.5405\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.6282,\tval_loss: 0.5358\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.6185,\tval_loss: 0.5313\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.6138,\tval_loss: 0.5259\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.6281,\tval_loss: 0.5222\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.6070,\tval_loss: 0.5172\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.5964,\tval_loss: 0.5142\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.5934,\tval_loss: 0.5115\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.6014,\tval_loss: 0.5086\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.5947,\tval_loss: 0.5056\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.5628,\tval_loss: 0.5030\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.5901,\tval_loss: 0.5007\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.6037,\tval_loss: 0.4987\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.5820,\tval_loss: 0.4962\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.5686,\tval_loss: 0.4939\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.5848,\tval_loss: 0.4908\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.5701,\tval_loss: 0.4883\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.5955,\tval_loss: 0.4868\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.5744,\tval_loss: 0.4857\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.5532,\tval_loss: 0.4835\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 0.5683,\tval_loss: 0.4818\n",
            "41:\t[0s / 3s],\t\ttrain_loss: 0.5583,\tval_loss: 0.4804\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 0.5460,\tval_loss: 0.4788\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 0.5447,\tval_loss: 0.4765\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 0.5478,\tval_loss: 0.4752\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 0.5517,\tval_loss: 0.4739\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 0.5390,\tval_loss: 0.4737\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 0.5451,\tval_loss: 0.4729\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 0.5468,\tval_loss: 0.4722\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 0.5259,\tval_loss: 0.4718\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 0.5361,\tval_loss: 0.4718\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 0.5426,\tval_loss: 0.4704\n",
            "52:\t[0s / 4s],\t\ttrain_loss: 0.5417,\tval_loss: 0.4689\n",
            "53:\t[0s / 4s],\t\ttrain_loss: 0.5381,\tval_loss: 0.4686\n",
            "54:\t[0s / 4s],\t\ttrain_loss: 0.5289,\tval_loss: 0.4685\n",
            "55:\t[0s / 4s],\t\ttrain_loss: 0.5432,\tval_loss: 0.4677\n",
            "56:\t[0s / 4s],\t\ttrain_loss: 0.5390,\tval_loss: 0.4674\n",
            "57:\t[0s / 4s],\t\ttrain_loss: 0.5382,\tval_loss: 0.4666\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 0.5269,\tval_loss: 0.4654\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 0.5341,\tval_loss: 0.4647\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 0.5272,\tval_loss: 0.4643\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 0.5216,\tval_loss: 0.4638\n",
            "62:\t[0s / 5s],\t\ttrain_loss: 0.5290,\tval_loss: 0.4630\n",
            "63:\t[0s / 5s],\t\ttrain_loss: 0.5231,\tval_loss: 0.4624\n",
            "64:\t[0s / 5s],\t\ttrain_loss: 0.5065,\tval_loss: 0.4615\n",
            "65:\t[0s / 5s],\t\ttrain_loss: 0.5252,\tval_loss: 0.4614\n",
            "66:\t[0s / 5s],\t\ttrain_loss: 0.5146,\tval_loss: 0.4611\n",
            "67:\t[0s / 5s],\t\ttrain_loss: 0.5198,\tval_loss: 0.4609\n",
            "68:\t[0s / 5s],\t\ttrain_loss: 0.5218,\tval_loss: 0.4608\n",
            "69:\t[0s / 5s],\t\ttrain_loss: 0.5098,\tval_loss: 0.4606\n",
            "70:\t[0s / 5s],\t\ttrain_loss: 0.5174,\tval_loss: 0.4599\n",
            "71:\t[0s / 6s],\t\ttrain_loss: 0.5168,\tval_loss: 0.4592\n",
            "72:\t[0s / 6s],\t\ttrain_loss: 0.5000,\tval_loss: 0.4589\n",
            "73:\t[0s / 6s],\t\ttrain_loss: 0.4994,\tval_loss: 0.4583\n",
            "74:\t[0s / 6s],\t\ttrain_loss: 0.5111,\tval_loss: 0.4580\n",
            "75:\t[0s / 6s],\t\ttrain_loss: 0.5251,\tval_loss: 0.4582\n",
            "76:\t[0s / 6s],\t\ttrain_loss: 0.5163,\tval_loss: 0.4584\n",
            "77:\t[0s / 6s],\t\ttrain_loss: 0.5340,\tval_loss: 0.4582\n",
            "78:\t[0s / 6s],\t\ttrain_loss: 0.4991,\tval_loss: 0.4584\n",
            "79:\t[0s / 6s],\t\ttrain_loss: 0.5038,\tval_loss: 0.4582\n",
            "80:\t[0s / 6s],\t\ttrain_loss: 0.5113,\tval_loss: 0.4577\n",
            "81:\t[0s / 6s],\t\ttrain_loss: 0.5187,\tval_loss: 0.4581\n",
            "82:\t[0s / 7s],\t\ttrain_loss: 0.5055,\tval_loss: 0.4575\n",
            "83:\t[0s / 7s],\t\ttrain_loss: 0.5070,\tval_loss: 0.4573\n",
            "84:\t[0s / 7s],\t\ttrain_loss: 0.5019,\tval_loss: 0.4571\n",
            "85:\t[0s / 7s],\t\ttrain_loss: 0.5036,\tval_loss: 0.4572\n",
            "86:\t[0s / 7s],\t\ttrain_loss: 0.4909,\tval_loss: 0.4568\n",
            "87:\t[0s / 7s],\t\ttrain_loss: 0.5014,\tval_loss: 0.4564\n",
            "88:\t[0s / 7s],\t\ttrain_loss: 0.5130,\tval_loss: 0.4566\n",
            "89:\t[0s / 7s],\t\ttrain_loss: 0.5143,\tval_loss: 0.4566\n",
            "90:\t[0s / 7s],\t\ttrain_loss: 0.5027,\tval_loss: 0.4566\n",
            "91:\t[0s / 8s],\t\ttrain_loss: 0.5035,\tval_loss: 0.4569\n",
            "92:\t[0s / 8s],\t\ttrain_loss: 0.5011,\tval_loss: 0.4571\n",
            "93:\t[0s / 8s],\t\ttrain_loss: 0.4987,\tval_loss: 0.4570\n",
            "94:\t[0s / 8s],\t\ttrain_loss: 0.4941,\tval_loss: 0.4567\n",
            "95:\t[0s / 8s],\t\ttrain_loss: 0.4955,\tval_loss: 0.4565\n",
            "96:\t[0s / 8s],\t\ttrain_loss: 0.4943,\tval_loss: 0.4560\n",
            "97:\t[0s / 8s],\t\ttrain_loss: 0.4935,\tval_loss: 0.4555\n",
            "98:\t[0s / 8s],\t\ttrain_loss: 0.5128,\tval_loss: 0.4552\n",
            "99:\t[0s / 8s],\t\ttrain_loss: 0.4990,\tval_loss: 0.4552\n",
            "Current best c-index: 0.6262249897917518\n",
            "Random search... itr: 13\n",
            "{'batch_size': 174, 'layers': 1, 'nodes': 40, 'activation_fn': 'elu', 'alpha': 0.16523568431867075, 'sigma': 0.11418776170351198, 'lr': 0.060374136280818835, 'dropout': 0.13502058495987637, 'patience': 72, 'batch_norm': False}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2540,\tval_loss: 0.2151\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2334,\tval_loss: 0.2051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 0.2171,\tval_loss: 0.2059\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.2140,\tval_loss: 0.1972\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1957,\tval_loss: 0.1939\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.2095,\tval_loss: 0.1970\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.2290,\tval_loss: 0.1898\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.2164,\tval_loss: 0.1882\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1956,\tval_loss: 0.1734\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.1848,\tval_loss: 0.1601\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1656\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.2445,\tval_loss: 0.1811\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.2109,\tval_loss: 0.1884\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.2073,\tval_loss: 0.1724\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.1873,\tval_loss: 0.1606\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.1769,\tval_loss: 0.1613\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 0.1693,\tval_loss: 0.1596\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1542\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.1500,\tval_loss: 0.1507\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.1437,\tval_loss: 0.1533\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.1414,\tval_loss: 0.1525\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.1383,\tval_loss: 0.2011\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.2428,\tval_loss: 0.2141\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.2583,\tval_loss: 0.2517\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.2478,\tval_loss: 0.2069\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.2156,\tval_loss: 0.1913\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.2019,\tval_loss: 0.1856\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.1771,\tval_loss: 0.1816\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.2233,\tval_loss: 0.2290\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 0.2370,\tval_loss: 0.2368\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 0.2386,\tval_loss: 0.2209\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 0.2137,\tval_loss: 0.1949\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 0.1837,\tval_loss: 0.1878\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 0.1842,\tval_loss: 0.1820\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 0.1673,\tval_loss: 0.1800\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 0.1845,\tval_loss: 0.2127\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.2013,\tval_loss: 0.2239\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.2007,\tval_loss: 0.2015\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.1774,\tval_loss: 0.1844\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.1854,\tval_loss: 0.1876\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 0.1734,\tval_loss: 0.1814\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 0.1735,\tval_loss: 0.1791\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 0.1664,\tval_loss: 0.1717\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 0.1462,\tval_loss: 0.1726\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 0.1415,\tval_loss: 0.1711\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 0.1422,\tval_loss: 0.1707\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 0.1384,\tval_loss: 0.1693\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 0.1262,\tval_loss: 0.1700\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 0.1294,\tval_loss: 0.1671\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 0.1231,\tval_loss: 0.1703\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 0.1221,\tval_loss: 0.1653\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 0.1211,\tval_loss: 0.1666\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 0.1232,\tval_loss: 0.1701\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 0.1312,\tval_loss: 0.1602\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 0.1503,\tval_loss: 0.1751\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 0.1567,\tval_loss: 0.1737\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1693\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 0.1372,\tval_loss: 0.1679\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 0.1326,\tval_loss: 0.1648\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 0.1355,\tval_loss: 0.1703\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 0.1309,\tval_loss: 0.1670\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 0.1273,\tval_loss: 0.1731\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 0.1261,\tval_loss: 0.1737\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 0.1211,\tval_loss: 0.1788\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 0.1154,\tval_loss: 0.1752\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 0.1126,\tval_loss: 0.1757\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 0.1127,\tval_loss: 0.1788\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 0.1128,\tval_loss: 0.1873\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 0.1107,\tval_loss: 0.1873\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 0.1114,\tval_loss: 0.1856\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 0.1081,\tval_loss: 0.1923\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 0.1140,\tval_loss: 0.2024\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 0.1107,\tval_loss: 0.2143\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 0.1096,\tval_loss: 0.1911\n",
            "74:\t[0s / 4s],\t\ttrain_loss: 0.1043,\tval_loss: 0.1904\n",
            "75:\t[0s / 4s],\t\ttrain_loss: 0.1075,\tval_loss: 0.1955\n",
            "76:\t[0s / 4s],\t\ttrain_loss: 0.0984,\tval_loss: 0.1990\n",
            "77:\t[0s / 4s],\t\ttrain_loss: 0.1053,\tval_loss: 0.1819\n",
            "78:\t[0s / 4s],\t\ttrain_loss: 0.0989,\tval_loss: 0.1899\n",
            "79:\t[0s / 4s],\t\ttrain_loss: 0.0973,\tval_loss: 0.1940\n",
            "80:\t[0s / 4s],\t\ttrain_loss: 0.0963,\tval_loss: 0.1979\n",
            "81:\t[0s / 4s],\t\ttrain_loss: 0.0947,\tval_loss: 0.1932\n",
            "82:\t[0s / 4s],\t\ttrain_loss: 0.0996,\tval_loss: 0.1880\n",
            "83:\t[0s / 4s],\t\ttrain_loss: 0.0946,\tval_loss: 0.1913\n",
            "84:\t[0s / 4s],\t\ttrain_loss: 0.0980,\tval_loss: 0.2026\n",
            "85:\t[0s / 4s],\t\ttrain_loss: 0.0950,\tval_loss: 0.2020\n",
            "86:\t[0s / 4s],\t\ttrain_loss: 0.1032,\tval_loss: 0.1904\n",
            "87:\t[0s / 4s],\t\ttrain_loss: 0.1062,\tval_loss: 0.1820\n",
            "88:\t[0s / 4s],\t\ttrain_loss: 0.1007,\tval_loss: 0.1879\n",
            "89:\t[0s / 4s],\t\ttrain_loss: 0.1017,\tval_loss: 0.1916\n",
            "90:\t[0s / 4s],\t\ttrain_loss: 0.1016,\tval_loss: 0.2033\n",
            "Current best c-index: 0.6282666394446713\n",
            "Random search... itr: 14\n",
            "{'batch_size': 54, 'layers': 1, 'nodes': 32, 'activation_fn': 'relu', 'alpha': 0.6118240833753372, 'sigma': 0.38658238403976763, 'lr': 0.043986239927665455, 'dropout': 0.4020886712126899, 'patience': 51, 'batch_norm': False}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.4538,\tval_loss: 0.3391\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.3762,\tval_loss: 0.3386\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.3529,\tval_loss: 0.3442\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.3650,\tval_loss: 0.3470\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.3499,\tval_loss: 0.3359\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.3624,\tval_loss: 0.3372\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.3377,\tval_loss: 0.3366\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.3235,\tval_loss: 0.3483\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.3257,\tval_loss: 0.3317\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.3212,\tval_loss: 0.3391\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.3174,\tval_loss: 0.3385\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.3157,\tval_loss: 0.3376\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.3127,\tval_loss: 0.3314\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.3191,\tval_loss: 0.3355\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.3230,\tval_loss: 0.3338\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.3137,\tval_loss: 0.3443\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.3100,\tval_loss: 0.3394\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.3158,\tval_loss: 0.3338\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.3146,\tval_loss: 0.3489\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.3104,\tval_loss: 0.3394\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.3094,\tval_loss: 0.3442\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.3207,\tval_loss: 0.3498\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.3367,\tval_loss: 0.3751\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.3166,\tval_loss: 0.3625\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.3083,\tval_loss: 0.3637\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.3375,\tval_loss: 0.3514\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.3136,\tval_loss: 0.3647\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.3062,\tval_loss: 0.3503\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.3051,\tval_loss: 0.3500\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.3384,\tval_loss: 0.3508\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.3173,\tval_loss: 0.3730\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.3019,\tval_loss: 0.3876\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.3275,\tval_loss: 0.3977\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.3049,\tval_loss: 0.3963\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.2936,\tval_loss: 0.3977\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.3176,\tval_loss: 0.3990\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.3030,\tval_loss: 0.4054\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.2896,\tval_loss: 0.4229\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.3002,\tval_loss: 0.4063\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.3318,\tval_loss: 0.3959\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.3034,\tval_loss: 0.3812\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.2964,\tval_loss: 0.4009\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.2848,\tval_loss: 0.4109\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.2961,\tval_loss: 0.3916\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.2893,\tval_loss: 0.4153\n",
            "45:\t[0s / 6s],\t\ttrain_loss: 0.2981,\tval_loss: 0.3981\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.2882,\tval_loss: 0.3934\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.2913,\tval_loss: 0.4086\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.3233,\tval_loss: 0.3920\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.3217,\tval_loss: 0.3903\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.2905,\tval_loss: 0.3998\n",
            "51:\t[0s / 7s],\t\ttrain_loss: 0.2973,\tval_loss: 0.4008\n",
            "52:\t[0s / 7s],\t\ttrain_loss: 0.2982,\tval_loss: 0.3988\n",
            "53:\t[0s / 7s],\t\ttrain_loss: 0.2882,\tval_loss: 0.4127\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.2910,\tval_loss: 0.4172\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.2952,\tval_loss: 0.3936\n",
            "56:\t[0s / 8s],\t\ttrain_loss: 0.2904,\tval_loss: 0.4147\n",
            "57:\t[0s / 8s],\t\ttrain_loss: 0.2889,\tval_loss: 0.4224\n",
            "58:\t[0s / 8s],\t\ttrain_loss: 0.2936,\tval_loss: 0.4301\n",
            "59:\t[0s / 8s],\t\ttrain_loss: 0.3172,\tval_loss: 0.4271\n",
            "60:\t[0s / 8s],\t\ttrain_loss: 0.2952,\tval_loss: 0.4197\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.3117,\tval_loss: 0.4288\n",
            "62:\t[0s / 9s],\t\ttrain_loss: 0.2987,\tval_loss: 0.4163\n",
            "63:\t[0s / 9s],\t\ttrain_loss: 0.2910,\tval_loss: 0.4150\n",
            "Current best c-index: 0.6282666394446713\n",
            "Random search... itr: 15\n",
            "{'batch_size': 76, 'layers': 2, 'nodes': 45, 'activation_fn': 'elu', 'alpha': 0.7854100568335974, 'sigma': 0.19355631310532168, 'lr': 0.07932937045500837, 'dropout': 0.0046879434019114425, 'patience': 37, 'batch_norm': True}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.5398,\tval_loss: 0.4130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.4290,\tval_loss: 0.4134\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.4220,\tval_loss: 0.4168\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.4117,\tval_loss: 0.4190\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.3988,\tval_loss: 0.4075\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4026,\tval_loss: 0.4106\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.3950,\tval_loss: 0.4190\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.3919,\tval_loss: 0.4248\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.3894,\tval_loss: 0.4375\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.4035,\tval_loss: 0.4239\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.3828,\tval_loss: 0.4585\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.3708,\tval_loss: 0.4810\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.3798,\tval_loss: 0.4493\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.3852,\tval_loss: 0.4743\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.3662,\tval_loss: 0.4633\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.3783,\tval_loss: 0.4399\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.3942,\tval_loss: 0.4336\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.3877,\tval_loss: 0.4768\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.3674,\tval_loss: 0.4649\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.3634,\tval_loss: 0.4945\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.3597,\tval_loss: 0.4424\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.3527,\tval_loss: 0.5212\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.3349,\tval_loss: 0.5382\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.3542,\tval_loss: 0.5035\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.3246,\tval_loss: 0.4948\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.3277,\tval_loss: 0.5331\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.3367,\tval_loss: 1.4340\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.3317,\tval_loss: 2.9771\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.3309,\tval_loss: 0.5818\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.3442,\tval_loss: 0.5427\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.3366,\tval_loss: 0.5629\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.3393,\tval_loss: 0.6184\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.3158,\tval_loss: 0.5606\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.2920,\tval_loss: 0.5730\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.2912,\tval_loss: 0.6043\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.2995,\tval_loss: 0.5990\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.3127,\tval_loss: 0.5594\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.2983,\tval_loss: 0.6232\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.2856,\tval_loss: 0.5866\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.2809,\tval_loss: 0.5894\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.2845,\tval_loss: 0.6143\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.2814,\tval_loss: 0.6222\n",
            "Current best c-index: 0.6282666394446713\n",
            "Random search... itr: 16\n",
            "{'batch_size': 113, 'layers': 3, 'nodes': 35, 'activation_fn': 'elu', 'alpha': 0.16469389587712324, 'sigma': 0.5497471536132144, 'lr': 0.06434311591017271, 'dropout': 0.6666477592069613, 'patience': 41, 'batch_norm': False}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2662,\tval_loss: 0.1589\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1890,\tval_loss: 0.1430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1663,\tval_loss: 0.1423\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1418\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1419\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1502,\tval_loss: 0.1413\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1499,\tval_loss: 0.1408\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1525,\tval_loss: 0.1410\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1480,\tval_loss: 0.1409\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1407\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.1467,\tval_loss: 0.1412\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1482,\tval_loss: 0.1409\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1478,\tval_loss: 0.1408\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1488,\tval_loss: 0.1409\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1476,\tval_loss: 0.1410\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1483,\tval_loss: 0.1406\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1482,\tval_loss: 0.1409\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1473,\tval_loss: 0.1407\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.1453,\tval_loss: 0.1407\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.1489,\tval_loss: 0.1410\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.1474,\tval_loss: 0.1408\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.1474,\tval_loss: 0.1406\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.1469,\tval_loss: 0.1408\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1466,\tval_loss: 0.1407\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1471,\tval_loss: 0.1408\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1406\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1483,\tval_loss: 0.1407\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1478,\tval_loss: 0.1407\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.1474,\tval_loss: 0.1407\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.1471,\tval_loss: 0.1411\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.1470,\tval_loss: 0.1407\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.1480,\tval_loss: 0.1409\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.1488,\tval_loss: 0.1407\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1456\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.1584,\tval_loss: 0.1408\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1494,\tval_loss: 0.1409\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.1465,\tval_loss: 0.1406\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.1469,\tval_loss: 0.1408\n",
            "38:\t[0s / 3s],\t\ttrain_loss: 0.1478,\tval_loss: 0.1407\n",
            "39:\t[0s / 3s],\t\ttrain_loss: 0.1485,\tval_loss: 0.1407\n",
            "40:\t[0s / 3s],\t\ttrain_loss: 0.1477,\tval_loss: 0.1408\n",
            "41:\t[0s / 3s],\t\ttrain_loss: 0.1468,\tval_loss: 0.1408\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 0.1480,\tval_loss: 0.1408\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 0.1470,\tval_loss: 0.1409\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 0.1484,\tval_loss: 0.1408\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1408\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 0.1468,\tval_loss: 0.1406\n",
            "47:\t[0s / 4s],\t\ttrain_loss: 0.1469,\tval_loss: 0.1406\n",
            "48:\t[0s / 4s],\t\ttrain_loss: 0.1489,\tval_loss: 0.1407\n",
            "49:\t[0s / 4s],\t\ttrain_loss: 0.1481,\tval_loss: 0.1410\n",
            "50:\t[0s / 4s],\t\ttrain_loss: 0.1470,\tval_loss: 0.1407\n",
            "51:\t[0s / 4s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1405\n",
            "52:\t[0s / 4s],\t\ttrain_loss: 0.1480,\tval_loss: 0.1409\n",
            "53:\t[0s / 4s],\t\ttrain_loss: 0.1493,\tval_loss: 0.1411\n",
            "54:\t[0s / 4s],\t\ttrain_loss: 0.1474,\tval_loss: 0.1408\n",
            "55:\t[0s / 4s],\t\ttrain_loss: 0.1473,\tval_loss: 0.1407\n",
            "56:\t[0s / 4s],\t\ttrain_loss: 0.1464,\tval_loss: 0.1406\n",
            "57:\t[0s / 4s],\t\ttrain_loss: 0.1486,\tval_loss: 0.1408\n",
            "58:\t[0s / 5s],\t\ttrain_loss: 0.1480,\tval_loss: 0.1407\n",
            "59:\t[0s / 5s],\t\ttrain_loss: 0.1474,\tval_loss: 0.1406\n",
            "60:\t[0s / 5s],\t\ttrain_loss: 0.1481,\tval_loss: 0.1409\n",
            "61:\t[0s / 5s],\t\ttrain_loss: 0.1503,\tval_loss: 0.1405\n",
            "62:\t[0s / 5s],\t\ttrain_loss: 0.1472,\tval_loss: 0.1409\n",
            "63:\t[0s / 5s],\t\ttrain_loss: 0.1467,\tval_loss: 0.1408\n",
            "64:\t[0s / 5s],\t\ttrain_loss: 0.1466,\tval_loss: 0.1408\n",
            "65:\t[0s / 5s],\t\ttrain_loss: 0.1487,\tval_loss: 0.1407\n",
            "66:\t[0s / 6s],\t\ttrain_loss: 0.1483,\tval_loss: 0.1409\n",
            "67:\t[0s / 6s],\t\ttrain_loss: 0.1485,\tval_loss: 0.1408\n",
            "68:\t[0s / 6s],\t\ttrain_loss: 0.1462,\tval_loss: 0.1405\n",
            "69:\t[0s / 6s],\t\ttrain_loss: 0.1482,\tval_loss: 0.1409\n",
            "70:\t[0s / 6s],\t\ttrain_loss: 0.1461,\tval_loss: 0.1407\n",
            "71:\t[0s / 6s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1411\n",
            "72:\t[0s / 6s],\t\ttrain_loss: 0.1464,\tval_loss: 0.1407\n",
            "73:\t[0s / 6s],\t\ttrain_loss: 0.1486,\tval_loss: 0.1405\n",
            "74:\t[0s / 7s],\t\ttrain_loss: 0.1477,\tval_loss: 0.1408\n",
            "75:\t[0s / 7s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1410\n",
            "76:\t[0s / 7s],\t\ttrain_loss: 0.1468,\tval_loss: 0.1407\n",
            "77:\t[0s / 7s],\t\ttrain_loss: 0.1481,\tval_loss: 0.1408\n",
            "78:\t[0s / 7s],\t\ttrain_loss: 0.1466,\tval_loss: 0.1407\n",
            "79:\t[0s / 7s],\t\ttrain_loss: 0.1467,\tval_loss: 0.1405\n",
            "80:\t[0s / 7s],\t\ttrain_loss: 0.1456,\tval_loss: 0.1409\n",
            "81:\t[0s / 7s],\t\ttrain_loss: 0.1485,\tval_loss: 0.1408\n",
            "82:\t[0s / 8s],\t\ttrain_loss: 0.1479,\tval_loss: 0.1409\n",
            "83:\t[0s / 8s],\t\ttrain_loss: 0.1483,\tval_loss: 0.1405\n",
            "84:\t[0s / 8s],\t\ttrain_loss: 0.1469,\tval_loss: 0.1406\n",
            "85:\t[0s / 8s],\t\ttrain_loss: 0.1473,\tval_loss: 0.1408\n",
            "86:\t[0s / 8s],\t\ttrain_loss: 0.1479,\tval_loss: 0.1407\n",
            "87:\t[0s / 8s],\t\ttrain_loss: 0.1481,\tval_loss: 0.1409\n",
            "88:\t[0s / 8s],\t\ttrain_loss: 0.1477,\tval_loss: 0.1406\n",
            "89:\t[0s / 8s],\t\ttrain_loss: 0.1461,\tval_loss: 0.1409\n",
            "90:\t[0s / 9s],\t\ttrain_loss: 0.1462,\tval_loss: 0.1408\n",
            "91:\t[0s / 9s],\t\ttrain_loss: 0.1488,\tval_loss: 0.1407\n",
            "92:\t[0s / 9s],\t\ttrain_loss: 0.1474,\tval_loss: 0.1407\n",
            "Current best c-index: 0.6282666394446713\n",
            "Random search... itr: 17\n",
            "{'batch_size': 133, 'layers': 4, 'nodes': 56, 'activation_fn': 'elu', 'alpha': 0.8962128087638129, 'sigma': 0.9245056863495069, 'lr': 0.031118944150988877, 'dropout': 0.13322835665052216, 'patience': 62, 'batch_norm': True}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6099,\tval_loss: 0.5564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.4743,\tval_loss: 0.4589\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.4452,\tval_loss: 0.4597\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5181,\tval_loss: 0.4746\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5905,\tval_loss: 0.4933\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4410,\tval_loss: 0.4412\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.4409,\tval_loss: 0.4526\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.5006,\tval_loss: 0.4682\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.5250,\tval_loss: 0.4440\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.4384,\tval_loss: 0.4661\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.4397,\tval_loss: 0.4424\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.4122,\tval_loss: 0.4449\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.3968,\tval_loss: 0.4601\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.4044,\tval_loss: 0.4570\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.3968,\tval_loss: 0.4594\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.3973,\tval_loss: 0.4565\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.3868,\tval_loss: 0.4711\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.4218,\tval_loss: 0.4780\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.4048,\tval_loss: 0.4783\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.4469,\tval_loss: 0.4560\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.4172,\tval_loss: 0.4573\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.4266,\tval_loss: 0.4562\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.4272,\tval_loss: 0.4735\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.4032,\tval_loss: 0.4671\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.4413,\tval_loss: 0.4641\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.4146,\tval_loss: 0.4628\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.4220,\tval_loss: 0.4666\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.3897,\tval_loss: 0.4754\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.3731,\tval_loss: 0.4806\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.3762,\tval_loss: 0.4803\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.3682,\tval_loss: 0.4776\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.4129,\tval_loss: 0.4798\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.3797,\tval_loss: 0.4859\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.3756,\tval_loss: 0.4721\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.3771,\tval_loss: 0.4791\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.3715,\tval_loss: 0.4753\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.3618,\tval_loss: 0.4734\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.4193,\tval_loss: 0.4895\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.3639,\tval_loss: 0.4937\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.3818,\tval_loss: 0.4831\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.3806,\tval_loss: 0.5008\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.3629,\tval_loss: 0.5155\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.4046,\tval_loss: 0.4929\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.3969,\tval_loss: 0.4638\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.3777,\tval_loss: 0.4768\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.3666,\tval_loss: 0.5139\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.4076,\tval_loss: 0.4958\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.4567,\tval_loss: 0.5187\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.4211,\tval_loss: 0.4923\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.3624,\tval_loss: 0.4910\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.3693,\tval_loss: 0.4869\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.3966,\tval_loss: 0.4996\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.4373,\tval_loss: 0.4972\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.3892,\tval_loss: 0.4813\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.3834,\tval_loss: 0.4712\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.4263,\tval_loss: 0.4834\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.4696,\tval_loss: 0.4812\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.3987,\tval_loss: 0.4682\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.3868,\tval_loss: 0.4681\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.3582,\tval_loss: 0.4869\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.3566,\tval_loss: 0.4896\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.3476,\tval_loss: 0.4987\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.3456,\tval_loss: 0.5021\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.3750,\tval_loss: 0.5009\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.3817,\tval_loss: 0.5278\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.4204,\tval_loss: 0.4876\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.3850,\tval_loss: 0.4722\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.4058,\tval_loss: 0.4675\n",
            "Current best c-index: 0.6282666394446713\n",
            "Random search... itr: 18\n",
            "{'batch_size': 192, 'layers': 4, 'nodes': 68, 'activation_fn': 'tanh', 'alpha': 0.4207282357353004, 'sigma': 0.48651588730628914, 'lr': 0.054221104199881826, 'dropout': 0.2423782609999618, 'patience': 61, 'batch_norm': True}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.3660,\tval_loss: 0.6396\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2876,\tval_loss: 0.2760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 0.2638,\tval_loss: 0.2637\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.2614,\tval_loss: 0.2613\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.2609,\tval_loss: 0.2476\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.2556,\tval_loss: 0.2504\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.2461,\tval_loss: 0.2476\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.2490,\tval_loss: 0.2473\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.2466,\tval_loss: 0.2478\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.2437,\tval_loss: 0.2544\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.2371,\tval_loss: 0.2496\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.2435,\tval_loss: 0.2546\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.2486,\tval_loss: 0.2531\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.2509,\tval_loss: 0.2601\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.2493,\tval_loss: 0.2532\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.2353,\tval_loss: 0.2557\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.2354,\tval_loss: 0.2614\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.2366,\tval_loss: 0.2618\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.2410,\tval_loss: 0.2630\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.2413,\tval_loss: 0.2563\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.2440,\tval_loss: 0.2598\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.2328,\tval_loss: 0.2522\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.2351,\tval_loss: 0.2647\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.2297,\tval_loss: 0.2698\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.2289,\tval_loss: 0.2591\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.2283,\tval_loss: 0.2582\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.2343,\tval_loss: 0.2637\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.2338,\tval_loss: 0.2677\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.2169,\tval_loss: 0.2769\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.2321,\tval_loss: 0.2756\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.2234,\tval_loss: 0.2838\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.2190,\tval_loss: 0.2665\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.2225,\tval_loss: 0.2862\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.2315,\tval_loss: 0.2684\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.2170,\tval_loss: 0.2819\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.2222,\tval_loss: 0.2837\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.2289,\tval_loss: 0.2744\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.2188,\tval_loss: 0.2855\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.2222,\tval_loss: 0.2839\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.2173,\tval_loss: 0.2982\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.2184,\tval_loss: 0.2730\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.2197,\tval_loss: 0.2783\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.2127,\tval_loss: 0.2840\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.2196,\tval_loss: 0.2750\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.2035,\tval_loss: 0.2985\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.2165,\tval_loss: 0.2867\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.2169,\tval_loss: 0.2814\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.2163,\tval_loss: 0.2736\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.2117,\tval_loss: 0.2793\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.2116,\tval_loss: 0.2812\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.2100,\tval_loss: 0.2842\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.2087,\tval_loss: 0.2820\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.2065,\tval_loss: 0.2870\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.2243,\tval_loss: 0.2830\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.2121,\tval_loss: 0.2896\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.2088,\tval_loss: 0.3078\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.2052,\tval_loss: 0.3027\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.2037,\tval_loss: 0.2899\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.2072,\tval_loss: 0.3044\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1943,\tval_loss: 0.3081\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.2096,\tval_loss: 0.2910\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.2082,\tval_loss: 0.2962\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.2001,\tval_loss: 0.3001\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.2011,\tval_loss: 0.3015\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.1931,\tval_loss: 0.3003\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.2038,\tval_loss: 0.3031\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.2012,\tval_loss: 0.3006\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1936,\tval_loss: 0.3171\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.2146,\tval_loss: 0.3000\n",
            "Current best c-index: 0.6282666394446713\n",
            "Random search... itr: 19\n",
            "{'batch_size': 130, 'layers': 3, 'nodes': 89, 'activation_fn': 'tanh', 'alpha': 0.1634512911820602, 'sigma': 0.9968793745597865, 'lr': 0.05383633524786459, 'dropout': 0.782457166677337, 'patience': 68, 'batch_norm': True}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2428,\tval_loss: 0.1485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2122,\tval_loss: 0.1401\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1667,\tval_loss: 0.1442\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1401\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1400\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1494,\tval_loss: 0.1409\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1410\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1502,\tval_loss: 0.1405\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1537,\tval_loss: 0.1412\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1525,\tval_loss: 0.1400\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1556,\tval_loss: 0.1399\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1489,\tval_loss: 0.1408\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1413\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1504,\tval_loss: 0.1398\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1406\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1531,\tval_loss: 0.1402\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1400\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1419\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.1565,\tval_loss: 0.1399\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1407\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1482,\tval_loss: 0.1403\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1522,\tval_loss: 0.1403\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1516,\tval_loss: 0.1408\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1582,\tval_loss: 0.1396\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1518,\tval_loss: 0.1403\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1563,\tval_loss: 0.1402\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1555,\tval_loss: 0.1401\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1403\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1406\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1509,\tval_loss: 0.1409\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1512,\tval_loss: 0.1420\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1500,\tval_loss: 0.1391\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1395\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1530,\tval_loss: 0.1406\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1489,\tval_loss: 0.1391\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1502,\tval_loss: 0.1398\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.1539,\tval_loss: 0.1397\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.1582,\tval_loss: 0.1404\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1412\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1514,\tval_loss: 0.1416\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1410\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1518,\tval_loss: 0.1410\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1395\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1493,\tval_loss: 0.1397\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1403\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.1534,\tval_loss: 0.1387\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.1509,\tval_loss: 0.1423\n",
            "47:\t[0s / 4s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1399\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1397\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1531,\tval_loss: 0.1411\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1526,\tval_loss: 0.1424\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1409\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1394\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1541,\tval_loss: 0.1411\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1385\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1413\n",
            "56:\t[0s / 5s],\t\ttrain_loss: 0.1555,\tval_loss: 0.1403\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1425\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1397\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1401\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1499,\tval_loss: 0.1413\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.1554,\tval_loss: 0.1399\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1408\n",
            "63:\t[0s / 6s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1395\n",
            "64:\t[0s / 6s],\t\ttrain_loss: 0.1534,\tval_loss: 0.1397\n",
            "65:\t[0s / 6s],\t\ttrain_loss: 0.1537,\tval_loss: 0.1408\n",
            "66:\t[0s / 6s],\t\ttrain_loss: 0.1582,\tval_loss: 0.1408\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1392\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1541,\tval_loss: 0.1395\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.1592,\tval_loss: 0.1422\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1391\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.1554,\tval_loss: 0.1410\n",
            "72:\t[0s / 7s],\t\ttrain_loss: 0.1571,\tval_loss: 0.1406\n",
            "73:\t[0s / 7s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1403\n",
            "74:\t[0s / 7s],\t\ttrain_loss: 0.1606,\tval_loss: 0.1390\n",
            "75:\t[0s / 7s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1392\n",
            "76:\t[0s / 7s],\t\ttrain_loss: 0.1562,\tval_loss: 0.1390\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.1559,\tval_loss: 0.1401\n",
            "78:\t[0s / 8s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1407\n",
            "79:\t[0s / 8s],\t\ttrain_loss: 0.1580,\tval_loss: 0.1414\n",
            "80:\t[0s / 8s],\t\ttrain_loss: 0.1511,\tval_loss: 0.1397\n",
            "81:\t[0s / 8s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1400\n",
            "82:\t[0s / 8s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1413\n",
            "83:\t[0s / 8s],\t\ttrain_loss: 0.1497,\tval_loss: 0.1400\n",
            "84:\t[0s / 8s],\t\ttrain_loss: 0.1537,\tval_loss: 0.1402\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1390\n",
            "86:\t[0s / 9s],\t\ttrain_loss: 0.1510,\tval_loss: 0.1399\n",
            "87:\t[0s / 9s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1392\n",
            "88:\t[0s / 9s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1400\n",
            "89:\t[0s / 9s],\t\ttrain_loss: 0.1502,\tval_loss: 0.1395\n",
            "90:\t[0s / 10s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1395\n",
            "91:\t[0s / 10s],\t\ttrain_loss: 0.1537,\tval_loss: 0.1420\n",
            "92:\t[0s / 10s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1408\n",
            "93:\t[0s / 10s],\t\ttrain_loss: 0.1497,\tval_loss: 0.1384\n",
            "94:\t[0s / 10s],\t\ttrain_loss: 0.1530,\tval_loss: 0.1388\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.1516,\tval_loss: 0.1395\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.1488,\tval_loss: 0.1400\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1393\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1406\n",
            "99:\t[0s / 11s],\t\ttrain_loss: 0.1509,\tval_loss: 0.1391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 20\n",
            "{'batch_size': 143, 'layers': 3, 'nodes': 25, 'activation_fn': 'relu', 'alpha': 0.3685204379003709, 'sigma': 0.6707332861741353, 'lr': 0.01648528631483533, 'dropout': 0.7904520730033374, 'patience': 53, 'batch_norm': False}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6421,\tval_loss: 0.2834\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.3742,\tval_loss: 0.2801\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.3531,\tval_loss: 0.2611\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.3031,\tval_loss: 0.2468\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.2703,\tval_loss: 0.2350\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.2644,\tval_loss: 0.2309\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.2593,\tval_loss: 0.2310\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.2471,\tval_loss: 0.2289\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.2513,\tval_loss: 0.2267\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.2487,\tval_loss: 0.2271\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.2436,\tval_loss: 0.2256\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.2423,\tval_loss: 0.2251\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.2412,\tval_loss: 0.2255\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.2437,\tval_loss: 0.2261\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.2394,\tval_loss: 0.2262\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.2423,\tval_loss: 0.2252\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.2390,\tval_loss: 0.2252\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.2386,\tval_loss: 0.2254\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.2383,\tval_loss: 0.2256\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.2362,\tval_loss: 0.2249\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.2405,\tval_loss: 0.2247\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.2380,\tval_loss: 0.2242\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.2377,\tval_loss: 0.2249\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.2387,\tval_loss: 0.2251\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.2360,\tval_loss: 0.2250\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.2367,\tval_loss: 0.2248\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.2366,\tval_loss: 0.2246\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.2359,\tval_loss: 0.2247\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.2374,\tval_loss: 0.2249\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.2361,\tval_loss: 0.2250\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.2378,\tval_loss: 0.2253\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.2363,\tval_loss: 0.2248\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.2358,\tval_loss: 0.2245\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.2369,\tval_loss: 0.2251\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.2361,\tval_loss: 0.2250\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.2362,\tval_loss: 0.2252\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.2356,\tval_loss: 0.2248\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.2369,\tval_loss: 0.2242\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.2356,\tval_loss: 0.2244\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.2377,\tval_loss: 0.2246\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.2364,\tval_loss: 0.2248\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.2356,\tval_loss: 0.2251\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.2353,\tval_loss: 0.2253\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.2357,\tval_loss: 0.2250\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.2349,\tval_loss: 0.2249\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.2355,\tval_loss: 0.2248\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.2361,\tval_loss: 0.2249\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.2352,\tval_loss: 0.2254\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.2346,\tval_loss: 0.2251\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.2364,\tval_loss: 0.2255\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.2368,\tval_loss: 0.2254\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.2353,\tval_loss: 0.2255\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.2349,\tval_loss: 0.2252\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.2344,\tval_loss: 0.2248\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.2349,\tval_loss: 0.2247\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.2356,\tval_loss: 0.2247\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.2358,\tval_loss: 0.2248\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.2345,\tval_loss: 0.2250\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.2350,\tval_loss: 0.2251\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.2348,\tval_loss: 0.2248\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.2358,\tval_loss: 0.2246\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.2343,\tval_loss: 0.2247\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.2360,\tval_loss: 0.2249\n",
            "63:\t[0s / 6s],\t\ttrain_loss: 0.2348,\tval_loss: 0.2251\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.2348,\tval_loss: 0.2250\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.2354,\tval_loss: 0.2250\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.2355,\tval_loss: 0.2249\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.2355,\tval_loss: 0.2251\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.2352,\tval_loss: 0.2249\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.2345,\tval_loss: 0.2246\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.2352,\tval_loss: 0.2248\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.2347,\tval_loss: 0.2248\n",
            "72:\t[0s / 7s],\t\ttrain_loss: 0.2351,\tval_loss: 0.2250\n",
            "73:\t[0s / 7s],\t\ttrain_loss: 0.2348,\tval_loss: 0.2250\n",
            "74:\t[0s / 7s],\t\ttrain_loss: 0.2350,\tval_loss: 0.2251\n",
            "75:\t[0s / 7s],\t\ttrain_loss: 0.2348,\tval_loss: 0.2251\n",
            "76:\t[0s / 7s],\t\ttrain_loss: 0.2346,\tval_loss: 0.2250\n",
            "77:\t[0s / 7s],\t\ttrain_loss: 0.2349,\tval_loss: 0.2248\n",
            "78:\t[0s / 7s],\t\ttrain_loss: 0.2350,\tval_loss: 0.2249\n",
            "79:\t[0s / 8s],\t\ttrain_loss: 0.2351,\tval_loss: 0.2250\n",
            "80:\t[0s / 8s],\t\ttrain_loss: 0.2350,\tval_loss: 0.2253\n",
            "81:\t[0s / 8s],\t\ttrain_loss: 0.2354,\tval_loss: 0.2250\n",
            "82:\t[0s / 8s],\t\ttrain_loss: 0.2344,\tval_loss: 0.2249\n",
            "83:\t[0s / 8s],\t\ttrain_loss: 0.2347,\tval_loss: 0.2249\n",
            "84:\t[0s / 8s],\t\ttrain_loss: 0.2348,\tval_loss: 0.2247\n",
            "85:\t[0s / 8s],\t\ttrain_loss: 0.2352,\tval_loss: 0.2251\n",
            "86:\t[0s / 8s],\t\ttrain_loss: 0.2342,\tval_loss: 0.2249\n",
            "87:\t[0s / 8s],\t\ttrain_loss: 0.2348,\tval_loss: 0.2249\n",
            "88:\t[0s / 8s],\t\ttrain_loss: 0.2347,\tval_loss: 0.2251\n",
            "89:\t[0s / 8s],\t\ttrain_loss: 0.2346,\tval_loss: 0.2250\n",
            "90:\t[0s / 8s],\t\ttrain_loss: 0.2349,\tval_loss: 0.2248\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 21\n",
            "{'batch_size': 194, 'layers': 1, 'nodes': 89, 'activation_fn': 'elu', 'alpha': 0.8152203146509477, 'sigma': 0.7646426296708411, 'lr': 0.09934352614402893, 'dropout': 0.32022220842480115, 'patience': 37, 'batch_norm': True}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.7702,\tval_loss: 0.5080\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.4913,\tval_loss: 0.4280\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.4505,\tval_loss: 0.4354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 0.4434,\tval_loss: 0.4190\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.4239,\tval_loss: 0.4149\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.3998,\tval_loss: 0.4237\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.4182,\tval_loss: 0.4194\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.4033,\tval_loss: 0.4125\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.4076,\tval_loss: 0.4223\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.4114,\tval_loss: 0.4477\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.4151,\tval_loss: 0.4358\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.4027,\tval_loss: 0.4242\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.3908,\tval_loss: 0.4462\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.4049,\tval_loss: 0.4350\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.3999,\tval_loss: 0.4313\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.4084,\tval_loss: 0.4438\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.4248,\tval_loss: 0.4297\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.3989,\tval_loss: 0.4421\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.4191,\tval_loss: 0.4419\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.4085,\tval_loss: 0.4400\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.3848,\tval_loss: 0.4359\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.3885,\tval_loss: 0.4343\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.3917,\tval_loss: 0.4588\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.4149,\tval_loss: 0.4378\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.3584,\tval_loss: 0.4734\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.3811,\tval_loss: 0.4652\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.4059,\tval_loss: 0.4607\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.3816,\tval_loss: 0.4735\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.3870,\tval_loss: 0.4919\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 0.3988,\tval_loss: 0.4730\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 0.4011,\tval_loss: 0.4795\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 0.3765,\tval_loss: 0.4866\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.3721,\tval_loss: 0.5130\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.3871,\tval_loss: 0.4884\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.3626,\tval_loss: 0.4893\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.3859,\tval_loss: 0.5297\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.3775,\tval_loss: 0.5064\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.3780,\tval_loss: 0.4822\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.3487,\tval_loss: 0.4997\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.3779,\tval_loss: 0.5151\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 0.3555,\tval_loss: 0.5179\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 0.4012,\tval_loss: 0.4943\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 0.3863,\tval_loss: 0.4985\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 0.3979,\tval_loss: 0.5259\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 0.3794,\tval_loss: 0.5134\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 22\n",
            "{'batch_size': 237, 'layers': 2, 'nodes': 78, 'activation_fn': 'tanh', 'alpha': 0.15446883442999224, 'sigma': 0.47801826294342065, 'lr': 0.09779199954757815, 'dropout': 0.7252935657200946, 'patience': 51, 'batch_norm': True}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2457,\tval_loss: 0.1906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2048,\tval_loss: 0.1454\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1677,\tval_loss: 0.1397\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1359\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1401\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1541,\tval_loss: 0.1362\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1377\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1507,\tval_loss: 0.1368\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1378\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.1489,\tval_loss: 0.1381\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.1504,\tval_loss: 0.1379\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.1491,\tval_loss: 0.1411\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.1490,\tval_loss: 0.1378\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.1477,\tval_loss: 0.1356\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.1465,\tval_loss: 0.1371\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1508,\tval_loss: 0.1354\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1484,\tval_loss: 0.1371\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1451,\tval_loss: 0.1364\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.1486,\tval_loss: 0.1346\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.1493,\tval_loss: 0.1351\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.1503,\tval_loss: 0.1352\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.1478,\tval_loss: 0.1406\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.1509,\tval_loss: 0.1372\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.1497,\tval_loss: 0.1360\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.1493,\tval_loss: 0.1391\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.1541,\tval_loss: 0.1371\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.1491,\tval_loss: 0.1349\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1362\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.1521,\tval_loss: 0.1389\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 0.1479,\tval_loss: 0.1347\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.1420,\tval_loss: 0.1349\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.1515,\tval_loss: 0.1347\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1368\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1370\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.1509,\tval_loss: 0.1353\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.1486,\tval_loss: 0.1357\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.1500,\tval_loss: 0.1354\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.1505,\tval_loss: 0.1351\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.1496,\tval_loss: 0.1353\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.1493,\tval_loss: 0.1354\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 0.1500,\tval_loss: 0.1354\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1349\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1392\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 0.1462,\tval_loss: 0.1368\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 0.1481,\tval_loss: 0.1355\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1371\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 0.1497,\tval_loss: 0.1387\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 0.1482,\tval_loss: 0.1361\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 0.1519,\tval_loss: 0.1335\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 0.1490,\tval_loss: 0.1356\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 0.1461,\tval_loss: 0.1388\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 0.1480,\tval_loss: 0.1373\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 0.1482,\tval_loss: 0.1366\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1354\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 0.1522,\tval_loss: 0.1349\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 0.1522,\tval_loss: 0.1355\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 0.1443,\tval_loss: 0.1357\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1363\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 0.1523,\tval_loss: 0.1345\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1368\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 0.1457,\tval_loss: 0.1351\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 0.1487,\tval_loss: 0.1404\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 0.1503,\tval_loss: 0.1349\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 0.1481,\tval_loss: 0.1348\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 0.1461,\tval_loss: 0.1373\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 0.1489,\tval_loss: 0.1332\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 0.1486,\tval_loss: 0.1358\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 0.1464,\tval_loss: 0.1366\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1345\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 0.1453,\tval_loss: 0.1355\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 0.1452,\tval_loss: 0.1350\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 0.1471,\tval_loss: 0.1358\n",
            "72:\t[0s / 5s],\t\ttrain_loss: 0.1464,\tval_loss: 0.1361\n",
            "73:\t[0s / 5s],\t\ttrain_loss: 0.1463,\tval_loss: 0.1344\n",
            "74:\t[0s / 5s],\t\ttrain_loss: 0.1485,\tval_loss: 0.1383\n",
            "75:\t[0s / 5s],\t\ttrain_loss: 0.1470,\tval_loss: 0.1345\n",
            "76:\t[0s / 5s],\t\ttrain_loss: 0.1502,\tval_loss: 0.1369\n",
            "77:\t[0s / 5s],\t\ttrain_loss: 0.1494,\tval_loss: 0.1353\n",
            "78:\t[0s / 5s],\t\ttrain_loss: 0.1483,\tval_loss: 0.1367\n",
            "79:\t[0s / 5s],\t\ttrain_loss: 0.1453,\tval_loss: 0.1358\n",
            "80:\t[0s / 5s],\t\ttrain_loss: 0.1502,\tval_loss: 0.1359\n",
            "81:\t[0s / 5s],\t\ttrain_loss: 0.1526,\tval_loss: 0.1386\n",
            "82:\t[0s / 5s],\t\ttrain_loss: 0.1497,\tval_loss: 0.1355\n",
            "83:\t[0s / 6s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1378\n",
            "84:\t[0s / 6s],\t\ttrain_loss: 0.1457,\tval_loss: 0.1347\n",
            "85:\t[0s / 6s],\t\ttrain_loss: 0.1502,\tval_loss: 0.1360\n",
            "86:\t[0s / 6s],\t\ttrain_loss: 0.1449,\tval_loss: 0.1368\n",
            "87:\t[0s / 6s],\t\ttrain_loss: 0.1477,\tval_loss: 0.1361\n",
            "88:\t[0s / 6s],\t\ttrain_loss: 0.1473,\tval_loss: 0.1378\n",
            "89:\t[0s / 6s],\t\ttrain_loss: 0.1439,\tval_loss: 0.1352\n",
            "90:\t[0s / 6s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1370\n",
            "91:\t[0s / 6s],\t\ttrain_loss: 0.1494,\tval_loss: 0.1339\n",
            "92:\t[0s / 6s],\t\ttrain_loss: 0.1471,\tval_loss: 0.1364\n",
            "93:\t[0s / 6s],\t\ttrain_loss: 0.1516,\tval_loss: 0.1375\n",
            "94:\t[0s / 7s],\t\ttrain_loss: 0.1498,\tval_loss: 0.1371\n",
            "95:\t[0s / 7s],\t\ttrain_loss: 0.1436,\tval_loss: 0.1397\n",
            "96:\t[0s / 7s],\t\ttrain_loss: 0.1505,\tval_loss: 0.1364\n",
            "97:\t[0s / 7s],\t\ttrain_loss: 0.1515,\tval_loss: 0.1371\n",
            "98:\t[0s / 7s],\t\ttrain_loss: 0.1466,\tval_loss: 0.1369\n",
            "99:\t[0s / 7s],\t\ttrain_loss: 0.1440,\tval_loss: 0.1394\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 23\n",
            "{'batch_size': 104, 'layers': 1, 'nodes': 65, 'activation_fn': 'relu', 'alpha': 0.18976645664355862, 'sigma': 0.5676024473096796, 'lr': 0.04743251204350298, 'dropout': 0.8396649818591223, 'patience': 62, 'batch_norm': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2504,\tval_loss: 0.1762\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2064,\tval_loss: 0.1544\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1708,\tval_loss: 0.1504\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1672,\tval_loss: 0.1494\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1671,\tval_loss: 0.1515\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1698,\tval_loss: 0.1512\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1648,\tval_loss: 0.1515\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1502\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1493\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1621,\tval_loss: 0.1510\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1596,\tval_loss: 0.1487\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1563,\tval_loss: 0.1516\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1500\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1551,\tval_loss: 0.1512\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1624,\tval_loss: 0.1508\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1495\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1605,\tval_loss: 0.1519\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1554,\tval_loss: 0.1529\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1654,\tval_loss: 0.1509\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1503\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1584,\tval_loss: 0.1480\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1676,\tval_loss: 0.1496\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1482\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1490\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1476\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1506\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1617,\tval_loss: 0.1503\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1485\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.1583,\tval_loss: 0.1498\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.1577,\tval_loss: 0.1500\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1670,\tval_loss: 0.1485\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1504\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1484\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1606,\tval_loss: 0.1485\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1653,\tval_loss: 0.1500\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1489\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1505\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1499\n",
            "38:\t[0s / 3s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1513\n",
            "39:\t[0s / 3s],\t\ttrain_loss: 0.1584,\tval_loss: 0.1493\n",
            "40:\t[0s / 3s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1491\n",
            "41:\t[0s / 3s],\t\ttrain_loss: 0.1606,\tval_loss: 0.1505\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1519\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1639,\tval_loss: 0.1528\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1489\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.1547,\tval_loss: 0.1488\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1480\n",
            "47:\t[0s / 4s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1494\n",
            "48:\t[0s / 4s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1518\n",
            "49:\t[0s / 4s],\t\ttrain_loss: 0.1656,\tval_loss: 0.1507\n",
            "50:\t[0s / 4s],\t\ttrain_loss: 0.1602,\tval_loss: 0.1493\n",
            "51:\t[0s / 4s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1508\n",
            "52:\t[0s / 4s],\t\ttrain_loss: 0.1642,\tval_loss: 0.1508\n",
            "53:\t[0s / 4s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1482\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.1658,\tval_loss: 0.1488\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1507\n",
            "56:\t[0s / 5s],\t\ttrain_loss: 0.1617,\tval_loss: 0.1503\n",
            "57:\t[0s / 5s],\t\ttrain_loss: 0.1562,\tval_loss: 0.1497\n",
            "58:\t[0s / 5s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1493\n",
            "59:\t[0s / 5s],\t\ttrain_loss: 0.1603,\tval_loss: 0.1512\n",
            "60:\t[0s / 5s],\t\ttrain_loss: 0.1633,\tval_loss: 0.1480\n",
            "61:\t[0s / 5s],\t\ttrain_loss: 0.1641,\tval_loss: 0.1515\n",
            "62:\t[0s / 5s],\t\ttrain_loss: 0.1629,\tval_loss: 0.1480\n",
            "63:\t[0s / 5s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1493\n",
            "64:\t[0s / 5s],\t\ttrain_loss: 0.1674,\tval_loss: 0.1504\n",
            "65:\t[0s / 5s],\t\ttrain_loss: 0.1678,\tval_loss: 0.1504\n",
            "66:\t[0s / 6s],\t\ttrain_loss: 0.1629,\tval_loss: 0.1502\n",
            "67:\t[0s / 6s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1490\n",
            "68:\t[0s / 6s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1497\n",
            "69:\t[0s / 6s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1524\n",
            "70:\t[0s / 6s],\t\ttrain_loss: 0.1654,\tval_loss: 0.1512\n",
            "71:\t[0s / 6s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1504\n",
            "72:\t[0s / 6s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1503\n",
            "73:\t[0s / 6s],\t\ttrain_loss: 0.1654,\tval_loss: 0.1472\n",
            "74:\t[0s / 6s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1491\n",
            "75:\t[0s / 6s],\t\ttrain_loss: 0.1678,\tval_loss: 0.1509\n",
            "76:\t[0s / 6s],\t\ttrain_loss: 0.1605,\tval_loss: 0.1491\n",
            "77:\t[0s / 6s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1475\n",
            "78:\t[0s / 6s],\t\ttrain_loss: 0.1639,\tval_loss: 0.1479\n",
            "79:\t[0s / 7s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1508\n",
            "80:\t[0s / 7s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1502\n",
            "81:\t[0s / 7s],\t\ttrain_loss: 0.1571,\tval_loss: 0.1509\n",
            "82:\t[0s / 7s],\t\ttrain_loss: 0.1643,\tval_loss: 0.1513\n",
            "83:\t[0s / 7s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1519\n",
            "84:\t[0s / 7s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1503\n",
            "85:\t[0s / 7s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1485\n",
            "86:\t[0s / 7s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1486\n",
            "87:\t[0s / 7s],\t\ttrain_loss: 0.1597,\tval_loss: 0.1529\n",
            "88:\t[0s / 7s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1507\n",
            "89:\t[0s / 7s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1502\n",
            "90:\t[0s / 7s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1499\n",
            "91:\t[0s / 8s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1538\n",
            "92:\t[0s / 8s],\t\ttrain_loss: 0.1664,\tval_loss: 0.1496\n",
            "93:\t[0s / 8s],\t\ttrain_loss: 0.1713,\tval_loss: 0.1505\n",
            "94:\t[0s / 8s],\t\ttrain_loss: 0.1607,\tval_loss: 0.1483\n",
            "95:\t[0s / 8s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1501\n",
            "96:\t[0s / 8s],\t\ttrain_loss: 0.1664,\tval_loss: 0.1491\n",
            "97:\t[0s / 8s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1492\n",
            "98:\t[0s / 8s],\t\ttrain_loss: 0.1683,\tval_loss: 0.1493\n",
            "99:\t[0s / 8s],\t\ttrain_loss: 0.1670,\tval_loss: 0.1507\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 24\n",
            "{'batch_size': 59, 'layers': 4, 'nodes': 95, 'activation_fn': 'elu', 'alpha': 0.8357448132550818, 'sigma': 0.5582456440390068, 'lr': 0.06387409506891473, 'dropout': 0.35532276098510046, 'patience': 37, 'batch_norm': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.7226,\tval_loss: 0.5145\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.4888,\tval_loss: 0.4275\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.4714,\tval_loss: 0.4194\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.4506,\tval_loss: 0.4318\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.4509,\tval_loss: 0.4131\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.4478,\tval_loss: 0.4132\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.4501,\tval_loss: 0.4205\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.4447,\tval_loss: 0.4286\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.4525,\tval_loss: 0.4569\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.4515,\tval_loss: 0.4160\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.4512,\tval_loss: 0.4221\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 0.4528,\tval_loss: 0.4123\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 0.4467,\tval_loss: 0.4327\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.4489,\tval_loss: 0.4227\n",
            "14:\t[0s / 3s],\t\ttrain_loss: 0.4530,\tval_loss: 0.4437\n",
            "15:\t[0s / 3s],\t\ttrain_loss: 0.4444,\tval_loss: 0.4431\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.4523,\tval_loss: 0.4352\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.4561,\tval_loss: 0.4259\n",
            "18:\t[0s / 4s],\t\ttrain_loss: 0.4437,\tval_loss: 0.4316\n",
            "19:\t[0s / 4s],\t\ttrain_loss: 0.4499,\tval_loss: 0.4256\n",
            "20:\t[0s / 5s],\t\ttrain_loss: 0.4503,\tval_loss: 0.4397\n",
            "21:\t[0s / 5s],\t\ttrain_loss: 0.4527,\tval_loss: 0.4397\n",
            "22:\t[0s / 5s],\t\ttrain_loss: 0.4506,\tval_loss: 0.4270\n",
            "23:\t[0s / 6s],\t\ttrain_loss: 0.4598,\tval_loss: 0.4528\n",
            "24:\t[0s / 6s],\t\ttrain_loss: 0.4542,\tval_loss: 0.4290\n",
            "25:\t[0s / 6s],\t\ttrain_loss: 0.4471,\tval_loss: 0.4388\n",
            "26:\t[0s / 7s],\t\ttrain_loss: 0.4495,\tval_loss: 0.4448\n",
            "27:\t[0s / 7s],\t\ttrain_loss: 0.4621,\tval_loss: 0.4496\n",
            "28:\t[0s / 7s],\t\ttrain_loss: 0.4468,\tval_loss: 0.4370\n",
            "29:\t[0s / 7s],\t\ttrain_loss: 0.4452,\tval_loss: 0.4326\n",
            "30:\t[0s / 8s],\t\ttrain_loss: 0.4507,\tval_loss: 0.4486\n",
            "31:\t[0s / 8s],\t\ttrain_loss: 0.4530,\tval_loss: 0.4412\n",
            "32:\t[0s / 8s],\t\ttrain_loss: 0.4477,\tval_loss: 0.4534\n",
            "33:\t[0s / 8s],\t\ttrain_loss: 0.4520,\tval_loss: 0.4426\n",
            "34:\t[0s / 8s],\t\ttrain_loss: 0.4455,\tval_loss: 0.4427\n",
            "35:\t[0s / 9s],\t\ttrain_loss: 0.4480,\tval_loss: 0.4733\n",
            "36:\t[0s / 9s],\t\ttrain_loss: 0.4453,\tval_loss: 0.4460\n",
            "37:\t[0s / 9s],\t\ttrain_loss: 0.4627,\tval_loss: 0.4489\n",
            "38:\t[0s / 9s],\t\ttrain_loss: 0.4459,\tval_loss: 0.5172\n",
            "39:\t[0s / 10s],\t\ttrain_loss: 0.4511,\tval_loss: 0.4285\n",
            "40:\t[0s / 10s],\t\ttrain_loss: 0.4481,\tval_loss: 0.4584\n",
            "41:\t[0s / 10s],\t\ttrain_loss: 0.4561,\tval_loss: 0.4457\n",
            "42:\t[0s / 10s],\t\ttrain_loss: 0.4526,\tval_loss: 0.4743\n",
            "43:\t[0s / 10s],\t\ttrain_loss: 0.4456,\tval_loss: 0.4525\n",
            "44:\t[0s / 11s],\t\ttrain_loss: 0.4632,\tval_loss: 0.4271\n",
            "45:\t[0s / 11s],\t\ttrain_loss: 0.4472,\tval_loss: 0.4306\n",
            "46:\t[0s / 11s],\t\ttrain_loss: 0.4520,\tval_loss: 0.4259\n",
            "47:\t[0s / 11s],\t\ttrain_loss: 0.4789,\tval_loss: 0.4527\n",
            "48:\t[0s / 11s],\t\ttrain_loss: 0.5047,\tval_loss: 0.4721\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 25\n",
            "{'batch_size': 225, 'layers': 4, 'nodes': 36, 'activation_fn': 'tanh', 'alpha': 0.833269388280053, 'sigma': 0.8093617827597362, 'lr': 0.08851531659334702, 'dropout': 0.39746609546002903, 'patience': 66, 'batch_norm': True}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6604,\tval_loss: 0.8378\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5084,\tval_loss: 0.4604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 0.4624,\tval_loss: 0.4269\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.4608,\tval_loss: 0.4211\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.4508,\tval_loss: 0.4149\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4431,\tval_loss: 0.4149\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.4440,\tval_loss: 0.4165\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.4385,\tval_loss: 0.4119\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.4402,\tval_loss: 0.4090\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.4368,\tval_loss: 0.4128\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.4368,\tval_loss: 0.4118\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.4387,\tval_loss: 0.4154\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.4324,\tval_loss: 0.4081\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.4287,\tval_loss: 0.4244\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.4408,\tval_loss: 0.4199\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.4388,\tval_loss: 0.4146\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.4377,\tval_loss: 0.4228\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.4321,\tval_loss: 0.4132\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.4329,\tval_loss: 0.4203\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.4311,\tval_loss: 0.4266\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.4333,\tval_loss: 0.4104\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.4289,\tval_loss: 0.4202\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.4310,\tval_loss: 0.4304\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.4326,\tval_loss: 0.4146\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.4338,\tval_loss: 0.4198\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.4306,\tval_loss: 0.4260\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.4256,\tval_loss: 0.4238\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.4335,\tval_loss: 0.4203\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.4279,\tval_loss: 0.4117\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.4308,\tval_loss: 0.4166\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.4311,\tval_loss: 0.4134\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.4236,\tval_loss: 0.4250\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.4259,\tval_loss: 0.4097\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.4305,\tval_loss: 0.4145\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.4252,\tval_loss: 0.4151\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.4277,\tval_loss: 0.4177\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.4308,\tval_loss: 0.4165\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.4235,\tval_loss: 0.4274\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.4352,\tval_loss: 0.4208\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.4311,\tval_loss: 0.4242\n",
            "40:\t[0s / 3s],\t\ttrain_loss: 0.4267,\tval_loss: 0.4207\n",
            "41:\t[0s / 3s],\t\ttrain_loss: 0.4329,\tval_loss: 0.4180\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 0.4277,\tval_loss: 0.4164\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 0.4243,\tval_loss: 0.4178\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 0.4240,\tval_loss: 0.4301\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 0.4313,\tval_loss: 0.4154\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 0.4308,\tval_loss: 0.4170\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 0.4172,\tval_loss: 0.4222\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 0.4275,\tval_loss: 0.4257\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 0.4271,\tval_loss: 0.4322\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 0.4250,\tval_loss: 0.4183\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 0.4255,\tval_loss: 0.4175\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 0.4327,\tval_loss: 0.4231\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 0.4312,\tval_loss: 0.4268\n",
            "54:\t[0s / 4s],\t\ttrain_loss: 0.4232,\tval_loss: 0.4234\n",
            "55:\t[0s / 4s],\t\ttrain_loss: 0.4291,\tval_loss: 0.4434\n",
            "56:\t[0s / 4s],\t\ttrain_loss: 0.4250,\tval_loss: 0.4288\n",
            "57:\t[0s / 4s],\t\ttrain_loss: 0.4274,\tval_loss: 0.4174\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 0.4295,\tval_loss: 0.4216\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 0.4193,\tval_loss: 0.4414\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 0.4154,\tval_loss: 0.4319\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 0.4263,\tval_loss: 0.4212\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 0.4194,\tval_loss: 0.4382\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 0.4089,\tval_loss: 0.4362\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 0.4262,\tval_loss: 0.4292\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 0.4177,\tval_loss: 0.4348\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 0.4259,\tval_loss: 0.4262\n",
            "67:\t[0s / 5s],\t\ttrain_loss: 0.4318,\tval_loss: 0.4230\n",
            "68:\t[0s / 5s],\t\ttrain_loss: 0.4188,\tval_loss: 0.4276\n",
            "69:\t[0s / 5s],\t\ttrain_loss: 0.4248,\tval_loss: 0.4166\n",
            "70:\t[0s / 5s],\t\ttrain_loss: 0.4227,\tval_loss: 0.4308\n",
            "71:\t[0s / 5s],\t\ttrain_loss: 0.4305,\tval_loss: 0.4331\n",
            "72:\t[0s / 5s],\t\ttrain_loss: 0.4229,\tval_loss: 0.4237\n",
            "73:\t[0s / 5s],\t\ttrain_loss: 0.4204,\tval_loss: 0.4359\n",
            "74:\t[0s / 5s],\t\ttrain_loss: 0.4241,\tval_loss: 0.4353\n",
            "75:\t[0s / 5s],\t\ttrain_loss: 0.4245,\tval_loss: 0.4302\n",
            "76:\t[0s / 5s],\t\ttrain_loss: 0.4218,\tval_loss: 0.4304\n",
            "77:\t[0s / 5s],\t\ttrain_loss: 0.4279,\tval_loss: 0.4283\n",
            "78:\t[0s / 6s],\t\ttrain_loss: 0.4272,\tval_loss: 0.4326\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 26\n",
            "{'batch_size': 205, 'layers': 3, 'nodes': 79, 'activation_fn': 'relu', 'alpha': 0.2014199705255241, 'sigma': 0.7065598901905235, 'lr': 0.025816440468446996, 'dropout': 0.33694351127998456, 'patience': 48, 'batch_norm': True}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2236,\tval_loss: 0.2022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1915,\tval_loss: 0.1696\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1698,\tval_loss: 0.1675\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1648,\tval_loss: 0.1606\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1583\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1603,\tval_loss: 0.1565\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1559\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1536\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1568\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1570\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1567\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1593\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1514,\tval_loss: 0.1592\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1499,\tval_loss: 0.1567\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1572\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1530,\tval_loss: 0.1578\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1486,\tval_loss: 0.1590\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1467,\tval_loss: 0.1597\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1461,\tval_loss: 0.1587\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1472,\tval_loss: 0.1567\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1458,\tval_loss: 0.1604\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1433,\tval_loss: 0.1620\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1438,\tval_loss: 0.1607\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1447,\tval_loss: 0.1623\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1444,\tval_loss: 0.1602\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1455,\tval_loss: 0.1602\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1435,\tval_loss: 0.1607\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1417,\tval_loss: 0.1634\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1406,\tval_loss: 0.1668\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1365,\tval_loss: 0.1677\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1378,\tval_loss: 0.1702\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1401,\tval_loss: 0.1690\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1371,\tval_loss: 0.1655\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1404,\tval_loss: 0.1696\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1404,\tval_loss: 0.1644\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1333,\tval_loss: 0.1670\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1388,\tval_loss: 0.1660\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1328,\tval_loss: 0.1682\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1359,\tval_loss: 0.1678\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1358,\tval_loss: 0.1660\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1371,\tval_loss: 0.1737\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1353,\tval_loss: 0.1702\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1361,\tval_loss: 0.1671\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1352,\tval_loss: 0.1779\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1309,\tval_loss: 0.1712\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.1311,\tval_loss: 0.1734\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1298,\tval_loss: 0.1769\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1274,\tval_loss: 0.1758\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1361,\tval_loss: 0.1767\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1352,\tval_loss: 0.1727\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1341,\tval_loss: 0.1731\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1312,\tval_loss: 0.1695\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1292,\tval_loss: 0.1790\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1272,\tval_loss: 0.1785\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.1255,\tval_loss: 0.1783\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.1257,\tval_loss: 0.1812\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 27\n",
            "{'batch_size': 253, 'layers': 4, 'nodes': 48, 'activation_fn': 'elu', 'alpha': 0.8612661551219855, 'sigma': 0.711034757585895, 'lr': 0.011800571997508866, 'dropout': 0.5313838937174591, 'patience': 74, 'batch_norm': True}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.8190,\tval_loss: 0.6617\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.6613,\tval_loss: 0.4851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5787,\tval_loss: 0.4826\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5391,\tval_loss: 0.4728\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5131,\tval_loss: 0.4447\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4985,\tval_loss: 0.4305\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.4909,\tval_loss: 0.4316\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.4762,\tval_loss: 0.4340\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.4710,\tval_loss: 0.4276\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.4690,\tval_loss: 0.4259\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.4596,\tval_loss: 0.4273\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.4672,\tval_loss: 0.4274\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.4555,\tval_loss: 0.4282\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.4609,\tval_loss: 0.4259\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.4600,\tval_loss: 0.4265\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.4581,\tval_loss: 0.4285\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.4574,\tval_loss: 0.4272\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.4454,\tval_loss: 0.4258\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.4525,\tval_loss: 0.4257\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.4479,\tval_loss: 0.4235\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.4518,\tval_loss: 0.4236\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.4474,\tval_loss: 0.4246\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.4523,\tval_loss: 0.4204\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.4502,\tval_loss: 0.4221\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.4500,\tval_loss: 0.4235\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.4505,\tval_loss: 0.4240\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.4527,\tval_loss: 0.4270\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.4410,\tval_loss: 0.4227\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.4431,\tval_loss: 0.4216\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.4495,\tval_loss: 0.4210\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.4509,\tval_loss: 0.4223\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.4463,\tval_loss: 0.4215\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.4394,\tval_loss: 0.4212\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.4444,\tval_loss: 0.4207\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.4438,\tval_loss: 0.4180\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.4470,\tval_loss: 0.4192\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.4434,\tval_loss: 0.4211\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.4405,\tval_loss: 0.4234\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.4393,\tval_loss: 0.4205\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.4339,\tval_loss: 0.4220\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 0.4369,\tval_loss: 0.4226\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 0.4433,\tval_loss: 0.4202\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 0.4365,\tval_loss: 0.4201\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 0.4399,\tval_loss: 0.4213\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 0.4347,\tval_loss: 0.4219\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 0.4435,\tval_loss: 0.4196\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 0.4318,\tval_loss: 0.4189\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 0.4353,\tval_loss: 0.4219\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 0.4327,\tval_loss: 0.4196\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 0.4322,\tval_loss: 0.4185\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 0.4324,\tval_loss: 0.4226\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 0.4306,\tval_loss: 0.4201\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 0.4339,\tval_loss: 0.4197\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 0.4323,\tval_loss: 0.4241\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 0.4304,\tval_loss: 0.4245\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 0.4308,\tval_loss: 0.4194\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 0.4309,\tval_loss: 0.4207\n",
            "57:\t[0s / 4s],\t\ttrain_loss: 0.4316,\tval_loss: 0.4202\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 0.4396,\tval_loss: 0.4194\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 0.4379,\tval_loss: 0.4216\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 0.4293,\tval_loss: 0.4202\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 0.4323,\tval_loss: 0.4199\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 0.4283,\tval_loss: 0.4200\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 0.4264,\tval_loss: 0.4192\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 0.4306,\tval_loss: 0.4206\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 0.4261,\tval_loss: 0.4188\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 0.4271,\tval_loss: 0.4193\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 0.4314,\tval_loss: 0.4182\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 0.4267,\tval_loss: 0.4214\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 0.4265,\tval_loss: 0.4214\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 0.4375,\tval_loss: 0.4215\n",
            "71:\t[0s / 5s],\t\ttrain_loss: 0.4276,\tval_loss: 0.4211\n",
            "72:\t[0s / 5s],\t\ttrain_loss: 0.4245,\tval_loss: 0.4205\n",
            "73:\t[0s / 5s],\t\ttrain_loss: 0.4313,\tval_loss: 0.4212\n",
            "74:\t[0s / 5s],\t\ttrain_loss: 0.4270,\tval_loss: 0.4213\n",
            "75:\t[0s / 5s],\t\ttrain_loss: 0.4259,\tval_loss: 0.4185\n",
            "76:\t[0s / 5s],\t\ttrain_loss: 0.4229,\tval_loss: 0.4194\n",
            "77:\t[0s / 5s],\t\ttrain_loss: 0.4188,\tval_loss: 0.4197\n",
            "78:\t[0s / 5s],\t\ttrain_loss: 0.4231,\tval_loss: 0.4209\n",
            "79:\t[0s / 5s],\t\ttrain_loss: 0.4220,\tval_loss: 0.4223\n",
            "80:\t[0s / 5s],\t\ttrain_loss: 0.4294,\tval_loss: 0.4200\n",
            "81:\t[0s / 5s],\t\ttrain_loss: 0.4235,\tval_loss: 0.4184\n",
            "82:\t[0s / 5s],\t\ttrain_loss: 0.4230,\tval_loss: 0.4193\n",
            "83:\t[0s / 5s],\t\ttrain_loss: 0.4229,\tval_loss: 0.4203\n",
            "84:\t[0s / 5s],\t\ttrain_loss: 0.4197,\tval_loss: 0.4208\n",
            "85:\t[0s / 6s],\t\ttrain_loss: 0.4200,\tval_loss: 0.4201\n",
            "86:\t[0s / 6s],\t\ttrain_loss: 0.4225,\tval_loss: 0.4223\n",
            "87:\t[0s / 6s],\t\ttrain_loss: 0.4238,\tval_loss: 0.4243\n",
            "88:\t[0s / 6s],\t\ttrain_loss: 0.4236,\tval_loss: 0.4218\n",
            "89:\t[0s / 6s],\t\ttrain_loss: 0.4195,\tval_loss: 0.4200\n",
            "90:\t[0s / 6s],\t\ttrain_loss: 0.4251,\tval_loss: 0.4224\n",
            "91:\t[0s / 6s],\t\ttrain_loss: 0.4222,\tval_loss: 0.4212\n",
            "92:\t[0s / 6s],\t\ttrain_loss: 0.4178,\tval_loss: 0.4225\n",
            "93:\t[0s / 6s],\t\ttrain_loss: 0.4130,\tval_loss: 0.4210\n",
            "94:\t[0s / 6s],\t\ttrain_loss: 0.4142,\tval_loss: 0.4224\n",
            "95:\t[0s / 6s],\t\ttrain_loss: 0.4273,\tval_loss: 0.4203\n",
            "96:\t[0s / 6s],\t\ttrain_loss: 0.4194,\tval_loss: 0.4195\n",
            "97:\t[0s / 6s],\t\ttrain_loss: 0.4210,\tval_loss: 0.4204\n",
            "98:\t[0s / 6s],\t\ttrain_loss: 0.4227,\tval_loss: 0.4185\n",
            "99:\t[0s / 7s],\t\ttrain_loss: 0.4144,\tval_loss: 0.4200\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 28\n",
            "{'batch_size': 94, 'layers': 2, 'nodes': 78, 'activation_fn': 'relu', 'alpha': 0.7972815225863752, 'sigma': 0.8418074091592838, 'lr': 0.01824291366946584, 'dropout': 0.5435810434986534, 'patience': 60, 'batch_norm': False}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.5798,\tval_loss: 0.4795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5302,\tval_loss: 0.4416\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.4771,\tval_loss: 0.4200\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.4732,\tval_loss: 0.4148\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.4527,\tval_loss: 0.4119\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4523,\tval_loss: 0.4213\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.4205,\tval_loss: 0.4058\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.4327,\tval_loss: 0.4180\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.4277,\tval_loss: 0.4074\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.4299,\tval_loss: 0.4142\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.4379,\tval_loss: 0.4064\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.4253,\tval_loss: 0.4014\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.4181,\tval_loss: 0.4014\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.4303,\tval_loss: 0.4043\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.4287,\tval_loss: 0.3998\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.4265,\tval_loss: 0.4062\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.3959,\tval_loss: 0.3989\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.4174,\tval_loss: 0.3999\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.4101,\tval_loss: 0.4012\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.4232,\tval_loss: 0.3964\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.4307,\tval_loss: 0.4019\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.4203,\tval_loss: 0.4036\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.4108,\tval_loss: 0.3998\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.4105,\tval_loss: 0.4021\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.4057,\tval_loss: 0.3982\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.4150,\tval_loss: 0.3962\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.4068,\tval_loss: 0.4016\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.4117,\tval_loss: 0.3985\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.4046,\tval_loss: 0.3976\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.4015,\tval_loss: 0.3975\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.4104,\tval_loss: 0.3963\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.4099,\tval_loss: 0.4011\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.4113,\tval_loss: 0.3970\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.4033,\tval_loss: 0.3982\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.4303,\tval_loss: 0.3999\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.4050,\tval_loss: 0.4020\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.4161,\tval_loss: 0.4005\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.3994,\tval_loss: 0.4023\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.4241,\tval_loss: 0.3996\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.4063,\tval_loss: 0.4008\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.4096,\tval_loss: 0.4003\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.4117,\tval_loss: 0.3956\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.4223,\tval_loss: 0.3953\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.4070,\tval_loss: 0.3962\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.4113,\tval_loss: 0.4042\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.4203,\tval_loss: 0.3988\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.3979,\tval_loss: 0.3958\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.4156,\tval_loss: 0.3982\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.4053,\tval_loss: 0.4002\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.4257,\tval_loss: 0.4007\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.4000,\tval_loss: 0.4046\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.4175,\tval_loss: 0.4046\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.4118,\tval_loss: 0.4007\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.4070,\tval_loss: 0.3983\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.4093,\tval_loss: 0.3996\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.4029,\tval_loss: 0.4012\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.4082,\tval_loss: 0.4003\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.4046,\tval_loss: 0.4120\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.4046,\tval_loss: 0.4140\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.4151,\tval_loss: 0.4053\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.4049,\tval_loss: 0.4042\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.4204,\tval_loss: 0.4015\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.4107,\tval_loss: 0.4037\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.3981,\tval_loss: 0.4073\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.4119,\tval_loss: 0.3991\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.4075,\tval_loss: 0.3994\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.4056,\tval_loss: 0.4012\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.4098,\tval_loss: 0.4023\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.4047,\tval_loss: 0.3986\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.4053,\tval_loss: 0.3985\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.4152,\tval_loss: 0.4028\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.4114,\tval_loss: 0.3990\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.4279,\tval_loss: 0.4014\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.4120,\tval_loss: 0.3978\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.4062,\tval_loss: 0.4006\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.4183,\tval_loss: 0.4016\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.3965,\tval_loss: 0.4056\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.3903,\tval_loss: 0.4137\n",
            "78:\t[0s / 8s],\t\ttrain_loss: 0.4013,\tval_loss: 0.4125\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.3932,\tval_loss: 0.4077\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.4198,\tval_loss: 0.4089\n",
            "81:\t[0s / 9s],\t\ttrain_loss: 0.3976,\tval_loss: 0.4114\n",
            "82:\t[0s / 9s],\t\ttrain_loss: 0.4111,\tval_loss: 0.4183\n",
            "83:\t[0s / 9s],\t\ttrain_loss: 0.4218,\tval_loss: 0.4234\n",
            "84:\t[0s / 9s],\t\ttrain_loss: 0.3994,\tval_loss: 0.4124\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.4076,\tval_loss: 0.4134\n",
            "86:\t[0s / 9s],\t\ttrain_loss: 0.4091,\tval_loss: 0.4020\n",
            "87:\t[0s / 9s],\t\ttrain_loss: 0.4113,\tval_loss: 0.3989\n",
            "88:\t[0s / 9s],\t\ttrain_loss: 0.4161,\tval_loss: 0.4083\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.4095,\tval_loss: 0.4025\n",
            "90:\t[0s / 10s],\t\ttrain_loss: 0.4046,\tval_loss: 0.4038\n",
            "91:\t[0s / 10s],\t\ttrain_loss: 0.4055,\tval_loss: 0.4087\n",
            "92:\t[0s / 10s],\t\ttrain_loss: 0.4259,\tval_loss: 0.4123\n",
            "93:\t[0s / 10s],\t\ttrain_loss: 0.4206,\tval_loss: 0.4108\n",
            "94:\t[0s / 10s],\t\ttrain_loss: 0.4032,\tval_loss: 0.4099\n",
            "95:\t[0s / 10s],\t\ttrain_loss: 0.4074,\tval_loss: 0.4098\n",
            "96:\t[0s / 10s],\t\ttrain_loss: 0.4184,\tval_loss: 0.4040\n",
            "97:\t[0s / 10s],\t\ttrain_loss: 0.3962,\tval_loss: 0.4008\n",
            "98:\t[0s / 10s],\t\ttrain_loss: 0.4128,\tval_loss: 0.4020\n",
            "99:\t[0s / 11s],\t\ttrain_loss: 0.4109,\tval_loss: 0.4018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 29\n",
            "{'batch_size': 171, 'layers': 2, 'nodes': 58, 'activation_fn': 'elu', 'alpha': 0.41993234851848316, 'sigma': 0.7859517856477491, 'lr': 0.05958590391863763, 'dropout': 0.01571558761310095, 'patience': 46, 'batch_norm': False}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.3137,\tval_loss: 0.2895\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2652,\tval_loss: 0.2550\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.2511,\tval_loss: 0.2651\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.2528,\tval_loss: 0.2601\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.2383,\tval_loss: 0.2831\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.2318,\tval_loss: 0.2788\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.2303,\tval_loss: 0.2927\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.2237,\tval_loss: 0.3070\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.2312,\tval_loss: 0.3003\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.2324,\tval_loss: 0.3045\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.2275,\tval_loss: 0.2894\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.2280,\tval_loss: 0.2962\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.2252,\tval_loss: 0.3251\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.2182,\tval_loss: 0.3249\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.2160,\tval_loss: 0.3035\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.2222,\tval_loss: 0.3095\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.2256,\tval_loss: 0.3255\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.2249,\tval_loss: 0.3211\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.2265,\tval_loss: 0.3048\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.2219,\tval_loss: 0.2990\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.2184,\tval_loss: 0.3608\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.2234,\tval_loss: 0.3354\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.2224,\tval_loss: 0.3466\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.2176,\tval_loss: 0.3833\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.2089,\tval_loss: 0.3651\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.2031,\tval_loss: 0.3878\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.2139,\tval_loss: 0.3414\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.2106,\tval_loss: 0.3806\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.2224,\tval_loss: 0.3102\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 0.2229,\tval_loss: 0.3527\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 0.2196,\tval_loss: 0.3518\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.2186,\tval_loss: 0.3397\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.2164,\tval_loss: 0.3906\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.2172,\tval_loss: 0.4250\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.2172,\tval_loss: 0.4168\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.2171,\tval_loss: 0.4397\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.2113,\tval_loss: 0.4195\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.2161,\tval_loss: 0.3664\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.2160,\tval_loss: 0.3517\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.2091,\tval_loss: 0.3824\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 0.2182,\tval_loss: 0.3305\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 0.2118,\tval_loss: 0.3500\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 0.2141,\tval_loss: 0.3785\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 0.2137,\tval_loss: 0.3430\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 0.2122,\tval_loss: 0.3498\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 0.2097,\tval_loss: 0.3371\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 0.2109,\tval_loss: 0.3401\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 0.2162,\tval_loss: 0.3464\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 30\n",
            "{'batch_size': 150, 'layers': 3, 'nodes': 36, 'activation_fn': 'tanh', 'alpha': 0.8389233839160657, 'sigma': 0.47491562014476696, 'lr': 0.0632712407941047, 'dropout': 0.15206189933127892, 'patience': 53, 'batch_norm': False}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.5396,\tval_loss: 0.4574\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.4882,\tval_loss: 0.4304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 0.4667,\tval_loss: 0.4357\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.4556,\tval_loss: 0.4264\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.4491,\tval_loss: 0.4203\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4381,\tval_loss: 0.4187\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.4220,\tval_loss: 0.4263\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.4257,\tval_loss: 0.4232\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.4253,\tval_loss: 0.4298\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.4435,\tval_loss: 0.4289\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.4263,\tval_loss: 0.4165\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.4285,\tval_loss: 0.4200\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.4483,\tval_loss: 0.4289\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.4363,\tval_loss: 0.4146\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.4335,\tval_loss: 0.4332\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.4462,\tval_loss: 0.4177\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.4267,\tval_loss: 0.4162\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.4322,\tval_loss: 0.4235\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.4250,\tval_loss: 0.4224\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.4312,\tval_loss: 0.4198\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.4318,\tval_loss: 0.4225\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.4270,\tval_loss: 0.4176\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.4211,\tval_loss: 0.4216\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.4266,\tval_loss: 0.4203\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.4135,\tval_loss: 0.4145\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.4184,\tval_loss: 0.4197\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.4295,\tval_loss: 0.4389\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.4392,\tval_loss: 0.4637\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.4338,\tval_loss: 0.4183\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.4269,\tval_loss: 0.4124\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.4328,\tval_loss: 0.4204\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.4596,\tval_loss: 0.4165\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.4370,\tval_loss: 0.4208\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.4460,\tval_loss: 0.4175\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.4330,\tval_loss: 0.4211\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.4251,\tval_loss: 0.4192\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.4254,\tval_loss: 0.4239\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.4338,\tval_loss: 0.4173\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.4290,\tval_loss: 0.4275\n",
            "39:\t[0s / 3s],\t\ttrain_loss: 0.4325,\tval_loss: 0.4242\n",
            "40:\t[0s / 3s],\t\ttrain_loss: 0.4453,\tval_loss: 0.4219\n",
            "41:\t[0s / 3s],\t\ttrain_loss: 0.4262,\tval_loss: 0.4251\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 0.4283,\tval_loss: 0.4309\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 0.4241,\tval_loss: 0.4188\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 0.4290,\tval_loss: 0.4200\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 0.4240,\tval_loss: 0.4169\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 0.4231,\tval_loss: 0.4307\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 0.4326,\tval_loss: 0.4164\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 0.4386,\tval_loss: 0.4205\n",
            "49:\t[0s / 4s],\t\ttrain_loss: 0.4250,\tval_loss: 0.4166\n",
            "50:\t[0s / 4s],\t\ttrain_loss: 0.4347,\tval_loss: 0.4170\n",
            "51:\t[0s / 4s],\t\ttrain_loss: 0.4214,\tval_loss: 0.4175\n",
            "52:\t[0s / 4s],\t\ttrain_loss: 0.4309,\tval_loss: 0.4190\n",
            "53:\t[0s / 4s],\t\ttrain_loss: 0.4214,\tval_loss: 0.4345\n",
            "54:\t[0s / 4s],\t\ttrain_loss: 0.4386,\tval_loss: 0.4198\n",
            "55:\t[0s / 4s],\t\ttrain_loss: 0.4264,\tval_loss: 0.4169\n",
            "56:\t[0s / 4s],\t\ttrain_loss: 0.4249,\tval_loss: 0.4191\n",
            "57:\t[0s / 4s],\t\ttrain_loss: 0.4263,\tval_loss: 0.4174\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 0.4384,\tval_loss: 0.4195\n",
            "59:\t[0s / 5s],\t\ttrain_loss: 0.4218,\tval_loss: 0.4196\n",
            "60:\t[0s / 5s],\t\ttrain_loss: 0.4245,\tval_loss: 0.4151\n",
            "61:\t[0s / 5s],\t\ttrain_loss: 0.4300,\tval_loss: 0.4142\n",
            "62:\t[0s / 5s],\t\ttrain_loss: 0.4249,\tval_loss: 0.4309\n",
            "63:\t[0s / 5s],\t\ttrain_loss: 0.4265,\tval_loss: 0.4249\n",
            "64:\t[0s / 5s],\t\ttrain_loss: 0.4299,\tval_loss: 0.4254\n",
            "65:\t[0s / 5s],\t\ttrain_loss: 0.4367,\tval_loss: 0.4189\n",
            "66:\t[0s / 5s],\t\ttrain_loss: 0.4434,\tval_loss: 0.4178\n",
            "67:\t[0s / 5s],\t\ttrain_loss: 0.4354,\tval_loss: 0.4209\n",
            "68:\t[0s / 5s],\t\ttrain_loss: 0.5027,\tval_loss: 0.4194\n",
            "69:\t[0s / 6s],\t\ttrain_loss: 0.4704,\tval_loss: 0.4196\n",
            "70:\t[0s / 6s],\t\ttrain_loss: 0.4341,\tval_loss: 0.4181\n",
            "71:\t[0s / 6s],\t\ttrain_loss: 0.4345,\tval_loss: 0.4206\n",
            "72:\t[0s / 6s],\t\ttrain_loss: 0.4345,\tval_loss: 0.4191\n",
            "73:\t[0s / 6s],\t\ttrain_loss: 0.4338,\tval_loss: 0.4191\n",
            "74:\t[0s / 6s],\t\ttrain_loss: 0.4344,\tval_loss: 0.4201\n",
            "75:\t[0s / 6s],\t\ttrain_loss: 0.4401,\tval_loss: 0.4196\n",
            "76:\t[0s / 6s],\t\ttrain_loss: 0.4281,\tval_loss: 0.4176\n",
            "77:\t[0s / 6s],\t\ttrain_loss: 0.4417,\tval_loss: 0.4205\n",
            "78:\t[0s / 7s],\t\ttrain_loss: 0.4308,\tval_loss: 0.4196\n",
            "79:\t[0s / 7s],\t\ttrain_loss: 0.4350,\tval_loss: 0.4202\n",
            "80:\t[0s / 7s],\t\ttrain_loss: 0.4332,\tval_loss: 0.4199\n",
            "81:\t[0s / 7s],\t\ttrain_loss: 0.4402,\tval_loss: 0.4191\n",
            "82:\t[0s / 7s],\t\ttrain_loss: 0.4389,\tval_loss: 0.4191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 31\n",
            "{'batch_size': 89, 'layers': 2, 'nodes': 46, 'activation_fn': 'elu', 'alpha': 0.9632045250100247, 'sigma': 0.4310328214540088, 'lr': 0.03998511271622363, 'dropout': 0.45962906712178286, 'patience': 72, 'batch_norm': True}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.7180,\tval_loss: 0.5138\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5382,\tval_loss: 0.4793\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5078,\tval_loss: 0.4740\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5114,\tval_loss: 0.4702\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.4932,\tval_loss: 0.4652\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4852,\tval_loss: 0.4651\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.4844,\tval_loss: 0.4679\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.4891,\tval_loss: 0.4662\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.4813,\tval_loss: 0.4610\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.4850,\tval_loss: 0.4594\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.4806,\tval_loss: 0.4680\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.4782,\tval_loss: 0.4654\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.4689,\tval_loss: 0.4606\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.4976,\tval_loss: 0.4601\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.4820,\tval_loss: 0.4717\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.4700,\tval_loss: 0.4667\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.4791,\tval_loss: 0.4610\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.4705,\tval_loss: 0.4673\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.4730,\tval_loss: 0.4600\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.4619,\tval_loss: 0.4632\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.4694,\tval_loss: 0.4749\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.4747,\tval_loss: 0.4761\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.4691,\tval_loss: 0.4776\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.4587,\tval_loss: 0.4760\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.4719,\tval_loss: 0.4820\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.4731,\tval_loss: 0.4637\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.4595,\tval_loss: 0.4657\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.4607,\tval_loss: 0.4669\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.4496,\tval_loss: 0.4754\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.4667,\tval_loss: 0.4630\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.4602,\tval_loss: 0.4651\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.4682,\tval_loss: 0.4704\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.4721,\tval_loss: 0.4718\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.4783,\tval_loss: 0.4740\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.4608,\tval_loss: 0.4770\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.4511,\tval_loss: 0.4532\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.4688,\tval_loss: 0.4532\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.4841,\tval_loss: 0.4672\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.4506,\tval_loss: 0.4743\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.4514,\tval_loss: 0.4842\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.4552,\tval_loss: 0.4683\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.4539,\tval_loss: 0.4656\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.4665,\tval_loss: 0.4547\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.4690,\tval_loss: 0.4781\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.4543,\tval_loss: 0.4624\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.4695,\tval_loss: 0.4702\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.4528,\tval_loss: 0.4736\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.4532,\tval_loss: 0.4767\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.4478,\tval_loss: 0.4811\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.4472,\tval_loss: 0.4815\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.4638,\tval_loss: 0.4845\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.4554,\tval_loss: 0.4826\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.4603,\tval_loss: 0.4818\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.4538,\tval_loss: 0.4626\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.4450,\tval_loss: 0.4877\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.4493,\tval_loss: 0.4781\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.4585,\tval_loss: 0.4801\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.4455,\tval_loss: 0.4757\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.4440,\tval_loss: 0.4928\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.4587,\tval_loss: 0.4771\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.4454,\tval_loss: 0.4912\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.4635,\tval_loss: 0.4757\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.4458,\tval_loss: 0.4750\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.4491,\tval_loss: 0.4868\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.4468,\tval_loss: 0.4736\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.4551,\tval_loss: 0.4712\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.4325,\tval_loss: 0.4855\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.4499,\tval_loss: 0.4855\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.4422,\tval_loss: 0.4950\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.4653,\tval_loss: 0.4778\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.4513,\tval_loss: 0.4865\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.4503,\tval_loss: 0.4933\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.4495,\tval_loss: 0.4838\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.4348,\tval_loss: 0.4911\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.4346,\tval_loss: 0.4990\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.4471,\tval_loss: 0.4856\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.4395,\tval_loss: 0.5016\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.4334,\tval_loss: 0.5019\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.4396,\tval_loss: 0.4911\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.4426,\tval_loss: 0.4894\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.4370,\tval_loss: 0.5282\n",
            "81:\t[0s / 9s],\t\ttrain_loss: 0.4470,\tval_loss: 0.5168\n",
            "82:\t[0s / 9s],\t\ttrain_loss: 0.4446,\tval_loss: 0.5048\n",
            "83:\t[0s / 9s],\t\ttrain_loss: 0.4576,\tval_loss: 0.4695\n",
            "84:\t[0s / 9s],\t\ttrain_loss: 0.4265,\tval_loss: 0.4964\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.4437,\tval_loss: 0.4965\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.4452,\tval_loss: 0.5033\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.4386,\tval_loss: 0.5106\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.4401,\tval_loss: 0.5041\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.4481,\tval_loss: 0.5001\n",
            "90:\t[0s / 10s],\t\ttrain_loss: 0.4317,\tval_loss: 0.5035\n",
            "91:\t[0s / 10s],\t\ttrain_loss: 0.4281,\tval_loss: 0.4995\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.4417,\tval_loss: 0.5076\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.4350,\tval_loss: 0.5008\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.4486,\tval_loss: 0.5106\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.4265,\tval_loss: 0.5000\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.4280,\tval_loss: 0.4958\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.4370,\tval_loss: 0.5099\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.4313,\tval_loss: 0.4997\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.4235,\tval_loss: 0.5053\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 32\n",
            "{'batch_size': 238, 'layers': 3, 'nodes': 64, 'activation_fn': 'tanh', 'alpha': 0.10202806298158205, 'sigma': 0.9097236520337647, 'lr': 0.06471453754796315, 'dropout': 0.8706791103660821, 'patience': 47, 'batch_norm': False}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.5750,\tval_loss: 0.1307\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.7480,\tval_loss: 0.1252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5591,\tval_loss: 0.1199\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.6344,\tval_loss: 0.1189\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.3618,\tval_loss: 0.1214\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4676,\tval_loss: 0.1168\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.5155,\tval_loss: 0.1164\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.4696,\tval_loss: 0.1163\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.5001,\tval_loss: 0.1163\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.5339,\tval_loss: 0.1166\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.3781,\tval_loss: 0.1165\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.3567,\tval_loss: 0.1166\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.2951,\tval_loss: 0.1162\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.3170,\tval_loss: 0.1157\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1901,\tval_loss: 0.1148\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.2265,\tval_loss: 0.1148\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1697,\tval_loss: 0.1150\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1697,\tval_loss: 0.1149\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.2746,\tval_loss: 0.1149\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.2296,\tval_loss: 0.1151\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.3247,\tval_loss: 0.1150\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.1683,\tval_loss: 0.1151\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1842,\tval_loss: 0.1149\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1952,\tval_loss: 0.1148\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.3135,\tval_loss: 0.1150\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.2203,\tval_loss: 0.1152\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.2060,\tval_loss: 0.1152\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1150\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.3141,\tval_loss: 0.1150\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1149\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.2101,\tval_loss: 0.1150\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.1265,\tval_loss: 0.1151\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.1931,\tval_loss: 0.1150\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.1350,\tval_loss: 0.1149\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.1268,\tval_loss: 0.1148\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1225,\tval_loss: 0.1149\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.1277,\tval_loss: 0.1149\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1149\n",
            "38:\t[0s / 3s],\t\ttrain_loss: 0.1721,\tval_loss: 0.1152\n",
            "39:\t[0s / 3s],\t\ttrain_loss: 0.1375,\tval_loss: 0.1150\n",
            "40:\t[0s / 3s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1150\n",
            "41:\t[0s / 3s],\t\ttrain_loss: 0.1373,\tval_loss: 0.1148\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1148\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1148\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 0.1230,\tval_loss: 0.1149\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 0.1328,\tval_loss: 0.1148\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 0.1216,\tval_loss: 0.1148\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 0.1361,\tval_loss: 0.1148\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 0.1265,\tval_loss: 0.1149\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 0.1350,\tval_loss: 0.1149\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 0.3596,\tval_loss: 0.1150\n",
            "51:\t[0s / 4s],\t\ttrain_loss: 0.3082,\tval_loss: 0.1150\n",
            "52:\t[0s / 4s],\t\ttrain_loss: 0.2047,\tval_loss: 0.1151\n",
            "53:\t[0s / 4s],\t\ttrain_loss: 0.1333,\tval_loss: 0.1150\n",
            "54:\t[0s / 4s],\t\ttrain_loss: 0.1276,\tval_loss: 0.1149\n",
            "55:\t[0s / 4s],\t\ttrain_loss: 0.1262,\tval_loss: 0.1149\n",
            "56:\t[0s / 4s],\t\ttrain_loss: 0.1286,\tval_loss: 0.1149\n",
            "57:\t[0s / 4s],\t\ttrain_loss: 0.1449,\tval_loss: 0.1148\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 0.1355,\tval_loss: 0.1148\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 0.1293,\tval_loss: 0.1148\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 0.2565,\tval_loss: 0.1149\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 0.1264,\tval_loss: 0.1149\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 0.1275,\tval_loss: 0.1148\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 0.1792,\tval_loss: 0.1150\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 0.1250,\tval_loss: 0.1150\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 0.2361,\tval_loss: 0.1150\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 0.1361,\tval_loss: 0.1150\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 0.1346,\tval_loss: 0.1149\n",
            "68:\t[0s / 5s],\t\ttrain_loss: 0.1239,\tval_loss: 0.1150\n",
            "69:\t[0s / 5s],\t\ttrain_loss: 0.1267,\tval_loss: 0.1149\n",
            "70:\t[0s / 5s],\t\ttrain_loss: 0.1221,\tval_loss: 0.1150\n",
            "71:\t[0s / 5s],\t\ttrain_loss: 0.1242,\tval_loss: 0.1149\n",
            "72:\t[0s / 5s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1148\n",
            "73:\t[0s / 5s],\t\ttrain_loss: 0.1242,\tval_loss: 0.1150\n",
            "74:\t[0s / 5s],\t\ttrain_loss: 0.1299,\tval_loss: 0.1148\n",
            "75:\t[0s / 5s],\t\ttrain_loss: 0.1470,\tval_loss: 0.1149\n",
            "76:\t[0s / 5s],\t\ttrain_loss: 0.1224,\tval_loss: 0.1148\n",
            "77:\t[0s / 5s],\t\ttrain_loss: 0.1494,\tval_loss: 0.1149\n",
            "78:\t[0s / 5s],\t\ttrain_loss: 0.1360,\tval_loss: 0.1149\n",
            "79:\t[0s / 5s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1149\n",
            "80:\t[0s / 5s],\t\ttrain_loss: 0.1236,\tval_loss: 0.1147\n",
            "81:\t[0s / 5s],\t\ttrain_loss: 0.1479,\tval_loss: 0.1147\n",
            "82:\t[0s / 5s],\t\ttrain_loss: 0.1221,\tval_loss: 0.1149\n",
            "83:\t[0s / 5s],\t\ttrain_loss: 0.1206,\tval_loss: 0.1150\n",
            "84:\t[0s / 6s],\t\ttrain_loss: 0.1220,\tval_loss: 0.1151\n",
            "85:\t[0s / 6s],\t\ttrain_loss: 0.1245,\tval_loss: 0.1151\n",
            "86:\t[0s / 6s],\t\ttrain_loss: 0.1255,\tval_loss: 0.1150\n",
            "87:\t[0s / 6s],\t\ttrain_loss: 0.1232,\tval_loss: 0.1150\n",
            "88:\t[0s / 6s],\t\ttrain_loss: 0.1371,\tval_loss: 0.1148\n",
            "89:\t[0s / 6s],\t\ttrain_loss: 0.1186,\tval_loss: 0.1148\n",
            "90:\t[0s / 6s],\t\ttrain_loss: 0.1266,\tval_loss: 0.1150\n",
            "91:\t[0s / 6s],\t\ttrain_loss: 0.1269,\tval_loss: 0.1150\n",
            "92:\t[0s / 6s],\t\ttrain_loss: 0.1288,\tval_loss: 0.1150\n",
            "93:\t[0s / 6s],\t\ttrain_loss: 0.1240,\tval_loss: 0.1150\n",
            "94:\t[0s / 6s],\t\ttrain_loss: 0.1241,\tval_loss: 0.1148\n",
            "95:\t[0s / 6s],\t\ttrain_loss: 0.1229,\tval_loss: 0.1149\n",
            "96:\t[0s / 6s],\t\ttrain_loss: 0.1210,\tval_loss: 0.1149\n",
            "97:\t[0s / 6s],\t\ttrain_loss: 0.1214,\tval_loss: 0.1151\n",
            "98:\t[0s / 6s],\t\ttrain_loss: 0.1212,\tval_loss: 0.1150\n",
            "99:\t[0s / 6s],\t\ttrain_loss: 0.1233,\tval_loss: 0.1148\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 33\n",
            "{'batch_size': 253, 'layers': 2, 'nodes': 64, 'activation_fn': 'elu', 'alpha': 0.11963980965633245, 'sigma': 0.32703281468530887, 'lr': 0.08829360781461772, 'dropout': 0.46250405323531074, 'patience': 61, 'batch_norm': False}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2003,\tval_loss: 0.1370\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1675,\tval_loss: 0.1314\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1265\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1390,\tval_loss: 0.1241\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1327,\tval_loss: 0.1235\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1340,\tval_loss: 0.1230\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1335,\tval_loss: 0.1227\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1311,\tval_loss: 0.1226\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1300,\tval_loss: 0.1225\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.1280,\tval_loss: 0.1224\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.1276,\tval_loss: 0.1222\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.1301,\tval_loss: 0.1223\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.1291,\tval_loss: 0.1222\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.1294,\tval_loss: 0.1224\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.1286,\tval_loss: 0.1222\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.1288,\tval_loss: 0.1221\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 0.1284,\tval_loss: 0.1221\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 0.1298,\tval_loss: 0.1223\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 0.1280,\tval_loss: 0.1221\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.1284,\tval_loss: 0.1220\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.1311,\tval_loss: 0.1222\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.1304,\tval_loss: 0.1218\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.1305,\tval_loss: 0.1218\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.1340,\tval_loss: 0.1222\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.1280,\tval_loss: 0.1222\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.1279,\tval_loss: 0.1221\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.1288,\tval_loss: 0.1221\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.1291,\tval_loss: 0.1223\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.1285,\tval_loss: 0.1223\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 0.1279,\tval_loss: 0.1220\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 0.1303,\tval_loss: 0.1222\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 0.1285,\tval_loss: 0.1221\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 0.1283,\tval_loss: 0.1222\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 0.1319,\tval_loss: 0.1221\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 0.1296,\tval_loss: 0.1222\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 0.1305,\tval_loss: 0.1222\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 0.1287,\tval_loss: 0.1222\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 0.1280,\tval_loss: 0.1222\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.1292,\tval_loss: 0.1221\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.1288,\tval_loss: 0.1221\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 0.1288,\tval_loss: 0.1222\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 0.1283,\tval_loss: 0.1222\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 0.1288,\tval_loss: 0.1223\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 0.1282,\tval_loss: 0.1221\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 0.1285,\tval_loss: 0.1222\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 0.1290,\tval_loss: 0.1221\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 0.1296,\tval_loss: 0.1222\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 0.1283,\tval_loss: 0.1220\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 0.1290,\tval_loss: 0.1223\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 0.1286,\tval_loss: 0.1222\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 0.1282,\tval_loss: 0.1221\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 0.1282,\tval_loss: 0.1221\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 0.1283,\tval_loss: 0.1222\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 0.1290,\tval_loss: 0.1222\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 0.1288,\tval_loss: 0.1221\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 0.1284,\tval_loss: 0.1222\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 0.1286,\tval_loss: 0.1223\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 0.1280,\tval_loss: 0.1222\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 0.1285,\tval_loss: 0.1222\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 0.1283,\tval_loss: 0.1221\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 0.1281,\tval_loss: 0.1221\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 0.1291,\tval_loss: 0.1221\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 0.1287,\tval_loss: 0.1222\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 0.1285,\tval_loss: 0.1224\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 0.1305,\tval_loss: 0.1221\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 0.1287,\tval_loss: 0.1221\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 0.1285,\tval_loss: 0.1222\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 0.1306,\tval_loss: 0.1221\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 0.1299,\tval_loss: 0.1221\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 0.1297,\tval_loss: 0.1222\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 0.1285,\tval_loss: 0.1222\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 0.1288,\tval_loss: 0.1220\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 0.1294,\tval_loss: 0.1223\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 0.1287,\tval_loss: 0.1223\n",
            "74:\t[0s / 4s],\t\ttrain_loss: 0.1284,\tval_loss: 0.1221\n",
            "75:\t[0s / 4s],\t\ttrain_loss: 0.1306,\tval_loss: 0.1221\n",
            "76:\t[0s / 4s],\t\ttrain_loss: 0.1296,\tval_loss: 0.1221\n",
            "77:\t[0s / 4s],\t\ttrain_loss: 0.1285,\tval_loss: 0.1223\n",
            "78:\t[0s / 4s],\t\ttrain_loss: 0.1286,\tval_loss: 0.1224\n",
            "79:\t[0s / 4s],\t\ttrain_loss: 0.1283,\tval_loss: 0.1220\n",
            "80:\t[0s / 4s],\t\ttrain_loss: 0.1286,\tval_loss: 0.1220\n",
            "81:\t[0s / 4s],\t\ttrain_loss: 0.1285,\tval_loss: 0.1222\n",
            "82:\t[0s / 4s],\t\ttrain_loss: 0.1282,\tval_loss: 0.1222\n",
            "83:\t[0s / 4s],\t\ttrain_loss: 0.1287,\tval_loss: 0.1223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 34\n",
            "{'batch_size': 198, 'layers': 3, 'nodes': 91, 'activation_fn': 'tanh', 'alpha': 0.9233550058028855, 'sigma': 0.9571261573555485, 'lr': 0.0627113196459892, 'dropout': 0.535890131253898, 'patience': 29, 'batch_norm': True}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.9045,\tval_loss: 1.0745\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.6945,\tval_loss: 0.4996\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5538,\tval_loss: 0.4708\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5018,\tval_loss: 0.4551\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5214,\tval_loss: 0.4595\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4913,\tval_loss: 0.4559\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.4832,\tval_loss: 0.4645\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.5122,\tval_loss: 0.4512\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.4971,\tval_loss: 0.4554\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.4954,\tval_loss: 0.4541\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.5410,\tval_loss: 0.4489\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.5120,\tval_loss: 0.4463\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.4752,\tval_loss: 0.4737\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.4937,\tval_loss: 0.4487\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.4560,\tval_loss: 0.4623\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.4872,\tval_loss: 0.4533\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.5136,\tval_loss: 0.4560\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.4683,\tval_loss: 0.4685\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.4918,\tval_loss: 0.4492\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.5011,\tval_loss: 0.4481\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.4921,\tval_loss: 0.4545\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.4561,\tval_loss: 0.4659\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.4602,\tval_loss: 0.4508\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.4756,\tval_loss: 0.4422\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.5082,\tval_loss: 0.4381\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.5069,\tval_loss: 0.4696\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.4689,\tval_loss: 0.4553\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.4861,\tval_loss: 0.4488\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.5351,\tval_loss: 0.4508\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.5085,\tval_loss: 0.4543\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.4796,\tval_loss: 0.4707\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.4818,\tval_loss: 0.4949\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.4686,\tval_loss: 0.4408\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.4626,\tval_loss: 0.4617\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.4577,\tval_loss: 0.4446\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.4662,\tval_loss: 0.4475\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.4973,\tval_loss: 0.4586\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.4727,\tval_loss: 0.4499\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.4394,\tval_loss: 0.4647\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.4763,\tval_loss: 0.4538\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.5008,\tval_loss: 0.4456\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.4942,\tval_loss: 0.4648\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.4658,\tval_loss: 0.4652\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.4650,\tval_loss: 0.4493\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.4942,\tval_loss: 0.4547\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.4717,\tval_loss: 0.4658\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.4797,\tval_loss: 0.4578\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.4781,\tval_loss: 0.4579\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.4592,\tval_loss: 0.4490\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.4702,\tval_loss: 0.4465\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.4530,\tval_loss: 0.4489\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.4740,\tval_loss: 0.4489\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.4516,\tval_loss: 0.4649\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.4637,\tval_loss: 0.4537\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 35\n",
            "{'batch_size': 72, 'layers': 3, 'nodes': 37, 'activation_fn': 'relu', 'alpha': 0.13492285360427153, 'sigma': 0.6961275855432675, 'lr': 0.00995559027573693, 'dropout': 0.8499061609045255, 'patience': 34, 'batch_norm': False}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.3398,\tval_loss: 0.1416\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2573,\tval_loss: 0.1479\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1862,\tval_loss: 0.1431\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1785,\tval_loss: 0.1394\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1683,\tval_loss: 0.1353\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1334\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1313\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1459,\tval_loss: 0.1307\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1424,\tval_loss: 0.1301\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1445,\tval_loss: 0.1299\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1402,\tval_loss: 0.1296\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1407,\tval_loss: 0.1294\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1402,\tval_loss: 0.1292\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1421,\tval_loss: 0.1291\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1374,\tval_loss: 0.1289\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1380,\tval_loss: 0.1288\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1363,\tval_loss: 0.1287\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1381,\tval_loss: 0.1286\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1359,\tval_loss: 0.1287\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1364,\tval_loss: 0.1288\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1349,\tval_loss: 0.1287\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1353,\tval_loss: 0.1288\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1346,\tval_loss: 0.1288\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1363,\tval_loss: 0.1288\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1352,\tval_loss: 0.1287\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1347,\tval_loss: 0.1287\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1368,\tval_loss: 0.1287\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1361,\tval_loss: 0.1287\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1351,\tval_loss: 0.1285\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1351,\tval_loss: 0.1284\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1346,\tval_loss: 0.1285\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1354,\tval_loss: 0.1285\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1364,\tval_loss: 0.1286\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1362,\tval_loss: 0.1285\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1354,\tval_loss: 0.1285\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1345,\tval_loss: 0.1285\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1354,\tval_loss: 0.1286\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1352,\tval_loss: 0.1285\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1361,\tval_loss: 0.1285\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1352,\tval_loss: 0.1285\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1354,\tval_loss: 0.1284\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1336,\tval_loss: 0.1284\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1347,\tval_loss: 0.1285\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1355,\tval_loss: 0.1285\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1351,\tval_loss: 0.1285\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1357,\tval_loss: 0.1285\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1340,\tval_loss: 0.1285\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1343,\tval_loss: 0.1285\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1333,\tval_loss: 0.1286\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1347,\tval_loss: 0.1284\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1351,\tval_loss: 0.1284\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1353,\tval_loss: 0.1285\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.1346,\tval_loss: 0.1284\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.1343,\tval_loss: 0.1286\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.1356,\tval_loss: 0.1285\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.1348,\tval_loss: 0.1285\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1338,\tval_loss: 0.1284\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1357,\tval_loss: 0.1285\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1350,\tval_loss: 0.1284\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1344,\tval_loss: 0.1285\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1334,\tval_loss: 0.1284\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.1345,\tval_loss: 0.1285\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.1355,\tval_loss: 0.1286\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.1344,\tval_loss: 0.1284\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.1351,\tval_loss: 0.1284\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.1347,\tval_loss: 0.1285\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.1338,\tval_loss: 0.1285\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1341,\tval_loss: 0.1284\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1346,\tval_loss: 0.1285\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.1346,\tval_loss: 0.1285\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.1344,\tval_loss: 0.1285\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.1345,\tval_loss: 0.1285\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.1339,\tval_loss: 0.1285\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.1338,\tval_loss: 0.1284\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.1344,\tval_loss: 0.1285\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 36\n",
            "{'batch_size': 60, 'layers': 4, 'nodes': 65, 'activation_fn': 'tanh', 'alpha': 0.3441672185854532, 'sigma': 0.7058905373699317, 'lr': 0.0698785906591001, 'dropout': 0.887729550744748, 'patience': 66, 'batch_norm': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.4848,\tval_loss: 0.2266\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.3010,\tval_loss: 0.2147\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.2825,\tval_loss: 0.2177\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.2509,\tval_loss: 0.2155\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.2460,\tval_loss: 0.2158\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.2469,\tval_loss: 0.2150\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.2450,\tval_loss: 0.2203\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.2461,\tval_loss: 0.2142\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.2483,\tval_loss: 0.2168\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.2534,\tval_loss: 0.2179\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.2518,\tval_loss: 0.2268\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 0.2461,\tval_loss: 0.2236\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.2514,\tval_loss: 0.2158\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.2467,\tval_loss: 0.2185\n",
            "14:\t[0s / 3s],\t\ttrain_loss: 0.2597,\tval_loss: 0.2263\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.2747,\tval_loss: 0.2186\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.2805,\tval_loss: 0.2175\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.2893,\tval_loss: 0.2177\n",
            "18:\t[0s / 4s],\t\ttrain_loss: 0.2762,\tval_loss: 0.2209\n",
            "19:\t[0s / 5s],\t\ttrain_loss: 0.2871,\tval_loss: 0.2291\n",
            "20:\t[0s / 5s],\t\ttrain_loss: 0.2981,\tval_loss: 0.2214\n",
            "21:\t[0s / 5s],\t\ttrain_loss: 0.2944,\tval_loss: 0.2267\n",
            "22:\t[0s / 6s],\t\ttrain_loss: 0.2869,\tval_loss: 0.2246\n",
            "23:\t[0s / 6s],\t\ttrain_loss: 0.2830,\tval_loss: 0.2246\n",
            "24:\t[0s / 6s],\t\ttrain_loss: 0.3015,\tval_loss: 0.2233\n",
            "25:\t[0s / 6s],\t\ttrain_loss: 0.2915,\tval_loss: 0.2156\n",
            "26:\t[0s / 6s],\t\ttrain_loss: 0.2757,\tval_loss: 0.2208\n",
            "27:\t[0s / 7s],\t\ttrain_loss: 0.2696,\tval_loss: 0.2242\n",
            "28:\t[0s / 7s],\t\ttrain_loss: 0.2873,\tval_loss: 0.2244\n",
            "29:\t[0s / 7s],\t\ttrain_loss: 0.3029,\tval_loss: 0.2226\n",
            "30:\t[0s / 7s],\t\ttrain_loss: 0.3034,\tval_loss: 0.2270\n",
            "31:\t[0s / 7s],\t\ttrain_loss: 0.2986,\tval_loss: 0.2229\n",
            "32:\t[0s / 8s],\t\ttrain_loss: 0.2902,\tval_loss: 0.2273\n",
            "33:\t[0s / 8s],\t\ttrain_loss: 0.3202,\tval_loss: 0.2236\n",
            "34:\t[0s / 8s],\t\ttrain_loss: 0.3116,\tval_loss: 0.2208\n",
            "35:\t[0s / 8s],\t\ttrain_loss: 0.3640,\tval_loss: 0.2202\n",
            "36:\t[0s / 8s],\t\ttrain_loss: 0.3213,\tval_loss: 0.2261\n",
            "37:\t[0s / 9s],\t\ttrain_loss: 0.2931,\tval_loss: 0.2254\n",
            "38:\t[0s / 9s],\t\ttrain_loss: 0.2843,\tval_loss: 0.2290\n",
            "39:\t[0s / 9s],\t\ttrain_loss: 0.3095,\tval_loss: 0.2246\n",
            "40:\t[0s / 9s],\t\ttrain_loss: 0.2785,\tval_loss: 0.2271\n",
            "41:\t[0s / 9s],\t\ttrain_loss: 0.2913,\tval_loss: 0.2365\n",
            "42:\t[0s / 10s],\t\ttrain_loss: 0.2936,\tval_loss: 0.2262\n",
            "43:\t[0s / 10s],\t\ttrain_loss: 0.2796,\tval_loss: 0.2250\n",
            "44:\t[0s / 10s],\t\ttrain_loss: 0.2856,\tval_loss: 0.2330\n",
            "45:\t[0s / 10s],\t\ttrain_loss: 0.2814,\tval_loss: 0.2254\n",
            "46:\t[0s / 10s],\t\ttrain_loss: 0.2706,\tval_loss: 0.2382\n",
            "47:\t[0s / 11s],\t\ttrain_loss: 0.2620,\tval_loss: 0.2258\n",
            "48:\t[0s / 11s],\t\ttrain_loss: 0.3076,\tval_loss: 0.2304\n",
            "49:\t[0s / 11s],\t\ttrain_loss: 0.2898,\tval_loss: 0.2213\n",
            "50:\t[0s / 11s],\t\ttrain_loss: 0.2979,\tval_loss: 0.2382\n",
            "51:\t[0s / 11s],\t\ttrain_loss: 0.2828,\tval_loss: 0.2299\n",
            "52:\t[0s / 12s],\t\ttrain_loss: 0.2819,\tval_loss: 0.2302\n",
            "53:\t[0s / 12s],\t\ttrain_loss: 0.2583,\tval_loss: 0.2344\n",
            "54:\t[0s / 12s],\t\ttrain_loss: 0.2670,\tval_loss: 0.2283\n",
            "55:\t[0s / 12s],\t\ttrain_loss: 0.2809,\tval_loss: 0.2271\n",
            "56:\t[0s / 12s],\t\ttrain_loss: 0.2634,\tval_loss: 0.2244\n",
            "57:\t[0s / 13s],\t\ttrain_loss: 0.2598,\tval_loss: 0.2317\n",
            "58:\t[0s / 13s],\t\ttrain_loss: 0.2767,\tval_loss: 0.2206\n",
            "59:\t[0s / 13s],\t\ttrain_loss: 0.2842,\tval_loss: 0.2352\n",
            "60:\t[0s / 13s],\t\ttrain_loss: 0.2915,\tval_loss: 0.2327\n",
            "61:\t[0s / 13s],\t\ttrain_loss: 0.3330,\tval_loss: 0.2352\n",
            "62:\t[0s / 13s],\t\ttrain_loss: 0.3139,\tval_loss: 0.2285\n",
            "63:\t[0s / 14s],\t\ttrain_loss: 0.3233,\tval_loss: 0.2260\n",
            "64:\t[0s / 14s],\t\ttrain_loss: 0.3156,\tval_loss: 0.2364\n",
            "65:\t[0s / 14s],\t\ttrain_loss: 0.3934,\tval_loss: 0.2495\n",
            "66:\t[0s / 14s],\t\ttrain_loss: 0.3336,\tval_loss: 0.2269\n",
            "67:\t[0s / 14s],\t\ttrain_loss: 0.3475,\tval_loss: 0.2457\n",
            "68:\t[0s / 15s],\t\ttrain_loss: 0.2993,\tval_loss: 0.2414\n",
            "69:\t[0s / 15s],\t\ttrain_loss: 0.3442,\tval_loss: 0.2404\n",
            "70:\t[0s / 15s],\t\ttrain_loss: 0.4009,\tval_loss: 0.2644\n",
            "71:\t[0s / 15s],\t\ttrain_loss: 0.3919,\tval_loss: 0.2509\n",
            "72:\t[0s / 15s],\t\ttrain_loss: 0.3712,\tval_loss: 0.2573\n",
            "73:\t[0s / 16s],\t\ttrain_loss: 0.3555,\tval_loss: 0.2414\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 37\n",
            "{'batch_size': 111, 'layers': 1, 'nodes': 46, 'activation_fn': 'tanh', 'alpha': 0.23999204243498717, 'sigma': 0.1917960001200602, 'lr': 0.0022003352640512916, 'dropout': 0.28135902976646926, 'patience': 64, 'batch_norm': True}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2948,\tval_loss: 0.2600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2631,\tval_loss: 0.2440\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.2532,\tval_loss: 0.2317\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.2277,\tval_loss: 0.2212\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.2154,\tval_loss: 0.2124\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.2160,\tval_loss: 0.1996\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1946,\tval_loss: 0.1970\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1872,\tval_loss: 0.1922\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1849,\tval_loss: 0.1900\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1793,\tval_loss: 0.1871\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1745,\tval_loss: 0.1844\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1699,\tval_loss: 0.1826\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1650,\tval_loss: 0.1799\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1621,\tval_loss: 0.1791\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1642,\tval_loss: 0.1790\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1792\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.1748,\tval_loss: 0.1778\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1787\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1585,\tval_loss: 0.1781\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1779\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1780\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1777\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1785\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1786,\tval_loss: 0.1787\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1863,\tval_loss: 0.1787\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1557,\tval_loss: 0.1774\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1758,\tval_loss: 0.1771\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1496,\tval_loss: 0.1780\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1778\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1777\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1494,\tval_loss: 0.1763\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1786\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1510,\tval_loss: 0.1782\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1496,\tval_loss: 0.1782\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.1484,\tval_loss: 0.1788\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1470,\tval_loss: 0.1784\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1795\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1513,\tval_loss: 0.1778\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1780\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1756,\tval_loss: 0.1781\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1464,\tval_loss: 0.1778\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1772\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1428,\tval_loss: 0.1779\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1453,\tval_loss: 0.1780\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1457,\tval_loss: 0.1793\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1777\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1723,\tval_loss: 0.1793\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1507,\tval_loss: 0.1805\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1431,\tval_loss: 0.1792\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1433,\tval_loss: 0.1793\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1685,\tval_loss: 0.1791\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1403,\tval_loss: 0.1796\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1408,\tval_loss: 0.1810\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1733,\tval_loss: 0.1799\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.1420,\tval_loss: 0.1806\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.1404,\tval_loss: 0.1824\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1428,\tval_loss: 0.1816\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1380,\tval_loss: 0.1817\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1718,\tval_loss: 0.1816\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1821,\tval_loss: 0.1838\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1393,\tval_loss: 0.1811\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.1397,\tval_loss: 0.1791\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.1389,\tval_loss: 0.1794\n",
            "63:\t[0s / 6s],\t\ttrain_loss: 0.1388,\tval_loss: 0.1798\n",
            "64:\t[0s / 6s],\t\ttrain_loss: 0.1361,\tval_loss: 0.1792\n",
            "65:\t[0s / 6s],\t\ttrain_loss: 0.1394,\tval_loss: 0.1804\n",
            "66:\t[0s / 6s],\t\ttrain_loss: 0.1389,\tval_loss: 0.1803\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1372,\tval_loss: 0.1794\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1361,\tval_loss: 0.1798\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.1396,\tval_loss: 0.1789\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.1353,\tval_loss: 0.1807\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.1441,\tval_loss: 0.1805\n",
            "72:\t[0s / 7s],\t\ttrain_loss: 0.1308,\tval_loss: 0.1815\n",
            "73:\t[0s / 7s],\t\ttrain_loss: 0.1361,\tval_loss: 0.1808\n",
            "74:\t[0s / 7s],\t\ttrain_loss: 0.1326,\tval_loss: 0.1806\n",
            "75:\t[0s / 7s],\t\ttrain_loss: 0.1349,\tval_loss: 0.1801\n",
            "76:\t[0s / 7s],\t\ttrain_loss: 0.1362,\tval_loss: 0.1816\n",
            "77:\t[0s / 7s],\t\ttrain_loss: 0.1380,\tval_loss: 0.1817\n",
            "78:\t[0s / 7s],\t\ttrain_loss: 0.1375,\tval_loss: 0.1801\n",
            "79:\t[0s / 7s],\t\ttrain_loss: 0.1310,\tval_loss: 0.1807\n",
            "80:\t[0s / 8s],\t\ttrain_loss: 0.1358,\tval_loss: 0.1800\n",
            "81:\t[0s / 8s],\t\ttrain_loss: 0.1380,\tval_loss: 0.1810\n",
            "82:\t[0s / 8s],\t\ttrain_loss: 0.1326,\tval_loss: 0.1826\n",
            "83:\t[0s / 8s],\t\ttrain_loss: 0.1380,\tval_loss: 0.1817\n",
            "84:\t[0s / 8s],\t\ttrain_loss: 0.1318,\tval_loss: 0.1826\n",
            "85:\t[0s / 8s],\t\ttrain_loss: 0.1350,\tval_loss: 0.1834\n",
            "86:\t[0s / 8s],\t\ttrain_loss: 0.1338,\tval_loss: 0.1832\n",
            "87:\t[0s / 8s],\t\ttrain_loss: 0.1291,\tval_loss: 0.1841\n",
            "88:\t[0s / 8s],\t\ttrain_loss: 0.1363,\tval_loss: 0.1839\n",
            "89:\t[0s / 8s],\t\ttrain_loss: 0.1325,\tval_loss: 0.1835\n",
            "90:\t[0s / 8s],\t\ttrain_loss: 0.1340,\tval_loss: 0.1831\n",
            "91:\t[0s / 8s],\t\ttrain_loss: 0.1300,\tval_loss: 0.1812\n",
            "92:\t[0s / 9s],\t\ttrain_loss: 0.1285,\tval_loss: 0.1820\n",
            "93:\t[0s / 9s],\t\ttrain_loss: 0.1308,\tval_loss: 0.1834\n",
            "94:\t[0s / 9s],\t\ttrain_loss: 0.1312,\tval_loss: 0.1825\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 38\n",
            "{'batch_size': 166, 'layers': 1, 'nodes': 70, 'activation_fn': 'tanh', 'alpha': 0.24180209856604665, 'sigma': 0.9306455592544185, 'lr': 0.04410248928322004, 'dropout': 0.9335238524446804, 'patience': 63, 'batch_norm': False}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.3371,\tval_loss: 0.2591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.3506,\tval_loss: 0.2285\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.3555,\tval_loss: 0.1984\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.3159,\tval_loss: 0.1905\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.3188,\tval_loss: 0.1898\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.2725,\tval_loss: 0.1910\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.2882,\tval_loss: 0.1945\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.2877,\tval_loss: 0.2028\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.3001,\tval_loss: 0.1818\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.2598,\tval_loss: 0.1836\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.2661,\tval_loss: 0.1884\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.2878,\tval_loss: 0.1889\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.2469,\tval_loss: 0.1952\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.2537,\tval_loss: 0.1989\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.2325,\tval_loss: 0.1862\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.2506,\tval_loss: 0.1844\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 0.2406,\tval_loss: 0.1851\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.2446,\tval_loss: 0.1905\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.1841,\tval_loss: 0.1929\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.2389,\tval_loss: 0.1904\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.2236,\tval_loss: 0.1911\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.2600,\tval_loss: 0.1994\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.2185,\tval_loss: 0.1956\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.2672,\tval_loss: 0.1882\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.2182,\tval_loss: 0.1820\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.2158,\tval_loss: 0.1929\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.2449,\tval_loss: 0.1854\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.2327,\tval_loss: 0.1955\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.2064,\tval_loss: 0.1948\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 0.2098,\tval_loss: 0.1958\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 0.2286,\tval_loss: 0.1940\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 0.2008,\tval_loss: 0.1961\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 0.2027,\tval_loss: 0.2009\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 0.2246,\tval_loss: 0.2014\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.1916,\tval_loss: 0.1993\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.1749,\tval_loss: 0.1975\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.1965,\tval_loss: 0.2000\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.2007,\tval_loss: 0.2002\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.2408,\tval_loss: 0.1977\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.2035,\tval_loss: 0.1975\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 0.1808,\tval_loss: 0.1964\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 0.2336,\tval_loss: 0.1976\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 0.2083,\tval_loss: 0.1930\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 0.1787,\tval_loss: 0.1901\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 0.1960,\tval_loss: 0.1899\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 0.2020,\tval_loss: 0.1887\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 0.1739,\tval_loss: 0.1894\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 0.1855,\tval_loss: 0.1883\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 0.1791,\tval_loss: 0.1889\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 0.1996,\tval_loss: 0.1870\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 0.1994,\tval_loss: 0.1728\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 0.1835,\tval_loss: 0.1724\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 0.1689,\tval_loss: 0.1728\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 0.1860,\tval_loss: 0.1730\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 0.1701,\tval_loss: 0.1732\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 0.1772,\tval_loss: 0.1748\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 0.1712,\tval_loss: 0.1764\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 0.1921,\tval_loss: 0.1747\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 0.1987,\tval_loss: 0.1731\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 0.1721,\tval_loss: 0.1721\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 0.1694,\tval_loss: 0.1727\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 0.1695,\tval_loss: 0.1731\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 0.1813,\tval_loss: 0.1731\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 0.1809,\tval_loss: 0.1729\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 0.1936,\tval_loss: 0.1737\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 0.1867,\tval_loss: 0.1729\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 0.1696,\tval_loss: 0.1732\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 0.1822,\tval_loss: 0.1735\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 0.1820,\tval_loss: 0.1738\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 0.1710,\tval_loss: 0.1744\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 0.1825,\tval_loss: 0.1734\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 0.1741,\tval_loss: 0.1725\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 0.1825,\tval_loss: 0.1727\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 0.1695,\tval_loss: 0.1733\n",
            "74:\t[0s / 4s],\t\ttrain_loss: 0.1794,\tval_loss: 0.1728\n",
            "75:\t[0s / 4s],\t\ttrain_loss: 0.1688,\tval_loss: 0.1725\n",
            "76:\t[0s / 4s],\t\ttrain_loss: 0.1694,\tval_loss: 0.1726\n",
            "77:\t[0s / 4s],\t\ttrain_loss: 0.1820,\tval_loss: 0.1722\n",
            "78:\t[0s / 4s],\t\ttrain_loss: 0.1683,\tval_loss: 0.1717\n",
            "79:\t[0s / 4s],\t\ttrain_loss: 0.1697,\tval_loss: 0.1718\n",
            "80:\t[0s / 4s],\t\ttrain_loss: 0.1690,\tval_loss: 0.1716\n",
            "81:\t[0s / 4s],\t\ttrain_loss: 0.1858,\tval_loss: 0.1719\n",
            "82:\t[0s / 4s],\t\ttrain_loss: 0.1700,\tval_loss: 0.1725\n",
            "83:\t[0s / 4s],\t\ttrain_loss: 0.1822,\tval_loss: 0.1723\n",
            "84:\t[0s / 4s],\t\ttrain_loss: 0.1813,\tval_loss: 0.1725\n",
            "85:\t[0s / 4s],\t\ttrain_loss: 0.1829,\tval_loss: 0.1725\n",
            "86:\t[0s / 5s],\t\ttrain_loss: 0.1833,\tval_loss: 0.1714\n",
            "87:\t[0s / 5s],\t\ttrain_loss: 0.1693,\tval_loss: 0.1710\n",
            "88:\t[0s / 5s],\t\ttrain_loss: 0.1974,\tval_loss: 0.1712\n",
            "89:\t[0s / 5s],\t\ttrain_loss: 0.2052,\tval_loss: 0.1717\n",
            "90:\t[0s / 5s],\t\ttrain_loss: 0.1722,\tval_loss: 0.1732\n",
            "91:\t[0s / 5s],\t\ttrain_loss: 0.1850,\tval_loss: 0.1735\n",
            "92:\t[0s / 5s],\t\ttrain_loss: 0.1904,\tval_loss: 0.1731\n",
            "93:\t[0s / 5s],\t\ttrain_loss: 0.1929,\tval_loss: 0.1726\n",
            "94:\t[0s / 5s],\t\ttrain_loss: 0.1794,\tval_loss: 0.1719\n",
            "95:\t[0s / 5s],\t\ttrain_loss: 0.1686,\tval_loss: 0.1720\n",
            "96:\t[0s / 5s],\t\ttrain_loss: 0.1844,\tval_loss: 0.1719\n",
            "97:\t[0s / 5s],\t\ttrain_loss: 0.1699,\tval_loss: 0.1715\n",
            "98:\t[0s / 5s],\t\ttrain_loss: 0.1827,\tval_loss: 0.1714\n",
            "99:\t[0s / 5s],\t\ttrain_loss: 0.1693,\tval_loss: 0.1713\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 39\n",
            "{'batch_size': 37, 'layers': 1, 'nodes': 72, 'activation_fn': 'tanh', 'alpha': 0.8042007504807112, 'sigma': 0.2752318345789786, 'lr': 0.07616672758860887, 'dropout': 0.43475421282667437, 'patience': 52, 'batch_norm': False}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 1.0322,\tval_loss: 0.8796\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 1.0155,\tval_loss: 0.5440\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.7665,\tval_loss: 0.4866\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.7111,\tval_loss: 0.4995\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.5989,\tval_loss: 0.4271\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.5280,\tval_loss: 0.4514\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.4685,\tval_loss: 0.4216\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.4334,\tval_loss: 0.4159\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.4169,\tval_loss: 0.4342\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.4046,\tval_loss: 0.4275\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.4232,\tval_loss: 0.4266\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 0.4228,\tval_loss: 0.4194\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.4461,\tval_loss: 0.4231\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.4238,\tval_loss: 0.4365\n",
            "14:\t[0s / 3s],\t\ttrain_loss: 0.4065,\tval_loss: 0.4253\n",
            "15:\t[0s / 3s],\t\ttrain_loss: 0.4191,\tval_loss: 0.4279\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.4624,\tval_loss: 0.4292\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.4082,\tval_loss: 0.4306\n",
            "18:\t[0s / 4s],\t\ttrain_loss: 0.4857,\tval_loss: 0.4285\n",
            "19:\t[0s / 4s],\t\ttrain_loss: 0.4152,\tval_loss: 0.4170\n",
            "20:\t[0s / 5s],\t\ttrain_loss: 0.4085,\tval_loss: 0.4340\n",
            "21:\t[0s / 5s],\t\ttrain_loss: 0.3994,\tval_loss: 0.4058\n",
            "22:\t[0s / 5s],\t\ttrain_loss: 0.4406,\tval_loss: 0.4332\n",
            "23:\t[0s / 5s],\t\ttrain_loss: 0.4138,\tval_loss: 0.4274\n",
            "24:\t[0s / 5s],\t\ttrain_loss: 0.4022,\tval_loss: 0.4132\n",
            "25:\t[0s / 5s],\t\ttrain_loss: 0.4016,\tval_loss: 0.4288\n",
            "26:\t[0s / 6s],\t\ttrain_loss: 0.3987,\tval_loss: 0.4374\n",
            "27:\t[0s / 6s],\t\ttrain_loss: 0.4346,\tval_loss: 0.4310\n",
            "28:\t[0s / 6s],\t\ttrain_loss: 0.4136,\tval_loss: 0.4246\n",
            "29:\t[0s / 6s],\t\ttrain_loss: 0.4078,\tval_loss: 0.4163\n",
            "30:\t[0s / 6s],\t\ttrain_loss: 0.4058,\tval_loss: 0.4309\n",
            "31:\t[0s / 6s],\t\ttrain_loss: 0.4058,\tval_loss: 0.4357\n",
            "32:\t[0s / 7s],\t\ttrain_loss: 0.4080,\tval_loss: 0.4364\n",
            "33:\t[0s / 7s],\t\ttrain_loss: 0.4068,\tval_loss: 0.4254\n",
            "34:\t[0s / 7s],\t\ttrain_loss: 0.4047,\tval_loss: 0.4457\n",
            "35:\t[0s / 7s],\t\ttrain_loss: 0.4274,\tval_loss: 0.4291\n",
            "36:\t[0s / 7s],\t\ttrain_loss: 0.4105,\tval_loss: 0.4194\n",
            "37:\t[0s / 8s],\t\ttrain_loss: 0.4133,\tval_loss: 0.4143\n",
            "38:\t[0s / 8s],\t\ttrain_loss: 0.4321,\tval_loss: 0.4227\n",
            "39:\t[0s / 8s],\t\ttrain_loss: 0.4346,\tval_loss: 0.4282\n",
            "40:\t[0s / 8s],\t\ttrain_loss: 0.4174,\tval_loss: 0.4141\n",
            "41:\t[0s / 8s],\t\ttrain_loss: 0.4139,\tval_loss: 0.4380\n",
            "42:\t[0s / 8s],\t\ttrain_loss: 0.4081,\tval_loss: 0.4366\n",
            "43:\t[0s / 9s],\t\ttrain_loss: 0.4729,\tval_loss: 0.4459\n",
            "44:\t[0s / 9s],\t\ttrain_loss: 0.4239,\tval_loss: 0.4117\n",
            "45:\t[0s / 9s],\t\ttrain_loss: 0.4345,\tval_loss: 0.4124\n",
            "46:\t[0s / 9s],\t\ttrain_loss: 0.4689,\tval_loss: 0.4115\n",
            "47:\t[0s / 9s],\t\ttrain_loss: 0.4878,\tval_loss: 0.4662\n",
            "48:\t[0s / 9s],\t\ttrain_loss: 0.4444,\tval_loss: 0.4393\n",
            "49:\t[0s / 10s],\t\ttrain_loss: 0.4195,\tval_loss: 0.4387\n",
            "50:\t[0s / 10s],\t\ttrain_loss: 0.4213,\tval_loss: 0.4043\n",
            "51:\t[0s / 10s],\t\ttrain_loss: 0.4111,\tval_loss: 0.4191\n",
            "52:\t[0s / 10s],\t\ttrain_loss: 0.4369,\tval_loss: 0.4193\n",
            "53:\t[0s / 10s],\t\ttrain_loss: 0.4135,\tval_loss: 0.4491\n",
            "54:\t[0s / 10s],\t\ttrain_loss: 0.4170,\tval_loss: 0.4171\n",
            "55:\t[0s / 11s],\t\ttrain_loss: 0.4062,\tval_loss: 0.4273\n",
            "56:\t[0s / 11s],\t\ttrain_loss: 0.4117,\tval_loss: 0.4188\n",
            "57:\t[0s / 11s],\t\ttrain_loss: 0.4074,\tval_loss: 0.4416\n",
            "58:\t[0s / 11s],\t\ttrain_loss: 0.4197,\tval_loss: 0.4140\n",
            "59:\t[0s / 11s],\t\ttrain_loss: 0.4106,\tval_loss: 0.4160\n",
            "60:\t[0s / 12s],\t\ttrain_loss: 0.4080,\tval_loss: 0.4308\n",
            "61:\t[0s / 12s],\t\ttrain_loss: 0.4111,\tval_loss: 0.4316\n",
            "62:\t[0s / 12s],\t\ttrain_loss: 0.4111,\tval_loss: 0.4253\n",
            "63:\t[0s / 12s],\t\ttrain_loss: 0.4128,\tval_loss: 0.4368\n",
            "64:\t[0s / 12s],\t\ttrain_loss: 0.4096,\tval_loss: 0.4486\n",
            "65:\t[0s / 12s],\t\ttrain_loss: 0.4074,\tval_loss: 0.4452\n",
            "66:\t[0s / 13s],\t\ttrain_loss: 0.4362,\tval_loss: 0.4338\n",
            "67:\t[0s / 13s],\t\ttrain_loss: 0.4093,\tval_loss: 0.4142\n",
            "68:\t[0s / 13s],\t\ttrain_loss: 0.4077,\tval_loss: 0.4392\n",
            "69:\t[0s / 13s],\t\ttrain_loss: 0.4093,\tval_loss: 0.4196\n",
            "70:\t[0s / 13s],\t\ttrain_loss: 0.4098,\tval_loss: 0.4286\n",
            "71:\t[0s / 14s],\t\ttrain_loss: 0.4429,\tval_loss: 0.4217\n",
            "72:\t[0s / 14s],\t\ttrain_loss: 0.4131,\tval_loss: 0.4316\n",
            "73:\t[0s / 14s],\t\ttrain_loss: 0.4106,\tval_loss: 0.4257\n",
            "74:\t[0s / 14s],\t\ttrain_loss: 0.4074,\tval_loss: 0.4238\n",
            "75:\t[0s / 14s],\t\ttrain_loss: 0.4085,\tval_loss: 0.4336\n",
            "76:\t[0s / 15s],\t\ttrain_loss: 0.4644,\tval_loss: 0.4356\n",
            "77:\t[0s / 15s],\t\ttrain_loss: 0.4371,\tval_loss: 0.4234\n",
            "78:\t[0s / 15s],\t\ttrain_loss: 0.4390,\tval_loss: 0.4292\n",
            "79:\t[0s / 15s],\t\ttrain_loss: 0.4156,\tval_loss: 0.4239\n",
            "80:\t[0s / 16s],\t\ttrain_loss: 0.4062,\tval_loss: 0.4398\n",
            "81:\t[0s / 16s],\t\ttrain_loss: 0.4073,\tval_loss: 0.4401\n",
            "82:\t[0s / 16s],\t\ttrain_loss: 0.4163,\tval_loss: 0.4194\n",
            "83:\t[0s / 16s],\t\ttrain_loss: 0.4105,\tval_loss: 0.4327\n",
            "84:\t[0s / 17s],\t\ttrain_loss: 0.4088,\tval_loss: 0.4235\n",
            "85:\t[0s / 17s],\t\ttrain_loss: 0.4065,\tval_loss: 0.4411\n",
            "86:\t[0s / 17s],\t\ttrain_loss: 0.4079,\tval_loss: 0.4506\n",
            "87:\t[0s / 17s],\t\ttrain_loss: 0.4556,\tval_loss: 0.4411\n",
            "88:\t[0s / 18s],\t\ttrain_loss: 0.4617,\tval_loss: 0.4343\n",
            "89:\t[0s / 18s],\t\ttrain_loss: 0.4284,\tval_loss: 0.4340\n",
            "90:\t[0s / 18s],\t\ttrain_loss: 0.4097,\tval_loss: 0.4461\n",
            "91:\t[0s / 18s],\t\ttrain_loss: 0.4078,\tval_loss: 0.4162\n",
            "92:\t[0s / 19s],\t\ttrain_loss: 0.4190,\tval_loss: 0.4263\n",
            "93:\t[0s / 19s],\t\ttrain_loss: 0.4138,\tval_loss: 0.4107\n",
            "94:\t[0s / 19s],\t\ttrain_loss: 0.5517,\tval_loss: 0.5201\n",
            "95:\t[0s / 19s],\t\ttrain_loss: 0.4649,\tval_loss: 0.4597\n",
            "96:\t[0s / 19s],\t\ttrain_loss: 0.4752,\tval_loss: 0.4066\n",
            "97:\t[0s / 20s],\t\ttrain_loss: 0.4163,\tval_loss: 0.4118\n",
            "98:\t[0s / 20s],\t\ttrain_loss: 0.4144,\tval_loss: 0.4101\n",
            "99:\t[0s / 20s],\t\ttrain_loss: 0.4134,\tval_loss: 0.4118\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 40\n",
            "{'batch_size': 220, 'layers': 4, 'nodes': 52, 'activation_fn': 'tanh', 'alpha': 0.21097009092705388, 'sigma': 0.7904938952957362, 'lr': 0.06154512472737134, 'dropout': 0.58818695560961, 'patience': 72, 'batch_norm': False}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.3104,\tval_loss: 0.2046\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2410,\tval_loss: 0.1738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 0.2227,\tval_loss: 0.1717\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.2099,\tval_loss: 0.1667\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.2268,\tval_loss: 0.1632\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1869,\tval_loss: 0.1626\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.2723,\tval_loss: 0.1630\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1840,\tval_loss: 0.1622\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1742,\tval_loss: 0.1616\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.1743,\tval_loss: 0.1612\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.1659,\tval_loss: 0.1612\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1610\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.1793,\tval_loss: 0.1608\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1604\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1707,\tval_loss: 0.1604\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1914,\tval_loss: 0.1604\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1605\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1838,\tval_loss: 0.1604\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1603\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.1757,\tval_loss: 0.1605\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.1715,\tval_loss: 0.1607\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.1735,\tval_loss: 0.1601\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.1668,\tval_loss: 0.1600\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.1789,\tval_loss: 0.1602\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.1738,\tval_loss: 0.1605\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.1674,\tval_loss: 0.1601\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.1726,\tval_loss: 0.1598\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.1700,\tval_loss: 0.1594\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1598\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.1728,\tval_loss: 0.1601\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.1657,\tval_loss: 0.1597\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.1765,\tval_loss: 0.1598\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.1768,\tval_loss: 0.1598\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.1724,\tval_loss: 0.1603\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.1786,\tval_loss: 0.1605\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.1607,\tval_loss: 0.1601\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1603\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.1674,\tval_loss: 0.1605\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.1762,\tval_loss: 0.1602\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.1669,\tval_loss: 0.1600\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 0.1685,\tval_loss: 0.1598\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 0.1654,\tval_loss: 0.1598\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1594\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 0.1671,\tval_loss: 0.1597\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 0.1656,\tval_loss: 0.1598\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 0.1815,\tval_loss: 0.1599\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 0.1782,\tval_loss: 0.1602\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 0.1743,\tval_loss: 0.1601\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 0.1791,\tval_loss: 0.1601\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1599\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 0.1660,\tval_loss: 0.1602\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 0.1704,\tval_loss: 0.1601\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 0.1607,\tval_loss: 0.1597\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 0.1779,\tval_loss: 0.1594\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1591\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 0.1720,\tval_loss: 0.1589\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 0.1714,\tval_loss: 0.1596\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 0.1771,\tval_loss: 0.1599\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 0.1667,\tval_loss: 0.1599\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 0.1728,\tval_loss: 0.1595\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 0.1610,\tval_loss: 0.1593\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 0.1671,\tval_loss: 0.1598\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1600\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 0.1824,\tval_loss: 0.1600\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 0.1828,\tval_loss: 0.1602\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 0.1557,\tval_loss: 0.1600\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1602\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 0.1661,\tval_loss: 0.1597\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 0.1672,\tval_loss: 0.1596\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 0.1726,\tval_loss: 0.1595\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1602\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 0.1655,\tval_loss: 0.1603\n",
            "72:\t[0s / 5s],\t\ttrain_loss: 0.1648,\tval_loss: 0.1600\n",
            "73:\t[0s / 5s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1601\n",
            "74:\t[0s / 5s],\t\ttrain_loss: 0.1707,\tval_loss: 0.1600\n",
            "75:\t[0s / 5s],\t\ttrain_loss: 0.1676,\tval_loss: 0.1599\n",
            "76:\t[0s / 5s],\t\ttrain_loss: 0.1719,\tval_loss: 0.1597\n",
            "77:\t[0s / 5s],\t\ttrain_loss: 0.1671,\tval_loss: 0.1592\n",
            "78:\t[0s / 5s],\t\ttrain_loss: 0.1727,\tval_loss: 0.1600\n",
            "79:\t[0s / 5s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1608\n",
            "80:\t[0s / 5s],\t\ttrain_loss: 0.1610,\tval_loss: 0.1607\n",
            "81:\t[0s / 5s],\t\ttrain_loss: 0.1715,\tval_loss: 0.1601\n",
            "82:\t[0s / 5s],\t\ttrain_loss: 0.1728,\tval_loss: 0.1603\n",
            "83:\t[0s / 5s],\t\ttrain_loss: 0.1728,\tval_loss: 0.1601\n",
            "84:\t[0s / 5s],\t\ttrain_loss: 0.1656,\tval_loss: 0.1598\n",
            "85:\t[0s / 5s],\t\ttrain_loss: 0.1661,\tval_loss: 0.1599\n",
            "86:\t[0s / 5s],\t\ttrain_loss: 0.1730,\tval_loss: 0.1600\n",
            "87:\t[0s / 6s],\t\ttrain_loss: 0.1663,\tval_loss: 0.1596\n",
            "88:\t[0s / 6s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1600\n",
            "89:\t[0s / 6s],\t\ttrain_loss: 0.1684,\tval_loss: 0.1597\n",
            "90:\t[0s / 6s],\t\ttrain_loss: 0.1790,\tval_loss: 0.1600\n",
            "91:\t[0s / 6s],\t\ttrain_loss: 0.1547,\tval_loss: 0.1605\n",
            "92:\t[0s / 6s],\t\ttrain_loss: 0.1659,\tval_loss: 0.1605\n",
            "93:\t[0s / 6s],\t\ttrain_loss: 0.1763,\tval_loss: 0.1603\n",
            "94:\t[0s / 6s],\t\ttrain_loss: 0.1829,\tval_loss: 0.1599\n",
            "95:\t[0s / 6s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1596\n",
            "96:\t[0s / 6s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1599\n",
            "97:\t[0s / 6s],\t\ttrain_loss: 0.1664,\tval_loss: 0.1597\n",
            "98:\t[0s / 6s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1593\n",
            "99:\t[0s / 6s],\t\ttrain_loss: 0.1723,\tval_loss: 0.1595\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 41\n",
            "{'batch_size': 177, 'layers': 2, 'nodes': 95, 'activation_fn': 'elu', 'alpha': 0.5939446233701559, 'sigma': 0.28637114037095124, 'lr': 0.02554142920260629, 'dropout': 0.48883080877046914, 'patience': 52, 'batch_norm': False}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.4675,\tval_loss: 0.3405\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.3767,\tval_loss: 0.3421\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.3827,\tval_loss: 0.3382\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.3635,\tval_loss: 0.3492\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.3789,\tval_loss: 0.3274\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.3470,\tval_loss: 0.3255\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.3532,\tval_loss: 0.3349\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.3355,\tval_loss: 0.3382\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.3381,\tval_loss: 0.3266\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.3312,\tval_loss: 0.3241\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.3330,\tval_loss: 0.3171\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.3305,\tval_loss: 0.3217\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.3349,\tval_loss: 0.3233\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.3309,\tval_loss: 0.3209\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.3223,\tval_loss: 0.3230\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.3312,\tval_loss: 0.3287\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.3166,\tval_loss: 0.3303\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.3322,\tval_loss: 0.3250\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.3239,\tval_loss: 0.3154\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.3259,\tval_loss: 0.3227\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.3146,\tval_loss: 0.3214\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.3213,\tval_loss: 0.3220\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.3108,\tval_loss: 0.3232\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.3210,\tval_loss: 0.3204\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.3192,\tval_loss: 0.3237\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.3336,\tval_loss: 0.3194\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.3402,\tval_loss: 0.3174\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.3167,\tval_loss: 0.3199\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.3119,\tval_loss: 0.3249\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.3143,\tval_loss: 0.3208\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.3212,\tval_loss: 0.3234\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.3221,\tval_loss: 0.3282\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.3390,\tval_loss: 0.3186\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.3143,\tval_loss: 0.3270\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.3187,\tval_loss: 0.3269\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.3326,\tval_loss: 0.3247\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.3154,\tval_loss: 0.3288\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.3090,\tval_loss: 0.3331\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.3199,\tval_loss: 0.3332\n",
            "39:\t[0s / 3s],\t\ttrain_loss: 0.3228,\tval_loss: 0.3378\n",
            "40:\t[0s / 3s],\t\ttrain_loss: 0.3205,\tval_loss: 0.3317\n",
            "41:\t[0s / 3s],\t\ttrain_loss: 0.3290,\tval_loss: 0.3247\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 0.3359,\tval_loss: 0.3291\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 0.3268,\tval_loss: 0.3246\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 0.3139,\tval_loss: 0.3328\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 0.3185,\tval_loss: 0.3312\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 0.3124,\tval_loss: 0.3227\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 0.3366,\tval_loss: 0.3255\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 0.3307,\tval_loss: 0.3302\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 0.3085,\tval_loss: 0.3316\n",
            "50:\t[0s / 4s],\t\ttrain_loss: 0.3162,\tval_loss: 0.3318\n",
            "51:\t[0s / 4s],\t\ttrain_loss: 0.3170,\tval_loss: 0.3415\n",
            "52:\t[0s / 4s],\t\ttrain_loss: 0.3109,\tval_loss: 0.3405\n",
            "53:\t[0s / 4s],\t\ttrain_loss: 0.3070,\tval_loss: 0.3416\n",
            "54:\t[0s / 4s],\t\ttrain_loss: 0.3224,\tval_loss: 0.3378\n",
            "55:\t[0s / 4s],\t\ttrain_loss: 0.3264,\tval_loss: 0.3361\n",
            "56:\t[0s / 4s],\t\ttrain_loss: 0.3108,\tval_loss: 0.3392\n",
            "57:\t[0s / 4s],\t\ttrain_loss: 0.3042,\tval_loss: 0.3392\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 0.3127,\tval_loss: 0.3371\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 0.3099,\tval_loss: 0.3355\n",
            "60:\t[0s / 5s],\t\ttrain_loss: 0.3099,\tval_loss: 0.3277\n",
            "61:\t[0s / 5s],\t\ttrain_loss: 0.3104,\tval_loss: 0.3305\n",
            "62:\t[0s / 5s],\t\ttrain_loss: 0.3184,\tval_loss: 0.3374\n",
            "63:\t[0s / 5s],\t\ttrain_loss: 0.3225,\tval_loss: 0.3341\n",
            "64:\t[0s / 5s],\t\ttrain_loss: 0.3068,\tval_loss: 0.3312\n",
            "65:\t[0s / 5s],\t\ttrain_loss: 0.3111,\tval_loss: 0.3326\n",
            "66:\t[0s / 5s],\t\ttrain_loss: 0.3159,\tval_loss: 0.3366\n",
            "67:\t[0s / 5s],\t\ttrain_loss: 0.3226,\tval_loss: 0.3426\n",
            "68:\t[0s / 5s],\t\ttrain_loss: 0.3177,\tval_loss: 0.3327\n",
            "69:\t[0s / 5s],\t\ttrain_loss: 0.3241,\tval_loss: 0.3293\n",
            "70:\t[0s / 6s],\t\ttrain_loss: 0.3289,\tval_loss: 0.3328\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 42\n",
            "{'batch_size': 32, 'layers': 1, 'nodes': 60, 'activation_fn': 'elu', 'alpha': 0.39797409174468856, 'sigma': 0.3738679573353064, 'lr': 0.07327712770410588, 'dropout': 0.012794106535787808, 'patience': 74, 'batch_norm': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.3182,\tval_loss: 0.2658\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2598,\tval_loss: 0.2516\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.2579,\tval_loss: 0.2477\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.2485,\tval_loss: 0.2500\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.2571,\tval_loss: 0.2625\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.2547,\tval_loss: 0.2513\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.2542,\tval_loss: 0.2623\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.2548,\tval_loss: 0.2439\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.2528,\tval_loss: 0.2548\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.2499,\tval_loss: 0.2646\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.2480,\tval_loss: 0.2621\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 0.2484,\tval_loss: 0.2506\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.2506,\tval_loss: 0.2525\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.2443,\tval_loss: 0.2487\n",
            "14:\t[0s / 3s],\t\ttrain_loss: 0.2521,\tval_loss: 0.2650\n",
            "15:\t[0s / 3s],\t\ttrain_loss: 0.2473,\tval_loss: 0.2556\n",
            "16:\t[0s / 3s],\t\ttrain_loss: 0.2473,\tval_loss: 0.2769\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.2487,\tval_loss: 0.2631\n",
            "18:\t[0s / 4s],\t\ttrain_loss: 0.2464,\tval_loss: 0.2786\n",
            "19:\t[0s / 4s],\t\ttrain_loss: 0.2395,\tval_loss: 0.2748\n",
            "20:\t[0s / 4s],\t\ttrain_loss: 0.2433,\tval_loss: 0.2693\n",
            "21:\t[0s / 5s],\t\ttrain_loss: 0.2426,\tval_loss: 0.2976\n",
            "22:\t[0s / 5s],\t\ttrain_loss: 0.2476,\tval_loss: 0.2701\n",
            "23:\t[0s / 5s],\t\ttrain_loss: 0.2432,\tval_loss: 0.2677\n",
            "24:\t[0s / 5s],\t\ttrain_loss: 0.2450,\tval_loss: 0.2612\n",
            "25:\t[0s / 5s],\t\ttrain_loss: 0.2381,\tval_loss: 0.3023\n",
            "26:\t[0s / 6s],\t\ttrain_loss: 0.2326,\tval_loss: 0.2689\n",
            "27:\t[0s / 6s],\t\ttrain_loss: 0.2321,\tval_loss: 0.3227\n",
            "28:\t[0s / 6s],\t\ttrain_loss: 0.2373,\tval_loss: 0.2731\n",
            "29:\t[0s / 6s],\t\ttrain_loss: 0.2398,\tval_loss: 0.3116\n",
            "30:\t[0s / 7s],\t\ttrain_loss: 0.2408,\tval_loss: 0.2786\n",
            "31:\t[0s / 7s],\t\ttrain_loss: 0.2326,\tval_loss: 0.3270\n",
            "32:\t[0s / 7s],\t\ttrain_loss: 0.2286,\tval_loss: 0.2873\n",
            "33:\t[0s / 7s],\t\ttrain_loss: 0.2283,\tval_loss: 0.2789\n",
            "34:\t[0s / 7s],\t\ttrain_loss: 0.2311,\tval_loss: 0.3147\n",
            "35:\t[0s / 8s],\t\ttrain_loss: 0.2313,\tval_loss: 0.3020\n",
            "36:\t[0s / 8s],\t\ttrain_loss: 0.2270,\tval_loss: 0.2961\n",
            "37:\t[0s / 8s],\t\ttrain_loss: 0.2206,\tval_loss: 0.3166\n",
            "38:\t[0s / 8s],\t\ttrain_loss: 0.2220,\tval_loss: 0.3172\n",
            "39:\t[0s / 8s],\t\ttrain_loss: 0.2214,\tval_loss: 0.3289\n",
            "40:\t[0s / 9s],\t\ttrain_loss: 0.2288,\tval_loss: 0.2998\n",
            "41:\t[0s / 9s],\t\ttrain_loss: 0.2259,\tval_loss: 0.3144\n",
            "42:\t[0s / 9s],\t\ttrain_loss: 0.2366,\tval_loss: 0.2922\n",
            "43:\t[0s / 9s],\t\ttrain_loss: 0.2242,\tval_loss: 0.3359\n",
            "44:\t[0s / 10s],\t\ttrain_loss: 0.2263,\tval_loss: 0.3265\n",
            "45:\t[0s / 10s],\t\ttrain_loss: 0.2191,\tval_loss: 0.3270\n",
            "46:\t[0s / 10s],\t\ttrain_loss: 0.2252,\tval_loss: 0.3464\n",
            "47:\t[0s / 10s],\t\ttrain_loss: 0.2252,\tval_loss: 0.3290\n",
            "48:\t[0s / 10s],\t\ttrain_loss: 0.2286,\tval_loss: 0.3452\n",
            "49:\t[0s / 11s],\t\ttrain_loss: 0.2163,\tval_loss: 0.3518\n",
            "50:\t[0s / 11s],\t\ttrain_loss: 0.2204,\tval_loss: 0.3606\n",
            "51:\t[0s / 11s],\t\ttrain_loss: 0.2194,\tval_loss: 0.3581\n",
            "52:\t[0s / 12s],\t\ttrain_loss: 0.2377,\tval_loss: 0.3570\n",
            "53:\t[0s / 12s],\t\ttrain_loss: 0.2303,\tval_loss: 0.3376\n",
            "54:\t[0s / 13s],\t\ttrain_loss: 0.2231,\tval_loss: 0.3396\n",
            "55:\t[0s / 13s],\t\ttrain_loss: 0.2089,\tval_loss: 0.3653\n",
            "56:\t[0s / 13s],\t\ttrain_loss: 0.2187,\tval_loss: 0.3607\n",
            "57:\t[0s / 14s],\t\ttrain_loss: 0.2169,\tval_loss: 0.3406\n",
            "58:\t[0s / 14s],\t\ttrain_loss: 0.2159,\tval_loss: 0.3782\n",
            "59:\t[0s / 14s],\t\ttrain_loss: 0.2126,\tval_loss: 0.3749\n",
            "60:\t[0s / 15s],\t\ttrain_loss: 0.2104,\tval_loss: 0.3443\n",
            "61:\t[0s / 15s],\t\ttrain_loss: 0.2156,\tval_loss: 0.3702\n",
            "62:\t[0s / 15s],\t\ttrain_loss: 0.2171,\tval_loss: 0.3477\n",
            "63:\t[0s / 16s],\t\ttrain_loss: 0.2206,\tval_loss: 0.3721\n",
            "64:\t[0s / 16s],\t\ttrain_loss: 0.2136,\tval_loss: 0.3805\n",
            "65:\t[0s / 16s],\t\ttrain_loss: 0.2135,\tval_loss: 0.4133\n",
            "66:\t[0s / 17s],\t\ttrain_loss: 0.2080,\tval_loss: 0.4205\n",
            "67:\t[0s / 17s],\t\ttrain_loss: 0.2304,\tval_loss: 0.3988\n",
            "68:\t[0s / 17s],\t\ttrain_loss: 0.2040,\tval_loss: 0.3662\n",
            "69:\t[0s / 18s],\t\ttrain_loss: 0.2162,\tval_loss: 0.3728\n",
            "70:\t[0s / 18s],\t\ttrain_loss: 0.2060,\tval_loss: 0.3618\n",
            "71:\t[0s / 18s],\t\ttrain_loss: 0.2020,\tval_loss: 0.3732\n",
            "72:\t[0s / 19s],\t\ttrain_loss: 0.2045,\tval_loss: 0.3916\n",
            "73:\t[0s / 19s],\t\ttrain_loss: 0.2051,\tval_loss: 0.3677\n",
            "74:\t[0s / 19s],\t\ttrain_loss: 0.2040,\tval_loss: 0.3543\n",
            "75:\t[0s / 20s],\t\ttrain_loss: 0.1966,\tval_loss: 0.3869\n",
            "76:\t[0s / 20s],\t\ttrain_loss: 0.2044,\tval_loss: 0.3964\n",
            "77:\t[0s / 20s],\t\ttrain_loss: 0.2018,\tval_loss: 0.3876\n",
            "78:\t[0s / 20s],\t\ttrain_loss: 0.2037,\tval_loss: 0.3708\n",
            "79:\t[0s / 21s],\t\ttrain_loss: 0.1988,\tval_loss: 0.4128\n",
            "80:\t[0s / 21s],\t\ttrain_loss: 0.2144,\tval_loss: 0.3667\n",
            "81:\t[0s / 21s],\t\ttrain_loss: 0.2026,\tval_loss: 0.3578\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 43\n",
            "{'batch_size': 206, 'layers': 1, 'nodes': 32, 'activation_fn': 'relu', 'alpha': 0.2694858117308386, 'sigma': 0.9677140546248013, 'lr': 0.07519999708656931, 'dropout': 0.6032349736601433, 'patience': 32, 'batch_norm': True}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2725,\tval_loss: 0.1986\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2140,\tval_loss: 0.1833\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1988,\tval_loss: 0.1833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1975,\tval_loss: 0.1821\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1921,\tval_loss: 0.1849\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1946,\tval_loss: 0.1815\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1891,\tval_loss: 0.1824\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1923,\tval_loss: 0.1814\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1904,\tval_loss: 0.1842\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.1876,\tval_loss: 0.1840\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.1862,\tval_loss: 0.1831\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.1864,\tval_loss: 0.1818\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.1904,\tval_loss: 0.1812\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.1874,\tval_loss: 0.1849\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.1900,\tval_loss: 0.1818\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.1900,\tval_loss: 0.1817\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 0.1835,\tval_loss: 0.1824\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 0.1878,\tval_loss: 0.1833\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.1876,\tval_loss: 0.1862\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.1886,\tval_loss: 0.1807\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.1851,\tval_loss: 0.1839\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.1879,\tval_loss: 0.1834\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.1859,\tval_loss: 0.1853\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.1889,\tval_loss: 0.1836\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.1859,\tval_loss: 0.1828\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.1853,\tval_loss: 0.1825\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.1835,\tval_loss: 0.1842\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.1833,\tval_loss: 0.1825\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.1876,\tval_loss: 0.1848\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 0.1853,\tval_loss: 0.1853\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 0.1849,\tval_loss: 0.1856\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 0.1835,\tval_loss: 0.1832\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 0.1855,\tval_loss: 0.1853\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 0.1852,\tval_loss: 0.1876\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 0.1849,\tval_loss: 0.1828\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 0.1840,\tval_loss: 0.1857\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.1797,\tval_loss: 0.1866\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.1850,\tval_loss: 0.1844\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.1828,\tval_loss: 0.1933\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.1824,\tval_loss: 0.1886\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 0.1851,\tval_loss: 0.1879\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 0.1813,\tval_loss: 0.1864\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 0.1817,\tval_loss: 0.1849\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 0.1842,\tval_loss: 0.1867\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 0.1840,\tval_loss: 0.1871\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 0.1848,\tval_loss: 0.1864\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 0.1831,\tval_loss: 0.1843\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 0.1842,\tval_loss: 0.1876\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 0.1847,\tval_loss: 0.1868\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 0.1836,\tval_loss: 0.1840\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 0.1858,\tval_loss: 0.1909\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 0.1818,\tval_loss: 0.1853\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 44\n",
            "{'batch_size': 236, 'layers': 1, 'nodes': 68, 'activation_fn': 'relu', 'alpha': 0.9255148358185177, 'sigma': 0.9361434503294366, 'lr': 0.06277025146976428, 'dropout': 0.4720988844431447, 'patience': 61, 'batch_norm': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.7530,\tval_loss: 0.5522\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5385,\tval_loss: 0.4989\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.4965,\tval_loss: 0.4730\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.4819,\tval_loss: 0.4634\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.4649,\tval_loss: 0.4680\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4443,\tval_loss: 0.4645\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.4511,\tval_loss: 0.4576\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.4453,\tval_loss: 0.4666\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.4471,\tval_loss: 0.4626\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.4452,\tval_loss: 0.4614\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.4366,\tval_loss: 0.4635\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.4296,\tval_loss: 0.4632\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.4297,\tval_loss: 0.4619\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.4285,\tval_loss: 0.4881\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.4218,\tval_loss: 0.4927\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.4537,\tval_loss: 0.4652\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 0.4238,\tval_loss: 0.4770\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.4313,\tval_loss: 0.4654\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.4261,\tval_loss: 0.4801\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.4313,\tval_loss: 0.4789\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.4196,\tval_loss: 0.4719\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.4178,\tval_loss: 0.5191\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.4438,\tval_loss: 0.4753\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.4203,\tval_loss: 0.4870\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.4007,\tval_loss: 0.4853\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.4149,\tval_loss: 0.4936\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.4134,\tval_loss: 0.4879\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.4049,\tval_loss: 0.4962\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.4079,\tval_loss: 0.4889\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 0.4129,\tval_loss: 0.4965\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 0.4010,\tval_loss: 0.4947\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 0.4054,\tval_loss: 0.5027\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 0.4021,\tval_loss: 0.5070\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 0.4006,\tval_loss: 0.4979\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 0.3985,\tval_loss: 0.5080\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 0.3987,\tval_loss: 0.5147\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.4028,\tval_loss: 0.5197\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.4251,\tval_loss: 0.5298\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.4026,\tval_loss: 0.5203\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.4048,\tval_loss: 0.5168\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 0.4045,\tval_loss: 0.5407\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 0.3966,\tval_loss: 0.5310\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 0.3939,\tval_loss: 0.4978\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 0.3933,\tval_loss: 0.5100\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 0.3709,\tval_loss: 0.5125\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 0.4030,\tval_loss: 0.5352\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 0.3955,\tval_loss: 0.5487\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 0.3911,\tval_loss: 0.5239\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 0.3927,\tval_loss: 0.5248\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 0.4143,\tval_loss: 0.5148\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 0.3873,\tval_loss: 0.5201\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 0.3781,\tval_loss: 0.5521\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 0.3747,\tval_loss: 0.5576\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 0.3638,\tval_loss: 0.5737\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 0.4065,\tval_loss: 0.5478\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 0.3780,\tval_loss: 0.5517\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 0.3721,\tval_loss: 0.5762\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 0.3887,\tval_loss: 0.5851\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 0.3609,\tval_loss: 0.5849\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 0.4082,\tval_loss: 0.5441\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 0.3710,\tval_loss: 0.5495\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 0.3907,\tval_loss: 0.5722\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 0.3696,\tval_loss: 0.5586\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 0.3880,\tval_loss: 0.5967\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 0.3741,\tval_loss: 0.5962\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 0.3756,\tval_loss: 0.5922\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 0.3841,\tval_loss: 0.5898\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 0.3726,\tval_loss: 0.5597\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 45\n",
            "{'batch_size': 143, 'layers': 3, 'nodes': 73, 'activation_fn': 'relu', 'alpha': 0.7753411359411481, 'sigma': 0.6273693721114441, 'lr': 0.09470460183698229, 'dropout': 0.6422877145814143, 'patience': 51, 'batch_norm': False}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 1.5232,\tval_loss: 0.5437\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 1.0827,\tval_loss: 0.4235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 0.8194,\tval_loss: 0.4071\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5483,\tval_loss: 0.3997\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.7788,\tval_loss: 0.3980\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.8513,\tval_loss: 0.3955\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.5361,\tval_loss: 0.3940\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.6214,\tval_loss: 0.3950\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.4916,\tval_loss: 0.3947\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.5827,\tval_loss: 0.3928\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.4141,\tval_loss: 0.3940\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.4216,\tval_loss: 0.3950\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.5520,\tval_loss: 0.3933\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.4765,\tval_loss: 0.3936\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.5731,\tval_loss: 0.3921\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.5383,\tval_loss: 0.3936\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.5536,\tval_loss: 0.3937\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.4298,\tval_loss: 0.3921\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.6005,\tval_loss: 0.3931\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.7075,\tval_loss: 0.3935\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.4440,\tval_loss: 0.3941\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.6572,\tval_loss: 0.3920\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.6648,\tval_loss: 0.3941\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.6231,\tval_loss: 0.3927\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.4169,\tval_loss: 0.3927\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.4464,\tval_loss: 0.3923\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.4158,\tval_loss: 0.3923\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.5553,\tval_loss: 0.3930\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.5152,\tval_loss: 0.3953\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.4336,\tval_loss: 0.3925\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.5117,\tval_loss: 0.3910\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.4540,\tval_loss: 0.3936\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.5260,\tval_loss: 0.3926\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.6460,\tval_loss: 0.3932\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 1.9867,\tval_loss: 0.3915\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.4260,\tval_loss: 0.3935\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.4226,\tval_loss: 0.3933\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.4413,\tval_loss: 0.3927\n",
            "38:\t[0s / 3s],\t\ttrain_loss: 0.4403,\tval_loss: 0.3931\n",
            "39:\t[0s / 3s],\t\ttrain_loss: 0.4280,\tval_loss: 0.3917\n",
            "40:\t[0s / 3s],\t\ttrain_loss: 0.4396,\tval_loss: 0.3941\n",
            "41:\t[0s / 3s],\t\ttrain_loss: 0.4113,\tval_loss: 0.3935\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 0.6334,\tval_loss: 0.3922\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.8274,\tval_loss: 0.3923\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.4212,\tval_loss: 0.3928\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.5298,\tval_loss: 0.3929\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 1.4013,\tval_loss: 0.3920\n",
            "47:\t[0s / 4s],\t\ttrain_loss: 0.4934,\tval_loss: 0.3940\n",
            "48:\t[0s / 4s],\t\ttrain_loss: 0.4151,\tval_loss: 0.3944\n",
            "49:\t[0s / 4s],\t\ttrain_loss: 0.4146,\tval_loss: 0.3919\n",
            "50:\t[0s / 4s],\t\ttrain_loss: 0.4092,\tval_loss: 0.3923\n",
            "51:\t[0s / 4s],\t\ttrain_loss: 0.4154,\tval_loss: 0.3916\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.4216,\tval_loss: 0.3927\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.4213,\tval_loss: 0.3940\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.4215,\tval_loss: 0.3923\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 1.2180,\tval_loss: 0.3939\n",
            "56:\t[0s / 5s],\t\ttrain_loss: 0.8098,\tval_loss: 0.3916\n",
            "57:\t[0s / 5s],\t\ttrain_loss: 0.4276,\tval_loss: 0.3917\n",
            "58:\t[0s / 5s],\t\ttrain_loss: 0.4391,\tval_loss: 0.3957\n",
            "59:\t[0s / 5s],\t\ttrain_loss: 0.4338,\tval_loss: 0.3920\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.4263,\tval_loss: 0.3927\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.7624,\tval_loss: 0.3933\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.4145,\tval_loss: 0.3912\n",
            "63:\t[0s / 6s],\t\ttrain_loss: 6.9029,\tval_loss: 0.3942\n",
            "64:\t[0s / 6s],\t\ttrain_loss: 0.7785,\tval_loss: 0.3941\n",
            "65:\t[0s / 6s],\t\ttrain_loss: 0.4217,\tval_loss: 0.3913\n",
            "66:\t[0s / 6s],\t\ttrain_loss: 0.4228,\tval_loss: 0.3915\n",
            "67:\t[0s / 6s],\t\ttrain_loss: 0.4213,\tval_loss: 0.3927\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.4291,\tval_loss: 0.3929\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.4151,\tval_loss: 0.3926\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.4087,\tval_loss: 0.3920\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 2.5981,\tval_loss: 0.3931\n",
            "72:\t[0s / 7s],\t\ttrain_loss: 0.4733,\tval_loss: 0.3922\n",
            "73:\t[0s / 7s],\t\ttrain_loss: 0.4091,\tval_loss: 0.3944\n",
            "74:\t[0s / 7s],\t\ttrain_loss: 0.5909,\tval_loss: 0.3918\n",
            "75:\t[0s / 7s],\t\ttrain_loss: 0.9865,\tval_loss: 0.3918\n",
            "76:\t[0s / 7s],\t\ttrain_loss: 0.4261,\tval_loss: 0.3929\n",
            "77:\t[0s / 7s],\t\ttrain_loss: 3.0023,\tval_loss: 0.3939\n",
            "78:\t[0s / 7s],\t\ttrain_loss: 0.4282,\tval_loss: 0.3922\n",
            "79:\t[0s / 7s],\t\ttrain_loss: 0.8370,\tval_loss: 0.3923\n",
            "80:\t[0s / 8s],\t\ttrain_loss: 0.4195,\tval_loss: 0.3933\n",
            "81:\t[0s / 8s],\t\ttrain_loss: 0.4156,\tval_loss: 0.3912\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 46\n",
            "{'batch_size': 115, 'layers': 2, 'nodes': 77, 'activation_fn': 'tanh', 'alpha': 0.5718971141891177, 'sigma': 0.4040152857243382, 'lr': 0.02411754559642267, 'dropout': 0.018545256036146752, 'patience': 55, 'batch_norm': True}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.4678,\tval_loss: 0.3965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.3271,\tval_loss: 0.3292\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.2969,\tval_loss: 0.3339\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.2894,\tval_loss: 0.3304\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.2658,\tval_loss: 0.3492\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.2605,\tval_loss: 0.3437\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.2521,\tval_loss: 0.3740\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.2308,\tval_loss: 0.3595\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.2287,\tval_loss: 0.3922\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.2296,\tval_loss: 0.3964\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.2195,\tval_loss: 0.3843\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.2274,\tval_loss: 0.3968\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1940,\tval_loss: 0.4104\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1932,\tval_loss: 0.4094\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1906,\tval_loss: 0.4442\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1921,\tval_loss: 0.4296\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1809,\tval_loss: 0.4309\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1819,\tval_loss: 0.4332\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.1706,\tval_loss: 0.4463\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.1543,\tval_loss: 0.4779\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1596,\tval_loss: 0.4762\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1691,\tval_loss: 0.4644\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1704,\tval_loss: 0.4820\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1601,\tval_loss: 0.4749\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1613,\tval_loss: 0.4786\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1437,\tval_loss: 0.4933\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1611,\tval_loss: 0.5222\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1808,\tval_loss: 0.5127\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.1676,\tval_loss: 0.4942\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.1559,\tval_loss: 0.5086\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1581,\tval_loss: 0.4937\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1568,\tval_loss: 0.5184\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1493,\tval_loss: 0.5058\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1480,\tval_loss: 0.4973\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1376,\tval_loss: 0.5301\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1378,\tval_loss: 0.5473\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.1349,\tval_loss: 0.5515\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.1337,\tval_loss: 0.5500\n",
            "38:\t[0s / 3s],\t\ttrain_loss: 0.1389,\tval_loss: 0.5390\n",
            "39:\t[0s / 3s],\t\ttrain_loss: 0.1286,\tval_loss: 0.5466\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1284,\tval_loss: 0.5393\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1338,\tval_loss: 0.5251\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1376,\tval_loss: 0.5335\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1389,\tval_loss: 0.5557\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1437,\tval_loss: 0.5864\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.1338,\tval_loss: 0.5614\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.1285,\tval_loss: 0.5787\n",
            "47:\t[0s / 4s],\t\ttrain_loss: 0.1325,\tval_loss: 0.5656\n",
            "48:\t[0s / 4s],\t\ttrain_loss: 0.1338,\tval_loss: 0.5690\n",
            "49:\t[0s / 4s],\t\ttrain_loss: 0.1312,\tval_loss: 0.5604\n",
            "50:\t[0s / 4s],\t\ttrain_loss: 0.1282,\tval_loss: 0.5557\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1274,\tval_loss: 0.5638\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1277,\tval_loss: 0.5627\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1216,\tval_loss: 0.5666\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.1251,\tval_loss: 0.5557\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.1278,\tval_loss: 0.5887\n",
            "56:\t[0s / 5s],\t\ttrain_loss: 0.1236,\tval_loss: 0.5916\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 47\n",
            "{'batch_size': 125, 'layers': 3, 'nodes': 94, 'activation_fn': 'elu', 'alpha': 0.837972390451424, 'sigma': 0.6056950545067219, 'lr': 0.06721610126911039, 'dropout': 0.5034212150770188, 'patience': 41, 'batch_norm': False}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 1.0120,\tval_loss: 0.5228\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.7601,\tval_loss: 0.4768\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.6516,\tval_loss: 0.4432\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5375,\tval_loss: 0.4327\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.4611,\tval_loss: 0.4262\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4551,\tval_loss: 0.4239\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.4852,\tval_loss: 0.4236\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.4476,\tval_loss: 0.4209\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.4416,\tval_loss: 0.4203\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.4566,\tval_loss: 0.4204\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.4429,\tval_loss: 0.4211\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.4974,\tval_loss: 0.4180\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.4412,\tval_loss: 0.4186\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.4541,\tval_loss: 0.4201\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.4570,\tval_loss: 0.4205\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.4535,\tval_loss: 0.4210\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.4863,\tval_loss: 0.4187\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.4364,\tval_loss: 0.4189\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.4363,\tval_loss: 0.4184\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.4364,\tval_loss: 0.4199\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.4438,\tval_loss: 0.4189\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.4425,\tval_loss: 0.4195\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.4430,\tval_loss: 0.4184\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.4397,\tval_loss: 0.4191\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.4366,\tval_loss: 0.4187\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.4358,\tval_loss: 0.4190\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.4357,\tval_loss: 0.4189\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.4359,\tval_loss: 0.4183\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.4364,\tval_loss: 0.4185\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.4362,\tval_loss: 0.4191\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.4520,\tval_loss: 0.4177\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.4344,\tval_loss: 0.4183\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.4425,\tval_loss: 0.4198\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.4360,\tval_loss: 0.4175\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.4371,\tval_loss: 0.4186\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.4363,\tval_loss: 0.4193\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.4359,\tval_loss: 0.4202\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.4356,\tval_loss: 0.4181\n",
            "38:\t[0s / 3s],\t\ttrain_loss: 0.4356,\tval_loss: 0.4182\n",
            "39:\t[0s / 3s],\t\ttrain_loss: 0.4358,\tval_loss: 0.4183\n",
            "40:\t[0s / 3s],\t\ttrain_loss: 0.4402,\tval_loss: 0.4196\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.4362,\tval_loss: 0.4185\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.4357,\tval_loss: 0.4188\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.4387,\tval_loss: 0.4163\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.4359,\tval_loss: 0.4201\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.4361,\tval_loss: 0.4189\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.4361,\tval_loss: 0.4185\n",
            "47:\t[0s / 4s],\t\ttrain_loss: 0.4361,\tval_loss: 0.4174\n",
            "48:\t[0s / 4s],\t\ttrain_loss: 0.4357,\tval_loss: 0.4194\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.4356,\tval_loss: 0.4191\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.4358,\tval_loss: 0.4174\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.4360,\tval_loss: 0.4185\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.4361,\tval_loss: 0.4188\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.4360,\tval_loss: 0.4185\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.4373,\tval_loss: 0.4179\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.4355,\tval_loss: 0.4192\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.4542,\tval_loss: 0.4183\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.4608,\tval_loss: 0.4188\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.4365,\tval_loss: 0.4197\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.4360,\tval_loss: 0.4177\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.4943,\tval_loss: 0.4173\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.4387,\tval_loss: 0.4193\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.4354,\tval_loss: 0.4187\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.4356,\tval_loss: 0.4172\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.4379,\tval_loss: 0.4192\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.4357,\tval_loss: 0.4177\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.4364,\tval_loss: 0.4180\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.4365,\tval_loss: 0.4185\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.4356,\tval_loss: 0.4201\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.4358,\tval_loss: 0.4175\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.4362,\tval_loss: 0.4193\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.4357,\tval_loss: 0.4167\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.4357,\tval_loss: 0.4195\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.4364,\tval_loss: 0.4194\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.4431,\tval_loss: 0.4180\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.4359,\tval_loss: 0.4181\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.4356,\tval_loss: 0.4196\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.4392,\tval_loss: 0.4161\n",
            "78:\t[0s / 8s],\t\ttrain_loss: 0.4365,\tval_loss: 0.4195\n",
            "79:\t[0s / 8s],\t\ttrain_loss: 0.4364,\tval_loss: 0.4194\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.4351,\tval_loss: 0.4177\n",
            "81:\t[0s / 9s],\t\ttrain_loss: 0.4540,\tval_loss: 0.4188\n",
            "82:\t[0s / 9s],\t\ttrain_loss: 0.4395,\tval_loss: 0.4181\n",
            "83:\t[0s / 9s],\t\ttrain_loss: 0.4355,\tval_loss: 0.4182\n",
            "84:\t[0s / 9s],\t\ttrain_loss: 0.4508,\tval_loss: 0.4185\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.4356,\tval_loss: 0.4181\n",
            "86:\t[0s / 9s],\t\ttrain_loss: 0.4358,\tval_loss: 0.4183\n",
            "87:\t[0s / 9s],\t\ttrain_loss: 0.4357,\tval_loss: 0.4200\n",
            "88:\t[0s / 9s],\t\ttrain_loss: 0.4354,\tval_loss: 0.4191\n",
            "89:\t[0s / 9s],\t\ttrain_loss: 0.4424,\tval_loss: 0.4179\n",
            "90:\t[0s / 10s],\t\ttrain_loss: 0.4360,\tval_loss: 0.4187\n",
            "91:\t[0s / 10s],\t\ttrain_loss: 0.4364,\tval_loss: 0.4190\n",
            "92:\t[0s / 10s],\t\ttrain_loss: 0.4358,\tval_loss: 0.4175\n",
            "93:\t[0s / 10s],\t\ttrain_loss: 0.4367,\tval_loss: 0.4178\n",
            "94:\t[0s / 10s],\t\ttrain_loss: 0.4355,\tval_loss: 0.4197\n",
            "95:\t[0s / 10s],\t\ttrain_loss: 0.4355,\tval_loss: 0.4193\n",
            "96:\t[0s / 10s],\t\ttrain_loss: 0.4356,\tval_loss: 0.4188\n",
            "97:\t[0s / 10s],\t\ttrain_loss: 0.4368,\tval_loss: 0.4162\n",
            "98:\t[0s / 10s],\t\ttrain_loss: 0.4356,\tval_loss: 0.4194\n",
            "99:\t[0s / 10s],\t\ttrain_loss: 0.4359,\tval_loss: 0.4197\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 48\n",
            "{'batch_size': 77, 'layers': 1, 'nodes': 66, 'activation_fn': 'tanh', 'alpha': 0.5241365411497173, 'sigma': 0.10397261797080248, 'lr': 0.07134776472580859, 'dropout': 0.20564893323797145, 'patience': 64, 'batch_norm': True}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 1.0341,\tval_loss: 0.6414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5007,\tval_loss: 0.3195\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.3636,\tval_loss: 0.3002\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.3217,\tval_loss: 0.2957\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.3161,\tval_loss: 0.3029\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.3129,\tval_loss: 0.2989\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.2987,\tval_loss: 0.2875\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.2969,\tval_loss: 0.2859\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.2892,\tval_loss: 0.2891\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.2859,\tval_loss: 0.2898\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.2865,\tval_loss: 0.2957\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.2853,\tval_loss: 0.2891\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.2858,\tval_loss: 0.2917\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.2855,\tval_loss: 0.2973\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.2823,\tval_loss: 0.2982\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.2722,\tval_loss: 0.2997\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.2776,\tval_loss: 0.2994\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.2743,\tval_loss: 0.3009\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.2759,\tval_loss: 0.3065\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.2740,\tval_loss: 0.3051\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.2695,\tval_loss: 0.3076\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.2696,\tval_loss: 0.3093\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.2693,\tval_loss: 0.3081\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.2620,\tval_loss: 0.3108\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.2639,\tval_loss: 0.3061\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.2578,\tval_loss: 0.3192\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.2654,\tval_loss: 0.3359\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.2687,\tval_loss: 0.3026\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.2620,\tval_loss: 0.3081\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.2656,\tval_loss: 0.3111\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.2667,\tval_loss: 0.3121\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.2660,\tval_loss: 0.3037\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.2606,\tval_loss: 0.3109\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.2556,\tval_loss: 0.3215\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.2525,\tval_loss: 0.3195\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.2635,\tval_loss: 0.3255\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.2736,\tval_loss: 0.3292\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.3433,\tval_loss: 0.3849\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 1.8437,\tval_loss: 3.1543\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 5.7892,\tval_loss: 7.3431\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 10.6746,\tval_loss: 10.6676\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 10.0607,\tval_loss: 10.2651\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 13.3429,\tval_loss: 15.5147\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 20.5784,\tval_loss: 15.8407\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 18.5869,\tval_loss: 15.2476\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 15.8980,\tval_loss: 17.0729\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 18.4396,\tval_loss: 16.1796\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 15.2197,\tval_loss: 9.5169\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 10.6601,\tval_loss: 9.0027\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 11.1465,\tval_loss: 11.5365\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 12.5024,\tval_loss: 15.0178\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 14.1625,\tval_loss: 14.8868\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 12.8808,\tval_loss: 12.4886\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 12.8094,\tval_loss: 10.7857\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 10.5007,\tval_loss: 9.8847\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 10.9212,\tval_loss: 11.1013\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 9.6807,\tval_loss: 9.5119\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 9.9482,\tval_loss: 8.3294\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 9.4116,\tval_loss: 8.9204\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 8.6567,\tval_loss: 6.9657\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 11.1104,\tval_loss: 9.5703\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 11.9199,\tval_loss: 10.5931\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 8.2657,\tval_loss: 6.1126\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 8.4955,\tval_loss: 11.4085\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 9.0911,\tval_loss: 7.2461\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 6.9719,\tval_loss: 5.7851\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 7.2836,\tval_loss: 5.1832\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 6.5517,\tval_loss: 4.9718\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 6.8212,\tval_loss: 4.9843\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 6.1234,\tval_loss: 5.1241\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 5.3400,\tval_loss: 4.3362\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 5.4443,\tval_loss: 4.6937\n",
            "Current best c-index: 0.638985300122499\n",
            "Random search... itr: 49\n",
            "{'batch_size': 157, 'layers': 4, 'nodes': 79, 'activation_fn': 'elu', 'alpha': 0.5225611564421194, 'sigma': 0.7906995349983704, 'lr': 0.033120346102452694, 'dropout': 0.9402689446763565, 'patience': 25, 'batch_norm': False}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 18.9600,\tval_loss: 0.3238\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 25.2900,\tval_loss: 0.3298\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 14.4455,\tval_loss: 0.3304\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 23.2965,\tval_loss: 0.3193\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 33.1016,\tval_loss: 0.3046\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 25.8315,\tval_loss: 0.3065\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 25.5458,\tval_loss: 0.3026\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 24.5759,\tval_loss: 0.2979\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 16.2746,\tval_loss: 0.2955\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 17.8470,\tval_loss: 0.2934\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 17.7637,\tval_loss: 0.2941\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 15.7756,\tval_loss: 0.2949\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 26.4908,\tval_loss: 0.2895\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 28.7835,\tval_loss: 0.2929\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 25.1879,\tval_loss: 0.2919\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 21.9308,\tval_loss: 0.2886\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 12.9539,\tval_loss: 0.2913\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 28.4962,\tval_loss: 0.2957\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 14.1283,\tval_loss: 0.2951\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 27.4683,\tval_loss: 0.2906\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 12.9937,\tval_loss: 0.2882\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 15.6711,\tval_loss: 0.2944\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 7.8883,\tval_loss: 0.2911\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 16.8662,\tval_loss: 0.2905\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 62.1393,\tval_loss: 0.2992\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 39.6594,\tval_loss: 0.2893\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 11.6867,\tval_loss: 0.2899\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 18.8751,\tval_loss: 0.2910\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 18.5599,\tval_loss: 0.3053\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 15.2336,\tval_loss: 0.3298\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 40.9913,\tval_loss: 0.3027\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 26.9146,\tval_loss: 0.2903\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 45.0347,\tval_loss: 0.2908\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 75.3263,\tval_loss: 0.2901\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 20.7481,\tval_loss: 0.2896\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 24.2066,\tval_loss: 0.2899\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 20.3336,\tval_loss: 0.2897\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 11.6934,\tval_loss: 0.2893\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 35.7639,\tval_loss: 0.2887\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 7.6777,\tval_loss: 0.2947\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 9.5027,\tval_loss: 0.3227\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 14.4441,\tval_loss: 0.3436\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 31.1334,\tval_loss: 0.3137\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 22.5080,\tval_loss: 0.2951\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 13.2578,\tval_loss: 0.3000\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 19.0169,\tval_loss: 0.3035\n",
            "Current best c-index: 0.638985300122499\n",
            "Best hyperparameters: {'batch_size': 130, 'layers': 3, 'nodes': 89, 'activation_fn': 'tanh', 'alpha': 0.1634512911820602, 'sigma': 0.9968793745597865, 'lr': 0.05383633524786459, 'dropout': 0.782457166677337, 'patience': 68, 'batch_norm': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        }
      ],
      "source": [
        "RS_ITERATION = 100\n",
        "from lifelines.utils import concordance_index\n",
        "def get_random_hyperparameters():\n",
        "    SET_BATCH_SIZE = [32, 256]\n",
        "    SET_LAYERS = [1,5]\n",
        "    SET_NODES = [25, 100]\n",
        "    SET_ACTIVATION_FN = ['relu', 'elu', 'tanh']\n",
        "    SET_ALPHA = [0.1, 1.0]\n",
        "    SET_SIGMA = [0.1, 1.0]\n",
        "    SET_LR = [0.001, 0.1]\n",
        "    SET_DROPOUT = [0.0, 0.95]\n",
        "    SET_PATIENCE = [25, 75]\n",
        "    SET_BATCH_NORM = [True, False]\n",
        "\n",
        "    return {\n",
        "        'batch_size': int(np.random.uniform(*SET_BATCH_SIZE)),\n",
        "        'layers': int(np.random.uniform(*SET_LAYERS)),\n",
        "        'nodes': int(np.random.uniform(*SET_NODES)),\n",
        "        'activation_fn': SET_ACTIVATION_FN[np.random.randint(len(SET_ACTIVATION_FN))],\n",
        "        'alpha': np.random.uniform(*SET_ALPHA),\n",
        "        'sigma': np.random.uniform(*SET_SIGMA),\n",
        "        'lr': np.random.uniform(*SET_LR),\n",
        "        'dropout': np.random.uniform(*SET_DROPOUT),\n",
        "        'patience': int(np.random.uniform(*SET_PATIENCE)),\n",
        "        'batch_norm': np.random.choice(SET_BATCH_NORM)\n",
        "    }\n",
        "\n",
        "# Main loop\n",
        "max_valid = 0.0\n",
        "best_model = None\n",
        "best_hyperparameters = None\n",
        "\n",
        "for r_itr in range(RS_ITERATION):\n",
        "    print(f'Random search... itr: {r_itr}')\n",
        "    hyperparameters = get_random_hyperparameters()\n",
        "    print(hyperparameters)\n",
        "\n",
        "\n",
        "    num_nodes = [hyperparameters['nodes']] * hyperparameters['layers']\n",
        "    batch_norm = hyperparameters['batch_norm']\n",
        "    dropout = hyperparameters['dropout']\n",
        "\n",
        "    net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
        "\n",
        "    model = DeepHitSingle(net, tt.optim.Adam, alpha=hyperparameters['alpha'], sigma=hyperparameters['sigma'], duration_index=labtrans.cuts)\n",
        "\n",
        "    batch_size = hyperparameters['batch_size']\n",
        "    model.optimizer.set_lr(hyperparameters['lr'])\n",
        "    epochs = 100\n",
        "    callbacks = [tt.callbacks.EarlyStopping(patience=hyperparameters['patience'])]\n",
        "    log = model.fit(x_train, y_train, batch_size, epochs, callbacks, val_data=val)\n",
        "\n",
        "    # Validate the model\n",
        "    surv = model.predict_surv_df(x_val)\n",
        "    ev = EvalSurv(surv, durations_val, events_val, censor_surv='km')\n",
        "    c_index = ev.concordance_td('antolini')\n",
        "\n",
        "    # If this model is better, save it\n",
        "    if c_index > max_valid:\n",
        "        max_valid = c_index\n",
        "        best_model = model\n",
        "        best_hyperparameters = hyperparameters\n",
        "\n",
        "    print(f'Current best c-index: {max_valid}')\n",
        "\n",
        "print(f'Best hyperparameters: {best_hyperparameters}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 15/8/23 - Lets go with this.\n",
        "num_nodes = [best_hyperparameters['nodes']] * best_hyperparameters['layers']\n",
        "batch_norm = True if best_hyperparameters['activation_fn'] == 'relu' else False\n",
        "dropout = [best_hyperparameters['dropout']]\n",
        "\n",
        "best_net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
        "\n",
        "best_model = DeepHitSingle(best_net, tt.optim.Adam, alpha=best_hyperparameters['alpha'], sigma=best_hyperparameters['sigma'], duration_index=labtrans.cuts)\n",
        "\n",
        "batch_size = best_hyperparameters['batch_size']\n",
        "best_model.optimizer.set_lr(best_hyperparameters['lr'])\n",
        "\n",
        "# Train on the entire training set\n",
        "epochs = 100\n",
        "callbacks = [tt.callbacks.EarlyStopping()]\n",
        "log = best_model.fit(x_train, y_train, batch_size, epochs, callbacks, val_data=val)\n",
        "_ = log.plot()\n",
        "\n",
        "# Evaluate on the test set\n",
        "surv = best_model.predict_surv_df(x_test)\n",
        "ev_test = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
        "c_index_test = ev_test.concordance_td('antolini')\n",
        "\n",
        "print(f'Concordance index on test set: {c_index_test}')\n",
        "\n",
        "# Calculate the integrated Brier score\n",
        "ibs = ev_test.integrated_brier_score(time_grid=np.linspace(0, durations_test.max(), 100))\n",
        "\n",
        "print(f'Integrated Brier Score on test set: {ibs}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "meUI1yuB0lfb",
        "outputId": "a8fc2705-fdeb-44b0-ad90-f842c2a92ee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2414,\tval_loss: 0.1621\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2297,\tval_loss: 0.1564\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.2010,\tval_loss: 0.1601\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.2139,\tval_loss: 0.1542\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.2082,\tval_loss: 0.1528\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1817,\tval_loss: 0.1561\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1827,\tval_loss: 0.1484\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1632,\tval_loss: 0.1461\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1664,\tval_loss: 0.1456\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1479\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1454\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1423\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1403\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1507,\tval_loss: 0.1402\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1404\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1390\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1531,\tval_loss: 0.1398\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1504,\tval_loss: 0.1404\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1401\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.1504,\tval_loss: 0.1402\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.1493,\tval_loss: 0.1408\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.1485,\tval_loss: 0.1398\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1385\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1399\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.1488,\tval_loss: 0.1406\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1409\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1422\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1429,\tval_loss: 0.1433\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.1468,\tval_loss: 0.1430\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.1464,\tval_loss: 0.1403\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.1470,\tval_loss: 0.1408\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.1467,\tval_loss: 0.1444\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.1487,\tval_loss: 0.1430\n",
            "Concordance index on test set: 0.6553199876115663\n",
            "Integrated Brier Score on test set: 0.08371766140070269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGhCAYAAACUFDUXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB2WUlEQVR4nO3dd3hUZfr/8ffUZDLJpCeQhBASIPQqvTcRUVkBFV2VVXdFRV1BXVl314o/EZVVUdeKBdnFjn4RUJQmvYj0mgIpkJ5JmUkymTm/P0IiMQnJpM1MuF/XlYvkzDln7nkYmE/OeYpKURQFIYQQQggPpXZ1AUIIIYQQTSFhRgghhBAeTcKMEEIIITyahBkhhBBCeDQJM0IIIYTwaBJmhBBCCOHRJMwIIYQQwqNpXV1AS9u/fz+KoqDT6VxdihBCCCEayGazoVKp6N+/f737tvkrM4qi0FLzAiqKQllZWYud31NJu9RN2qZ20i61k3apm7RN7dpSuzjz+d3mr8xUXpHp3bt3s5/bYrFw7NgxOnfujI+PT7Of31NJu9RN2qZ20i61k3apm7RN7dpSuxw6dKjB+7b5KzNCCCGEaNskzAghhBDCo0mYEUIIIYRHkzAjhBBCCI8mYUYIIYQQHq3Nj2YSQgjhGex2OzabrUH7lpaWVv2pVsvv5ZU8pV10Oh0ajabZzidhRgghhEspisL58+fJz89v8DEOhwOtVkt6erpbf2i3Nk9ql4CAANq1a4dKpWryuSTMCCGEcKnKIBMWFoaPj0+DPtzsdjulpaV4eXk162/4ns4T2kVRFCwWC5mZmQC0b9++yeeUMCOEEMJl7HZ7VZAJDg526jgAb29vt/3QdgVPaReDwQBAZmYmYWFhTa7Vva9BCSGEaNMq+8h4+my1wnmVf+cN7Sd1KRJmhBBCuFxz9JsQnqU5/84lzAghhBDCo0mYEUIIIYRHkzAjhBBCNIMff/yRFStWNOs5x48fzzPPPNOs5/zqq6+Ij48nNze3Wc/rSk6HmYSEBO644w769evHiBEjWLx4MWVlZZc8JjMzk8WLFzNt2jT69+/P6NGjefjhh0lLS6vzGIfDwfTp04mPj2fdunXOltniTqfkc+dzG9l1osjVpQghhHADP/74I//73/+a9Zyvv/46d955Z7Oesy1yKsyYzWZmz56NzWZj6dKlzJs3j88++4xFixZd8rgjR46wfv16pkyZwptvvsmCBQs4efIkN9xwQ53JcOXKlWRkZDhTXqvKLyqluKScn48W4HAori5HCCGEB1AUpd4LABfr0aMHUVFRLVhR2+BUmFm5ciXFxcW8/vrrjBo1ipkzZ/Loo4/WGzwGDhzI2rVrueeeexg2bBhXX3017777Lrm5uaxatarG/rm5ubz66qvMnz/f6RfUWvp2CcHXoKPI6uBQYtu5VCeEEMJ5CxYs4Ouvv+bUqVPEx8cTHx/PggULWLBgAddccw2bN2/muuuuo3fv3mzYsAGLxcIzzzzD5MmT6du3L+PHj+eJJ56gsLCw2nl/f5up8ny7du3iD3/4A/369WPmzJkcPny4SfXn5+fz97//nSFDhtCnTx9mzZrFnj17qu2zb98+/vjHPzJw4ED69+/Ptddey9dff93gx1uSU5PmbdmyhWHDhhEQEFC1bcqUKTz55JNs27aN6dOn13qcyWSqsa1du3YEBQVVzQB4sSVLljBkyBCGDBniTHmtSqfVMKJPO77flcKW/ekM69PB1SUJIUSboSgKpWX2Oh+3O+yUlNlBXY5G3bxXx730GqeHDd93333k5uaSmJjISy+9BEBQUBBvvvkmmZmZLFy4kHvvvZf27dsTERFBSUkJdrudefPmERQUxLlz53jrrbe47777WL58+SWfKysri4ULF3L33Xfj5+fHyy+/zP3338/69esbtYSB3W7nL3/5CykpKTzyyCOEhISwfPly7rjjDlauXEmvXr0oKipizpw5DBw4kCVLlqDX6zl9+jQFBQUA9T7e0pwKM4mJicyYMaPaNpPJRGhoKImJiU49cVJSEjk5OcTFxVXbfvDgQVavXs3q1audOp8rjO7Xnu93pbD7WCaWEhs+3jpXlySEEB5PURQee30rx5Jdc9W7e0wQL9w/0qlAEx0dTVBQEOnp6fTr16/aY2azmXfffZe+fftW2/70009XfV9eXk5UVBS33HILSUlJdOrUqc7nMpvNfPLJJ3Tp0gWomE339ttv58CBA/Tv37/BNVfatGkTBw8e5L333mPUqFEAjBw5kiuvvJK3336bpUuXkpSURGFhIfPnzyc+Ph6AYcOGVZ2jvsdbmlNhpqCgoNarLP7+/pjN5gafR1EUFi5cSFhYGFOnTq3a7nA4ePrpp7njjjuIiooiNTXVmfIu+XwWi6VZznWxiCAdwSYtOQXlbNybzLgBkc3+HJ7IarVW+1P8RtqmdtIutbsc2qW0tBSHw4Hdbq+ail9RFMCVfREV7Ha701dnFEVBUZSq11G5LSAggF69elXbDvDtt9/y4YcfcubMmWp/x4mJiURHR9d6TkVRCAsLIzY2tmpbZfA5d+5cVZD6fR0XczgcVX/a7Xb27NmDr68vw4cPrzpGrVYzceJEvvvuO+x2O5GRkfj6+vLUU0/xxz/+kSFDhhAUFFR1zvoer43dbsfhcGC1Wqtq+n17NvTvwCVrMy1dupSdO3fy3nvvVZvC+vPPPyc7O5u77767WZ/PZrNx7NixZj1npb6dfNhwoIB12xJoZ2idy2meIjk52dUluC1pm9pJu9SurbeLVqultLS02rYn7hhAqa3mB1xr8NKpa9TTEHa7HUVRKCkpqbYtKCio2jaADRs2sGDBAqZPn859992Hv78/2dnZPPzwwxQVFVXtrygK5eXlVT/b7XZ8fX2rna8yCBQVFVXVfan6K5cPKCkpoaSkhLy8PAIDA2vUWHmhoqSkBC8vL958803eeustFixYgN1up3///vztb3+jS5cu9T5em9LSUsrLyy95Z0ev19f52MWcCjMmk6lG5ySouOTl7+/foHN89tlnvPHGGzz33HPVLkEVFxezZMkS5s2bh81mw2azUVRUMey5pKSEoqIifH19nSm3ik6no3Pnzo069lKsViv5xafZcKCA5MxSQtrHEBpgaPbn8TRWq5Xk5GRiYmKqFhMTFaRtaiftUrvLoV1KS0tJT0/Hy8sLb2/vao9d6iUrilK1OrS7LIWg0VT0tbn4dWg0GtRqdY3XtnHjRrp168bChQurtlV2uNXpdFX7q1QqtFpt1c+1PUfl6CidToeXl1e97aLTVXSJ8Pb2xtvbm6CgIPLy8mrUWPnZXrn9iiuu4L333qOkpIRdu3bx4osv8sgjj/D999836PHaaLVaoqOj8fLyqvHY6dOn6zyuxnkavCcQGxtbI0EVFhaSlZVFbGxsvcevX7+ep556igcffJCZM2dWeywvL4/8/HyefPJJnnzyyWqPPfbYY4SEhLBt2zZnyq2iUqlabBGzAKOWnp0COZKUx86j2dw0Mb5FnscTGQwGWTyuDtI2tZN2qV1bbhe1Wo1arUaj0Ti1cnLl7RCVSuU2q0Pr9XrKysqq1aNSqWqtsbS0FL1eX237d999B1DVHrUdX9v5Kr9Xq9VVAeZS7VLZSbjyea644gqWLVvGjh07GDlyJFDRh+enn35i4MCBNc5jNBoZP348aWlpPPfcc5SXl1cLI/U9fnHdarUag8FQI0hVvoaGcirMjB49mrfeeqta35l169ahVqsZMWLEJY/dtWsX8+fP54YbbmDu3Lk1Hg8NDeXjjz+uti07O5v58+fzwAMPMHz4cGdKbVVj+kdwJCmPjXtTuHFCV7f5LUEIIUTriYuL48svv2T16tV07NiRwMDAOvcdPnw4zzzzDG+88Qb9+/dn8+bN7NixoxWr/c3YsWPp06cPjz76KA8//HDVaKbMzExee+01oKKT8BdffMHEiROJiIggOzubTz75hAEDBuDl5VXv4y3NqTAza9Ysli9fzty5c5kzZw4ZGRksXryYWbNmER4eXrXf7NmzSU9PZ/369UDFrMFz584lJiaGadOm8euvv1btGxQUVHWJ6fdDsSs7AHfu3JkBAwY09jW2uME9wnh/9XHSsoo5cTaPbh0v3elJCCFE2zNz5kwOHjzIs88+S35+Ptdff32d+86aNYvU1FQ++eQT3n//fUaOHMnLL7/MjTfe2IoVV9BoNLzzzjssXryYF198EYvFQs+ePVm2bBm9evUCKkZrqdVqXnnlFXJycggICGDkyJFV88HV93hLcyrM+Pv789FHH/Hss88yd+5cjEYjM2fOZN68edX2q+whXenAgQMUFhZSWFjIzTffXG3f66+/vt4ZhN2dwUvLsN7t2bQvlQ17UyTMCCHEZcjX15clS5Y0aF+NRsNjjz3GY489Vm37iRMnqv28YcOGaj/X9nlpMpmqjqtrBNPFpk+fXmNeuMDAQJ5//vk6j4mNja26StOYx1ua06OZ4uLi+PDDDy+5z+8n/Kmt4RoiKiqqxl+suxo/sAOb9qXy8/40/jKtFzqte9zDFUIIIdo6WTW7mfTpEkqQyZsiq409R913TSkhhBBtl8PhoLy8vM6vijl82h4JM81Eo1YxbmDFYmAb9qa4uBohhBCXozfffJPBgwfTp08fevbsWeOrtdZKam0umTSvrRp3RQe+3HiavccyMBeV4u/b8j24hRBCiEo33ngjw4cPR6/X17pOU1tdgVvCTDPq2M5E5yh/Tqea+fnXNK4ZWf/cO0IIIURzCQsLw2Qy4e3t7Tbz77QGuc3UzMZdUbF69k9yq0kIIYRoFRJmmtnoflFo1CpOp+Rz9rys1SSEEEK0NAkzzSzAz4uB3SomENy4r3lW/RZCCCFE3STMtIDxF241bdqXgt3RNofBCSGEEO5CwkwLGNwzHKNBR7a5hMOns11djhBCCNGmSZhpATqthtH9IgHYsE86AgshhBAtScJMC6m81bT9YDrW0nIXVyOEEMIT7Nq1i/j4eA4dOtSg/b/66ivi4+PJzc1t4crcm4SZFhLfMZD2IUZKyuzsOJTu6nKEEEKINkvCTAtRqVRVV2dkeQMhhBCi5UiYaUFjB1RMG33wdDZZeVYXVyOEEJ5DURQcZSWX/FJspfXu05ivxizG+NVXX9GjRw+ys6sP+sjPz6dXr16sXLmS/fv3c8899zBy5Ej69evHtGnTWLVqVTO12G/MZjP/+Mc/GDJkCH369GHWrFns2bOn2j779u3jj3/8IwMHDqR///5ce+211dZtqu9xdyPLGbSgdsFGesYGcyQxh02/pHDDhK6uLkkIIdyeoiikf/wPSlNPuOT5vaK6EXH7QlQqVYOPmTRpEk8++STr1q3j1ltvrdr+ww8/AHDVVVexbds2BgwYwM0334xer+eXX37hn//8J4qicP311zdL7Xa7nQceeIC0tDQeeeQRQkJCWL58OXfccQcrV66kV69eFBUVMWfOHAYOHMiSJUvQ6/WcPn2agoKKiV7re9wdSZhpYROu6MCRxBw27kth5vguTv3jEEKIy5dn/V/p5+fHmDFjWL16dbUws3r1akaMGEFAQABTp06t2q4oCoMGDSIjI4NPP/202cLM5s2bOXz4MO+88w5jxowBYOTIkVx55ZW8/fbbLF26lKSkJAoLC5k/fz7x8fEADBs2rOoc9T3ujiTMtLARfSN466uDpGQUcSoln67Rga4uSQgh3JpKpSLi9oUottI697Hb7ZSWluLl5dXsCyqqdF6N+sVz6tSpzJs3j/T0dCIiIsjMzGTPnj288MILQMXtn6VLl/LTTz+RkZGB3W4HICAgoNlq37dvH76+vowcObJqm06nY9KkSaxevRqA6OhofH19eeqpp7jtttsYOnQoQUFBVfvX97g7kj4zLczHW8fQ3u0B2CgdgYUQokFUKhVqvfclv1Q6r3r3acxXY6+gjxs3DoPBwHfffQfA2rVr8fLyYuLEiQAsWLCA1atXc+edd/L+++/zxRdfMGPGDMrKypqt3QoKCggMrPlLc0hICGazGQB/f38++OADjEYjf/vb3xgxYgS33XYbJ06caNDj7kjCTCuoHNW0eX8atnKHi6sRQgjREry9vZk4cSJr1qwBYM2aNYwbNw4fHx9KS0vZtGkT9957L7fddhvDhg2jd+/ejepsfCn+/v7k5eXV2J6dnY2/v3/Vz3369OG9995j7969vPXWW+Tk5DB37twGP+5uJMy0gn5dQgn086LQUsa+4xmuLkcIIUQLueaaazh69Cg///wzv/76a1U/mbKyMhwOBzqdrmrfoqIiNmzY0KzPP2DAAIqKiti2bVvVtvLycn788UcGDhxYY39vb2/GjBnDzTffTGpqKqWlpU497i6kz0wr0GjUjBkQxarNCWzYm8LQXu1dXZIQQogWMHz4cAICAnj88ccxmUyMHj0aqOgg3Lt3b959912CgoLQarW88847+Pr6NuvsvWPGjKFXr1489thjPPzww1WjmTIzM3nttdcA2LRpE1988QUTJ04kIiKC7OxsPvnkEwYMGICXl1e9j7sjCTOtZMKgaFZtTmDP0fMUWsrw89G7uiQhhBDNTKfTMXnyZD799FNmzpyJXv/b//Uvv/wyTzzxBAsWLCAgIIDbbrsNi8XCsmXLmu35NRoNr732Gq+99hovvvgiFouFnj17smzZMnr16gVUdPBVq9W88sor5OTkEBAQwMiRI5k/f36DHndHKqW5b9i5mcr1LXr37t3s57ZYLBw7dozu3bvj4+NT7/5/fXkTielm7p3Rh6uHd2r2etyFs+1yOZG2qZ20S+0uh3YpKSkhKSmJTp064e3t3eDj7HY7JSUleHt7N/toJk/mSe1S39+9M5/f0memFY2rXN5gj4xqEkIIIZqLhJlWNKZ/JGq1ihNn80jNLHR1OUIIIdyYw+GgvLy8zq82fmPFKRJmWlGgyZsB8WGALD4phBDi0t544w169uxZ55c7r5XU2qQDcCsb3T+SvccyOHAqy9WlCCGEcGM33ngjY8eOrfPxqKio1ivGzUmYaWWxERWTFqVlFaMoiqzVJIQQolbh4eGEh4e7ugyPILeZWlm7ECMqFRRbbZiLmm8KayGE8GTS/+Py05x/5xJmWpmXTkNoYMUQy7SsIhdXI4QQrlU5I67FYnFxJaK1Vf6dXzwrcmPJbSYXiAwxkplrIS2riJ6xwa4uRwghXEaj0RAQEEBmZiYAPj4+Dbr9XrlqduU5RAVPaBdFUbBYLGRmZhIQENAsdUqYcYHIMF/2n8wiXa7MCCEE7dq1A6gKNA1ROWxZq9WiVstNhkqe1C4BAQFVf/dNJWHGBSJDfQFIzZQwI4QQKpWK9u3bExYWhs1ma9AxVquVxMREoqOjMRgMLVyh5/CUdtHpdM165UjCjAtUhpn0bAkzQghRSaPRNPgDzuFwAODl5eXUMght3eXaLu59DaqNqgwz57KLsdsdLq5GCCGE8GwSZlwgJMCAXqum3K6QmWd1dTlCCCGER5Mw4wJqtYqIC1dnZHi2EEII0TQSZlwkUsKMEEII0SwkzLhIRKgRgDQZ0SSEEEI0iYQZF4kKkyszQgghRHOQMOMi0mdGCCGEaB4SZlykss9MjrkEa2m5i6sRQgghPJeEGRfx89FjMuqBivlmhBBCCNE4EmZcqGpEk3QCFkIIIRpNwowLVYUZWdZACCGEaDQJMy4kw7OFEEKIppMw40IyPFsIIYRoOgkzLnTx8GxFUVxcjRBCCOGZJMy4UESIEZUKLCXl5BeVurocIYQQwiNJmHEhnVZDWKAPIP1mhBBCiMaSMONikVX9ZmSuGSGEEKIxJMy4mKyeLYQQQjSNhBkXqwwz6RJmhBBCiEbROntAQkICCxcuZP/+/RiNRqZNm8ZDDz2EXq+v85jMzEw+/PBDtm3bxtmzZ/Hz82PQoEHMnz+fyMjIqv22b9/O559/zoEDB8jJySEyMpLp06cze/ZsdDpd416hm4u8MNdMqvSZEUIIIRrFqTBjNpuZPXs2MTExLF26lIyMDBYtWkRJSQlPPPFEnccdOXKE9evXM2PGDPr27UteXh7/+c9/uOGGG1i9ejVBQUEArFy5kpKSEh588EHat2/PgQMHWLp0KQkJCTz//PNNe6VuKjLUD4DzOcXY7Q40GrlYJoQQQjjDqTCzcuVKiouLef311wkICADAbrfz9NNPM2fOHMLDw2s9buDAgaxduxat9renGzBgAGPHjmXVqlXceeedADz11FNVwQZgyJAhOBwOXnnlFR599NFqj7UVwf7e6HUaymx2MnItVXPPCCGEEKJhnLoMsGXLFoYNG1YVZACmTJmCw+Fg27ZtdR5nMpmqBRmAdu3aERQURGZmZtW22sJK9+7dURSFrKwsZ0r1GGq1ioiQC8saSL8ZIYQQwmlOXZlJTExkxowZ1baZTCZCQ0NJTEx06omTkpLIyckhLi7ukvv98ssv6PV6oqKinDr/xRRFwWKxNPr4ulit1mp/Nla7IAPJ5wpISsujZ4ypOUpzqeZql7ZI2qZ20i61k3apm7RN7dpSuyiKgkqlatC+ToWZgoICTKaaH7b+/v6YzeYGn0dRFBYuXEhYWBhTp06tc7/k5GQ+/vhjZs2ahdFodKbUamw2G8eOHWv08fVJTk5u0vE6KoLW0dNpxAU1f+hylaa2S1smbVM7aZfaSbvUTdqmdm2lXS41uOhiTo9mag5Lly5l586dvPfee/j4+NS6T1FREQ888ABRUVHMmzevSc+n0+no3Llzk85RG6vVSnJyMjExMRgMhkafJ6s0nZ+PHMFq19O9e/dmrNA1mqtd2iJpm9pJu9RO2qVu0ja1a0vtcvr06Qbv61SYMZlMFBYW1thuNpvx9/dv0Dk+++wz3njjDZ577jmGDRtW6z5lZWXMnTsXs9nMp59+WmfgaSiVStXkc1yKwWBo0vk7RVb0FTqfY23ROltbU9ulLZO2qZ20S+2kXeombVO7ttAuDb3FBE6GmdjY2Bp9YwoLC8nKyiI2Nrbe49evX89TTz3Fgw8+yMyZM2vdx+Fw8Mgjj3DkyBFWrFhB+/btnSnRI1VOnJdbUIKlxIaPd9ucU0cIIYRoCU6NZho9ejTbt2+noKCgatu6detQq9WMGDHiksfu2rWL+fPnc8MNNzB37tw693v66afZuHEjb775JvHx8c6U57F8ffT4+1bcF0zPljWahBBCCGc4FWYqO+LOnTuXrVu38uWXX7J48WJmzZpVbY6Z2bNnM2nSpKqfExISmDt3LjExMUybNo1ff/216uvs2bNV+7311lusXLmS2267Db1eX22/oqK2PWy5ao0mmQlYCCGEcIpTt5n8/f356KOPePbZZ5k7dy5Go5GZM2fW6KDrcDiw2+1VPx84cIDCwkIKCwu5+eabq+17/fXXs2jRIoCquWref/993n///Wr7ffzxxwwZMsSZcj1KZKgvR5NyZY0mIYQQwklOj2aKi4vjww8/vOQ+y5cvr/bz9OnTmT59er3n/v1xl5PKKzOpEmaEEEIIp8hCQG4iQlbPFkIIIRpFwoybiAq70GcmqxhFUVxcjRBCCOE5JMy4iXbBPqhVYC0tJ6+w1NXlCCGEEB5Dwoyb0Gk1hAfJgpNCCCGEsyTMuJGI0AthRoZnCyGEEA0mYcaNRFb1m5EwI4QQQjSUhBk3UjVxnoQZIYQQosEkzLiRyBAZni2EEEI4S8KMG6m8zXQ+x0K53eHiaoQQQgjPIGHGjQSZvPHSa7A7FDJyLa4uRwghhPAIEmbciFqtqrrV1JwjmoqtNkpt9vp3FEIIITyQhBk3UzU8u5n6zeQVlnDXc+uZ9+9NFFttzXJOIYQQwp1ImHEzzT08e+uv6RRbbaRkFPHqp/tlqQQhhBBtjoQZN9Pcw7O3HUyv+n7HoXN8+3Nis5xXCCGEcBcSZtxMVZhphj4zOWYrR5NyAJgxrjMAH/zfEY6fyW3yuYUQQgh3IWHGzVSGmbzCUiwlTevjsv3gORQFunUMZPbUHozoG4HdofDCx3spKC5rjnKFEEIIl5Mw42aMBh0Bfl5A0281bT2QBsDIfpGoVCoevLEfESFGsvOtLPnvPhwO6T8jhBDC80mYcUO/9ZspbvQ5csxWjiVX3E4a0ScCAB9vHQtmD0KvVbPveCZfbDjV9GKFEEIIF5Mw44aao9/MtoPpKAp0jwkiJMBQtb1ThD9zpvcBYMW6Yxw6nd20YoUQQggXkzDjhiIvzDXTlDWath2oGMU0om9EjccmDY5m/BUdcCiw+JO95BWUNPp5hBBCCFeTMOOGKq/MpDYyzNR2i+liKpWKe6f3IbqdH/mFpbz4yT7s0n9GCCGEh5Iw44YiQn9bPbsxk9zVdYvpYt5eWhbcPghvvYZDCdn89/vjTapZCCGEcBUJM26oXbARtVpFSZmd3EbcAqq8xTSylltMF+sQ7sf9N/QD4LMfT7L3WIbTzyWEEEK4moQZN6TTqgkP8gGcH55dMVFexS2m4bXcYvq9MQOimDI8BoAl//2FrDyrc8UKIYQQLiZhxk01dnh25fIFl7rF9Ht/vq4XcVH+FFrKeGH5HmzlDueKFUIIIVxIwoybauzw7K2/NuwW08X0Og0Lbh+E0VvLiTN5fPTdUaeeUwghhHAlCTNuqnJ4tjO3mS4exdSQW0wXaxds5KGbBwDwzZYEdhxKr+cIIYQQwj1ImHFTkWHOr57dmFtMFxvaqz1/GBMHwCsr93Muu/EzEAshhBCtRcKMm6q8zZSRa2lwH5bG3GL6vdlTe9A9JghLSTmLPt5Dmc3e6HMJIYQQrUHCjJsKMnnjrdfgcCicz6n/Ckm1ifKaEGa0GjV/u+0KTEY9iWlm3vvmcKPPJYQQQrQGCTNuSqVSVZs8rz6Vc8t0jwki2N/5W0wXCwkw8PAfBwKwbmcylhJbk84nhBBCtCQJM24sKrTh/Wa2Vk6U16/xV2UuNiA+jEA/LxQFUpuw4KUQQgjR0iTMuLGIBs41k51/6bWYGqtDuB8AZ88XNts5hRBCiOYmYcaNNXRE0/aDzXeL6WKVYSY1U8KMEEII9yVhxo01dK6Z5r7FVKnqykyGhBkhhBDuS8KMG6scnp1fWEqxtfZOuC11iwkg+kKYSZEwI4QQwo1JmHFjPt46Av28gLqvzlTeYurRqXlvMcFvV2Yyci2UynwzQggh3JSEGTdXX7+ZyltMTZlbpi7+vnr8fHQoivNrRAkhhBCtRcKMm4u8xPDsyltMKlXz32KCirlupN+MEEIIdydhxs1FhNS9eva2FhrFdLGqEU0SZoQQQrgpCTNuLiqschbgmnPNVM76O7JvZIs9v1yZEUII4e4kzLi5iMrh2dlFOBxK1fasvN9uMQ3v077Fnr+DjGgSQgjh5iTMuLl2wUbUahWlZXZyC0qqtm8/VDmKKbjFbjHBb8Oz07OLG7x6txBCCNGaJMy4Oa1GTbsgH6B6v5nKW0wt0fH3YsH+3hi8tDgcCueyZUSTEEII9yNhxgNUDc++ECZa6xYTVI5oqnj+lAwJM0IIIdyPhBkPUDU8+8KVmda6xVRJOgELIYRwZxJmPMDv55rZ+msa0PK3mCp1CJPh2UIIIdyXhBkPcHGYycqzcvxMXqvcYqrUoZ1cmRFCCOG+JMx4gMo+M5m5FjbvTwVa7xYT/DaiKS2rCPtFw8OFEEIIdyBhxgME+nlh8NLgUODbLQkAjGyBtZjqEhrog16nwVbuICO35uR9QgghhCtJmPEAKpWq6lZTXmHphVtMrRdmNGoVUReeP+W83GoSQgjhXiTMeIiIC2ECKm4xBZm8W/X5ZUSTEEIId+V0mElISOCOO+6gX79+jBgxgsWLF1NWVnbJYzIzM1m8eDHTpk2jf//+jB49mocffpi0tLQa+2ZkZPDAAw/Qv39/Bg8ezD/+8Q+KimR+k6iLwkxr3mKq1KFdxfOn1rLgpRBCCOFKWmd2NpvNzJ49m5iYGJYuXUpGRgaLFi2ipKSEJ554os7jjhw5wvr165kxYwZ9+/YlLy+P//znP9xwww2sXr2aoKAgAGw2G3/+858BePnllykpKeGFF17g4Ycf5u23327Cy/R8lVdmWvsWU6XK4dlyZUYIIYS7cSrMrFy5kuLiYl5//XUCAgIAsNvtPP3008yZM4fw8PBajxs4cCBr165Fq/3t6QYMGMDYsWNZtWoVd955JwDff/89p06dYs2aNcTGxgJgMpm46667OHjwIH369GnMa2wTesUFY/TWMrB7eKvfYoLfbjOlZhTicCio1apWr0EIIYSojVO3mbZs2cKwYcOqggzAlClTcDgcbNu2rc7jTCZTtSAD0K5dO4KCgsjMzKx2/vj4+KogAzBixAgCAgLYvHmzM6W2OcH+BlY8ezXzbxnokudvH2JEq1FRUmYnO9/qkhqEEEKI2jh1ZSYxMZEZM2ZU22YymQgNDSUxMdGpJ05KSiInJ4e4uLhq5784yEDFSJ5OnTo5ff6LKYqCxWJp9PF1sVqt1f5s69oF+ZCaVczplGx8vUPq3O9yaxdnSNvUTtqldtIudZO2qV1bahdFUVCpGnYXwKkwU1BQgMlkqrHd398fs9nc4PMoisLChQsJCwtj6tSp1c7v5+fX5PP/ns1m49ixY40+vj7Jycktdm53YvJ2ALDvUCJe5Vn17n+5tEtjSNvUTtqldtIudZO2qV1baRe9Xt+g/ZwKM81l6dKl7Ny5k/feew8fH58Wfz6dTkfnzp2b/bxWq5Xk5GRiYmIwGFpnNl5X6p6ewNGURGxqI927d69zv8utXZwhbVM7aZfaSbvUTdqmdm2pXU6fPt3gfZ0KMyaTicLCmqNZzGYz/v7+DTrHZ599xhtvvMFzzz3HsGHDapy/tmHYZrOZ9u0bvw6RSqVq0dBkMBhaJZS5WlxUEJDI+ZySBr3ey6VdGkPapnbSLrWTdqmbtE3t2kK7NPQWEzjZATg2NrZG35XCwkKysrJq9HWpzfr163nqqad48MEHmTlzZoPOrygKSUlJDTq/aFlR4RXDw89mFKIoskaTEEII9+BUmBk9ejTbt2+noKCgatu6detQq9WMGDHiksfu2rWL+fPnc8MNNzB37tw6z3/8+PFq9/p27NhBfn4+Y8aMcaZU0QIiQ31Rq6DYaiOvsNTV5QghhBCAk2Fm1qxZGI1G5s6dy9atW/nyyy9ZvHgxs2bNqjbHzOzZs5k0aVLVzwkJCcydO5eYmBimTZvGr7/+WvV19uzZqv0mT55Mly5deOCBB9i4cSNr1qzh8ccfZ+zYsZf1HDPuQq/T0C7YCECKTJ4nhBDCTTjVZ8bf35+PPvqIZ599lrlz52I0Gpk5cybz5s2rtp/D4cBut1f9fODAAQoLCyksLOTmm2+utu/111/PokWLgIqOuu+99x4LFy5k/vz5aLVaJk2axOOPP97Y1yeaWYdwP9Kzi0nJKKRvl1BXlyOEEEI4P5opLi6ODz/88JL7LF++vNrP06dPZ/r06Q06f3h4OEuXLnW2LNFKOoT7sevIeVnWQAghhNuQVbOFU35b1kAWnBRCCOEeJMwIp3S4MKJJ+swIIYRwFxJmhFOiLqyenV9UirlIRjQJIYRwPQkzwikGLy1hgRWzSqZmyq0mIYQQridhRjitst+M3GoSQgjhDiTMCKdJmBFCCOFOJMwIp1WGGRmeLYQQwh1ImBFOi64ani1hRgghhOtJmBFOi7oQZrLNJVhKbC6uRgghxOVOwoxwmq9BR5DJC5B+M0IIIVxPwoxolN86AcvwbCGEEK4lYUY0SocwGdEkhBDCPUiYEY3SoZ2MaBJCCOEeJMyIRpG5ZoQQQrgLCTOiUSpvM2XmWSgpK3dxNUIIIS5nEmZEo/j76vHz0aMokCZrNAkhhHAhCTOiUVQqFdHt5FaTEEII15MwIxqtqt+MXJkRQgjhQhJmRKN1CPMF5MqMEEII15IwIxqtasHJ8xJmhBBCuI6EGdFolX1mzuUUYyt3uLgaIYQQlysJM6LRgkzeGLy0OBwK6dnSb0YIIYRrSJgRjaZSqYiWyfOEEEK4mIQZ0SSy4KQQQghXkzAjmqRDuIxoEkII4VoSZkSTyBpNQgghXE3CjGiSyjCTmlmE3S4jmoQQQrQ+CTOiScICfdDrNJTbHWTkWlxdjhBCiMuQhBnRJGq1iqgLMwGflVtNQgghXEDCjGgyGZ4thBDClSTMiCaTTsBCCCFcScKMaDIZni2EEMKVJMyIJqu6MpNZhMOhuLgaIYQQlxsJM6LJ2gcb0WpUlJbZyc63urocIYQQlxkJM6LJNBo1EaEyokkIIYRrSJgRzUI6AQshhHAVCTOiWcjwbCGEEK4iYUY0C7kyI4QQwlUkzIhmcXGYURQZ0SSEEKL1SJgRzSIy1IhaBcUl5eQVlrq6HCGEEJcRCTOiWei0GtqHGAFIyyp2cTVCCCEuJxJmRLOJCqu41ZQqYUYIIUQrkjAjmk10u4owk5YpYUYIIUTrkTAjmk1lJ2C5zSSEEKI1SZgRzaZD1W2mIhdXIoQQ4nIiYUY0m6iwiiUNCoptFJfYXVyNEEKIy4WEGdFsvL20hAX5AJBdUO7iaoQQQlwuJMyIZtXhwtWZLLOtwccoikJKRiFrdySzaV9KS5UmhBCijdK6ugDRtnQI92Pf8UyyzHVfmbE7FM6cK+BwYjaHE3I4mpSDuais6vHIMF+6dAhsjXKFEEK0ARJmRLOqXHAyq+C3KzPldgcJqfkcTsjhcGIOx5JyKC6pHnb0WjV6nYYiq40jibkSZoQQQjSYhBnRrDpcmGvmfJ6NLzcmcjKlgGNnciktq94h2OClpXunIHrFBtMzNpguHQJYtTmBj9cc4/iZXCDOBdULIYTwRBJmRLOqHJ5tKXXw2YaEqu1+Pjp6xgbTMzaEXrHBdIowodFU77LVrWMQACeSc1uvYCGEEB7P6TCTkJDAwoUL2b9/P0ajkWnTpvHQQw+h1+svedyKFSvYsmULBw4cIC8vj1dffZWrrrqqxn579+7l1Vdf5fjx46jVanr37s3DDz9M9+7dnS1VuIDRoGNU3/YcPJVJj9gQ+nYNp1dsMB3C/VCrVZc8tnOHANQqyDaXkJ1vJSTA0EpVCyGE8GROjWYym83Mnj0bm83G0qVLmTdvHp999hmLFi2q99hvvvmGvLw8xowZU+c+iYmJ3HXXXfj4+PDyyy/z3HPPYTab+dOf/kRWVpYzpQoXun9mL+b9oT0P3dSHqSM60bG9qd4gAxW3nmLa+wNw4kxeS5cphBCijXDqyszKlSspLi7m9ddfJyAgAAC73c7TTz/NnDlzCA8Pv+SxarWa1NRUVq1aVes+P/74I4qi8Oqrr+Lt7Q1AfHw8EydOZNu2bfzhD39wplzhgeI7BpKYbub4mVxG9I1wdTlCCCE8gFNXZrZs2cKwYcOqggzAlClTcDgcbNu27dJPpK7/qWw2G3q9Hi8vr6ptfn5+zpQoPFy3mIpRTHJlRgghREM5dWUmMTGRGTNmVNtmMpkIDQ0lMTGxycVMnTqV9957j1deeYU//elPlJWVsWTJEtq3b8+ECRMafV5FUbBYLE2u7/esVmu1P0WFprRLx/CKfjKnU/MpKChCq21b8zrKe6Z20i61k3apm7RN7dpSuyiKgkpVfxcFcDLMFBQUYDKZamz39/fHbDY7c6paxcTE8OGHH3Lffffx1ltvARAZGckHH3zQpCs0NpuNY8eONbm+uiQnJ7fYuT1ZY9pFURQMXmqspQ427jhEVMilO5Z7KnnP1E7apXbSLnWTtqldW2mX+gYXVXKrodlJSUk88MADjBgxgj/84Q+UlpaybNky/vKXv7By5UpCQkIadV6dTkfnzp2budqK5JucnExMTAwGg4y8qdTUdum+r5RfTmZj0wbSvXt0C1ToOvKeqZ20S+2kXeombVO7ttQup0+fbvC+ToUZk8lEYWFhje1msxl/f39nTlWrf//734SEhLB48eKqbYMHD2bcuHF8/PHHzJ8/v1HnValU+Pj4NLm+uhgMhhY9v6dqbLv0iA3hl5PZJKUXtdl2lfdM7aRdaiftUjdpm9q1hXZp6C0mcLIDcGxsbI2+MYWFhWRlZREbG+vMqWp1+vRpunXrVm2b0WgkOjqas2fPNvn8wjNUTp5XMROwEEIIcWlOhZnRo0ezfft2CgoKqratW7cOtVrNiBEjmlxMREQEx44dQ1GUqm1FRUWcOXOGyMjIJp9feIYu0QGoVJCZZyW3oMTV5QghhHBzToWZWbNmYTQamTt3Llu3buXLL79k8eLFzJo1q9ocM7Nnz2bSpEnVjj106BDr1q1jy5YtABw4cIB169axe/fuauc/evQojzzyCFu2bOHHH3/k7rvvpqysjBtuuKEpr1N4EB9vHR3bVXQ0PyFXZ4QQQtTDqT4z/v7+fPTRRzz77LPMnTsXo9HIzJkzmTdvXrX9HA4Hdnv1hQVXrFjB119/XfXzsmXLgIo+McuXLwdg4sSJvPLKK7z//vvMmzcPnU5Hjx49+Pjjj4mJiWnM6xMeKr5jIMnnCjienMew3jJ5nhBCiLo5PZopLi6ODz/88JL7VIaTiy1atKhByx5MmTKFKVOmOFuWaGO6dQzk+51nOHFWJs8TQghxaW1rRjLRZsRf6AR8KiWfcrvDxdUIIYRwZxJmhFuKDPXF16CjzGYnOb2g/gOEEEJctiTMCLekVqvo2rFinSYZoi2EEOJSJMwIt1U130yy9JsRQghRNwkzwm3FX7gyc+KsXJkRQghRNwkzwm3FRweiUsH5HAv5haWuLkcIIYSbkjAj3JbRoCMqrGK1dJk8TwghRF0kzAi31q2qE7D0mxFCCFE7CTPCrXWLkUUnhRBCXJqEGeHWKjsBn0rJxy6T5wkhhKiFhBnh1jqE+eHjraW0zE7yOZk8TwghRE0SZoRbU6tVdI2uHKIt/WaEEELUJGFGuL3fJs+TfjNCCCFqkjAj3F63GBnRJIQQom4SZoTbi79wm+lcdjHmIpk8TwghRHUSZoTb8/XRExXmC0i/GSGEEDVJmBEeoWqdJrnVJIQQ4nckzAiPIJ2AhRBC1EXCjPAIlTMBn0rJw+5QXFyNEEIIdyJhRniEDuF+GLy0WEvtnD0vk+cJIYT4jYQZ4RE0ahVdowMAGaIthBCiOgkzwmPEX+g3c0IWnRRCCHERCTPCY3S7MKLpeLJcmRFCCPEbCTPCY1RemUnLKqLQUubiaoQQQrgLCTPCY5iMeiJCjIDMNyOEEOI3EmaER6kcon1c+s0IIYS4QMKM8CgyE7AQQojfkzAjPErlTMAnz+bhkMnzhBBCIGFGeJiO7fzw1muwlJSTklno6nKEEEK4AQkzwqNoNGq6dJAh2kIIIX4jYUZ4nG4xlf1mpBOwEEIICTPCA8VHX7gyI52AhRBCIGFGeKDKyfNSMgopstpcXI0QQghXkzAjPE6Anxftgn2AilFNQgghLm8SZoRHqhyifSJZ+s0IIcTlTsKM8EhVi042od9Mmc1OSoYM7xZCCE+ndXUBQjRGZb+ZExcmz1OrVU4dn5CazwvL93Iuu5i7ruvFH8bEtUSZQgghWoFcmREeKSbChF6nodhqIy2rqMHHKYrCd9uSeOS1nzmXXQzAB6uPcCQxp6VKFUII0cIkzAiPpNWo6dIhAGj4fDPFVhsvfLyXt746SLndwZCe7RjRNwKHQ2Hx8j3kFZa0YMVCCCFaioQZ4bGc6Tdz8mwef12yiW0H09FqVPx5Wi/+ccdg/npTfzqE+5JbUMpLn+zDLus9CSGEx5EwIzxWZb+Z45cY0aQoCt9sSeCx138mI9dCWJAPL9w/immj41CpVBi8tPx99mC89RoOns5mxbpjrVW+EEKIZiJhRnisyiszZzMKsZTUnDyv0FLGcx/s5r1vDlNuVxjWuz2vzh9L1wszCFfqEO7HAzf2A+Dzn06x5+j5Fq9dCCFE85EwIzxWoMmbsCAfFKXm5HnHz+Ty1yWb2HXkPFqNmnuu783fZw/C16Cr9Vyj+0dxzYhOACz57y9k5FpavH4hhBDNQ8KM8GjdoisXnawIMw6HwlcbT7Hg9a1k5VlpH2zkxQdHMXVkLCrVpYdv33ldT7pGB1BktbHoo92U2ewtXr8QQoimkzAjPFp8zG+dgM1FpTy7bBcfrD6K3aEwql8kr8wfQ+eogAadS6fV8Njtg/Dz0XM61cx73xxuwcqFEEI0FwkzwqNVLmtwNCmHvy7ZxN5jGei0aubO7Mujtw7Ex7v220p1CQv04eE/DkClgrU7ktm4L6UlyhZCCNGMJMwIj9Ypwh+9Vo2lpJwccwmRob68/NfRXDUspt7bSnUZ2C2cmybGA/DGFwc4c66gOUsWQgjRzCTMCI+m06rp1TkEgHEDo/j3vDF0ivBv8nlnXRlPv66hlJbZef6jPbWOlhJCCOEeJMwIj/forVew5KHRzLt5AAav5lluTKNW8cgfBxLi701aVhGvffYritL4CfUsJTbWbE/ilU8PkpkvwUgIIZqTLDQpPJ6vQUeXDoH17+gkf18vHrt9EAve2Mq2A+n8X6dErhvl3IKUZ84VsGZ7Ehv3pWAtrRgdlZntxZhhzV6uEEJctiTMNFLpuUQyVz6LV9RA6N7d1eWIFtItJog7r+3Ju98cZtm3R+jaIZBuMUGXPMZW7mDHoXTWbE+utoBlRIiR9OxiEs6XkplnJcbHp6XLF0KIy4LcZmokpbwUh6UAn5MbKUn81dXliBZ07ahYRvaNwO5QeOHjPZiLSmvdLzPPwvK1x7jz2R948ZN9HEnMQa1WMbxPexbeM5y3FkygT1xFENqwL601X4IQQrRpcmWmkbw7dMen3yQsv67HvO4t/KI6owsIc3VZogWoVCoeuLEfSekFpGUV8dKKfTz1l2Fo1CocDoVfT2axZnsSe46ep3KdyiCTN5OHdmTy0I4E+xuqzjX+iigOJuSy6Zd0Zk/thUYjv08IIURTOR1mEhISWLhwIfv378doNDJt2jQeeugh9Hr9JY9bsWIFW7Zs4cCBA+Tl5fHqq69y1VVX1brvpk2beOuttzh+/Dg6nY5u3brx4osv0q5dO2fLbVF+o26mIOkIWnM6GV++RMTshai1l24H4Zl8vHX8ffYgHn5tC7+ezOLj744S4OfF2u3JnMsprtqvT+cQrh7RiSE926GtJagM6haKj5eavMJS9h7LYEiv9q35MoQQok1y6tdCs9nM7NmzsdlsLF26lHnz5vHZZ5+xaNGieo/95ptvyMvLY8yYMfXud//99zN48GDeeustFi1aRK9evSgtrf3SviuptDqK+l2PytuXsvMJ5Kz/wNUliRbUsb2J+2b0BeCrTadZ9n9HOJdTjNFby7WjYnnzb+N57t4RjOgTUWuQAdBq1fSLregrs27nmVarXQgh2jKnrsysXLmS4uJiXn/9dQICAgCw2+08/fTTzJkzh/Dw8Eseq1arSU1NZdWqVbXuk5+fzzPPPMPjjz/OLbfcUrV9woQJzpTZqhSDPwFT7iXv65co/OUHvKO64df70oFNeK7xV3TgVEoeq7cmERvpz9XDOzGmfyTeTgwJHxBnZPuxIn45nkF2vpWQAEP9BwkhhKiTU1dmtmzZwrBhw6qCDMCUKVNwOBxs27bt0k+krv+p1q5di8PhYObMmc6U5XJeMX0IGHUDANlr3qIs82yzP4e92EzW2rcpOvJzs59bOOfuP/Tm46cm88q8MUwe2tGpIAMQYtLRIyYQhwLrdzf/e0UIIS43Tv0vnJiYyIwZM6ptM5lMhIaGkpiY2ORiDhw4QKdOnVi1ahX/+c9/yMjIoEuXLsyfP7/e21OXoigKFoulyfX9ntVqrfrTe8BU9GePUXbmEOe+eIHgW55BrW+e37jLc9LIW/Uy9oIsCvevp1zviz4yvlnO3RIubpe2ykvTuNdXeczIPqEcTc7jh53JXDs8CrW6cUsvtBWXw3umMaRd6iZtU7u21C6KojR4WRqnwkxBQQEmk6nGdn9/f8xmszOnqlVWVhZJSUm8+uqrPProo4SGhrJixQruu+8+Vq1aRZcuXRp1XpvNxrFjx5pcX12Sk5MBUMVNwJSRDHnnSf1yCcV9r4dGrg9USZuThHH/V6jLS1FUalSKg+xvX6NgxF0oOve+PVHZLqKmUEMx3noV2eYSVm/cT5cI9/67bC3ynqmdtEvdpG1q11bapb7BRZXcamh25RWUl156qaqfzODBg5k8eTLvvvsuixcvbtR5dTodnTt3bs5SgYrkm5ycTExMDAZDxYdRWZg/uZ8tRH/+OMHxKRgHTG70+S2HN1Gw7zNw2NG174L/lHvI+2ox5GcQfmYrAdc80OjFFFtSbe0iKlS2TZe4TowbqGHtjrOczNBw3YTLe+JFec/UTtqlbtI2tWtL7XL69OkG7+tUmDGZTBQWFtbYbjab8fdv+uJ+lVd9hg4dWrVNp9MxaNAgTp061ejzqlQqfFpwtlWDwVB1fp+4Pqgmzibnh2UU/vw//GJ64B3l3C0hRXGQt+m/FGz/GgBjz5GEXjMXtVaP/vr5pH/0OKWn92A/uR1T/0nN/nqay8XtIqozGAxMHRnH2h1n+eVEFqXlagJN3q4uy+XkPVM7aZe6SdvUri20izO/rDvVATg2NrZG35jCwkKysrKIjY115lS1utTVE3ccml0X0xVXY+w+HBx2Mr56GXtxw2/BOWylZH69hPwLQSZg5A2ETXuoav4a74jOBI2tGOmV88MyyrJTm/8FiFbRsZ2Jbh0DsTsUftwjHYGFEKKxnAozo0ePZvv27RQUFFRtW7duHWq1mhEjRjS5mHHjxgGwY8eOqm1lZWXs2bOHnj17Nvn8rUWlUhE69T50wRHYC3PI/OYVFIe93uPKi/I598mTFB/bAWotodc+QNCYWTXSqf/Q6zB06otSXkbm10twlJe11EsRLWzy0BgAfth1Boej8atyCyHE5cypMDNr1iyMRiNz585l69atfPnllyxevJhZs2ZVm2Nm9uzZTJpU/fbHoUOHWLduHVu2bAEqRi6tW7eO3bt3V+3Ts2dPJk+ezL/+9S+++OILNm/ezAMPPEB2djZ33XVXU15nq1N7GQif8SgqnRfWpIPk/fz5Jfcvy0oh/cO/U5p+CrW3L+1veQK/PmNr3VelUhN67QOofUyUZZ4hd8PyFngFojWM7BuBj7eW8zkWDp3OdnU5QgjhkZwKM/7+/nz00UdoNBrmzp3Lyy+/zMyZM1mwYEG1/RwOB3Z79SsRK1as4K9//StPP/00AMuWLeOvf/0rS5curbbfokWLmDp1Ki+//DL3338/ZrOZDz74gPh49x2KXBd9aDQhV98DQP7WL7Ak7K91P0vSAdI+epxycybawHZE/Ol5DB0vfSVK6xdI2LX3A1CwZw3Fp/Y2b/GiVXh7aRkzIAqA73fJjMBCCNEYTo9miouL48MPP7zkPsuX17xSsGjRogYte+Dj48M///lP/vnPfzpbmlvy6zWa0pTjFPzyPZnfvELkXS+i8/9tQcqC/T+Sve4dcNjx7tCd8Jl/Q+NTc/h7bXw6D8Q0aCoFe74ja/UbeP35ZbR+QS31UkQLmTykI2u3J7PjUDrmolL8fb1cXZIQQngUWbK3FQRPugOv9nE4rEVkfrUEpdyGojjI2bCc7DX/AYcd316jaX/Lkw0OMlXnHn8b+vBOOCwFZH37GoriaKFXIVpKXFQAnTsEUG5X2LA3xdXlCCGEx5Ew0wpUWh1h0x9B7e1Lafopsn94n8yvXsa8YxUAgaNuIvS6B1FpdY079x8equibk3wI845vmrl60RomD+kIwPc7z6Ao0hFYCCGcIWGmlegCwgib9iAAhfvXU3x8J2i0hF73IIGjb2zS5Hf6kCiCr7wTgNzN/6Mk7WSz1Cxaz+j+kXjrNaRlFXE0KdfV5QghhEeRMNOKfDoPJGBExdpWaoMv7W95stlW2PbrOwFj92HgsJO56t84Spt/LaqGUBQHlgM/4ZW8W64wOMHHW8fo/hUdgdftTHZtMUII4WEkzLSywDGzaHfTP4j68xIM0T2a7bwqlYqQq+9F6x9KeX4m2WvfafUwYbcUcH7lcxRs+BCf4z9SelpGWDlj8tCKW03bD6RTZJG5g4QQoqEkzLQylUqNT+cBaE3BzX5ujbeRsGkPgUpN0ZGfKTq0udmfoy4laadIff9RrIm/Vm0r/HklSrmt1WrwdF06BBDT3kRZuYON+2RmZyGEaCgJM22Md4duBI66EYDs79/Flpveos+nKArmvWtJ//if2Auy0Qa2I+imf+HwMmI3Z2Let7ZFn78tUalUVVdnftglHYGFEKKhJMy0QQEjpuMd3QOlrISMr19BsbfM1RFHmZXMb14h5/v3wFGOT/wQou5cjD6iK9YuY4GKyQLtlpqLk4rajR3YAb1WTfK5Ak6czXN1OUII4REkzLRBKrWGsGl/Re3tS9n5BHI3/a/Zn6MsO5W0DxZQfGQrqNQETZxN+IxHUXsbKx6P7I02pAOOkmLytn7W7M/fVvkadIzsFwnADzs9a0bgIquNf//vF9788gApGRJghRCtR8JMG6U1hRA69T4AzDu/adblDoqObCVt2WPYslPR+AYRcdszBAy5rvrwcpUav9EVq3sX7PuespyWvd3Vllx5Yc6ZLb+mYSnxjD5HuQUl/P2NrWzYm8La7cnct3gDz76/i0MJ2XK7TAjR4iTMtGHGbkPwG3AlABmfPU/KOw+Ru+l/lJ5LbNQHjFJuI/v798hc9W8UWwneMb2JvOtFvDt0r3V/r4698Ok8EBx2cjd83KTXcjnp0SmIDuG+lJbZ2bw/zdXl1Cs9u4hHl/5M8rkCAv28GNKzHSoV7D56nsff3Mb8V7fw8/407HaZnVoI0TKcXptJeJbgiX/CYS2i+MQubFkp5GelkL/tC7T+ofh0HYwxfgjeHbqhUmsueZ5ycxYZX71MafopAAKGTydwzKx6jwuacDuWhP1YTu7BeuYwho69mu21tVUqlYorh8Tw/reH+X5nMlOGxbi6pDolpObz1Ls7yS8qpX2wkWfmDKNdsJG0rCK+2ZzAT3vOcjoln8Wf7CUs0MC00XFMHByNj7fzs10LIURd5MpMG6fWeRE+/WE6PrSM0OsexCd+CCqtnnJzFgV7vuPcJ09w5tU/k7X6DSyn9uEorzm/iSVhP6nvP0pp+inU3kbCb/w7QeP+WG+QgYrZiU0Xrg7lrP9Q1o5qoHEDo9Bq1CSkmjmdmt+oc6RkFPLtlgSOJ7fMjMKHTmfz9ze3kV9USmyEPy88MJJ2wRV9piJDfblvZl+W/etKbpncDX9fPZl5Vt795jB3LlzPR98dJcdsbZG6ROOVlJXz056zZOW13b8bue3ZNsmVmcuExuCLX+8x+PUeg8NWijXxV4pP7MZyai8OSwGFBzZQeGADKr03PnEDMMYPwRDXH/Ou/yN/6xeAgr5dLOEzHkEXEO7UcweOupHCw1soy0ii6NBm/PqMa5kX2Yb4+3oxvHd7tvyaxg87z9B5ZkCDjrOU2Nh6IJ31u85w/Mxvo6EmDormT9f0aLYVuXccOseLn+zFVu6gV1ww/7xjCEZDzast/r5e3HxlPNPHdWbj3hRWbT5NWlYxX2w4xarNpxkzIIrrx3Qm1L/2/4rsdge5BaXkmK3kmEvINlvJzreSW/m9uYRgkzd3XNOT7p1afsX4IksZGbkWYiP9m7QEiTsqtzt4/qM9/HI8E39fPU/cNZSu0YGuLqtOWflWTqRZySk7hx0N1hIblpJyLKXlWEvKsZRW/Fz5vbXysdJyunUM4vm5I9Go29bf4eVMwsxlSK3zwhg/BGP8EBR7OSVnj1J8YhfFJ3djL8yl+Nh2io9tB1RAxW8xfv2vJPjKO1Br9U4/n8boT+CIGeRuWE7upv9i7DYMtd67eV9UG3Tl0I5s+TWNTb+kcse1PTF41f7PVVEUjibl8uPus2w9kEZJmR0AtVpFlw4BnDiTx497zrLryDn+dE1PJg6KRt2E/8R/2HWGNz7/FYcCQ3u149Fbr0Cvu/RVOi+dhquGxXDlkI7sOXqerzcncCQxh5/2pPDTnhT6dg4mxGhjZ+JxzMXlZOdXhJf8whIc9fwinZlr4W+v/8xVw2KYfXV3fH2cf4/Wp9zuYM22JP77wwmKrTYGdAvj7j/0JjLUt9mfyxUURWHpZ7/yy/FMAMxFZTz+n208dtsVDOrRzsXV1bT5l1SW/O8XHA4FyHH6+GPJuew5ep6hvdo3f3HCJSTMXOZUGi2GTn0wdOpD8OS7KE1PoPjETiwndmPLTUel1RNy9Rz8eo9t0vOYBl1Nwb51lJuzMO/6tmpiP1G33nEhtA8xci67mK2/pjHpwiinSrkFJWzYm8KPu8+QllVctT0y1JdJg6MZd0UHgkzeHE/O5Y0vDpB8roCln/3Kj7vPct/MvsS0NzlVj6IofLHhFB+vOQbApMHRzJ3ZF42m4Xer1WoVQ3q1Z0iv9pw4k8vXmxPYcTCdA6crP5AKahyjUasI9vcm2N9AsL83IQEGgv0NhAR4E+jnzU97zrJ+91nW7Uhm5+Fz/GVaL0b1i2y2Kye/nMjkvW8OkZJR9Nu245nc/+IGpo2O48aJXT2+D9DytcfYsDcFtVrFI7cM5Mc9Z/nlRCYLP9jNfTP6MHlojKtLrPL9zjO88cWvKAqEmLS0CzHh66PH4KXFx1uHj7e22vc+F76v2Kblu21JfPtzIt9tTZIw04aolDZ+A/HQoUMA9O7du9nPbbFYOHbsGN27d8fHx6fZz+9KiqJgyz2HWufl9NILdbVL0dFtZH69BJXOiw73vo7Wr+VvC7gbZ98zX2w4xUffHSW+YyAvPTiacruDPUcz+HH3WfYez7jwmyl46zWM6hfJxMHRdI8JqvFBbrc7+L+tiaxYd5ySMjtqtYppo+O4+cr4Oq/4XMzhUPhg9RFWbU4AYOb4Ltx+dfdmCQznc4r5dvMpzqRlERsdRrtgP4IDDIT4GwgO8Mbf6FXvlaRDCdm8+cUBUjMrAseA+DDundGnqg9PY6RnFfH+t0fYffQ8ACajntumdKdnbDDvf3uYfReuYgSZvLjjmp6MGRDV7LeeWuP/mNVbE3n764r/J/96Uz8mDu5Iud3B65//yk97UgC4aVJX/ji5m8tvrX2zJYH3vjkMwKRBUQzrrNCzRw+n2iYj18Ld/289DgXe/Nt4OoT7tVS5LtGWPpec+fyWMNMEbelN05zqahdFUUj/6HFK007i13c8odfMdWGVruHseyavsIQ7nvkBu0Nh8tCO7Dp8nvyi0qrHu8cEMWlwNCP7RTYolGTlWXn3m0PsOHQOgJAAA3Ou733J31DL7Q5e+3R/1XpRd13Xkz+M6VzvczmjOf4t2crtfLXxNJ/+eBJbuQO9Vs2sK+O5fmxntE5cPbKU2Pjsx5N8syWBcruCRq3impGxzLoyHt8L/YIURWHPsQzeW3WYczkVV8W6xwQx5/rexEUFNKr+Wmtp4f9jth1I54Xle1AUuHVKN26aGF/1mKIorPj+OJ+uPwnAhEEduP+Gfk61ZXNRFIXPfjrJJ2uPA3D92M7cND6G48ePN6ptFi7bxa4j57lmZCfmXN+nJUp2mbb0ueTM57eMZhKtRqVSETzxTwAUHthIaUayS+vxBIF+3gzuWdFn4fudZ8gvKiXAz4sZ4zrz5t/Gs/iBUUwa0rFBQQYgNNDA438azBN3DSEsyIfsfCvPfbCbZ9/fRWaupcb+JWXlPPfBbjbuS0WtVjHv5v7NHmSai06r4aZJ8bz+yDj6dgmhrNzBx2uO8dclmziaVH+/CodD4cfdZ5iz6Ce+3HiacrvCgG5hLH1kHH+e1qsqyEDFe3lwj3a8/ug4bpvSHS+9hmPJucx/ZTNvfnGAgmL3X/X8UEI2L63Yh6LA1cNjuHFC12qPq1Qqbr2qO3Nn9kWtgp/2pPDs+7tafSJHRVH4eM2xqiBzy+Ru3HFNjyZdJbpmZCeg4jV5ysSU4tKkz4xoVd5R8Ri7D6f42HZyf/yQdrc86fJL1+7upoldST5XQHS4H5MGRzOwe3iTfzse1KMdvTuH8NmPJ/l602l2Hz3PgdNZzJoUzx/GxKHVqCmylPHM+7s4lpyLXqvmsdmDGOyGnUF/LyLUl2fnDGfTL6m8981hzp4v5LHXtzJ5aEf+NLVHrR2EjyXl8s6qg5xONVecI8TIn6f14oru4Zd8f+p1Gm6c2JVxAzvwweoj/PxrGmt3JLP1QBq3TunO5KExbjliJvlcAc8t20W53cGw3u25+/o+db7Oq4bFEOTvzeLle/nlRCZ/f3MbT/55KEGmlu/E73AovLvqEKu3JQFw57U9uX5s08N03y6hRIb6kpZVxMZ9qUwd0anJ5xSuJVdmRKsLGn8raLRYkw9hPf2Lq8txe3FRAbzz94n8884hDOnVvtku83vrtdx+dQ9enT+WnrHBlJbZ+ei7o/x1ySZ2HEpnwRtbOZaci9Gg45k5wz0iyFRSqVSMG9iB/zw2gUmDo4GKK1v3Lt7A5l9Sq+Yayc638tIn+/jb6z9zOtWMwUvLndf25PVHxzOoR7sGB+3QQAN/u+0K/t+9I4hpb6LQYuM/Xx5k/r83cyTR+dE2LSkzz8JT7+6guKScHp2CePiPA+sNXIN7tOP/3TsCf189iWlmHn1tS4uvv2V3KLz22X5Wb0tCpYL7ZvRpliADFe+Pyqsz321r3Izowr1ImBGtThcQjv+gqQDk/PQRir3cxRVd3qLbmXj+vhE8NKs/JqOes+cL+X8f7uHM+UKCTF48f98IesY61wncXZiMeh68qT/P3zeCqDBf8gtLeWnFPp58Zwcr1h3nnhd+YvP+VFSqitFZb/99AteP7YxO27j/Gnt3DuGVeWO4+w+9MRp0JKabWfDGVl5esc8tJgkstJTx1Ls7yDGX0CHcj3/dOQSveobVV+oaHciLD4ymfYiRzDwrj73+c4Nu3zWGrdzBS5/s5ac9KahV8NCsAUwZ3rxXT8Zf0QGDl4aUjCIOns5u1nOL1idhRrhEwIgZqH1M2HLSKNj/o6vLueypVComDIrmrQUTmDy0Ygh4+xAjL9w/ik4R/i6urul6xYXw2sNjufWqbui0avafzGLl+hOUltnpHhPEkr+O4cGb+hPo1/RbJxqNmmtHxfL2gglcOaQjKhVs+iWVu5//iSff2cHnP53k+Jlcylt5rapSm51n399FSkYRwf7ePP2XYU7PydM+xMiLD4wiPjqQQouNf761ne0Hm3cR2TKbnec/2s3WA+loNSoeu30Q46/o0KzPAeDjrWPcwIrzfnfhNpbwXNJnRriExttI4Kgbyfn+PfJ+/hS/XqNQezd+GK1oHn4+eu6/oR83TYzH31df72R4nqSyg/CofpG8+81hzmUXcfOV3Rjdv/nmpLmYv68XD9zYj6uGdeTtrw9x4kwev5zI5JcTFUO6DV4auncKpndcCL3jgukcFeDUnD3OsDsUXvpkb9Vtw6f/MozQQEOjzuXv68XCe4fz4vJ97D56nkUf7+Ev03pz7ajYJtdpLS1n4bJdHDydjV6r5vE7BjOwm3Mzjjtj6ohOrNmezK7D58jMsxAW6Nmjfy5nEmaEy5j6T6Jg71psOWnkbf+K4PG3ubokcUFjP+g8QUSoL0/+eWirPV+XDoG8+MAoks8VcCghm8MJORxOyKbQYuOX45lVs+4avDT0qAw3nUOIi2yeK2KKovDWVwfZefg8Oq2af94xmI5OTpj4e956LY//aRBvfX2IdTuSeWfVIbLyrfxpao9Gzy5dZLXx9Ls7OH4mD4OXhn/dNZTecSFNqrM+0e1M9OkcwsHT2azbkcztV/do0ecTLUfCjHAZlUZL0ITbyfjsecy7V2MacKXT6z4J4QlUKhWdIvzpFOHPdaPicDgUzpwv4NDp7KqAU2S1se94ZtVkfAYvLfHR/oQYbZTrc+gRp8WvEUs1fPrjSdbtSEalgkf+OJBezRQQNBo1983oQ2iAgeVrj/H1ptNs3JdChzA/IsN8iQz1JSqs4is00OeSnYzNRaU88c4OEtPMF64cDSW+Y+tMqnnNyE4cPJ3N9zvPMGtSfJu6Gnk5kTAjXMqn80AMMb2xJh8id+MKwq+f7+qShGhxavVF4WZ09XBz8HQ2hxNzKLba+PVURQfbH3+tGPUXGmggNsKf2MjfvkIDDHXeJvt+5xlWrKuYn2XO9X0Y3ieiWV+HSqXixoldCQnw5o3PD5BfWEp+YSmHEqp3qNVp1USEGIkM8yUqzK9a0LGWlvOvt3eQklGIv6+eZ+cMb9V+WoN7tCMkwEB2vpWtB9JbpH+OaHkSZoRLqVQqgib+ibT3HqH46DZKBk3FOyq+/gOFaEN+H27sDoUz5wrYdyydPYdTyC2CjDwrWRe+dh05X3Wsn4+OThcCTlykP50i/YkK9WXfiUze/PIAADdM6NKic6mMvyKaob3ak5pZRGpmIamZRaRlFZGaWUR6VjG2cgdnzhdy5nwhcK7asVqNmnK7g2B/b56dM7zVlxfQaNRcPTyGj9cc47ttiRJmnJSdb+Xg6SyG947Au4GTd7YECTPC5bzCY/DtM46igxvIWf8B7f/4lKyqLS5rGrWK2Eh/2gXqiA200L17dxSVjqR0M4lpZhLSzCSlmzl7vpBCi42DF67oVNJr1TiUiknnJgzqwG1Turd4zT7eOrpGB9I1OrDadrtDISvPciHoVIacQtIyi8grLKXc7iA8yIeF9wxv0lpaTXHlkI789/sTnDybz8mzeTVeg6gpLauILzecYuO+FMrtCjnmEm743SzSrUnCjHALQWNvpvjYNkrTT5Hyn/sJHHUjfn3Ho9LIW1QIAKNBR6+4kGp9Xmzlds6cLyQxzUzShZCTfM6MtdQOwMBuYdx/Qz+XzrKtUatoF2ykXbCRK7pX7xNXbLWRmWchKsyv0XP7NAd/Xy9G9Ytg475UvtuWJGHmEhJS8/l8wym2H0yncq7BnrHBjB3g2ita8kkh3ILWL4jwGY+SvfYdys2ZZK99G/OubwkcewvGbsPcZskDu7UI885VWE7vw6/fJEwDJ6NSS4dB4Ro6rYbOUQF0vmhxS4dD4VxOMRm5FnrHhbhkYciGMhp0dDK4xzxG14yMZeO+VLbsT+POa3vi7+vl6pLchqIoHEnM4fOfTlVNLQAwqEc4N4zvSvdOrdNZ+1IkzAi34RPXnw73vEbB/h/I2/oFttxzZH71Ml7t4wgadyuGTq5b3dZhK6Vgzxryd3yNo6RileScH96nYP8PhFx5F4aY5l+VXYjGUKtVRIZWjCYSDdc1OpAuHQI4lZLPD7vOuPSWibuoXB3+i59OcSw5FwC1Ckb1i2LmhC7ENHGIf3OSMCPcikqrw3/QVPz6jCd/17eYd31L6bkEzv33aQyd+hI07la82jd9cq6GUuzlFB7YQN7Pn2EvygNAFxqNb7dhmPeuwZaVwrkVT2HsNpSgCbPRBYS1Wm1CiOZ1zchO/Pt/+1m7I5npYzu32CSG7s5ud/DzgXS+3HCK5HMFQMWItImDopk+rrPL+jZdioQZ4ZbUXgaCRt+E/8CryNv6BQW//IA16QBpSQcw9hhB0Jib0QW1b7HnVxQHxcd2kLvpv5TnVYwc0fqHEThmFr49R6JSazANupq8LZ9SsG8dxcd3Yjn9C/5DpxEw/HrUOrlELYSnGdk3kve/PUJWnpXdRzMY1rvp/8fkmK2cOJOHv68XgX5eBJq8MTTDqB9buZ3zORbO5xRzLruYcznFnM+xkJ5VSF5BCf6+OQT4eePv64XJqMff1wt/Xz0mY8Wf/kYvTL4V2yvX5yqz2flpz1m+2nSa8zkWoGK+o6uHx3Dd6LhWWSm9sSTMCLemMfoTMvku/AdPJW/LpxQd/pnio9soPr4TU7+JBIy6Aa1v83XWUxQFa+Kv5G5cQVlGUlUNASNmYuo/CZVW91ttBl9CJt+Fqf8ksn94n5Izh8nf+jmFBzcSPHG2W/X1EULUT6/TMHloRz7/6RTfbUtscpg5eDqLhct2Yy2tvpiut15DoMm7KtwEVX7v502gyYsgkzcBfl7otBrO5xRXBZbzOZaq4JJjtnKpxb6tuVbO5zZscVNvvQaTrxclpeUUFJcBFYu0Xjc6lqnDOzm9hpcrSJgRHkEX2I6waX/Ff+g0cjd+gjVhPwW/fE/hoU34D76GgKHTmry2U0naSXI3fkLJmSMAqPQGAoZOw3/INaj1dU/vrw+Lpv0fn6L4xE5y139IeUE2mV+9jHd0T4KvvBOv8Jgm1SWEaD1XDYvhyw2nOHAqm5SMwkbPe7PtQDovrdhXNfRcrVaRV1BCSZmdkjJ7RSjJLm5Srd56De1DKkaKtQ820i7ESKCvhtzMNMLbd6C0XIW5uIyColLMxWWYi0opKCrDXFyKuaiMguJSyu1KRU25FVdiQgIMTB/bmUlDovHWe05E8JxKhaBiTpr2s/6J9cwRcjcspzT9FPnbvsS86//Q+oeiNYWg8QtGa6r8Cqn40y+4zrBTlnWW3E3/w3JyNwAqjQ7TFVcRMHw6Gp+GdXBTqVT4dhuGT9wAzDu+IX/H15ScPULa+49iGnAlgaNnofFp3cnAhBDOCwv0YXDPduw8fJ7vtiVxz3TnBx58ty2Jt78+iKLAsN7teeSPA6uWSbCWlpNXUEJeYSm5BSXkFZaQV1DxfX7hb3+ai0tRFPD31VeFlerBxYcAX68aV38tFgvHyjLpHhOIj8+lF85UFAVLSTnm4oqQYyt30C0myKXD5BtLwozwSIaOPYn40/NYTuwmd9MKbDlpVV91UekNv4Ucv2A0phDK8zMpOrwFFAeo1Pj1GUvgqBvR+oc2qi61zovA0Tfi23csuT99TPGxHRTsW0fR0a0EjbkZTfzIxr5kIUQruWZELDsPn2fD3rPcfnV3fLx19R9ERThY8f1xPl1/Eqi4ynPP9D7V1qUyeGkxhPoSUc9os3K7g/JyR4vOqqtSqTAadBgNOiJadk3PFidhRngslUqFsdsQfOIHUZ53nvKCnAtf2ZQX5GAvvPB9YQ4OaxFKmRVbdiq27NQa5/KJH0LQ2FvQh0Q1S206/zDCpz+CNfkQ2T8sw5Z1lux176Lduw5N5wlAy8/IKoRonD5dQogK8yU1s4gNe1O4ZmT9IyjtDoX/fHmA73eeAeCWK+OZdWV8o/vNaTVqt54jyN1ImBEeT6VSowuKQBdU9yJ6jrISygtzsFeGncJcyguyUex2TAMm4R3ZMnNKGGJ6E/Xnlyj45QfyNq+kPDsFv5yPKFIVYhh7k0y4J4QbUqlUXDOiE299fYjvtiUxdUSnS4aSMpudl1bsY8ehc6hUcO/0PkwZ3nJrYYmaJMyIy4Ja740+OBKCI1v9uVVqDf5XTMG3xwgyvnuLkpO7KNrxJbaUI4RNexBdQHj9JxFCtKpxV3TgozXHSM0s4uCpbPp2rf3Wc5HVxsJluziSmINWo+aRWwcyoplXJxf1k2tYQrQSjY8J/6vnUtznOlR6A6Wpx0l992EKD25EudQYSyFEq/Px1jHhwgraq7cl1rpPjtnK39/YypHEHHy8tTxz9zCPDTLlhbmY966lLPOMR/5/JFdmhGhFKpWKsoheBF8xlqL171KScoys/3sdy+l9hEyZg8YgI56EcBdXj+jE6m1J7D5ynsxcC2FBv40OSssq4ol3dpCZayHQz4un7x5Gpwj3WGfKWSVpp8j4fBH24nwAdCFR+HYfgbHH8GbrR9jS5MqMEC6g9Q+l/a1PEzj2FlBrKD62g9R352NNPuTq0oQQF3QI96NvlxAcCqzdkVy1/eTZPP629Gcycy20DzGy+IFRHhtkio5u49wnT2AvzkfjFwQaLbbsVPJ+/pTUt/9K6rvzqtbKc2dyZUYIF1GpNQSOmIGhU1+yvnkVW24651Y8hf+Q6wgae0u12YaFEK4xdUQsB05l8/3OM9x8ZTxHEnP4fx/upqTMTucof5788zAC/Dxv+RJFUcj/+XPyfv4UAJ/OAwn7wzxQHBSf2kPx0e1YEg9QlnmWssyz5G3+H/rwTvj2qLhi4259/STMCOFi3hGdibzrRXJ+/JDC/esx7/oWa9JBwv7wV/Sh0a4uT4jLlqIo9A+zMTkwibCyVPa99iPpBXCtVo9faCAjB3dFk7SdYm9fNAY/1AZf1N6+aAy+qDTu+/HqsJWS9d2bFB/ZClDxC9T4W6tGV/r1Hotf77HYrUUUn9hF8bFtWJMOUZaRRG5GErkbP8ErogvGHsPx7T4crcn1k9S4b2sLcRlR670JvfoefDoPJOu7NynLTCZt2WMEjb8N0xVTZI0nIVqB4rBTlnmWkrNHsJ49SknKMRyWAq5WAV5ACYRXLlNkhcJNuyis41wqvQHNhXCjC4kkaPSsFl0ct6HKi/LI+PwFStNPgVpDyJS7MfWbWOu+GoMvpn4TMPWbgN1SQPHxnRQd207JmSOUpp+iNP0UuT9+hFdUN0KvmYs+2HWdnyXMCOFGjF0H4RWxhKz/ewNr4n5yfngfy+l9hF5zP1q/5ltQUwgBir2c0vOJlJw9WvGVcgxHqaXaPiqtHk27zqw5rSez3MgVcb4M6WxCKS3Cbi3EYS3CYS3CXlKEw1qIo6RivSWlzEp5mRXMWZRlJGE5vouAETMIGPYHl91CLs1I5vxnz2MvyEZt8CV8xqMYOvZq0LEaHxOmAVdiGnAl5UX5FB/fSfGxbZScPUZp6nEsp/aiD76uhV9B3STMCOFmtL6BtJv1Dwr2riV3w3Ksib+S+u48gsbegl+fcdKXRohGUhx2StNPYU06REnKUUpST6DYSqvto9Ib8O7QDUN0D7yje+DVPg6VRseIhGzMRaWM6BNxySulisOOo8SCo6QQu7UIu6WAgj1rsCYdIG/LSoqObCHkqrsxxPRu6ZdbTfHJPWSuegXFVoIuOIJ2Nz7e6CtFWt8A/K+4Cv8rrqK8IIfS84kYYvs2c8VO1uTSZxdC1EqlUuE/6GoMMb3J/OZVyjKSyF77Nnk/f4b/4GswDbgStdelF5ETQoCjvIySpEMUn9yN5dQe7MXmao+rDb54d6gILoboHujDY2qdmbt3XMP6hajUGjQ+fmh8/Kj8tcOn80CKj24jZ/0H2HIqOvr79h5D8ITZaIwtOwpKURTMu74l96flgIKhUx/Crn8YjeHSa0M1VOV6d64mYUYIN6YP7UDkn56n4Jfvyd/5LfbCHHI3LCd/25eYBl6FadBUtL4Bri5TCLdiLynGcnoflhO7sSTsR7GVVD2m9vLBENsX7+heGKJ7oAuNQqVq2VlKVCoVvj1HYojrT96m/1Kw73uKDm3GcmofQeNvxa/fhBapQbHbyF77LoUHfgLAb8CVhFx5l1t3Tm6stveKhGhjVFpdxdWYgZMpOvwz+TtWYctJI3/7V5h3/R9+fcfjP/Q6dIHtXF2qEC5TXpBD8ck9WE7uxnrmMDjsVY9p/IIwdh2MT/xgDNE9XfZhrvE2EnLVX/DtPYbste9UXHFd8xaFBzcSOmUO+rCOzfZcDmsh5758g5KzR0ClJnjSnzBdcXWbHUzg9N9oQkICCxcuZP/+/RiNRqZNm8ZDDz2EXq+/5HErVqxgy5YtHDhwgLy8PF599VWuuuqqOvd3OBzMnDmTI0eO1LuvEJcDlUaHX9/x+PYZi+XkHvK3f01p+ikKfvmegv3rMfYYTsCw6/EKj3F1qUK0OEVRUBdlUbT7FHmJ+yk9d7ra47qQKIxdB2OMH4K+fZxbfYh7R3Yl8s4XMO9ZQ97mlZSmniD1/UfxH3ItgSNvQK33btL51UXZ5PzvPezmTFR6A+HXz8en84Bmqt49ORVmzGYzs2fPJiYmhqVLl5KRkcGiRYsoKSnhiSeeuOSx33zzDQBjxoxh1apV9T7XypUrycjIcKY8IS4LKpUaY/wQfLoOpuTsUfK3f401cT/FR7ZSfGQrhrj+BAy/Hu8OPdzqP3BRP7u1EFvuOWw56dhy0ynJTME3+xwFGT1QYvviHd0DjU/bWvJCsZdjtxbhKC3GUXLhq9Ry0ffF2Kttt1RssxTgbymgqOpMKryiulZcgek62KXDhBtCpdYQMORafLsPI/uHZVhO7MK8YxXFR7cRPPnPGLtcUe85FMWBvdhMeUEO9oJsyguyseacx+/gBuzlpWj9w2h3098vi/mqnAozK1eupLi4mNdff52AgAAA7HY7Tz/9NHPmzCE8vO4ZAVeuXIlarSY1NbXeMJObm8urr77K3/72Nx5//HFnShTisqFSqTB07ImhY09KzyeRv+Nrio/twJqwH2vCfrwiu1ZcqYnsikqjqejUqNZUXGJXqRsVdBRFAXs5it2GUm5DqfZ9xc9a/zC37cdjtxZhy03HlpOGo9SCxseE2seExscfjdEfjY+p1s6fzclhK60ILLnnKmrJTceWU/G9w1pz1hIdYMlLwbL/ewD0YdF4R/fEu2NPDB16tHgH0uaiOOzY8s5TlnUWW2YKZVlnK77PPQeKo3HnVGnwjumFX/dh+HS5Aq2v501foDWF0G7m3yg+tZecde9Sbs4i47Pn8YkfQtDYW1Ds5ZQXZF8IKzmUV/2ZRXlhLtjLa5xTDegiuhJx4wKPeX80lVNhZsuWLQwbNqwqyABMmTKFJ598km3btjF9+vQ6j1WrG965acmSJQwZMoQhQ4Y4U54Qly2vdp0Iv34+trHnMe/8lsIDGyhNO0nGFy/UfZD6QsDRaFGpLw47GlRqLYrDXhVQKsNKbf9x1qTCK7IrxnjX/Ias2Mux5WdUXN3ISau6ylGWk4bDUlDv8WqDb7Vwo/HxR230v7DNhFpvuCjElVW0TfnF35f9FvAubHOUl+EotWDLPYe9IPuSz6/xC0YXHFExbNYvhPO5BYSoLJSnn8SWnVo1vXzB3rVAxe0UQ8deeEf3wDu6p8uDpKI4KDdnUZZ5Flt2CmVZKRU156Re4v2jQu3tg9rLiNrbWP17Lx/U3kY0F32v9jZSpqg5nZFP99798PHx/JF9xi5XYOjYi7ytn2Pe9X9YTuzCcmJX/Qeq1Gh8A9CaQtCaQlB8/MkqURE7fuZlE2TAyTCTmJjIjBkzqm0zmUyEhoaSmFj7EunOOnjwIKtXr2b16tXNcj6o+G3SYrHUv6OTrFZrtT9FBWmXurV423iZ8BlzK15XXItl//dYDm9CqeW3fQAcdhSHHcrLUBr7fJVXejS6qis+jqJcStNOUJp2gtwNy9EEReAdNwCvuIHo2sXWOmqjMe3iKLVSnpNCeW469txzlOdVfNnNWdU6f9Yo2TcQbWB71N6+OEoKcVgKKiY7sxaColRNgmbLSXO+PRpI5WVEG9QeTUA7tIEVX5rAdmgCwlHrfusvYbVaKUtORh8Tg7/BgN1ixpZ6grLUY5SlHqc8JxVbdsVXwb51AGgC26OP6o6+Qze8onuhbuGV2JVyG6Vnj1Ca+AvlWWcoz0mrMXdL1evW6tEGR6ENiUIbHFnxfXAUat8Ap0bzKEC51Qo51jb3/4xh6Ay0nQdTsOEjbGknUHn7ojEFo/ENRuMXhNovGI1fxfcav2DUxoBqHZor3zMltnJULfC515oURWnwFWSnwkxBQQEmk6nGdn9/f8xmcy1HOMfhcPD0009zxx13EBUVRWpqapPPCWCz2Th27FiznKs2ycnJLXZuTybtUrdWaZvg3jCmNygKoIDDAYodlcNRcVlfcaBy2H/7XnFUhIAL2xWVGtRalAtXbCr/vHgbtXwAqUoK0GeeQpdxEm3uGey56RTnplO8ZzUOL19sYV0oC+tKeXBHUFf/L6jWdnHYURfnoCnMQlOYiaYoq+L7krr/z1E0Ouw+QTiMQdiNwdiNwTiMwdiNQaCtY7CC4kBls6Iqs6AutaAqK0ZdZqn4uawY1YXvVeWlF9pAC5oLf6o1v/u5oo0UjfaifXXYfQJxGINQ9L+7kmAHsi2QnVRradXbxQ/aD4b2g1GVWdDmpaDNPYM29yyawkzseeew5p3DemgDCirKA6OwhXXBFtoFh28zzQdit6HLTkR3/jj6rNMVbXJxU6rU2H1DsPuG4vANwe4XWvG9IQAu/nCyAqkZQOP7R7bZ/2d6z4Ce9op/Z7+nAAUOKMgCsmo9vK20S32Diyq51dDszz//nOzsbO6+++5mPa9Op6Nz587Nek6oSMDJycnExMRgMBia/fyeStqlbpdP21TcInaUFFOafJDShH2UJh9AXVqEV8p+vFL2o9J74xXTF6+4ASjt4jmTnkF0sB+aoizKc1Ipz06hPDuV8rxzdV5pURsDK37DD2qPJrA92sD2aIPao/YNbPG5Q1pDw94vA6u+c5QUUZZ2suLKzdkjlGenoMur+OLEBjSB7fCKHYB3bH90EV2c6h/kKCuhNOlXSk/toTT5QLWrL2pjIN5drkAfGY82OApNQHiLD3++fP4tOacttcvp06fr3+kCp95tJpOJwsKal6zNZjP+/k27N1dcXMySJUuYN28eNpsNm81GUVFFP/WSkhKKiorw9W3cjIUqlapF76kaDIY2cc+2uUm71O2yaRsfH3yDJsCACSjlNqxnDlfMxHpyD/aiPEpO7qLk5C5QawhQaSi0l9V6GpWXD/rQDuhDO6IPi0YfGo0+LBpNC99CcRcNfr/4+EBQGPQeCYDNnInl5F4sp/diTT6CPe88ln1rsOxbg9rgi0/cAHy6DsIntl+tM0o7SoopPrWX4uM7sCYeQCn/7e9HawrB2H0Yxm5DKzqZuyg8Xjb/lpzUFtrFmUEKToWZ2NjYGn1jCgsLycrKIjY21plT1ZCXl0d+fj5PPvkkTz75ZLXHHnvsMUJCQti2bVuTnkMI4ToqrQ6fuP74xPVHueovlKYnYDm5m+KTu7Flp6Ki4pK6PiTyotDSEV1YB7SmUBlm3gg6/zD8B12N/6CrcZRasCT+iuXUXiyn9+GwFlF0eAtFh7eAWouhY098ulyBIaYXJWmnKD6+E2vSQXD81mlXG9gO3+7DMMYPdbu5W8TlzakwM3r0aN56661qfWfWrVuHWq1mxIgRTSokNDSUjz/+uNq27Oxs5s+fzwMPPMDw4cObdH4hhPtQqdR4R3bBO7ILQeP+SEF6EgknT9B14HCMfjX75YmmU3v54Nt9OL7dh6M47JRcWOnYcnIvttx0rEkHsCYdqHGcLiQKY7ehGLsNQx/WUQKMcEtOhZlZs2axfPly5s6dy5w5c8jIyGDx4sXMmjWr2hwzs2fPJj09nfXr11dtO3ToEGlpaeTm5gJw4EDFP5qgoCAGDx6Ml5dXjaHYlR2AO3fuzIABbXv2QiEuZ9qAcBx+uW1yzRh3pFJrMET3xBDdk+AJsynLSbsQbPZQknoCfWh01S0kfUiUq8sVol5O/c/h7+/PRx99xLPPPsvcuXMxGo3MnDmTefPmVdvP4XBgt1fvsLdixQq+/vrrqp+XLVsGwODBg1m+fHlj6xdCCNFE+uBI9MGRBAyd5tRwWCHchdO/BsXFxfHhhx9ecp/awsmiRYtYtGiRU88VFRXFiRMnnDpGCCFE40mQEZ7I88cuCiGEEOKyJmFGCCGEEB5NwowQQgghPJqEGSGEEEJ4NAkzQgghhPBoEmaEEEII4dEkzAghhBDCo0mYEUIIIYRHkzAjhBBCCI8mYUYIIYQQHk3CjBBCCCE8moQZIYQQQng0CTNCCCGE8GgqRVEUVxfRkn755RcURUGv1zf7uRVFwWazodPpZKXZi0i71E3apnbSLrWTdqmbtE3t2lK7lJWVoVKpGDBgQL37aluhHpdqyb9MlUrVIiHJ00m71E3apnbSLrWTdqmbtE3t2lK7qFSqBn+Gt/krM0IIIYRo26TPjBBCCCE8moQZIYQQQng0CTNCCCGE8GgSZoQQQgjh0STMCCGEEMKjSZgRQgghhEeTMCOEEEIIjyZhRgghhBAeTcKMEEIIITyahBkhhBBCeDQJM0IIIYTwaBJmhBBCCOHRJMw0QkJCAnfccQf9+vVjxIgRLF68mLKyMleX5VJfffUV8fHxNb5eeuklV5fW6s6cOcMTTzzBtGnT6NGjB9dcc02t+33++edMnjyZ3r17c91117Fx48ZWrrR1NaRdbrvttlrfRwkJCS6ouHWsXbuWe++9l9GjR9OvXz+mTZvGF198we/XAL7c3i8NaZfL8f0CsHnzZm699VaGDh1Kr169mDBhAs8//zyFhYXV9tuwYQPXXXcdvXv3ZvLkyXz55ZcuqrjlaV1dgKcxm83Mnj2bmJgYli5dSkZGBosWLaKkpIQnnnjC1eW53HvvvYefn1/Vz+Hh4S6sxjVOnTrF5s2b6du3Lw6Ho8aHEsB3333Hv/71L+655x6GDh3KmjVruP/++1mxYgX9+vVr/aJbQUPaBWDAgAE89thj1bZFRUW1Roku8eGHHxIZGcmCBQsIDAxk+/bt/Otf/+L8+fPcf//9wOX5fmlIu8Dl934ByM/Pp0+fPtx2220EBARw6tQpli5dyqlTp1i2bBkAe/fu5f7772fmzJk8/vjj7Ny5k3/84x8YjUauuuoqF7+CFqAIp7z11ltKv379lLy8vKptK1euVLp3766cP3/edYW52Jdffql07dpVycnJcXUpLme326u+f+yxx5SpU6fW2OfKK69U5s+fX23bTTfdpPz5z39u8fpcpSHtcuuttyp33313a5blcrX9m/nnP/+pDBgwoKrNLsf3S0Pa5XJ8v9Tl008/Vbp27Vr1OXTnnXcqN910U7V95s+fr0yZMsUV5bU4uc3kpC1btjBs2DACAgKqtk2ZMgWHw8G2bdtcV5hwG2r1pf9ZpaSkkJyczJQpU6ptv/rqq9mxY0ebvWVZX7tcroKCgmps6969O0VFRVgslsv2/VJfu4jqKj+TbDYbZWVl7Nq1q8YVmKuvvpqEhARSU1NdUGHLkv9dnJSYmEhsbGy1bSaTidDQUBITE11Ulfu45ppr6N69OxMmTODtt9/Gbre7uiS3U/k+6dSpU7XtcXFx2Gw2UlJSXFGW29i9ezf9+vWjd+/e3HrrrezZs8fVJbW6ffv2ER4ejq+vr7xfLnJxu1S6nN8vdrud0tJSjhw5whtvvMH48eOJiori7Nmz2Gy2Gp9VcXFxAG3ys0r6zDipoKAAk8lUY7u/vz9ms9kFFbmH0NBQHnjgAfr27YtKpWLDhg288sorZGRkSF+i36l8n/z+fVT58+X8Pho0aBDTpk0jJiaGzMxM3n//fe644w6WL19O//79XV1eq9i7dy9r1qyp6gci75cKv28XkPfLuHHjyMjIAGDUqFG8/PLLwOX5npEwI5rFqFGjGDVqVNXPI0eOxMvLi48++oh77rmHsLAwF1YnPMWDDz5Y7eexY8dyzTXX8Oabb/Luu++6qKrWc/78eebNm8eQIUO4/fbbXV2O26irXS7398s777yD1Wrl9OnT/Oc//+Gee+7hgw8+cHVZLiG3mZxkMplqDH+DiqTr7+/vgorc15QpU7Db7Rw7dszVpbiVyvfJ799HBQUF1R4X4OPjw5gxYzhy5IirS2lxBQUF/OUvfyEgIIClS5dW9TG63N8vdbVLbS6n9wtAt27d6N+/PzfccANvvvkmu3btYv369Zfle0bCjJNiY2Nr3G8sLCwkKyurxv1JIWpT+T75/fsoMTERnU5Hhw4dXFGWcKGSkhLmzJlDYWFhjekNLuf3y6XaRVQXHx+PTqfj7NmzREdHo9Ppan3PAG3ys0rCjJNGjx7N9u3bqxIuwLp161Cr1YwYMcKFlbmfNWvWoNFo6NGjh6tLcSsdOnQgJiaGdevWVdu+Zs0ahg0bhl6vd1Fl7sdisbBp0yZ69+7t6lJaTHl5OQ899BCJiYm89957NeZmulzfL/W1S20uh/dLXQ4cOIDNZiMqKgq9Xs+QIUP4/vvvq+2zZs0a4uLi2uQ8PNJnxkmzZs1i+fLlzJ07lzlz5pCRkcHixYuZNWvWZTlBXKW77rqLIUOGEB8fD8BPP/3EZ599xu23305oaKiLq2tdVquVzZs3A5CWlkZRUVHVB9HgwYMJCgrigQce4JFHHiE6OpohQ4awZs0aDh48yCeffOLK0ltUfe1S+aE1adIkIiMjyczM5IMPPiArK4tXX33VlaW3qKeffpqNGzeyYMECioqK+PXXX6se69GjB3q9/rJ8v9TXLgcPHrws3y8A999/P7169SI+Ph5vb2+OHz/O+++/T3x8PBMnTgTg3nvv5fbbb+epp55iypQp7Nq1i9WrV/Pvf//bxdW3DJWi1DENp6hTQkICzz77LPv378doNDJt2jTmzZvXZn9DaoiFCxfy888/c/78eRwOBzExMdxwww3cdtttqFQqV5fXqlJTU5kwYUKtj3388ccMGTIEqJie/t133yU9PZ1OnToxf/58xo0b15qltqr62qVdu3Y888wznDhxgvz8fAwGA/379+f++++nT58+rVxt6xk/fjxpaWm1PvbTTz9V/RZ9ub1f6msXu91+Wb5foKLj75o1azh79iyKohAZGcmkSZO46667qg1b/+mnn3jllVdISkoiIiKCu+++m5kzZ7qw8pYjYUYIIYQQHk36zAghhBDCo0mYEUIIIYRHkzAjhBBCCI8mYUYIIYQQHk3CjBBCCCE8moQZIYQQQng0CTNCCCGE8GgSZoQQQgjh0STMCCGEEMKjSZgRQgghhEeTMCOEEEIIj/b/AeSkqT6vHXmdAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# Number of bootstrap iterations\n",
        "n_bootstrap_iterations = 50\n",
        "\n",
        "# Arrays to store bootstrap C-indices and IBS scores\n",
        "bootstrap_c_indices_deephit = np.zeros(n_bootstrap_iterations)\n",
        "bootstrap_ibs_scores_deep_hit = np.zeros(n_bootstrap_iterations)\n",
        "\n",
        "\n",
        "for i in range(n_bootstrap_iterations):\n",
        "    # Generate a bootstrap sample of indices\n",
        "    bootstrap_indices = resample(np.arange(len(x_train)), replace=True)\n",
        "\n",
        "    # Use these indices to create bootstrap samples\n",
        "    bootstrap_train_x = x_train[bootstrap_indices]\n",
        "    bootstrap_train_y_times = y_train[0][bootstrap_indices]\n",
        "    bootstrap_train_y_events = y_train[1][bootstrap_indices]\n",
        "\n",
        "    # \n",
        "    # Fit the model using the resampled training data with the best hyperparameters\n",
        "    num_nodes = [best_hyperparameters['nodes']] * best_hyperparameters['layers']\n",
        "    batch_norm = best_hyperparameters['batch_norm']\n",
        "    dropout = best_hyperparameters['dropout']\n",
        "\n",
        "    bootstrap_net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
        "\n",
        "    bootstrap_model = DeepHitSingle(bootstrap_net, tt.optim.Adam, alpha=best_hyperparameters['alpha'], sigma=best_hyperparameters['sigma'], duration_index=labtrans.cuts)\n",
        "\n",
        "    batch_size = best_hyperparameters['batch_size']\n",
        "    bootstrap_model.optimizer.set_lr(best_hyperparameters['lr'])\n",
        "\n",
        "    epochs = 100\n",
        "    callbacks = [tt.callbacks.EarlyStopping(patience = best_hyperparameters['patience'])]\n",
        "    log = bootstrap_model.fit(bootstrap_train_x, (bootstrap_train_y_times, bootstrap_train_y_events), batch_size, epochs, callbacks, val_data=val)\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    surv = bootstrap_model.predict_surv_df(x_test)\n",
        "    ev_test = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
        "    c_index_test = ev_test.concordance_td('antolini')\n",
        "    bootstrap_c_indices_deephit[i] = c_index_test\n",
        "\n",
        "    # Calculate the integrated Brier score\n",
        "    ibs = ev_test.integrated_brier_score(time_grid=np.linspace(0, durations_test.max(), 100))\n",
        "    bootstrap_ibs_scores_deep_hit[i] = ibs\n",
        "\n",
        "# Compute the lower and upper percentiles for C-index\n",
        "lower_percentile_c_index = np.percentile(bootstrap_c_indices_deephit, 2.5)\n",
        "upper_percentile_c_index = np.percentile(bootstrap_c_indices_deephit, 97.5)\n",
        "\n",
        "# Compute the lower and upper percentiles for IBS\n",
        "lower_percentile_ibs = np.percentile(bootstrap_ibs_scores_deep_hit, 2.5)\n",
        "upper_percentile_ibs = np.percentile(bootstrap_ibs_scores_deep_hit, 97.5)\n",
        "\n",
        "print('Bootstrap 95% confidence interval for the C-index: ({:.2f}, {:.2f})'.format(lower_percentile_c_index, upper_percentile_c_index))\n",
        "print('Bootstrap 95% confidence interval for the IBS: ({:.2f}, {:.2f})'.format(lower_percentile_ibs, upper_percentile_ibs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUqoz3Ou6_jH",
        "outputId": "a3321145-8514-4e2b-e1b9-7966598572b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2467,\tval_loss: 0.1479\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2121,\tval_loss: 0.1447\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1806,\tval_loss: 0.1419\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1708,\tval_loss: 0.1410\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1735,\tval_loss: 0.1400\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1663,\tval_loss: 0.1422\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1629,\tval_loss: 0.1405\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.1635,\tval_loss: 0.1408\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1651,\tval_loss: 0.1401\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1407\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.1641,\tval_loss: 0.1401\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 0.1653,\tval_loss: 0.1408\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 0.1653,\tval_loss: 0.1412\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.1679,\tval_loss: 0.1410\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.1610,\tval_loss: 0.1404\n",
            "15:\t[0s / 3s],\t\ttrain_loss: 0.1650,\tval_loss: 0.1409\n",
            "16:\t[0s / 3s],\t\ttrain_loss: 0.1648,\tval_loss: 0.1410\n",
            "17:\t[0s / 3s],\t\ttrain_loss: 0.1629,\tval_loss: 0.1409\n",
            "18:\t[0s / 3s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1423\n",
            "19:\t[0s / 3s],\t\ttrain_loss: 0.1673,\tval_loss: 0.1404\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.1621,\tval_loss: 0.1407\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.1654,\tval_loss: 0.1402\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1415\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1637,\tval_loss: 0.1419\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1610,\tval_loss: 0.1417\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1657,\tval_loss: 0.1418\n",
            "26:\t[0s / 4s],\t\ttrain_loss: 0.1665,\tval_loss: 0.1404\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1401\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.1671,\tval_loss: 0.1409\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.1686,\tval_loss: 0.1410\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.1661,\tval_loss: 0.1409\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.1667,\tval_loss: 0.1415\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1417\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1410\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.1653,\tval_loss: 0.1413\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1669,\tval_loss: 0.1402\n",
            "36:\t[0s / 5s],\t\ttrain_loss: 0.1678,\tval_loss: 0.1427\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.1651,\tval_loss: 0.1401\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.1650,\tval_loss: 0.1401\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.1674,\tval_loss: 0.1401\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.1663,\tval_loss: 0.1419\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1643,\tval_loss: 0.1395\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.1665,\tval_loss: 0.1415\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1660,\tval_loss: 0.1406\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1624,\tval_loss: 0.1422\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1661,\tval_loss: 0.1427\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.1677,\tval_loss: 0.1407\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.1705,\tval_loss: 0.1401\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1456\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1641,\tval_loss: 0.1417\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1674,\tval_loss: 0.1412\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1648,\tval_loss: 0.1408\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.1642,\tval_loss: 0.1442\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.1665,\tval_loss: 0.1396\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.1679,\tval_loss: 0.1414\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1407\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.1664,\tval_loss: 0.1435\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.1624,\tval_loss: 0.1418\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1422\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1406\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.1654,\tval_loss: 0.1431\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1413\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1421\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.1658,\tval_loss: 0.1421\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.1675,\tval_loss: 0.1425\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1427\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1617,\tval_loss: 0.1424\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1419\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1655,\tval_loss: 0.1426\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1698,\tval_loss: 0.1412\n",
            "70:\t[0s / 9s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1419\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1416\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1438\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.1606,\tval_loss: 0.1424\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1579,\tval_loss: 0.1425\n",
            "75:\t[0s / 10s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1418\n",
            "76:\t[0s / 10s],\t\ttrain_loss: 0.1690,\tval_loss: 0.1431\n",
            "77:\t[0s / 10s],\t\ttrain_loss: 0.1624,\tval_loss: 0.1428\n",
            "78:\t[0s / 11s],\t\ttrain_loss: 0.1661,\tval_loss: 0.1428\n",
            "79:\t[0s / 11s],\t\ttrain_loss: 0.1652,\tval_loss: 0.1431\n",
            "80:\t[0s / 12s],\t\ttrain_loss: 0.1617,\tval_loss: 0.1417\n",
            "81:\t[0s / 12s],\t\ttrain_loss: 0.1617,\tval_loss: 0.1417\n",
            "82:\t[0s / 13s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1438\n",
            "83:\t[0s / 13s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1414\n",
            "84:\t[0s / 14s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1406\n",
            "85:\t[0s / 14s],\t\ttrain_loss: 0.1675,\tval_loss: 0.1420\n",
            "86:\t[0s / 14s],\t\ttrain_loss: 0.1610,\tval_loss: 0.1425\n",
            "87:\t[0s / 15s],\t\ttrain_loss: 0.1690,\tval_loss: 0.1413\n",
            "88:\t[0s / 15s],\t\ttrain_loss: 0.1643,\tval_loss: 0.1453\n",
            "89:\t[0s / 15s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1413\n",
            "90:\t[0s / 15s],\t\ttrain_loss: 0.1607,\tval_loss: 0.1414\n",
            "91:\t[0s / 16s],\t\ttrain_loss: 0.1688,\tval_loss: 0.1422\n",
            "92:\t[0s / 16s],\t\ttrain_loss: 0.1664,\tval_loss: 0.1410\n",
            "93:\t[0s / 16s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1433\n",
            "94:\t[0s / 16s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1423\n",
            "95:\t[0s / 16s],\t\ttrain_loss: 0.1746,\tval_loss: 0.1425\n",
            "96:\t[0s / 16s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1412\n",
            "97:\t[0s / 17s],\t\ttrain_loss: 0.1693,\tval_loss: 0.1412\n",
            "98:\t[0s / 17s],\t\ttrain_loss: 0.1610,\tval_loss: 0.1418\n",
            "99:\t[0s / 17s],\t\ttrain_loss: 0.1660,\tval_loss: 0.1431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2461,\tval_loss: 0.1604\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2071,\tval_loss: 0.1459\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1790,\tval_loss: 0.1415\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1405\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1559,\tval_loss: 0.1409\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1406\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1399\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.1521,\tval_loss: 0.1405\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1565,\tval_loss: 0.1399\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1531,\tval_loss: 0.1410\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1519,\tval_loss: 0.1403\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1404\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1530,\tval_loss: 0.1396\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.1487,\tval_loss: 0.1411\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.1522,\tval_loss: 0.1411\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.1509,\tval_loss: 0.1401\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.1531,\tval_loss: 0.1400\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1410\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1543,\tval_loss: 0.1393\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1499,\tval_loss: 0.1398\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1499,\tval_loss: 0.1399\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1504,\tval_loss: 0.1406\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1391\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1537,\tval_loss: 0.1400\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1497,\tval_loss: 0.1400\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1522,\tval_loss: 0.1402\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1430\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1505,\tval_loss: 0.1409\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1539,\tval_loss: 0.1397\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1399\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1400\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1401\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1404\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1392\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1387\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1579,\tval_loss: 0.1395\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1555,\tval_loss: 0.1401\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1498,\tval_loss: 0.1404\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1514,\tval_loss: 0.1408\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1534,\tval_loss: 0.1397\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1510,\tval_loss: 0.1406\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1505,\tval_loss: 0.1400\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1403\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1392\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1397\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1521,\tval_loss: 0.1394\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.1557,\tval_loss: 0.1394\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.1559,\tval_loss: 0.1395\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1408\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1633,\tval_loss: 0.1395\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1402\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1445\n",
            "52:\t[0s / 7s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1405\n",
            "53:\t[0s / 8s],\t\ttrain_loss: 0.1583,\tval_loss: 0.1410\n",
            "54:\t[1s / 9s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1408\n",
            "55:\t[0s / 9s],\t\ttrain_loss: 0.1656,\tval_loss: 0.1400\n",
            "56:\t[0s / 10s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1405\n",
            "57:\t[0s / 10s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1404\n",
            "58:\t[0s / 10s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1437\n",
            "59:\t[0s / 11s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1402\n",
            "60:\t[0s / 11s],\t\ttrain_loss: 0.1603,\tval_loss: 0.1415\n",
            "61:\t[0s / 11s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1408\n",
            "62:\t[0s / 12s],\t\ttrain_loss: 0.1570,\tval_loss: 0.1405\n",
            "63:\t[0s / 12s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1405\n",
            "64:\t[0s / 12s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1405\n",
            "65:\t[0s / 12s],\t\ttrain_loss: 0.1541,\tval_loss: 0.1400\n",
            "66:\t[0s / 13s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1414\n",
            "67:\t[0s / 13s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1401\n",
            "68:\t[0s / 13s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1406\n",
            "69:\t[0s / 13s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1412\n",
            "70:\t[0s / 13s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1401\n",
            "71:\t[0s / 13s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1398\n",
            "72:\t[0s / 14s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1405\n",
            "73:\t[0s / 14s],\t\ttrain_loss: 0.1562,\tval_loss: 0.1411\n",
            "74:\t[0s / 14s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1393\n",
            "75:\t[0s / 14s],\t\ttrain_loss: 0.1583,\tval_loss: 0.1400\n",
            "76:\t[0s / 14s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1390\n",
            "77:\t[0s / 14s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1405\n",
            "78:\t[0s / 15s],\t\ttrain_loss: 0.1526,\tval_loss: 0.1416\n",
            "79:\t[0s / 16s],\t\ttrain_loss: 0.1531,\tval_loss: 0.1397\n",
            "80:\t[0s / 16s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1393\n",
            "81:\t[0s / 16s],\t\ttrain_loss: 0.1548,\tval_loss: 0.1408\n",
            "82:\t[0s / 16s],\t\ttrain_loss: 0.1577,\tval_loss: 0.1389\n",
            "83:\t[0s / 16s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1393\n",
            "84:\t[0s / 17s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1403\n",
            "85:\t[0s / 17s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1402\n",
            "86:\t[0s / 17s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1401\n",
            "87:\t[0s / 17s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1405\n",
            "88:\t[0s / 17s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1389\n",
            "89:\t[0s / 18s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1418\n",
            "90:\t[0s / 18s],\t\ttrain_loss: 0.1510,\tval_loss: 0.1397\n",
            "91:\t[0s / 18s],\t\ttrain_loss: 0.1551,\tval_loss: 0.1389\n",
            "92:\t[0s / 18s],\t\ttrain_loss: 0.1557,\tval_loss: 0.1391\n",
            "93:\t[0s / 18s],\t\ttrain_loss: 0.1555,\tval_loss: 0.1396\n",
            "94:\t[0s / 18s],\t\ttrain_loss: 0.1499,\tval_loss: 0.1399\n",
            "95:\t[0s / 19s],\t\ttrain_loss: 0.1492,\tval_loss: 0.1394\n",
            "96:\t[0s / 19s],\t\ttrain_loss: 0.1516,\tval_loss: 0.1406\n",
            "97:\t[0s / 19s],\t\ttrain_loss: 0.1471,\tval_loss: 0.1408\n",
            "98:\t[0s / 19s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1402\n",
            "99:\t[0s / 19s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2590,\tval_loss: 0.1491\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2067,\tval_loss: 0.1453\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1807,\tval_loss: 0.1413\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1703,\tval_loss: 0.1412\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1653,\tval_loss: 0.1401\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1408\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1408\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1412\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1405\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1660,\tval_loss: 0.1408\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1409\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1401\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1398\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1621,\tval_loss: 0.1411\n",
            "14:\t[0s / 3s],\t\ttrain_loss: 0.1678,\tval_loss: 0.1403\n",
            "15:\t[0s / 3s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1409\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1636,\tval_loss: 0.1415\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1395\n",
            "18:\t[0s / 4s],\t\ttrain_loss: 0.1674,\tval_loss: 0.1411\n",
            "19:\t[0s / 4s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1418\n",
            "20:\t[0s / 5s],\t\ttrain_loss: 0.1661,\tval_loss: 0.1446\n",
            "21:\t[0s / 5s],\t\ttrain_loss: 0.1662,\tval_loss: 0.1403\n",
            "22:\t[0s / 5s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1422\n",
            "23:\t[0s / 5s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1420\n",
            "24:\t[0s / 5s],\t\ttrain_loss: 0.1635,\tval_loss: 0.1413\n",
            "25:\t[0s / 5s],\t\ttrain_loss: 0.1688,\tval_loss: 0.1401\n",
            "26:\t[0s / 6s],\t\ttrain_loss: 0.1690,\tval_loss: 0.1403\n",
            "27:\t[0s / 6s],\t\ttrain_loss: 0.1661,\tval_loss: 0.1407\n",
            "28:\t[0s / 6s],\t\ttrain_loss: 0.1660,\tval_loss: 0.1416\n",
            "29:\t[0s / 6s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1406\n",
            "30:\t[0s / 6s],\t\ttrain_loss: 0.1693,\tval_loss: 0.1407\n",
            "31:\t[0s / 6s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1404\n",
            "32:\t[0s / 7s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1409\n",
            "33:\t[0s / 7s],\t\ttrain_loss: 0.1684,\tval_loss: 0.1407\n",
            "34:\t[0s / 7s],\t\ttrain_loss: 0.1695,\tval_loss: 0.1405\n",
            "35:\t[0s / 7s],\t\ttrain_loss: 0.1687,\tval_loss: 0.1406\n",
            "36:\t[0s / 7s],\t\ttrain_loss: 0.1759,\tval_loss: 0.1421\n",
            "37:\t[0s / 7s],\t\ttrain_loss: 0.1675,\tval_loss: 0.1417\n",
            "38:\t[0s / 7s],\t\ttrain_loss: 0.1730,\tval_loss: 0.1391\n",
            "39:\t[0s / 7s],\t\ttrain_loss: 0.1687,\tval_loss: 0.1416\n",
            "40:\t[0s / 8s],\t\ttrain_loss: 0.1648,\tval_loss: 0.1408\n",
            "41:\t[0s / 8s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1411\n",
            "42:\t[0s / 8s],\t\ttrain_loss: 0.1660,\tval_loss: 0.1408\n",
            "43:\t[0s / 8s],\t\ttrain_loss: 0.1642,\tval_loss: 0.1409\n",
            "44:\t[0s / 8s],\t\ttrain_loss: 0.1660,\tval_loss: 0.1394\n",
            "45:\t[0s / 8s],\t\ttrain_loss: 0.1671,\tval_loss: 0.1418\n",
            "46:\t[0s / 8s],\t\ttrain_loss: 0.1678,\tval_loss: 0.1405\n",
            "47:\t[0s / 8s],\t\ttrain_loss: 0.1685,\tval_loss: 0.1396\n",
            "48:\t[0s / 8s],\t\ttrain_loss: 0.1639,\tval_loss: 0.1408\n",
            "49:\t[0s / 8s],\t\ttrain_loss: 0.1642,\tval_loss: 0.1404\n",
            "50:\t[0s / 9s],\t\ttrain_loss: 0.1682,\tval_loss: 0.1414\n",
            "51:\t[0s / 9s],\t\ttrain_loss: 0.1717,\tval_loss: 0.1402\n",
            "52:\t[0s / 9s],\t\ttrain_loss: 0.1684,\tval_loss: 0.1422\n",
            "53:\t[0s / 9s],\t\ttrain_loss: 0.1694,\tval_loss: 0.1409\n",
            "54:\t[0s / 9s],\t\ttrain_loss: 0.1704,\tval_loss: 0.1421\n",
            "55:\t[0s / 9s],\t\ttrain_loss: 0.1658,\tval_loss: 0.1443\n",
            "56:\t[0s / 9s],\t\ttrain_loss: 0.1685,\tval_loss: 0.1429\n",
            "57:\t[0s / 9s],\t\ttrain_loss: 0.1683,\tval_loss: 0.1431\n",
            "58:\t[0s / 9s],\t\ttrain_loss: 0.1644,\tval_loss: 0.1403\n",
            "59:\t[0s / 10s],\t\ttrain_loss: 0.1655,\tval_loss: 0.1422\n",
            "60:\t[0s / 10s],\t\ttrain_loss: 0.1691,\tval_loss: 0.1410\n",
            "61:\t[0s / 10s],\t\ttrain_loss: 0.1694,\tval_loss: 0.1403\n",
            "62:\t[0s / 10s],\t\ttrain_loss: 0.1659,\tval_loss: 0.1398\n",
            "63:\t[0s / 10s],\t\ttrain_loss: 0.1723,\tval_loss: 0.1419\n",
            "64:\t[0s / 10s],\t\ttrain_loss: 0.1698,\tval_loss: 0.1402\n",
            "65:\t[0s / 10s],\t\ttrain_loss: 0.1697,\tval_loss: 0.1416\n",
            "66:\t[0s / 10s],\t\ttrain_loss: 0.1718,\tval_loss: 0.1407\n",
            "67:\t[0s / 10s],\t\ttrain_loss: 0.1707,\tval_loss: 0.1415\n",
            "68:\t[0s / 10s],\t\ttrain_loss: 0.1715,\tval_loss: 0.1416\n",
            "69:\t[0s / 11s],\t\ttrain_loss: 0.1709,\tval_loss: 0.1426\n",
            "70:\t[0s / 11s],\t\ttrain_loss: 0.1680,\tval_loss: 0.1446\n",
            "71:\t[0s / 11s],\t\ttrain_loss: 0.1730,\tval_loss: 0.1427\n",
            "72:\t[0s / 11s],\t\ttrain_loss: 0.1680,\tval_loss: 0.1439\n",
            "73:\t[0s / 11s],\t\ttrain_loss: 0.1770,\tval_loss: 0.1447\n",
            "74:\t[0s / 11s],\t\ttrain_loss: 0.1827,\tval_loss: 0.1418\n",
            "75:\t[0s / 11s],\t\ttrain_loss: 0.1836,\tval_loss: 0.1434\n",
            "76:\t[0s / 11s],\t\ttrain_loss: 0.1773,\tval_loss: 0.1415\n",
            "77:\t[0s / 11s],\t\ttrain_loss: 0.1734,\tval_loss: 0.1429\n",
            "78:\t[0s / 12s],\t\ttrain_loss: 0.1707,\tval_loss: 0.1429\n",
            "79:\t[0s / 12s],\t\ttrain_loss: 0.1711,\tval_loss: 0.1429\n",
            "80:\t[0s / 12s],\t\ttrain_loss: 0.1778,\tval_loss: 0.1414\n",
            "81:\t[0s / 12s],\t\ttrain_loss: 0.1717,\tval_loss: 0.1409\n",
            "82:\t[0s / 12s],\t\ttrain_loss: 0.1793,\tval_loss: 0.1440\n",
            "83:\t[0s / 12s],\t\ttrain_loss: 0.1887,\tval_loss: 0.1437\n",
            "84:\t[0s / 12s],\t\ttrain_loss: 0.1774,\tval_loss: 0.1437\n",
            "85:\t[0s / 12s],\t\ttrain_loss: 0.1853,\tval_loss: 0.1445\n",
            "86:\t[0s / 12s],\t\ttrain_loss: 0.1838,\tval_loss: 0.1438\n",
            "87:\t[0s / 13s],\t\ttrain_loss: 0.1897,\tval_loss: 0.1416\n",
            "88:\t[0s / 13s],\t\ttrain_loss: 0.1781,\tval_loss: 0.1447\n",
            "89:\t[0s / 13s],\t\ttrain_loss: 0.1775,\tval_loss: 0.1469\n",
            "90:\t[0s / 13s],\t\ttrain_loss: 0.1857,\tval_loss: 0.1425\n",
            "91:\t[0s / 13s],\t\ttrain_loss: 0.1749,\tval_loss: 0.1424\n",
            "92:\t[0s / 13s],\t\ttrain_loss: 0.1716,\tval_loss: 0.1434\n",
            "93:\t[0s / 13s],\t\ttrain_loss: 0.1683,\tval_loss: 0.1414\n",
            "94:\t[0s / 13s],\t\ttrain_loss: 0.1698,\tval_loss: 0.1410\n",
            "95:\t[0s / 13s],\t\ttrain_loss: 0.1788,\tval_loss: 0.1423\n",
            "96:\t[0s / 14s],\t\ttrain_loss: 0.1745,\tval_loss: 0.1427\n",
            "97:\t[0s / 14s],\t\ttrain_loss: 0.1710,\tval_loss: 0.1414\n",
            "98:\t[0s / 14s],\t\ttrain_loss: 0.1726,\tval_loss: 0.1405\n",
            "99:\t[0s / 14s],\t\ttrain_loss: 0.1731,\tval_loss: 0.1428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2395,\tval_loss: 0.1532\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2051,\tval_loss: 0.1464\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1793,\tval_loss: 0.1448\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1681,\tval_loss: 0.1417\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1621,\tval_loss: 0.1417\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1664,\tval_loss: 0.1403\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1654,\tval_loss: 0.1411\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1413\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1413\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1583,\tval_loss: 0.1415\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1403\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1418\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1413\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1554,\tval_loss: 0.1425\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1408\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1406\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1422\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1621,\tval_loss: 0.1401\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1419\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1419\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1398\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1403\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1667,\tval_loss: 0.1411\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1644,\tval_loss: 0.1408\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1635,\tval_loss: 0.1411\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1417\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1605,\tval_loss: 0.1405\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1410\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1419\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1402\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1648,\tval_loss: 0.1420\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1416\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1406\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1401\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1433\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1607,\tval_loss: 0.1409\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1621,\tval_loss: 0.1413\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1585,\tval_loss: 0.1403\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1413\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1417\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.1610,\tval_loss: 0.1404\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1421\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.1584,\tval_loss: 0.1400\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1411\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1606,\tval_loss: 0.1402\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1654,\tval_loss: 0.1426\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.1643,\tval_loss: 0.1414\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1387\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1417\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1633,\tval_loss: 0.1422\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1414\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1678,\tval_loss: 0.1432\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.1672,\tval_loss: 0.1420\n",
            "53:\t[0s / 7s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1414\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.1610,\tval_loss: 0.1400\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1426\n",
            "56:\t[0s / 8s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1410\n",
            "57:\t[0s / 8s],\t\ttrain_loss: 0.1633,\tval_loss: 0.1402\n",
            "58:\t[0s / 8s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1417\n",
            "59:\t[0s / 8s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1408\n",
            "60:\t[0s / 8s],\t\ttrain_loss: 0.1661,\tval_loss: 0.1414\n",
            "61:\t[0s / 9s],\t\ttrain_loss: 0.1651,\tval_loss: 0.1412\n",
            "62:\t[0s / 9s],\t\ttrain_loss: 0.1699,\tval_loss: 0.1422\n",
            "63:\t[0s / 9s],\t\ttrain_loss: 0.1592,\tval_loss: 0.1427\n",
            "64:\t[0s / 9s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1398\n",
            "65:\t[0s / 9s],\t\ttrain_loss: 0.1635,\tval_loss: 0.1405\n",
            "66:\t[0s / 10s],\t\ttrain_loss: 0.1603,\tval_loss: 0.1412\n",
            "67:\t[0s / 10s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1393\n",
            "68:\t[0s / 10s],\t\ttrain_loss: 0.1605,\tval_loss: 0.1411\n",
            "69:\t[0s / 10s],\t\ttrain_loss: 0.1565,\tval_loss: 0.1397\n",
            "70:\t[0s / 10s],\t\ttrain_loss: 0.1607,\tval_loss: 0.1417\n",
            "71:\t[0s / 10s],\t\ttrain_loss: 0.1605,\tval_loss: 0.1408\n",
            "72:\t[0s / 10s],\t\ttrain_loss: 0.1670,\tval_loss: 0.1414\n",
            "73:\t[0s / 10s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1405\n",
            "74:\t[0s / 10s],\t\ttrain_loss: 0.1597,\tval_loss: 0.1416\n",
            "75:\t[0s / 11s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1412\n",
            "76:\t[0s / 11s],\t\ttrain_loss: 0.1603,\tval_loss: 0.1415\n",
            "77:\t[0s / 11s],\t\ttrain_loss: 0.1580,\tval_loss: 0.1397\n",
            "78:\t[0s / 11s],\t\ttrain_loss: 0.1606,\tval_loss: 0.1414\n",
            "79:\t[0s / 11s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1400\n",
            "80:\t[0s / 11s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1410\n",
            "81:\t[0s / 11s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1416\n",
            "82:\t[0s / 11s],\t\ttrain_loss: 0.1597,\tval_loss: 0.1407\n",
            "83:\t[0s / 11s],\t\ttrain_loss: 0.1651,\tval_loss: 0.1412\n",
            "84:\t[0s / 12s],\t\ttrain_loss: 0.1597,\tval_loss: 0.1407\n",
            "85:\t[0s / 12s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1405\n",
            "86:\t[0s / 12s],\t\ttrain_loss: 0.1705,\tval_loss: 0.1402\n",
            "87:\t[0s / 12s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1439\n",
            "88:\t[0s / 12s],\t\ttrain_loss: 0.1680,\tval_loss: 0.1393\n",
            "89:\t[0s / 12s],\t\ttrain_loss: 0.1661,\tval_loss: 0.1427\n",
            "90:\t[0s / 12s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1411\n",
            "91:\t[0s / 12s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1401\n",
            "92:\t[0s / 12s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1434\n",
            "93:\t[0s / 13s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1438\n",
            "94:\t[0s / 13s],\t\ttrain_loss: 0.1597,\tval_loss: 0.1403\n",
            "95:\t[0s / 13s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1414\n",
            "96:\t[0s / 13s],\t\ttrain_loss: 0.1591,\tval_loss: 0.1421\n",
            "97:\t[0s / 13s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1426\n",
            "98:\t[0s / 13s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1417\n",
            "99:\t[0s / 13s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2668,\tval_loss: 0.1613\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2123,\tval_loss: 0.1542\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1823,\tval_loss: 0.1414\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1701,\tval_loss: 0.1434\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1651,\tval_loss: 0.1414\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1433\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1651,\tval_loss: 0.1412\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1419\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1421\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1699,\tval_loss: 0.1425\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1426\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1699,\tval_loss: 0.1411\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1644,\tval_loss: 0.1414\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1617,\tval_loss: 0.1412\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1415\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1643,\tval_loss: 0.1413\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1438\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1663,\tval_loss: 0.1407\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1443\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1642,\tval_loss: 0.1405\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1651,\tval_loss: 0.1422\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1428\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1423\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1677,\tval_loss: 0.1421\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1410\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1678,\tval_loss: 0.1418\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1423\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1654,\tval_loss: 0.1413\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1689,\tval_loss: 0.1408\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1701,\tval_loss: 0.1418\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1753,\tval_loss: 0.1422\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1426\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1760,\tval_loss: 0.1437\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1644,\tval_loss: 0.1420\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1669,\tval_loss: 0.1416\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1664,\tval_loss: 0.1414\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1410\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1672,\tval_loss: 0.1428\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1669,\tval_loss: 0.1418\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1764,\tval_loss: 0.1428\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1641,\tval_loss: 0.1451\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1653,\tval_loss: 0.1448\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1687,\tval_loss: 0.1413\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1445\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1668,\tval_loss: 0.1413\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1676,\tval_loss: 0.1428\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1681,\tval_loss: 0.1414\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1415\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1423\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1415\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1665,\tval_loss: 0.1430\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1666,\tval_loss: 0.1426\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1419\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.1692,\tval_loss: 0.1417\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.1653,\tval_loss: 0.1412\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.1677,\tval_loss: 0.1417\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.1674,\tval_loss: 0.1407\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.1666,\tval_loss: 0.1418\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.1706,\tval_loss: 0.1413\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1682,\tval_loss: 0.1416\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.1693,\tval_loss: 0.1423\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.1661,\tval_loss: 0.1420\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.1686,\tval_loss: 0.1435\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.1633,\tval_loss: 0.1433\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.1633,\tval_loss: 0.1417\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.1679,\tval_loss: 0.1432\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1657,\tval_loss: 0.1442\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1681,\tval_loss: 0.1417\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1680,\tval_loss: 0.1435\n",
            "69:\t[0s / 9s],\t\ttrain_loss: 0.1697,\tval_loss: 0.1451\n",
            "70:\t[0s / 9s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1410\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.1663,\tval_loss: 0.1436\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1418\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.1674,\tval_loss: 0.1402\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1667,\tval_loss: 0.1436\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1696,\tval_loss: 0.1436\n",
            "76:\t[0s / 10s],\t\ttrain_loss: 0.1695,\tval_loss: 0.1416\n",
            "77:\t[0s / 10s],\t\ttrain_loss: 0.1744,\tval_loss: 0.1449\n",
            "78:\t[0s / 10s],\t\ttrain_loss: 0.1650,\tval_loss: 0.1415\n",
            "79:\t[0s / 10s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1456\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.1690,\tval_loss: 0.1424\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.1666,\tval_loss: 0.1405\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.1662,\tval_loss: 0.1416\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.1666,\tval_loss: 0.1428\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1428\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.1689,\tval_loss: 0.1416\n",
            "86:\t[0s / 11s],\t\ttrain_loss: 0.1769,\tval_loss: 0.1429\n",
            "87:\t[0s / 11s],\t\ttrain_loss: 0.1743,\tval_loss: 0.1426\n",
            "88:\t[0s / 11s],\t\ttrain_loss: 0.1732,\tval_loss: 0.1428\n",
            "89:\t[0s / 11s],\t\ttrain_loss: 0.1795,\tval_loss: 0.1436\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.1769,\tval_loss: 0.1454\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.1745,\tval_loss: 0.1435\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.1779,\tval_loss: 0.1426\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.1710,\tval_loss: 0.1437\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.1711,\tval_loss: 0.1463\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.1744,\tval_loss: 0.1462\n",
            "96:\t[0s / 12s],\t\ttrain_loss: 0.1691,\tval_loss: 0.1463\n",
            "97:\t[0s / 12s],\t\ttrain_loss: 0.1670,\tval_loss: 0.1444\n",
            "98:\t[0s / 12s],\t\ttrain_loss: 0.1688,\tval_loss: 0.1456\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2380,\tval_loss: 0.1617\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2120,\tval_loss: 0.1418\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1706,\tval_loss: 0.1414\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1427\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1534,\tval_loss: 0.1421\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1510,\tval_loss: 0.1425\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1510,\tval_loss: 0.1412\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1519,\tval_loss: 0.1416\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1480,\tval_loss: 0.1409\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1486,\tval_loss: 0.1424\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1497,\tval_loss: 0.1413\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1504,\tval_loss: 0.1416\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1450,\tval_loss: 0.1440\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1480,\tval_loss: 0.1430\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1498,\tval_loss: 0.1411\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1471,\tval_loss: 0.1420\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1481,\tval_loss: 0.1428\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1471,\tval_loss: 0.1413\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1454,\tval_loss: 0.1425\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1508,\tval_loss: 0.1413\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1432\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1547,\tval_loss: 0.1424\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1438,\tval_loss: 0.1455\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1494,\tval_loss: 0.1433\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1511,\tval_loss: 0.1419\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1472,\tval_loss: 0.1399\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1509,\tval_loss: 0.1405\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1476,\tval_loss: 0.1439\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1503,\tval_loss: 0.1430\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1468,\tval_loss: 0.1402\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1498,\tval_loss: 0.1400\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1444,\tval_loss: 0.1436\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1440\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1427\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1512,\tval_loss: 0.1399\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1430\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1423\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1412\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1510,\tval_loss: 0.1462\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1548,\tval_loss: 0.1410\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1423\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1419\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1539,\tval_loss: 0.1432\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1425\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1430\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1422\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1537,\tval_loss: 0.1469\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1424\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1470,\tval_loss: 0.1404\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1425\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1415\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1398\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1484,\tval_loss: 0.1430\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1530,\tval_loss: 0.1404\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.1539,\tval_loss: 0.1429\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.1484,\tval_loss: 0.1421\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1507,\tval_loss: 0.1417\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1514,\tval_loss: 0.1399\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1489,\tval_loss: 0.1433\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1426\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1448,\tval_loss: 0.1427\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.1490,\tval_loss: 0.1410\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.1446,\tval_loss: 0.1452\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1451\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.1522,\tval_loss: 0.1443\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1406\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.1493,\tval_loss: 0.1415\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1501,\tval_loss: 0.1417\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1488,\tval_loss: 0.1418\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1441\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.1539,\tval_loss: 0.1409\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.1463,\tval_loss: 0.1422\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1419\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.1466,\tval_loss: 0.1440\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.1516,\tval_loss: 0.1427\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.1491,\tval_loss: 0.1415\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1494,\tval_loss: 0.1429\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1518,\tval_loss: 0.1423\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1501,\tval_loss: 0.1413\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.1465,\tval_loss: 0.1420\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.1502,\tval_loss: 0.1408\n",
            "81:\t[0s / 9s],\t\ttrain_loss: 0.1526,\tval_loss: 0.1432\n",
            "82:\t[0s / 9s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1409\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.1500,\tval_loss: 0.1441\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.1497,\tval_loss: 0.1462\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.1570,\tval_loss: 0.1430\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1483,\tval_loss: 0.1418\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1494,\tval_loss: 0.1432\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1502,\tval_loss: 0.1417\n",
            "89:\t[0s / 11s],\t\ttrain_loss: 0.1497,\tval_loss: 0.1421\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.1488,\tval_loss: 0.1417\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.1522,\tval_loss: 0.1413\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.1504,\tval_loss: 0.1451\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.1496,\tval_loss: 0.1422\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1418\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.1490,\tval_loss: 0.1431\n",
            "96:\t[0s / 12s],\t\ttrain_loss: 0.1521,\tval_loss: 0.1418\n",
            "97:\t[0s / 12s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1410\n",
            "98:\t[0s / 12s],\t\ttrain_loss: 0.1508,\tval_loss: 0.1424\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1438\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2703,\tval_loss: 0.1519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2268,\tval_loss: 0.1496\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1947,\tval_loss: 0.1404\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1861,\tval_loss: 0.1414\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1775,\tval_loss: 0.1400\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1784,\tval_loss: 0.1402\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1784,\tval_loss: 0.1397\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1723,\tval_loss: 0.1402\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1720,\tval_loss: 0.1395\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1740,\tval_loss: 0.1401\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1755,\tval_loss: 0.1398\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1766,\tval_loss: 0.1402\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1721,\tval_loss: 0.1406\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1758,\tval_loss: 0.1399\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1718,\tval_loss: 0.1413\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1755,\tval_loss: 0.1401\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1748,\tval_loss: 0.1396\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1780,\tval_loss: 0.1403\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1755,\tval_loss: 0.1406\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1739,\tval_loss: 0.1397\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1774,\tval_loss: 0.1399\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1812,\tval_loss: 0.1410\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1783,\tval_loss: 0.1411\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1797,\tval_loss: 0.1407\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1783,\tval_loss: 0.1403\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1808,\tval_loss: 0.1403\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1788,\tval_loss: 0.1404\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1801,\tval_loss: 0.1408\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1758,\tval_loss: 0.1411\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1784,\tval_loss: 0.1408\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1762,\tval_loss: 0.1411\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1791,\tval_loss: 0.1408\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1786,\tval_loss: 0.1401\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1772,\tval_loss: 0.1401\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1768,\tval_loss: 0.1398\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1757,\tval_loss: 0.1395\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.1798,\tval_loss: 0.1404\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1793,\tval_loss: 0.1391\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1742,\tval_loss: 0.1415\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1743,\tval_loss: 0.1402\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1749,\tval_loss: 0.1404\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1792,\tval_loss: 0.1392\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1780,\tval_loss: 0.1413\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1760,\tval_loss: 0.1401\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1869,\tval_loss: 0.1395\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.1802,\tval_loss: 0.1409\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1759,\tval_loss: 0.1394\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1791,\tval_loss: 0.1405\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1794,\tval_loss: 0.1410\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1767,\tval_loss: 0.1404\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1783,\tval_loss: 0.1397\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1788,\tval_loss: 0.1402\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1782,\tval_loss: 0.1413\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1772,\tval_loss: 0.1412\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.1767,\tval_loss: 0.1422\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.1758,\tval_loss: 0.1392\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1787,\tval_loss: 0.1398\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1759,\tval_loss: 0.1399\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1793,\tval_loss: 0.1398\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1762,\tval_loss: 0.1395\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1785,\tval_loss: 0.1410\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.1786,\tval_loss: 0.1409\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.1789,\tval_loss: 0.1391\n",
            "63:\t[0s / 6s],\t\ttrain_loss: 0.1784,\tval_loss: 0.1398\n",
            "64:\t[0s / 6s],\t\ttrain_loss: 0.1799,\tval_loss: 0.1409\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.1758,\tval_loss: 0.1400\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.1813,\tval_loss: 0.1398\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1800,\tval_loss: 0.1400\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1810,\tval_loss: 0.1394\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.1809,\tval_loss: 0.1419\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.1765,\tval_loss: 0.1401\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.1807,\tval_loss: 0.1397\n",
            "72:\t[0s / 7s],\t\ttrain_loss: 0.1809,\tval_loss: 0.1388\n",
            "73:\t[0s / 7s],\t\ttrain_loss: 0.1755,\tval_loss: 0.1397\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.1755,\tval_loss: 0.1400\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.1805,\tval_loss: 0.1400\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.1793,\tval_loss: 0.1400\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.1770,\tval_loss: 0.1388\n",
            "78:\t[0s / 8s],\t\ttrain_loss: 0.1788,\tval_loss: 0.1404\n",
            "79:\t[0s / 8s],\t\ttrain_loss: 0.1851,\tval_loss: 0.1411\n",
            "80:\t[0s / 8s],\t\ttrain_loss: 0.1770,\tval_loss: 0.1397\n",
            "81:\t[0s / 8s],\t\ttrain_loss: 0.1845,\tval_loss: 0.1394\n",
            "82:\t[0s / 8s],\t\ttrain_loss: 0.1766,\tval_loss: 0.1398\n",
            "83:\t[0s / 9s],\t\ttrain_loss: 0.1783,\tval_loss: 0.1399\n",
            "84:\t[0s / 9s],\t\ttrain_loss: 0.1816,\tval_loss: 0.1423\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.1796,\tval_loss: 0.1400\n",
            "86:\t[0s / 9s],\t\ttrain_loss: 0.1824,\tval_loss: 0.1402\n",
            "87:\t[0s / 9s],\t\ttrain_loss: 0.1853,\tval_loss: 0.1423\n",
            "88:\t[0s / 9s],\t\ttrain_loss: 0.1804,\tval_loss: 0.1423\n",
            "89:\t[0s / 9s],\t\ttrain_loss: 0.1787,\tval_loss: 0.1408\n",
            "90:\t[0s / 9s],\t\ttrain_loss: 0.1826,\tval_loss: 0.1404\n",
            "91:\t[0s / 10s],\t\ttrain_loss: 0.1846,\tval_loss: 0.1411\n",
            "92:\t[0s / 10s],\t\ttrain_loss: 0.1782,\tval_loss: 0.1425\n",
            "93:\t[0s / 10s],\t\ttrain_loss: 0.1777,\tval_loss: 0.1403\n",
            "94:\t[0s / 10s],\t\ttrain_loss: 0.1811,\tval_loss: 0.1415\n",
            "95:\t[0s / 10s],\t\ttrain_loss: 0.1815,\tval_loss: 0.1412\n",
            "96:\t[0s / 10s],\t\ttrain_loss: 0.1781,\tval_loss: 0.1413\n",
            "97:\t[0s / 10s],\t\ttrain_loss: 0.1763,\tval_loss: 0.1422\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.1791,\tval_loss: 0.1419\n",
            "99:\t[0s / 11s],\t\ttrain_loss: 0.1803,\tval_loss: 0.1413\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2321,\tval_loss: 0.1559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2100,\tval_loss: 0.1452\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1846,\tval_loss: 0.1414\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1632,\tval_loss: 0.1410\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1610,\tval_loss: 0.1412\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1582,\tval_loss: 0.1400\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1410\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.1574,\tval_loss: 0.1408\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1563,\tval_loss: 0.1411\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1565,\tval_loss: 0.1412\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1412\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1405\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1563,\tval_loss: 0.1400\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1406\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.1566,\tval_loss: 0.1398\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.1584,\tval_loss: 0.1404\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1414\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1582,\tval_loss: 0.1402\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1607,\tval_loss: 0.1415\n",
            "19:\t[0s / 3s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1406\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.1579,\tval_loss: 0.1402\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.1562,\tval_loss: 0.1405\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.1579,\tval_loss: 0.1417\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1603,\tval_loss: 0.1417\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1582,\tval_loss: 0.1395\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1585,\tval_loss: 0.1420\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1406\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1406\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1416\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1409\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.1566,\tval_loss: 0.1397\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.1566,\tval_loss: 0.1413\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1591,\tval_loss: 0.1409\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1407\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.1570,\tval_loss: 0.1413\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1411\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1580,\tval_loss: 0.1418\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1402\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1397\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1397\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1424\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1409\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1405\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1425\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1597,\tval_loss: 0.1408\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1591,\tval_loss: 0.1428\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1403\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.1587,\tval_loss: 0.1419\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.1579,\tval_loss: 0.1410\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1407\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1400\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1423\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.1582,\tval_loss: 0.1413\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.1591,\tval_loss: 0.1402\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.1557,\tval_loss: 0.1407\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1419\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1404\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1415\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1402\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1416\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.1603,\tval_loss: 0.1414\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.1577,\tval_loss: 0.1423\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1417\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.1617,\tval_loss: 0.1402\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.1551,\tval_loss: 0.1409\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1415\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1562,\tval_loss: 0.1412\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1400\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1418\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1662,\tval_loss: 0.1455\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1413\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.1651,\tval_loss: 0.1413\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.1596,\tval_loss: 0.1450\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1425\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1419\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1565,\tval_loss: 0.1414\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1441\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1447\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1633,\tval_loss: 0.1451\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.1602,\tval_loss: 0.1458\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.1586,\tval_loss: 0.1443\n",
            "81:\t[0s / 9s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1429\n",
            "82:\t[0s / 9s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1446\n",
            "83:\t[0s / 9s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1443\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1418\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1441\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1415\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1596,\tval_loss: 0.1413\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1537,\tval_loss: 0.1429\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.1548,\tval_loss: 0.1429\n",
            "90:\t[0s / 10s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1413\n",
            "91:\t[0s / 10s],\t\ttrain_loss: 0.1530,\tval_loss: 0.1422\n",
            "92:\t[0s / 10s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1411\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2418,\tval_loss: 0.1785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2037,\tval_loss: 0.1549\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1694,\tval_loss: 0.1439\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1636,\tval_loss: 0.1429\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1409\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1405\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1526,\tval_loss: 0.1409\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1554,\tval_loss: 0.1412\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1507,\tval_loss: 0.1404\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1563,\tval_loss: 0.1402\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1547,\tval_loss: 0.1403\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1509,\tval_loss: 0.1398\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1518,\tval_loss: 0.1406\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1509,\tval_loss: 0.1402\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1403\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1510,\tval_loss: 0.1416\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1408\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1404\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1412\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1400\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1557,\tval_loss: 0.1402\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1583,\tval_loss: 0.1438\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1525,\tval_loss: 0.1442\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1410\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1478,\tval_loss: 0.1427\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1522,\tval_loss: 0.1401\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1400\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1403\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1551,\tval_loss: 0.1424\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1407\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1556,\tval_loss: 0.1402\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.1557,\tval_loss: 0.1404\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1411\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1401\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1410\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1412\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1591,\tval_loss: 0.1433\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.1644,\tval_loss: 0.1412\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.1574,\tval_loss: 0.1405\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.1515,\tval_loss: 0.1409\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1425\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1582,\tval_loss: 0.1395\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.1556,\tval_loss: 0.1400\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1400\n",
            "44:\t[0s / 6s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1400\n",
            "45:\t[0s / 6s],\t\ttrain_loss: 0.1567,\tval_loss: 0.1409\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1398\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.1579,\tval_loss: 0.1407\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1416\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1400\n",
            "50:\t[0s / 7s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1433\n",
            "51:\t[0s / 7s],\t\ttrain_loss: 0.1577,\tval_loss: 0.1416\n",
            "52:\t[0s / 7s],\t\ttrain_loss: 0.1597,\tval_loss: 0.1410\n",
            "53:\t[0s / 7s],\t\ttrain_loss: 0.1670,\tval_loss: 0.1417\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1406\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.1683,\tval_loss: 0.1404\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.1629,\tval_loss: 0.1410\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1427\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1411\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1418\n",
            "60:\t[0s / 8s],\t\ttrain_loss: 0.1680,\tval_loss: 0.1412\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.1671,\tval_loss: 0.1431\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1434\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.1675,\tval_loss: 0.1415\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1408\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1407\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1736,\tval_loss: 0.1421\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1583,\tval_loss: 0.1408\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1584,\tval_loss: 0.1427\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1472\n",
            "70:\t[0s / 9s],\t\ttrain_loss: 0.1716,\tval_loss: 0.1438\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1442\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.1632,\tval_loss: 0.1438\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.1686,\tval_loss: 0.1415\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1442\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1669,\tval_loss: 0.1409\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1682,\tval_loss: 0.1446\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1603,\tval_loss: 0.1463\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1580,\tval_loss: 0.1457\n",
            "79:\t[0s / 10s],\t\ttrain_loss: 0.1750,\tval_loss: 0.1427\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1411\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.1663,\tval_loss: 0.1458\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.1641,\tval_loss: 0.1425\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1433\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.1607,\tval_loss: 0.1413\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1417\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1421\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1693,\tval_loss: 0.1414\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1591,\tval_loss: 0.1419\n",
            "89:\t[0s / 11s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1437\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.1666,\tval_loss: 0.1465\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1430\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1451\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.1610,\tval_loss: 0.1459\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.1643,\tval_loss: 0.1453\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.1703,\tval_loss: 0.1461\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.1713,\tval_loss: 0.1445\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1585,\tval_loss: 0.1472\n",
            "98:\t[0s / 12s],\t\ttrain_loss: 0.1699,\tval_loss: 0.1506\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.1648,\tval_loss: 0.1482\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2327,\tval_loss: 0.1532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2086,\tval_loss: 0.1450\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1675,\tval_loss: 0.1422\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1602,\tval_loss: 0.1420\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1410\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1407\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1587,\tval_loss: 0.1406\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1518,\tval_loss: 0.1406\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1547,\tval_loss: 0.1412\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1525,\tval_loss: 0.1405\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1565,\tval_loss: 0.1402\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1521,\tval_loss: 0.1409\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1404\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1531,\tval_loss: 0.1409\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1537,\tval_loss: 0.1416\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1499,\tval_loss: 0.1404\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1499,\tval_loss: 0.1406\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1513,\tval_loss: 0.1400\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1519,\tval_loss: 0.1409\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1402\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1515,\tval_loss: 0.1396\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1548,\tval_loss: 0.1435\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1508,\tval_loss: 0.1407\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1398\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1406\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1398\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1515,\tval_loss: 0.1429\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1412\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1505,\tval_loss: 0.1399\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1410\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1577,\tval_loss: 0.1414\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1410\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1548,\tval_loss: 0.1408\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1574,\tval_loss: 0.1412\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1401\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1515,\tval_loss: 0.1412\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1501,\tval_loss: 0.1432\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1510,\tval_loss: 0.1408\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1415\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1511,\tval_loss: 0.1430\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1394\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1497,\tval_loss: 0.1429\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1582,\tval_loss: 0.1425\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1553,\tval_loss: 0.1418\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1559,\tval_loss: 0.1417\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1565,\tval_loss: 0.1438\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1438\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1407\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1438\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1534,\tval_loss: 0.1433\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1432\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1543,\tval_loss: 0.1404\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.1504,\tval_loss: 0.1416\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.1548,\tval_loss: 0.1425\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1421\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.1559,\tval_loss: 0.1408\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1554,\tval_loss: 0.1425\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1514,\tval_loss: 0.1450\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1551,\tval_loss: 0.1406\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1521,\tval_loss: 0.1426\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.1521,\tval_loss: 0.1404\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1441\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.1563,\tval_loss: 0.1433\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1408\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.1497,\tval_loss: 0.1422\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1466\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1429\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1531,\tval_loss: 0.1416\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1565,\tval_loss: 0.1418\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1418\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.1486,\tval_loss: 0.1467\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1437\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.1519,\tval_loss: 0.1423\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1434\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1559,\tval_loss: 0.1441\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1440\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1452\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1585,\tval_loss: 0.1446\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1514,\tval_loss: 0.1457\n",
            "79:\t[0s / 10s],\t\ttrain_loss: 0.1559,\tval_loss: 0.1459\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.1559,\tval_loss: 0.1460\n",
            "81:\t[0s / 11s],\t\ttrain_loss: 0.1505,\tval_loss: 0.1458\n",
            "82:\t[0s / 11s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1436\n",
            "83:\t[0s / 11s],\t\ttrain_loss: 0.1556,\tval_loss: 0.1450\n",
            "84:\t[0s / 11s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1419\n",
            "85:\t[0s / 11s],\t\ttrain_loss: 0.1504,\tval_loss: 0.1426\n",
            "86:\t[0s / 11s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1437\n",
            "87:\t[0s / 11s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1422\n",
            "88:\t[0s / 11s],\t\ttrain_loss: 0.1534,\tval_loss: 0.1440\n",
            "89:\t[0s / 12s],\t\ttrain_loss: 0.1487,\tval_loss: 0.1423\n",
            "90:\t[0s / 12s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1457\n",
            "91:\t[0s / 12s],\t\ttrain_loss: 0.1526,\tval_loss: 0.1446\n",
            "92:\t[0s / 12s],\t\ttrain_loss: 0.1515,\tval_loss: 0.1426\n",
            "93:\t[0s / 12s],\t\ttrain_loss: 0.1522,\tval_loss: 0.1447\n",
            "94:\t[0s / 12s],\t\ttrain_loss: 0.1534,\tval_loss: 0.1464\n",
            "95:\t[0s / 12s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1429\n",
            "96:\t[0s / 12s],\t\ttrain_loss: 0.1504,\tval_loss: 0.1424\n",
            "97:\t[0s / 12s],\t\ttrain_loss: 0.1570,\tval_loss: 0.1440\n",
            "98:\t[0s / 13s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1435\n",
            "99:\t[0s / 13s],\t\ttrain_loss: 0.1519,\tval_loss: 0.1418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2373,\tval_loss: 0.1582\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2143,\tval_loss: 0.1450\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1739,\tval_loss: 0.1425\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1571,\tval_loss: 0.1422\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1420\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1526,\tval_loss: 0.1427\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1419\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1435\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1505,\tval_loss: 0.1434\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1492,\tval_loss: 0.1413\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1525,\tval_loss: 0.1415\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1512,\tval_loss: 0.1422\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1488,\tval_loss: 0.1419\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1522,\tval_loss: 0.1419\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1509,\tval_loss: 0.1416\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1491,\tval_loss: 0.1431\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.1477,\tval_loss: 0.1421\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1509,\tval_loss: 0.1405\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1523,\tval_loss: 0.1427\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1403\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1525,\tval_loss: 0.1410\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1410\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.1488,\tval_loss: 0.1430\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1472,\tval_loss: 0.1414\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1417\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1551,\tval_loss: 0.1419\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1422\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1420\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1424\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1562,\tval_loss: 0.1412\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1512,\tval_loss: 0.1419\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.1553,\tval_loss: 0.1402\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1490,\tval_loss: 0.1427\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.1541,\tval_loss: 0.1413\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1406\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1577,\tval_loss: 0.1402\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1395\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1556,\tval_loss: 0.1410\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1414\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1412\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1399\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1427\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.1548,\tval_loss: 0.1418\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1415\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1476,\tval_loss: 0.1408\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1405\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1508,\tval_loss: 0.1417\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1406\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1429\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1483,\tval_loss: 0.1409\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1412\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1474,\tval_loss: 0.1388\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.1541,\tval_loss: 0.1401\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1394\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1405\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1425\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1487,\tval_loss: 0.1401\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1583,\tval_loss: 0.1392\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.1515,\tval_loss: 0.1402\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1417\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.1515,\tval_loss: 0.1411\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.1592,\tval_loss: 0.1403\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1379\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.1504,\tval_loss: 0.1406\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1397\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.1522,\tval_loss: 0.1404\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1523,\tval_loss: 0.1406\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1421\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1494,\tval_loss: 0.1398\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1412\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.1468,\tval_loss: 0.1406\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.1480,\tval_loss: 0.1411\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.1501,\tval_loss: 0.1401\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.1531,\tval_loss: 0.1384\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1409\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1505,\tval_loss: 0.1382\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1403\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1531,\tval_loss: 0.1397\n",
            "78:\t[0s / 10s],\t\ttrain_loss: 0.1503,\tval_loss: 0.1404\n",
            "79:\t[0s / 10s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1401\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.1553,\tval_loss: 0.1431\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.1496,\tval_loss: 0.1388\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1420\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.1474,\tval_loss: 0.1404\n",
            "84:\t[0s / 11s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1415\n",
            "85:\t[0s / 11s],\t\ttrain_loss: 0.1530,\tval_loss: 0.1385\n",
            "86:\t[0s / 11s],\t\ttrain_loss: 0.1492,\tval_loss: 0.1405\n",
            "87:\t[0s / 11s],\t\ttrain_loss: 0.1509,\tval_loss: 0.1405\n",
            "88:\t[0s / 11s],\t\ttrain_loss: 0.1485,\tval_loss: 0.1404\n",
            "89:\t[0s / 11s],\t\ttrain_loss: 0.1511,\tval_loss: 0.1393\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.1522,\tval_loss: 0.1403\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.1530,\tval_loss: 0.1410\n",
            "92:\t[0s / 12s],\t\ttrain_loss: 0.1451,\tval_loss: 0.1426\n",
            "93:\t[0s / 12s],\t\ttrain_loss: 0.1518,\tval_loss: 0.1418\n",
            "94:\t[0s / 12s],\t\ttrain_loss: 0.1484,\tval_loss: 0.1399\n",
            "95:\t[0s / 12s],\t\ttrain_loss: 0.1480,\tval_loss: 0.1406\n",
            "96:\t[0s / 12s],\t\ttrain_loss: 0.1486,\tval_loss: 0.1404\n",
            "97:\t[0s / 12s],\t\ttrain_loss: 0.1497,\tval_loss: 0.1389\n",
            "98:\t[0s / 12s],\t\ttrain_loss: 0.1507,\tval_loss: 0.1401\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.1553,\tval_loss: 0.1383\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2446,\tval_loss: 0.1580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1953,\tval_loss: 0.1406\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1699,\tval_loss: 0.1413\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1566,\tval_loss: 0.1408\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1405\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1500,\tval_loss: 0.1399\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1507,\tval_loss: 0.1402\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1526,\tval_loss: 0.1395\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1514,\tval_loss: 0.1420\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1412\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1516,\tval_loss: 0.1399\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1402\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1510,\tval_loss: 0.1407\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1398\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1403\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1508,\tval_loss: 0.1410\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1539,\tval_loss: 0.1395\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1485,\tval_loss: 0.1416\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1405\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1547,\tval_loss: 0.1412\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1530,\tval_loss: 0.1413\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1412\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1478,\tval_loss: 0.1414\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1511,\tval_loss: 0.1404\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1499,\tval_loss: 0.1422\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1522,\tval_loss: 0.1398\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1408\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1516,\tval_loss: 0.1402\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1407\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1503,\tval_loss: 0.1396\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1406\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1531,\tval_loss: 0.1404\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1518,\tval_loss: 0.1393\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1571,\tval_loss: 0.1403\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1432\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1579,\tval_loss: 0.1403\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1403\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1403\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1565,\tval_loss: 0.1401\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1525,\tval_loss: 0.1400\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1580,\tval_loss: 0.1396\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1493,\tval_loss: 0.1404\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1504,\tval_loss: 0.1414\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1418\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1531,\tval_loss: 0.1404\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.1518,\tval_loss: 0.1417\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.1522,\tval_loss: 0.1407\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1412\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1516,\tval_loss: 0.1412\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1565,\tval_loss: 0.1398\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1430\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1574,\tval_loss: 0.1394\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1406\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1579,\tval_loss: 0.1439\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1409\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.1516,\tval_loss: 0.1397\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1416\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1406\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1406\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1400\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1570,\tval_loss: 0.1400\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.1539,\tval_loss: 0.1407\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1406\n",
            "63:\t[0s / 6s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1406\n",
            "64:\t[0s / 6s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1408\n",
            "65:\t[0s / 6s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1406\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.1489,\tval_loss: 0.1399\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1518,\tval_loss: 0.1412\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1583,\tval_loss: 0.1395\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.1541,\tval_loss: 0.1401\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1404\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1401\n",
            "72:\t[0s / 7s],\t\ttrain_loss: 0.1497,\tval_loss: 0.1408\n",
            "73:\t[0s / 7s],\t\ttrain_loss: 0.1559,\tval_loss: 0.1398\n",
            "74:\t[0s / 7s],\t\ttrain_loss: 0.1516,\tval_loss: 0.1412\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.1563,\tval_loss: 0.1404\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.1557,\tval_loss: 0.1403\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.1509,\tval_loss: 0.1395\n",
            "78:\t[0s / 8s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1408\n",
            "79:\t[0s / 8s],\t\ttrain_loss: 0.1591,\tval_loss: 0.1411\n",
            "80:\t[0s / 8s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1403\n",
            "81:\t[0s / 8s],\t\ttrain_loss: 0.1493,\tval_loss: 0.1402\n",
            "82:\t[0s / 8s],\t\ttrain_loss: 0.1552,\tval_loss: 0.1408\n",
            "83:\t[0s / 8s],\t\ttrain_loss: 0.1477,\tval_loss: 0.1405\n",
            "84:\t[0s / 9s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1399\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.1556,\tval_loss: 0.1400\n",
            "86:\t[0s / 9s],\t\ttrain_loss: 0.1525,\tval_loss: 0.1398\n",
            "87:\t[0s / 9s],\t\ttrain_loss: 0.1511,\tval_loss: 0.1411\n",
            "88:\t[0s / 9s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1401\n",
            "89:\t[0s / 9s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1404\n",
            "90:\t[0s / 10s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1419\n",
            "91:\t[0s / 10s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1409\n",
            "92:\t[0s / 10s],\t\ttrain_loss: 0.1514,\tval_loss: 0.1400\n",
            "93:\t[0s / 10s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1400\n",
            "94:\t[0s / 10s],\t\ttrain_loss: 0.1487,\tval_loss: 0.1403\n",
            "95:\t[0s / 10s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1392\n",
            "96:\t[0s / 10s],\t\ttrain_loss: 0.1499,\tval_loss: 0.1408\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1507,\tval_loss: 0.1403\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.1486,\tval_loss: 0.1412\n",
            "99:\t[0s / 11s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1396\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2667,\tval_loss: 0.1483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2160,\tval_loss: 0.1435\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1779,\tval_loss: 0.1416\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1673,\tval_loss: 0.1421\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1704,\tval_loss: 0.1456\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1635,\tval_loss: 0.1429\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1610,\tval_loss: 0.1400\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.1629,\tval_loss: 0.1413\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1400\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1405\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1408\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1421\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 0.1606,\tval_loss: 0.1430\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.1617,\tval_loss: 0.1413\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1396\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1403\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.1650,\tval_loss: 0.1415\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1415\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1411\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1602,\tval_loss: 0.1402\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1409\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.1621,\tval_loss: 0.1401\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.1665,\tval_loss: 0.1415\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1413\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1398\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1421\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1632,\tval_loss: 0.1389\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1417\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1633,\tval_loss: 0.1402\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1624,\tval_loss: 0.1415\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1425\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.1633,\tval_loss: 0.1402\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1606,\tval_loss: 0.1409\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.1656,\tval_loss: 0.1406\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1410\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1644,\tval_loss: 0.1391\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1603,\tval_loss: 0.1401\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1642,\tval_loss: 0.1415\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1692,\tval_loss: 0.1410\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1648,\tval_loss: 0.1405\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1403\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1410\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.1624,\tval_loss: 0.1400\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1457\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1388\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1670,\tval_loss: 0.1418\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1413\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1411\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1423\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1414\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1671,\tval_loss: 0.1417\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1407\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1408\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.1580,\tval_loss: 0.1420\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1410\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.1633,\tval_loss: 0.1413\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1586,\tval_loss: 0.1403\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1417\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1416\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1404\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.1574,\tval_loss: 0.1424\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.1591,\tval_loss: 0.1408\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.1592,\tval_loss: 0.1413\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1401\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.1587,\tval_loss: 0.1432\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1405\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1406\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1417\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1425\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1414\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1423\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.1580,\tval_loss: 0.1423\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1406\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1408\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1423\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.1579,\tval_loss: 0.1400\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1408\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1400\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1574,\tval_loss: 0.1408\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.1607,\tval_loss: 0.1437\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1425\n",
            "81:\t[0s / 9s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1427\n",
            "82:\t[0s / 9s],\t\ttrain_loss: 0.1671,\tval_loss: 0.1426\n",
            "83:\t[0s / 9s],\t\ttrain_loss: 0.1597,\tval_loss: 0.1423\n",
            "84:\t[0s / 9s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1428\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1425\n",
            "86:\t[0s / 9s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1436\n",
            "87:\t[0s / 9s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1443\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1420\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1414\n",
            "90:\t[0s / 10s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1431\n",
            "91:\t[0s / 10s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1436\n",
            "92:\t[0s / 10s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1414\n",
            "93:\t[0s / 10s],\t\ttrain_loss: 0.1633,\tval_loss: 0.1445\n",
            "94:\t[0s / 10s],\t\ttrain_loss: 0.1610,\tval_loss: 0.1396\n",
            "95:\t[0s / 10s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1411\n",
            "96:\t[0s / 10s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1477\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1420\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1405\n",
            "99:\t[0s / 11s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1425\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2348,\tval_loss: 0.1442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1929,\tval_loss: 0.1472\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1405\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1521,\tval_loss: 0.1407\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1474,\tval_loss: 0.1404\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1447,\tval_loss: 0.1398\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1441,\tval_loss: 0.1406\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1456,\tval_loss: 0.1405\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1480,\tval_loss: 0.1414\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1451,\tval_loss: 0.1399\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1469,\tval_loss: 0.1398\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1451,\tval_loss: 0.1398\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1452,\tval_loss: 0.1406\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1410,\tval_loss: 0.1411\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1428,\tval_loss: 0.1410\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.1437,\tval_loss: 0.1402\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.1433,\tval_loss: 0.1396\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1418,\tval_loss: 0.1405\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1462,\tval_loss: 0.1392\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1459,\tval_loss: 0.1414\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1502,\tval_loss: 0.1399\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.1442,\tval_loss: 0.1404\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.1443,\tval_loss: 0.1410\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1451,\tval_loss: 0.1408\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1429,\tval_loss: 0.1397\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1422,\tval_loss: 0.1408\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1450,\tval_loss: 0.1405\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1439,\tval_loss: 0.1400\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.1456,\tval_loss: 0.1398\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.1448,\tval_loss: 0.1402\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.1452,\tval_loss: 0.1395\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.1466,\tval_loss: 0.1397\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1458,\tval_loss: 0.1423\n",
            "33:\t[0s / 5s],\t\ttrain_loss: 0.1436,\tval_loss: 0.1407\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.1395,\tval_loss: 0.1393\n",
            "35:\t[0s / 5s],\t\ttrain_loss: 0.1445,\tval_loss: 0.1411\n",
            "36:\t[0s / 5s],\t\ttrain_loss: 0.1414,\tval_loss: 0.1392\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.1485,\tval_loss: 0.1402\n",
            "38:\t[0s / 6s],\t\ttrain_loss: 0.1480,\tval_loss: 0.1410\n",
            "39:\t[0s / 6s],\t\ttrain_loss: 0.1502,\tval_loss: 0.1402\n",
            "40:\t[0s / 6s],\t\ttrain_loss: 0.1456,\tval_loss: 0.1409\n",
            "41:\t[0s / 6s],\t\ttrain_loss: 0.1422,\tval_loss: 0.1431\n",
            "42:\t[0s / 6s],\t\ttrain_loss: 0.1462,\tval_loss: 0.1421\n",
            "43:\t[0s / 6s],\t\ttrain_loss: 0.1434,\tval_loss: 0.1420\n",
            "44:\t[0s / 6s],\t\ttrain_loss: 0.1448,\tval_loss: 0.1406\n",
            "45:\t[0s / 7s],\t\ttrain_loss: 0.1476,\tval_loss: 0.1391\n",
            "46:\t[0s / 7s],\t\ttrain_loss: 0.1443,\tval_loss: 0.1395\n",
            "47:\t[0s / 7s],\t\ttrain_loss: 0.1428,\tval_loss: 0.1390\n",
            "48:\t[0s / 7s],\t\ttrain_loss: 0.1434,\tval_loss: 0.1389\n",
            "49:\t[0s / 7s],\t\ttrain_loss: 0.1433,\tval_loss: 0.1394\n",
            "50:\t[0s / 7s],\t\ttrain_loss: 0.1434,\tval_loss: 0.1400\n",
            "51:\t[0s / 8s],\t\ttrain_loss: 0.1425,\tval_loss: 0.1413\n",
            "52:\t[0s / 8s],\t\ttrain_loss: 0.1459,\tval_loss: 0.1407\n",
            "53:\t[0s / 8s],\t\ttrain_loss: 0.1443,\tval_loss: 0.1399\n",
            "54:\t[0s / 8s],\t\ttrain_loss: 0.1412,\tval_loss: 0.1408\n",
            "55:\t[0s / 8s],\t\ttrain_loss: 0.1458,\tval_loss: 0.1391\n",
            "56:\t[0s / 8s],\t\ttrain_loss: 0.1402,\tval_loss: 0.1414\n",
            "57:\t[0s / 8s],\t\ttrain_loss: 0.1499,\tval_loss: 0.1387\n",
            "58:\t[0s / 9s],\t\ttrain_loss: 0.1467,\tval_loss: 0.1386\n",
            "59:\t[0s / 9s],\t\ttrain_loss: 0.1458,\tval_loss: 0.1415\n",
            "60:\t[0s / 9s],\t\ttrain_loss: 0.1445,\tval_loss: 0.1400\n",
            "61:\t[0s / 9s],\t\ttrain_loss: 0.1452,\tval_loss: 0.1385\n",
            "62:\t[0s / 9s],\t\ttrain_loss: 0.1440,\tval_loss: 0.1393\n",
            "63:\t[0s / 9s],\t\ttrain_loss: 0.1438,\tval_loss: 0.1406\n",
            "64:\t[0s / 10s],\t\ttrain_loss: 0.1482,\tval_loss: 0.1401\n",
            "65:\t[0s / 10s],\t\ttrain_loss: 0.1436,\tval_loss: 0.1442\n",
            "66:\t[0s / 10s],\t\ttrain_loss: 0.1432,\tval_loss: 0.1388\n",
            "67:\t[0s / 10s],\t\ttrain_loss: 0.1472,\tval_loss: 0.1387\n",
            "68:\t[0s / 10s],\t\ttrain_loss: 0.1441,\tval_loss: 0.1426\n",
            "69:\t[0s / 10s],\t\ttrain_loss: 0.1446,\tval_loss: 0.1401\n",
            "70:\t[0s / 10s],\t\ttrain_loss: 0.1453,\tval_loss: 0.1399\n",
            "71:\t[0s / 10s],\t\ttrain_loss: 0.1420,\tval_loss: 0.1406\n",
            "72:\t[0s / 10s],\t\ttrain_loss: 0.1399,\tval_loss: 0.1410\n",
            "73:\t[0s / 11s],\t\ttrain_loss: 0.1434,\tval_loss: 0.1397\n",
            "74:\t[0s / 11s],\t\ttrain_loss: 0.1448,\tval_loss: 0.1397\n",
            "75:\t[0s / 11s],\t\ttrain_loss: 0.1430,\tval_loss: 0.1401\n",
            "76:\t[0s / 11s],\t\ttrain_loss: 0.1473,\tval_loss: 0.1408\n",
            "77:\t[0s / 11s],\t\ttrain_loss: 0.1424,\tval_loss: 0.1394\n",
            "78:\t[0s / 11s],\t\ttrain_loss: 0.1439,\tval_loss: 0.1395\n",
            "79:\t[0s / 11s],\t\ttrain_loss: 0.1405,\tval_loss: 0.1396\n",
            "80:\t[0s / 11s],\t\ttrain_loss: 0.1419,\tval_loss: 0.1391\n",
            "81:\t[0s / 11s],\t\ttrain_loss: 0.1456,\tval_loss: 0.1408\n",
            "82:\t[0s / 12s],\t\ttrain_loss: 0.1446,\tval_loss: 0.1424\n",
            "83:\t[0s / 12s],\t\ttrain_loss: 0.1434,\tval_loss: 0.1395\n",
            "84:\t[0s / 12s],\t\ttrain_loss: 0.1427,\tval_loss: 0.1394\n",
            "85:\t[0s / 12s],\t\ttrain_loss: 0.1453,\tval_loss: 0.1400\n",
            "86:\t[0s / 12s],\t\ttrain_loss: 0.1398,\tval_loss: 0.1386\n",
            "87:\t[0s / 12s],\t\ttrain_loss: 0.1453,\tval_loss: 0.1401\n",
            "88:\t[0s / 12s],\t\ttrain_loss: 0.1433,\tval_loss: 0.1386\n",
            "89:\t[0s / 12s],\t\ttrain_loss: 0.1438,\tval_loss: 0.1396\n",
            "90:\t[0s / 12s],\t\ttrain_loss: 0.1461,\tval_loss: 0.1394\n",
            "91:\t[0s / 12s],\t\ttrain_loss: 0.1433,\tval_loss: 0.1400\n",
            "92:\t[0s / 13s],\t\ttrain_loss: 0.1430,\tval_loss: 0.1401\n",
            "93:\t[0s / 13s],\t\ttrain_loss: 0.1426,\tval_loss: 0.1393\n",
            "94:\t[0s / 13s],\t\ttrain_loss: 0.1411,\tval_loss: 0.1401\n",
            "95:\t[0s / 13s],\t\ttrain_loss: 0.1433,\tval_loss: 0.1401\n",
            "96:\t[0s / 13s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1425\n",
            "97:\t[0s / 13s],\t\ttrain_loss: 0.1465,\tval_loss: 0.1422\n",
            "98:\t[0s / 13s],\t\ttrain_loss: 0.1418,\tval_loss: 0.1413\n",
            "99:\t[0s / 13s],\t\ttrain_loss: 0.1419,\tval_loss: 0.1395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2472,\tval_loss: 0.1438\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2223,\tval_loss: 0.1477\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1824,\tval_loss: 0.1424\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1711,\tval_loss: 0.1408\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1673,\tval_loss: 0.1413\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1420\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1406\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1409\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1402\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1409\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1403\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1641,\tval_loss: 0.1417\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1404\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1423\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1397\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1648,\tval_loss: 0.1410\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1406\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1606,\tval_loss: 0.1405\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1629,\tval_loss: 0.1407\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1409\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1402\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1404\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1650,\tval_loss: 0.1402\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1412\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1662,\tval_loss: 0.1410\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1404\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1660,\tval_loss: 0.1449\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1657,\tval_loss: 0.1404\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1669,\tval_loss: 0.1398\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1636,\tval_loss: 0.1419\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1400\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1418\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1669,\tval_loss: 0.1408\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.1655,\tval_loss: 0.1411\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.1642,\tval_loss: 0.1409\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1656,\tval_loss: 0.1415\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1408\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1656,\tval_loss: 0.1439\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1431\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1432\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.1663,\tval_loss: 0.1445\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1657,\tval_loss: 0.1422\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.1730,\tval_loss: 0.1420\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1656,\tval_loss: 0.1414\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1462\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1437\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.1650,\tval_loss: 0.1417\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.1629,\tval_loss: 0.1438\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1411\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1423\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1636,\tval_loss: 0.1456\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1617,\tval_loss: 0.1438\n",
            "52:\t[0s / 7s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1441\n",
            "53:\t[0s / 7s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1424\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1445\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1430\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1440\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.1651,\tval_loss: 0.1414\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.1666,\tval_loss: 0.1429\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1474\n",
            "60:\t[0s / 8s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1499\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.1636,\tval_loss: 0.1487\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1475\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.1685,\tval_loss: 0.1469\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1466\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.1668,\tval_loss: 0.1483\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1484\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1446\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1496\n",
            "69:\t[0s / 9s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1472\n",
            "70:\t[0s / 9s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1478\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.1582,\tval_loss: 0.1476\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1447\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1465\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1448\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1449\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1478\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1648,\tval_loss: 0.1507\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1629,\tval_loss: 0.1466\n",
            "79:\t[0s / 10s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1455\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1461\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.1682,\tval_loss: 0.1462\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2455,\tval_loss: 0.1620\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2213,\tval_loss: 0.1478\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1796,\tval_loss: 0.1426\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1680,\tval_loss: 0.1422\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1656,\tval_loss: 0.1404\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1412\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1416\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1407\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1602,\tval_loss: 0.1404\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1409\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1637,\tval_loss: 0.1425\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1399\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1605,\tval_loss: 0.1417\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1414\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1617,\tval_loss: 0.1424\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1431\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1399\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1426\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1660,\tval_loss: 0.1400\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1407\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1666,\tval_loss: 0.1405\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1602,\tval_loss: 0.1407\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1668,\tval_loss: 0.1412\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1408\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1403\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1415\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1416\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1417\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1408\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1636,\tval_loss: 0.1419\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1632,\tval_loss: 0.1413\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1425\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1658,\tval_loss: 0.1399\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1393\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1580,\tval_loss: 0.1420\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1602,\tval_loss: 0.1405\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.1662,\tval_loss: 0.1407\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1657,\tval_loss: 0.1408\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1401\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1416\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1407\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1602,\tval_loss: 0.1410\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1643,\tval_loss: 0.1391\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1404\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1406\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.1579,\tval_loss: 0.1399\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1421\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1400\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1411\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1577,\tval_loss: 0.1401\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1408\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1670,\tval_loss: 0.1409\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1658,\tval_loss: 0.1421\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1401\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.1655,\tval_loss: 0.1421\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.1621,\tval_loss: 0.1431\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1665,\tval_loss: 0.1414\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1662,\tval_loss: 0.1413\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1621,\tval_loss: 0.1419\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1684,\tval_loss: 0.1420\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1635,\tval_loss: 0.1428\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.1605,\tval_loss: 0.1416\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1420\n",
            "63:\t[0s / 6s],\t\ttrain_loss: 0.1643,\tval_loss: 0.1429\n",
            "64:\t[0s / 6s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1433\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1411\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1418\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1600,\tval_loss: 0.1458\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1421\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.1632,\tval_loss: 0.1440\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1410\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1415\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1419\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.1597,\tval_loss: 0.1409\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.1602,\tval_loss: 0.1451\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1436\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1440\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.1605,\tval_loss: 0.1408\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1426\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.1583,\tval_loss: 0.1443\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.1571,\tval_loss: 0.1416\n",
            "81:\t[0s / 9s],\t\ttrain_loss: 0.1610,\tval_loss: 0.1416\n",
            "82:\t[0s / 9s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1421\n",
            "83:\t[0s / 9s],\t\ttrain_loss: 0.1584,\tval_loss: 0.1429\n",
            "84:\t[0s / 9s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1412\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.1587,\tval_loss: 0.1414\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1607,\tval_loss: 0.1433\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1434\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1427\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.1676,\tval_loss: 0.1436\n",
            "90:\t[0s / 10s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1423\n",
            "91:\t[0s / 10s],\t\ttrain_loss: 0.1651,\tval_loss: 0.1449\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1424\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.1592,\tval_loss: 0.1468\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1431\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1443\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.1632,\tval_loss: 0.1431\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1424\n",
            "98:\t[0s / 12s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1438\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1417\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2555,\tval_loss: 0.1464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2192,\tval_loss: 0.1424\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1828,\tval_loss: 0.1424\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1726,\tval_loss: 0.1414\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1643,\tval_loss: 0.1413\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1702,\tval_loss: 0.1419\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1680,\tval_loss: 0.1406\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1675,\tval_loss: 0.1403\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1696,\tval_loss: 0.1411\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1669,\tval_loss: 0.1409\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1632,\tval_loss: 0.1408\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1418\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1675,\tval_loss: 0.1427\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1650,\tval_loss: 0.1414\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1665,\tval_loss: 0.1406\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1700,\tval_loss: 0.1406\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1643,\tval_loss: 0.1411\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1688,\tval_loss: 0.1415\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1665,\tval_loss: 0.1406\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1406\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1685,\tval_loss: 0.1410\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1662,\tval_loss: 0.1408\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1409\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1417\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1711,\tval_loss: 0.1421\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1633,\tval_loss: 0.1413\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1678,\tval_loss: 0.1412\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1718,\tval_loss: 0.1420\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1729,\tval_loss: 0.1409\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1659,\tval_loss: 0.1407\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1667,\tval_loss: 0.1419\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1657,\tval_loss: 0.1410\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1690,\tval_loss: 0.1414\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1412\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1686,\tval_loss: 0.1417\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1696,\tval_loss: 0.1420\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.1668,\tval_loss: 0.1431\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.1678,\tval_loss: 0.1408\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1404\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1411\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1692,\tval_loss: 0.1403\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1417\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1684,\tval_loss: 0.1430\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1677,\tval_loss: 0.1409\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1416\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.1654,\tval_loss: 0.1410\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.1635,\tval_loss: 0.1405\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1670,\tval_loss: 0.1415\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1697,\tval_loss: 0.1401\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1679,\tval_loss: 0.1415\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1653,\tval_loss: 0.1400\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1688,\tval_loss: 0.1403\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1682,\tval_loss: 0.1417\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1682,\tval_loss: 0.1399\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.1655,\tval_loss: 0.1413\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.1652,\tval_loss: 0.1410\n",
            "56:\t[0s / 5s],\t\ttrain_loss: 0.1658,\tval_loss: 0.1416\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1650,\tval_loss: 0.1416\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1692,\tval_loss: 0.1401\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1694,\tval_loss: 0.1410\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1413\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.1655,\tval_loss: 0.1406\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.1705,\tval_loss: 0.1402\n",
            "63:\t[0s / 6s],\t\ttrain_loss: 0.1715,\tval_loss: 0.1417\n",
            "64:\t[0s / 6s],\t\ttrain_loss: 0.1659,\tval_loss: 0.1402\n",
            "65:\t[0s / 6s],\t\ttrain_loss: 0.1667,\tval_loss: 0.1423\n",
            "66:\t[0s / 6s],\t\ttrain_loss: 0.1725,\tval_loss: 0.1405\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1703,\tval_loss: 0.1439\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1731,\tval_loss: 0.1447\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.1709,\tval_loss: 0.1431\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.1711,\tval_loss: 0.1412\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.1679,\tval_loss: 0.1426\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.1727,\tval_loss: 0.1430\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.1719,\tval_loss: 0.1477\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.1716,\tval_loss: 0.1424\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.1829,\tval_loss: 0.1414\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.1736,\tval_loss: 0.1428\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1735,\tval_loss: 0.1434\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1715,\tval_loss: 0.1424\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.1750,\tval_loss: 0.1430\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.1721,\tval_loss: 0.1428\n",
            "81:\t[0s / 9s],\t\ttrain_loss: 0.1690,\tval_loss: 0.1431\n",
            "82:\t[0s / 9s],\t\ttrain_loss: 0.1673,\tval_loss: 0.1432\n",
            "83:\t[0s / 9s],\t\ttrain_loss: 0.1736,\tval_loss: 0.1436\n",
            "84:\t[0s / 9s],\t\ttrain_loss: 0.1700,\tval_loss: 0.1431\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.1779,\tval_loss: 0.1425\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1788,\tval_loss: 0.1434\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1775,\tval_loss: 0.1417\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1791,\tval_loss: 0.1418\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.1751,\tval_loss: 0.1445\n",
            "90:\t[0s / 10s],\t\ttrain_loss: 0.1787,\tval_loss: 0.1438\n",
            "91:\t[0s / 10s],\t\ttrain_loss: 0.1787,\tval_loss: 0.1421\n",
            "92:\t[0s / 10s],\t\ttrain_loss: 0.1734,\tval_loss: 0.1425\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.1801,\tval_loss: 0.1489\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.1759,\tval_loss: 0.1431\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.1817,\tval_loss: 0.1419\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.1783,\tval_loss: 0.1452\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1771,\tval_loss: 0.1469\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.1835,\tval_loss: 0.1440\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.1739,\tval_loss: 0.1441\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2542,\tval_loss: 0.1558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2237,\tval_loss: 0.1453\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1824,\tval_loss: 0.1415\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1737,\tval_loss: 0.1414\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1679,\tval_loss: 0.1412\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1417\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1416\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.1658,\tval_loss: 0.1403\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1403\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1420\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1659,\tval_loss: 0.1410\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1398\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1424\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.1665,\tval_loss: 0.1403\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.1636,\tval_loss: 0.1398\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.1643,\tval_loss: 0.1417\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.1637,\tval_loss: 0.1400\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1636,\tval_loss: 0.1412\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1650,\tval_loss: 0.1407\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1644,\tval_loss: 0.1412\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.1644,\tval_loss: 0.1418\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.1706,\tval_loss: 0.1401\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1460\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1683,\tval_loss: 0.1412\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1689,\tval_loss: 0.1404\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1624,\tval_loss: 0.1399\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1404\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1648,\tval_loss: 0.1419\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1650,\tval_loss: 0.1425\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1664,\tval_loss: 0.1402\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.1632,\tval_loss: 0.1405\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1406\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1653,\tval_loss: 0.1404\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.1656,\tval_loss: 0.1434\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.1664,\tval_loss: 0.1410\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1404\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1617,\tval_loss: 0.1426\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1410\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1660,\tval_loss: 0.1408\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1412\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.1635,\tval_loss: 0.1408\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1682,\tval_loss: 0.1416\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.1662,\tval_loss: 0.1409\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1408\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1698,\tval_loss: 0.1414\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1412\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1404\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1418\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1655,\tval_loss: 0.1431\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1403\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1411\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1415\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.1685,\tval_loss: 0.1406\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1431\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1411\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1398\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1431\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1641,\tval_loss: 0.1406\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1610,\tval_loss: 0.1416\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1610,\tval_loss: 0.1414\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.1605,\tval_loss: 0.1414\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.1648,\tval_loss: 0.1408\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.1655,\tval_loss: 0.1410\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1438\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1425\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1417\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.1697,\tval_loss: 0.1421\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1688,\tval_loss: 0.1429\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1667,\tval_loss: 0.1410\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1653,\tval_loss: 0.1413\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.1657,\tval_loss: 0.1403\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.1624,\tval_loss: 0.1419\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1414\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.1639,\tval_loss: 0.1412\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.1617,\tval_loss: 0.1431\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.1624,\tval_loss: 0.1418\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.1659,\tval_loss: 0.1408\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.1621,\tval_loss: 0.1413\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1639,\tval_loss: 0.1419\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.1678,\tval_loss: 0.1416\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1418\n",
            "81:\t[0s / 9s],\t\ttrain_loss: 0.1629,\tval_loss: 0.1409\n",
            "82:\t[0s / 9s],\t\ttrain_loss: 0.1667,\tval_loss: 0.1425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2360,\tval_loss: 0.1585\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2136,\tval_loss: 0.1445\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1667,\tval_loss: 0.1424\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1582,\tval_loss: 0.1411\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1587,\tval_loss: 0.1415\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1408\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1548,\tval_loss: 0.1415\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1557,\tval_loss: 0.1415\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1566,\tval_loss: 0.1404\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1531,\tval_loss: 0.1414\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1562,\tval_loss: 0.1409\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1407\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1607,\tval_loss: 0.1417\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1602,\tval_loss: 0.1400\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1574,\tval_loss: 0.1418\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1559,\tval_loss: 0.1407\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1500,\tval_loss: 0.1404\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1503,\tval_loss: 0.1410\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1554,\tval_loss: 0.1415\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1518,\tval_loss: 0.1413\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1410\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1414\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1426\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1424\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1409\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1516,\tval_loss: 0.1411\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1410\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1418\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1548,\tval_loss: 0.1405\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1398\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1553,\tval_loss: 0.1414\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1541,\tval_loss: 0.1404\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1566,\tval_loss: 0.1431\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1510,\tval_loss: 0.1414\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.1537,\tval_loss: 0.1413\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1406\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1554,\tval_loss: 0.1403\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1403\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1413\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1531,\tval_loss: 0.1418\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1515,\tval_loss: 0.1388\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1415\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1400\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1551,\tval_loss: 0.1400\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1562,\tval_loss: 0.1397\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1395\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1556,\tval_loss: 0.1388\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1399\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1414\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1411\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1395\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1503,\tval_loss: 0.1391\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1409\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.1523,\tval_loss: 0.1397\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1419\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.1500,\tval_loss: 0.1416\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.1525,\tval_loss: 0.1408\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1397\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1419\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1512,\tval_loss: 0.1409\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.1509,\tval_loss: 0.1408\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1400\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.1534,\tval_loss: 0.1420\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1409\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1416\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1412\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1526,\tval_loss: 0.1422\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1422\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1537,\tval_loss: 0.1428\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1534,\tval_loss: 0.1430\n",
            "70:\t[0s / 9s],\t\ttrain_loss: 0.1525,\tval_loss: 0.1402\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1421\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.1501,\tval_loss: 0.1411\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1418\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1483,\tval_loss: 0.1423\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1399\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1565,\tval_loss: 0.1399\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1418\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1480,\tval_loss: 0.1470\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1396\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1437\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1438\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.1543,\tval_loss: 0.1417\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1429\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1422\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1429\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1435\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1415\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1504,\tval_loss: 0.1435\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.1502,\tval_loss: 0.1436\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.1525,\tval_loss: 0.1398\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.1510,\tval_loss: 0.1424\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1414\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.1523,\tval_loss: 0.1427\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1414\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.1478,\tval_loss: 0.1459\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.1513,\tval_loss: 0.1463\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1502,\tval_loss: 0.1434\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.1500,\tval_loss: 0.1404\n",
            "99:\t[0s / 11s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2330,\tval_loss: 0.1637\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2079,\tval_loss: 0.1412\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1719,\tval_loss: 0.1416\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1596,\tval_loss: 0.1406\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1580,\tval_loss: 0.1408\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1523,\tval_loss: 0.1433\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1574,\tval_loss: 0.1411\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1515,\tval_loss: 0.1412\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1407\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1512,\tval_loss: 0.1411\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1525,\tval_loss: 0.1403\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1397\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1405\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1493,\tval_loss: 0.1395\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1522,\tval_loss: 0.1403\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1519,\tval_loss: 0.1393\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1403\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1567,\tval_loss: 0.1401\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.1523,\tval_loss: 0.1401\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1398\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1516,\tval_loss: 0.1406\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1409\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1530,\tval_loss: 0.1395\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1386\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1419\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1408\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1539,\tval_loss: 0.1410\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1553,\tval_loss: 0.1402\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1591,\tval_loss: 0.1402\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1397\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1505,\tval_loss: 0.1395\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1398\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1412\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.1554,\tval_loss: 0.1405\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1397\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1541,\tval_loss: 0.1430\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1541,\tval_loss: 0.1421\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1548,\tval_loss: 0.1407\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1521,\tval_loss: 0.1395\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1386\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1552,\tval_loss: 0.1400\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1523,\tval_loss: 0.1401\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1419\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1579,\tval_loss: 0.1387\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1537,\tval_loss: 0.1395\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1571,\tval_loss: 0.1375\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1390\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1383\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1395\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1388\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1385\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1412\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.1577,\tval_loss: 0.1397\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1390\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.1478,\tval_loss: 0.1414\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.1584,\tval_loss: 0.1418\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1584,\tval_loss: 0.1391\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.1548,\tval_loss: 0.1397\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.1531,\tval_loss: 0.1401\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1400\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1391\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1388\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.1547,\tval_loss: 0.1389\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1387\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1388\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.1555,\tval_loss: 0.1392\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1539,\tval_loss: 0.1397\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1403\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1412\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1487,\tval_loss: 0.1398\n",
            "70:\t[0s / 9s],\t\ttrain_loss: 0.1518,\tval_loss: 0.1388\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.1571,\tval_loss: 0.1407\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1399\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1397\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1557,\tval_loss: 0.1388\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1555,\tval_loss: 0.1401\n",
            "76:\t[0s / 10s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1395\n",
            "77:\t[0s / 10s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1402\n",
            "78:\t[0s / 10s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1388\n",
            "79:\t[0s / 10s],\t\ttrain_loss: 0.1554,\tval_loss: 0.1387\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1393\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.1516,\tval_loss: 0.1406\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1400\n",
            "83:\t[0s / 11s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1410\n",
            "84:\t[0s / 11s],\t\ttrain_loss: 0.1554,\tval_loss: 0.1406\n",
            "85:\t[0s / 11s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1436\n",
            "86:\t[0s / 11s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1416\n",
            "87:\t[0s / 11s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1399\n",
            "88:\t[0s / 11s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1399\n",
            "89:\t[0s / 11s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1387\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.1583,\tval_loss: 0.1404\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1411\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1400\n",
            "93:\t[0s / 12s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1424\n",
            "94:\t[0s / 12s],\t\ttrain_loss: 0.1521,\tval_loss: 0.1401\n",
            "95:\t[0s / 12s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1391\n",
            "96:\t[0s / 12s],\t\ttrain_loss: 0.1482,\tval_loss: 0.1395\n",
            "97:\t[0s / 12s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1393\n",
            "98:\t[0s / 12s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1391\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.1511,\tval_loss: 0.1377\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2397,\tval_loss: 0.1530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2083,\tval_loss: 0.1469\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1751,\tval_loss: 0.1423\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1412\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1408\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1552,\tval_loss: 0.1400\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1530,\tval_loss: 0.1414\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1531,\tval_loss: 0.1409\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1548,\tval_loss: 0.1411\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1418\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1489,\tval_loss: 0.1408\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1521,\tval_loss: 0.1406\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1509,\tval_loss: 0.1400\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1512,\tval_loss: 0.1417\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1399\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1547,\tval_loss: 0.1415\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1407\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1519,\tval_loss: 0.1421\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1406\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1551,\tval_loss: 0.1404\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1567,\tval_loss: 0.1401\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1577,\tval_loss: 0.1404\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1534,\tval_loss: 0.1397\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1551,\tval_loss: 0.1443\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1406\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1559,\tval_loss: 0.1404\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1579,\tval_loss: 0.1406\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1523,\tval_loss: 0.1415\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1555,\tval_loss: 0.1399\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1420\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1516,\tval_loss: 0.1410\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1554,\tval_loss: 0.1403\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1587,\tval_loss: 0.1399\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1555,\tval_loss: 0.1424\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1404\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1579,\tval_loss: 0.1402\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.1556,\tval_loss: 0.1405\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1421\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1552,\tval_loss: 0.1420\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1412\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1537,\tval_loss: 0.1401\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1507,\tval_loss: 0.1403\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1412\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1587,\tval_loss: 0.1410\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1553,\tval_loss: 0.1406\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.1523,\tval_loss: 0.1424\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.1563,\tval_loss: 0.1417\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1577,\tval_loss: 0.1405\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1505,\tval_loss: 0.1408\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1592,\tval_loss: 0.1411\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1570,\tval_loss: 0.1402\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1512,\tval_loss: 0.1423\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1592,\tval_loss: 0.1402\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1596,\tval_loss: 0.1427\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1406\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1436\n",
            "56:\t[0s / 5s],\t\ttrain_loss: 0.1653,\tval_loss: 0.1428\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1423\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1577,\tval_loss: 0.1411\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1515,\tval_loss: 0.1443\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1563,\tval_loss: 0.1411\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1446\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1397\n",
            "63:\t[0s / 6s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1407\n",
            "64:\t[0s / 6s],\t\ttrain_loss: 0.1508,\tval_loss: 0.1426\n",
            "65:\t[0s / 6s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1412\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1415\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1555,\tval_loss: 0.1422\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1580,\tval_loss: 0.1395\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1455\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.1570,\tval_loss: 0.1405\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.1607,\tval_loss: 0.1413\n",
            "72:\t[0s / 7s],\t\ttrain_loss: 0.1577,\tval_loss: 0.1428\n",
            "73:\t[0s / 7s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1403\n",
            "74:\t[0s / 7s],\t\ttrain_loss: 0.1543,\tval_loss: 0.1398\n",
            "75:\t[0s / 7s],\t\ttrain_loss: 0.1537,\tval_loss: 0.1407\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.1565,\tval_loss: 0.1423\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.1503,\tval_loss: 0.1404\n",
            "78:\t[0s / 8s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1404\n",
            "79:\t[0s / 8s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1433\n",
            "80:\t[0s / 8s],\t\ttrain_loss: 0.1571,\tval_loss: 0.1409\n",
            "81:\t[0s / 8s],\t\ttrain_loss: 0.1553,\tval_loss: 0.1404\n",
            "82:\t[0s / 8s],\t\ttrain_loss: 0.1586,\tval_loss: 0.1412\n",
            "83:\t[0s / 9s],\t\ttrain_loss: 0.1592,\tval_loss: 0.1416\n",
            "84:\t[0s / 9s],\t\ttrain_loss: 0.1523,\tval_loss: 0.1395\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.1554,\tval_loss: 0.1416\n",
            "86:\t[0s / 9s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1403\n",
            "87:\t[0s / 9s],\t\ttrain_loss: 0.1563,\tval_loss: 0.1402\n",
            "88:\t[0s / 9s],\t\ttrain_loss: 0.1551,\tval_loss: 0.1426\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1417\n",
            "90:\t[0s / 10s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1404\n",
            "91:\t[0s / 10s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1404\n",
            "92:\t[0s / 10s],\t\ttrain_loss: 0.1543,\tval_loss: 0.1423\n",
            "93:\t[0s / 10s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1415\n",
            "94:\t[0s / 10s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1416\n",
            "95:\t[0s / 10s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1429\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.1510,\tval_loss: 0.1421\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1556,\tval_loss: 0.1434\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.1586,\tval_loss: 0.1423\n",
            "99:\t[0s / 11s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1423\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2465,\tval_loss: 0.1602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1845,\tval_loss: 0.1515\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1461\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1515,\tval_loss: 0.1406\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1469,\tval_loss: 0.1399\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1435,\tval_loss: 0.1401\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1392,\tval_loss: 0.1405\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.1435,\tval_loss: 0.1400\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1398,\tval_loss: 0.1418\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1417,\tval_loss: 0.1401\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1407,\tval_loss: 0.1411\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1431,\tval_loss: 0.1402\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1433,\tval_loss: 0.1409\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1426,\tval_loss: 0.1413\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.1466,\tval_loss: 0.1413\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.1415,\tval_loss: 0.1413\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.1465,\tval_loss: 0.1401\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1436,\tval_loss: 0.1407\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1398,\tval_loss: 0.1407\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1432,\tval_loss: 0.1412\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1447,\tval_loss: 0.1416\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1437,\tval_loss: 0.1404\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1448,\tval_loss: 0.1400\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1387,\tval_loss: 0.1427\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1454,\tval_loss: 0.1419\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1443,\tval_loss: 0.1413\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1370,\tval_loss: 0.1449\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1425,\tval_loss: 0.1434\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1430,\tval_loss: 0.1433\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1402\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1463,\tval_loss: 0.1414\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1420,\tval_loss: 0.1422\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1420,\tval_loss: 0.1417\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.1436,\tval_loss: 0.1419\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.1464,\tval_loss: 0.1408\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1439,\tval_loss: 0.1439\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1431,\tval_loss: 0.1417\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1474,\tval_loss: 0.1410\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1471,\tval_loss: 0.1390\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1429,\tval_loss: 0.1400\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1465,\tval_loss: 0.1411\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1416,\tval_loss: 0.1402\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1431,\tval_loss: 0.1398\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1402,\tval_loss: 0.1402\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1437,\tval_loss: 0.1462\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1444,\tval_loss: 0.1414\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1416,\tval_loss: 0.1405\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1438,\tval_loss: 0.1419\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1431,\tval_loss: 0.1414\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1446,\tval_loss: 0.1416\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1463,\tval_loss: 0.1410\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1499,\tval_loss: 0.1422\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.1486,\tval_loss: 0.1406\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.1413,\tval_loss: 0.1405\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.1511,\tval_loss: 0.1399\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.1413,\tval_loss: 0.1424\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1424,\tval_loss: 0.1415\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1441,\tval_loss: 0.1406\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1488,\tval_loss: 0.1400\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1406,\tval_loss: 0.1399\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1413,\tval_loss: 0.1409\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.1431,\tval_loss: 0.1410\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.1410,\tval_loss: 0.1408\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.1411,\tval_loss: 0.1419\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.1418,\tval_loss: 0.1404\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.1394,\tval_loss: 0.1436\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.1428,\tval_loss: 0.1424\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1430,\tval_loss: 0.1404\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1460,\tval_loss: 0.1446\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.1461,\tval_loss: 0.1403\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.1429,\tval_loss: 0.1411\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.1428,\tval_loss: 0.1403\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.1397,\tval_loss: 0.1414\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.1398,\tval_loss: 0.1415\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.1455,\tval_loss: 0.1463\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.1412,\tval_loss: 0.1462\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.1463,\tval_loss: 0.1430\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.1397,\tval_loss: 0.1428\n",
            "78:\t[0s / 8s],\t\ttrain_loss: 0.1443,\tval_loss: 0.1419\n",
            "79:\t[0s / 8s],\t\ttrain_loss: 0.1408,\tval_loss: 0.1422\n",
            "80:\t[0s / 8s],\t\ttrain_loss: 0.1431,\tval_loss: 0.1423\n",
            "81:\t[0s / 9s],\t\ttrain_loss: 0.1445,\tval_loss: 0.1402\n",
            "82:\t[0s / 9s],\t\ttrain_loss: 0.1423,\tval_loss: 0.1408\n",
            "83:\t[0s / 9s],\t\ttrain_loss: 0.1418,\tval_loss: 0.1402\n",
            "84:\t[0s / 9s],\t\ttrain_loss: 0.1448,\tval_loss: 0.1408\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.1419,\tval_loss: 0.1417\n",
            "86:\t[0s / 9s],\t\ttrain_loss: 0.1408,\tval_loss: 0.1408\n",
            "87:\t[0s / 9s],\t\ttrain_loss: 0.1464,\tval_loss: 0.1428\n",
            "88:\t[0s / 9s],\t\ttrain_loss: 0.1462,\tval_loss: 0.1411\n",
            "89:\t[0s / 9s],\t\ttrain_loss: 0.1472,\tval_loss: 0.1416\n",
            "90:\t[0s / 9s],\t\ttrain_loss: 0.1486,\tval_loss: 0.1421\n",
            "91:\t[0s / 10s],\t\ttrain_loss: 0.1477,\tval_loss: 0.1417\n",
            "92:\t[0s / 10s],\t\ttrain_loss: 0.1431,\tval_loss: 0.1443\n",
            "93:\t[0s / 10s],\t\ttrain_loss: 0.1452,\tval_loss: 0.1410\n",
            "94:\t[0s / 10s],\t\ttrain_loss: 0.1428,\tval_loss: 0.1423\n",
            "95:\t[0s / 10s],\t\ttrain_loss: 0.1467,\tval_loss: 0.1431\n",
            "96:\t[0s / 10s],\t\ttrain_loss: 0.1498,\tval_loss: 0.1427\n",
            "97:\t[0s / 10s],\t\ttrain_loss: 0.1467,\tval_loss: 0.1440\n",
            "98:\t[0s / 10s],\t\ttrain_loss: 0.1447,\tval_loss: 0.1431\n",
            "99:\t[0s / 10s],\t\ttrain_loss: 0.1401,\tval_loss: 0.1435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2534,\tval_loss: 0.1510\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2084,\tval_loss: 0.1450\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1802,\tval_loss: 0.1405\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1420\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1670,\tval_loss: 0.1409\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1637,\tval_loss: 0.1402\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1410\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1424\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1401\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1409\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1617,\tval_loss: 0.1402\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1411\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1399\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1406\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1408\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1410\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1397\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1401\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1409\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1399\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1413\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1391\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1398\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1583,\tval_loss: 0.1405\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1636,\tval_loss: 0.1401\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1416\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1390\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.1673,\tval_loss: 0.1410\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.1676,\tval_loss: 0.1402\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1410\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.1694,\tval_loss: 0.1390\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1403\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1678,\tval_loss: 0.1403\n",
            "33:\t[0s / 5s],\t\ttrain_loss: 0.1692,\tval_loss: 0.1421\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1394\n",
            "35:\t[0s / 5s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1400\n",
            "36:\t[0s / 5s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1403\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.1663,\tval_loss: 0.1410\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1408\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1402\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.1596,\tval_loss: 0.1430\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1677,\tval_loss: 0.1405\n",
            "42:\t[0s / 6s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1400\n",
            "43:\t[0s / 6s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1396\n",
            "44:\t[0s / 6s],\t\ttrain_loss: 0.1664,\tval_loss: 0.1394\n",
            "45:\t[0s / 6s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1409\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.1676,\tval_loss: 0.1403\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.1586,\tval_loss: 0.1399\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1412\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1402\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1405\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1592,\tval_loss: 0.1398\n",
            "52:\t[0s / 7s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1400\n",
            "53:\t[0s / 7s],\t\ttrain_loss: 0.1688,\tval_loss: 0.1404\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.1592,\tval_loss: 0.1410\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.1636,\tval_loss: 0.1410\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1406\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.1651,\tval_loss: 0.1417\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.1653,\tval_loss: 0.1414\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1605,\tval_loss: 0.1415\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1400\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.1636,\tval_loss: 0.1405\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.1632,\tval_loss: 0.1398\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1395\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1413\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.1642,\tval_loss: 0.1408\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1393\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1582,\tval_loss: 0.1415\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1637,\tval_loss: 0.1423\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1426\n",
            "70:\t[0s / 9s],\t\ttrain_loss: 0.1632,\tval_loss: 0.1397\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1401\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1399\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.1603,\tval_loss: 0.1415\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1407\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1403\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1555,\tval_loss: 0.1404\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1555,\tval_loss: 0.1400\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1648,\tval_loss: 0.1411\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.1605,\tval_loss: 0.1425\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1396\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.1586,\tval_loss: 0.1405\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1404\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.1637,\tval_loss: 0.1415\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.1624,\tval_loss: 0.1399\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1402\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1574,\tval_loss: 0.1405\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1407\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1562,\tval_loss: 0.1413\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1406\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1413\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.1577,\tval_loss: 0.1425\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.1596,\tval_loss: 0.1397\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1396\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1416\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1406\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1413\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1406\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2331,\tval_loss: 0.1535\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1857,\tval_loss: 0.1430\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1428\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1513,\tval_loss: 0.1414\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1442,\tval_loss: 0.1402\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1415,\tval_loss: 0.1421\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1440,\tval_loss: 0.1404\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1414,\tval_loss: 0.1411\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1406,\tval_loss: 0.1401\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1425,\tval_loss: 0.1403\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1411,\tval_loss: 0.1400\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1419,\tval_loss: 0.1411\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1418,\tval_loss: 0.1402\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1432,\tval_loss: 0.1405\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1418,\tval_loss: 0.1417\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1441,\tval_loss: 0.1405\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1463,\tval_loss: 0.1400\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1473,\tval_loss: 0.1428\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1435,\tval_loss: 0.1428\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1397,\tval_loss: 0.1409\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1438,\tval_loss: 0.1405\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1488,\tval_loss: 0.1409\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1421,\tval_loss: 0.1415\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1491,\tval_loss: 0.1412\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1455,\tval_loss: 0.1403\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1445,\tval_loss: 0.1400\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1448,\tval_loss: 0.1400\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1436,\tval_loss: 0.1412\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1469,\tval_loss: 0.1401\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1462,\tval_loss: 0.1401\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1470,\tval_loss: 0.1397\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1465,\tval_loss: 0.1418\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1457,\tval_loss: 0.1427\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1469,\tval_loss: 0.1410\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1454,\tval_loss: 0.1423\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1492,\tval_loss: 0.1424\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1420\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1432,\tval_loss: 0.1416\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1394\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1492,\tval_loss: 0.1404\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1461,\tval_loss: 0.1409\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1439,\tval_loss: 0.1407\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.1474,\tval_loss: 0.1403\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1392,\tval_loss: 0.1404\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1435,\tval_loss: 0.1402\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1450,\tval_loss: 0.1411\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1465,\tval_loss: 0.1406\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1446,\tval_loss: 0.1398\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1548,\tval_loss: 0.1415\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1537,\tval_loss: 0.1427\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1420\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1445,\tval_loss: 0.1505\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.1483,\tval_loss: 0.1420\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.1479,\tval_loss: 0.1400\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.1513,\tval_loss: 0.1438\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.1476,\tval_loss: 0.1422\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.1498,\tval_loss: 0.1421\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1427\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.1504,\tval_loss: 0.1418\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1501,\tval_loss: 0.1413\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1418\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.1481,\tval_loss: 0.1407\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.1432,\tval_loss: 0.1424\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1423\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.1482,\tval_loss: 0.1421\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.1434,\tval_loss: 0.1407\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1459,\tval_loss: 0.1424\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1477,\tval_loss: 0.1450\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1431,\tval_loss: 0.1425\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1421,\tval_loss: 0.1409\n",
            "70:\t[0s / 9s],\t\ttrain_loss: 0.1456,\tval_loss: 0.1414\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1410\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.1422,\tval_loss: 0.1408\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.1437,\tval_loss: 0.1406\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1411,\tval_loss: 0.1413\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1440,\tval_loss: 0.1408\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1444,\tval_loss: 0.1417\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1449,\tval_loss: 0.1413\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1443,\tval_loss: 0.1411\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.1472,\tval_loss: 0.1419\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.1399,\tval_loss: 0.1408\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.1427,\tval_loss: 0.1418\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.1419,\tval_loss: 0.1396\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.1447,\tval_loss: 0.1403\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.1433,\tval_loss: 0.1411\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.1393,\tval_loss: 0.1408\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1388,\tval_loss: 0.1408\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1385,\tval_loss: 0.1401\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1421,\tval_loss: 0.1405\n",
            "89:\t[0s / 11s],\t\ttrain_loss: 0.1385,\tval_loss: 0.1399\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.1379,\tval_loss: 0.1406\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.1416,\tval_loss: 0.1403\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.1376,\tval_loss: 0.1403\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.1446,\tval_loss: 0.1392\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.1424,\tval_loss: 0.1407\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.1430,\tval_loss: 0.1413\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.1396,\tval_loss: 0.1400\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1442,\tval_loss: 0.1413\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.1447,\tval_loss: 0.1414\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.1410,\tval_loss: 0.1408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2314,\tval_loss: 0.1597\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1911,\tval_loss: 0.1458\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1653,\tval_loss: 0.1408\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1489,\tval_loss: 0.1422\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1425,\tval_loss: 0.1423\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1414,\tval_loss: 0.1404\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1386,\tval_loss: 0.1420\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1424,\tval_loss: 0.1405\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1460,\tval_loss: 0.1412\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1440,\tval_loss: 0.1408\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1447,\tval_loss: 0.1402\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1422,\tval_loss: 0.1406\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1403,\tval_loss: 0.1420\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1401,\tval_loss: 0.1408\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1433,\tval_loss: 0.1423\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1426,\tval_loss: 0.1420\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1394,\tval_loss: 0.1421\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1402,\tval_loss: 0.1430\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.1414,\tval_loss: 0.1412\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1409,\tval_loss: 0.1411\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1425,\tval_loss: 0.1406\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1433,\tval_loss: 0.1423\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1425,\tval_loss: 0.1404\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1397,\tval_loss: 0.1408\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1454,\tval_loss: 0.1404\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1407,\tval_loss: 0.1411\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1416,\tval_loss: 0.1410\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1440,\tval_loss: 0.1411\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1439,\tval_loss: 0.1415\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1392,\tval_loss: 0.1400\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1448,\tval_loss: 0.1453\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1434,\tval_loss: 0.1415\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1409,\tval_loss: 0.1420\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1460,\tval_loss: 0.1398\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1414,\tval_loss: 0.1408\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1455,\tval_loss: 0.1421\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.1421,\tval_loss: 0.1422\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1415,\tval_loss: 0.1406\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1407,\tval_loss: 0.1415\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1420,\tval_loss: 0.1440\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1426,\tval_loss: 0.1402\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1446,\tval_loss: 0.1445\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1453,\tval_loss: 0.1423\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1396,\tval_loss: 0.1428\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1464,\tval_loss: 0.1411\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.1412,\tval_loss: 0.1416\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.1402,\tval_loss: 0.1406\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1403,\tval_loss: 0.1444\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1447,\tval_loss: 0.1410\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1428,\tval_loss: 0.1435\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1467,\tval_loss: 0.1419\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1440,\tval_loss: 0.1457\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1443,\tval_loss: 0.1436\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1423,\tval_loss: 0.1407\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.1406,\tval_loss: 0.1409\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.1426,\tval_loss: 0.1436\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1417,\tval_loss: 0.1407\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1401,\tval_loss: 0.1406\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1479,\tval_loss: 0.1405\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1414,\tval_loss: 0.1393\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1439,\tval_loss: 0.1406\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.1431,\tval_loss: 0.1423\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.1453,\tval_loss: 0.1410\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.1418,\tval_loss: 0.1419\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.1422,\tval_loss: 0.1409\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.1467,\tval_loss: 0.1410\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.1452,\tval_loss: 0.1397\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1458,\tval_loss: 0.1387\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1464,\tval_loss: 0.1391\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1399\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.1465,\tval_loss: 0.1401\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.1439,\tval_loss: 0.1428\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.1442,\tval_loss: 0.1396\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.1497,\tval_loss: 0.1406\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.1449,\tval_loss: 0.1431\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.1437,\tval_loss: 0.1427\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1425,\tval_loss: 0.1449\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1421,\tval_loss: 0.1417\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1464,\tval_loss: 0.1397\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.1407,\tval_loss: 0.1415\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.1458,\tval_loss: 0.1405\n",
            "81:\t[0s / 9s],\t\ttrain_loss: 0.1427,\tval_loss: 0.1395\n",
            "82:\t[0s / 9s],\t\ttrain_loss: 0.1434,\tval_loss: 0.1407\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.1406,\tval_loss: 0.1448\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.1438,\tval_loss: 0.1390\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.1470,\tval_loss: 0.1393\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1474,\tval_loss: 0.1413\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1399,\tval_loss: 0.1411\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1420,\tval_loss: 0.1422\n",
            "89:\t[0s / 11s],\t\ttrain_loss: 0.1426,\tval_loss: 0.1409\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.1442,\tval_loss: 0.1413\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.1428,\tval_loss: 0.1417\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.1405,\tval_loss: 0.1402\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.1434,\tval_loss: 0.1400\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.1477,\tval_loss: 0.1383\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.1447,\tval_loss: 0.1402\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.1405,\tval_loss: 0.1429\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1421,\tval_loss: 0.1431\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.1444,\tval_loss: 0.1391\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.1450,\tval_loss: 0.1407\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2513,\tval_loss: 0.1503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2430,\tval_loss: 0.1465\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1972,\tval_loss: 0.1417\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1769,\tval_loss: 0.1426\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1757,\tval_loss: 0.1430\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1701,\tval_loss: 0.1414\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1712,\tval_loss: 0.1418\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1684,\tval_loss: 0.1422\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1700,\tval_loss: 0.1432\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1719,\tval_loss: 0.1417\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1670,\tval_loss: 0.1421\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1673,\tval_loss: 0.1410\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1779,\tval_loss: 0.1419\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1714,\tval_loss: 0.1421\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1714,\tval_loss: 0.1416\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1695,\tval_loss: 0.1421\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1676,\tval_loss: 0.1415\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1696,\tval_loss: 0.1428\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1701,\tval_loss: 0.1410\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1708,\tval_loss: 0.1425\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1740,\tval_loss: 0.1427\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1688,\tval_loss: 0.1422\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1709,\tval_loss: 0.1425\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1733,\tval_loss: 0.1429\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1692,\tval_loss: 0.1410\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1728,\tval_loss: 0.1423\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1711,\tval_loss: 0.1406\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1738,\tval_loss: 0.1423\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1765,\tval_loss: 0.1410\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1736,\tval_loss: 0.1433\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1776,\tval_loss: 0.1442\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1741,\tval_loss: 0.1437\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1721,\tval_loss: 0.1411\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1710,\tval_loss: 0.1404\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1733,\tval_loss: 0.1425\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1724,\tval_loss: 0.1438\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.1698,\tval_loss: 0.1412\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.1738,\tval_loss: 0.1425\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1747,\tval_loss: 0.1413\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1690,\tval_loss: 0.1421\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1769,\tval_loss: 0.1401\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1684,\tval_loss: 0.1436\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1742,\tval_loss: 0.1408\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1758,\tval_loss: 0.1421\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1759,\tval_loss: 0.1418\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.1690,\tval_loss: 0.1416\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.1711,\tval_loss: 0.1422\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1708,\tval_loss: 0.1402\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1719,\tval_loss: 0.1448\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1699,\tval_loss: 0.1415\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1708,\tval_loss: 0.1410\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1748,\tval_loss: 0.1429\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1749,\tval_loss: 0.1436\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1721,\tval_loss: 0.1414\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.1680,\tval_loss: 0.1420\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.1707,\tval_loss: 0.1412\n",
            "56:\t[0s / 5s],\t\ttrain_loss: 0.1724,\tval_loss: 0.1421\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1725,\tval_loss: 0.1428\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1715,\tval_loss: 0.1444\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1741,\tval_loss: 0.1416\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1708,\tval_loss: 0.1414\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.1761,\tval_loss: 0.1422\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.1745,\tval_loss: 0.1425\n",
            "63:\t[0s / 6s],\t\ttrain_loss: 0.1712,\tval_loss: 0.1414\n",
            "64:\t[0s / 6s],\t\ttrain_loss: 0.1694,\tval_loss: 0.1426\n",
            "65:\t[0s / 6s],\t\ttrain_loss: 0.1700,\tval_loss: 0.1413\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.1718,\tval_loss: 0.1403\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1702,\tval_loss: 0.1435\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1661,\tval_loss: 0.1414\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.1721,\tval_loss: 0.1426\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.1730,\tval_loss: 0.1408\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.1719,\tval_loss: 0.1433\n",
            "72:\t[0s / 7s],\t\ttrain_loss: 0.1727,\tval_loss: 0.1431\n",
            "73:\t[0s / 7s],\t\ttrain_loss: 0.1718,\tval_loss: 0.1413\n",
            "74:\t[0s / 7s],\t\ttrain_loss: 0.1734,\tval_loss: 0.1438\n",
            "75:\t[0s / 7s],\t\ttrain_loss: 0.1737,\tval_loss: 0.1404\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.1687,\tval_loss: 0.1418\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.1710,\tval_loss: 0.1410\n",
            "78:\t[0s / 8s],\t\ttrain_loss: 0.1750,\tval_loss: 0.1430\n",
            "79:\t[0s / 8s],\t\ttrain_loss: 0.1743,\tval_loss: 0.1414\n",
            "80:\t[0s / 8s],\t\ttrain_loss: 0.1698,\tval_loss: 0.1416\n",
            "81:\t[0s / 8s],\t\ttrain_loss: 0.1696,\tval_loss: 0.1410\n",
            "82:\t[0s / 8s],\t\ttrain_loss: 0.1676,\tval_loss: 0.1418\n",
            "83:\t[0s / 8s],\t\ttrain_loss: 0.1719,\tval_loss: 0.1401\n",
            "84:\t[0s / 8s],\t\ttrain_loss: 0.1709,\tval_loss: 0.1403\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.1725,\tval_loss: 0.1424\n",
            "86:\t[0s / 9s],\t\ttrain_loss: 0.1738,\tval_loss: 0.1422\n",
            "87:\t[0s / 9s],\t\ttrain_loss: 0.1748,\tval_loss: 0.1420\n",
            "88:\t[0s / 9s],\t\ttrain_loss: 0.1693,\tval_loss: 0.1399\n",
            "89:\t[0s / 9s],\t\ttrain_loss: 0.1698,\tval_loss: 0.1415\n",
            "90:\t[0s / 9s],\t\ttrain_loss: 0.1693,\tval_loss: 0.1418\n",
            "91:\t[0s / 9s],\t\ttrain_loss: 0.1717,\tval_loss: 0.1403\n",
            "92:\t[0s / 10s],\t\ttrain_loss: 0.1663,\tval_loss: 0.1408\n",
            "93:\t[0s / 10s],\t\ttrain_loss: 0.1699,\tval_loss: 0.1424\n",
            "94:\t[0s / 10s],\t\ttrain_loss: 0.1715,\tval_loss: 0.1405\n",
            "95:\t[0s / 10s],\t\ttrain_loss: 0.1678,\tval_loss: 0.1431\n",
            "96:\t[0s / 10s],\t\ttrain_loss: 0.1722,\tval_loss: 0.1406\n",
            "97:\t[0s / 10s],\t\ttrain_loss: 0.1705,\tval_loss: 0.1410\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.1675,\tval_loss: 0.1415\n",
            "99:\t[0s / 11s],\t\ttrain_loss: 0.1717,\tval_loss: 0.1419\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2525,\tval_loss: 0.1466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2081,\tval_loss: 0.1397\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1726,\tval_loss: 0.1422\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1606,\tval_loss: 0.1408\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1404\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1409\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1406\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.1539,\tval_loss: 0.1412\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1559,\tval_loss: 0.1416\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1405\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1565,\tval_loss: 0.1404\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1553,\tval_loss: 0.1397\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1584,\tval_loss: 0.1404\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.1587,\tval_loss: 0.1409\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.1597,\tval_loss: 0.1418\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1398\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.1632,\tval_loss: 0.1394\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1574,\tval_loss: 0.1404\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1583,\tval_loss: 0.1402\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1403\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1419\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1406\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1397\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1403\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1403\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1582,\tval_loss: 0.1407\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1404\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1582,\tval_loss: 0.1398\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1398\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.1559,\tval_loss: 0.1393\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.1531,\tval_loss: 0.1395\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1398\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1400\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.1597,\tval_loss: 0.1403\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.1539,\tval_loss: 0.1412\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1543,\tval_loss: 0.1401\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1586,\tval_loss: 0.1395\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1396\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1553,\tval_loss: 0.1416\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1402\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.1552,\tval_loss: 0.1427\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1421\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.1571,\tval_loss: 0.1417\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1423\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1391\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1411\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1537,\tval_loss: 0.1421\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1565,\tval_loss: 0.1410\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1398\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1396\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1414\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1387\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1401\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1430\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.1584,\tval_loss: 0.1416\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1416\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1557,\tval_loss: 0.1456\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1410\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1402\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1563,\tval_loss: 0.1393\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1395\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.1579,\tval_loss: 0.1407\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1434\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1407\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1417\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.1600,\tval_loss: 0.1417\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1430\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1405\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1404\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1429\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1464\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.1602,\tval_loss: 0.1434\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1422\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1438\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1413\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.1570,\tval_loss: 0.1453\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.1562,\tval_loss: 0.1438\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1430\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1419\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.1548,\tval_loss: 0.1427\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1408\n",
            "81:\t[0s / 9s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1417\n",
            "82:\t[0s / 9s],\t\ttrain_loss: 0.1566,\tval_loss: 0.1439\n",
            "83:\t[0s / 9s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1465\n",
            "84:\t[0s / 9s],\t\ttrain_loss: 0.1629,\tval_loss: 0.1458\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1490\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1454\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1488\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1584,\tval_loss: 0.1464\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.1567,\tval_loss: 0.1435\n",
            "90:\t[0s / 10s],\t\ttrain_loss: 0.1510,\tval_loss: 0.1445\n",
            "91:\t[0s / 10s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1426\n",
            "92:\t[0s / 10s],\t\ttrain_loss: 0.1539,\tval_loss: 0.1437\n",
            "93:\t[0s / 10s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1440\n",
            "94:\t[0s / 10s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1420\n",
            "95:\t[0s / 10s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1454\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1444\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1586,\tval_loss: 0.1453\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1488\n",
            "99:\t[0s / 11s],\t\ttrain_loss: 0.1562,\tval_loss: 0.1453\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2508,\tval_loss: 0.1510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2279,\tval_loss: 0.1455\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1765,\tval_loss: 0.1422\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1730,\tval_loss: 0.1423\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1421\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1648,\tval_loss: 0.1411\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1648,\tval_loss: 0.1413\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1428\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1413\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1666,\tval_loss: 0.1421\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1629,\tval_loss: 0.1415\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1641,\tval_loss: 0.1409\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1677,\tval_loss: 0.1410\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1679,\tval_loss: 0.1418\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1650,\tval_loss: 0.1429\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1417\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.1624,\tval_loss: 0.1423\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1423\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1415\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1426\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1414\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1428\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1406\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1669,\tval_loss: 0.1423\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1679,\tval_loss: 0.1437\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1621,\tval_loss: 0.1414\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1652,\tval_loss: 0.1423\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1674,\tval_loss: 0.1443\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1661,\tval_loss: 0.1420\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1659,\tval_loss: 0.1414\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.1683,\tval_loss: 0.1407\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.1684,\tval_loss: 0.1438\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1671,\tval_loss: 0.1426\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.1633,\tval_loss: 0.1427\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.1723,\tval_loss: 0.1408\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1706,\tval_loss: 0.1442\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1688,\tval_loss: 0.1417\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.1697,\tval_loss: 0.1434\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1417\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.1674,\tval_loss: 0.1437\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.1720,\tval_loss: 0.1438\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1682,\tval_loss: 0.1422\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.1682,\tval_loss: 0.1430\n",
            "43:\t[0s / 6s],\t\ttrain_loss: 0.1670,\tval_loss: 0.1427\n",
            "44:\t[0s / 6s],\t\ttrain_loss: 0.1674,\tval_loss: 0.1415\n",
            "45:\t[0s / 6s],\t\ttrain_loss: 0.1648,\tval_loss: 0.1422\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.1702,\tval_loss: 0.1432\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.1711,\tval_loss: 0.1412\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.1705,\tval_loss: 0.1440\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1691,\tval_loss: 0.1430\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1679,\tval_loss: 0.1431\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1686,\tval_loss: 0.1435\n",
            "52:\t[0s / 7s],\t\ttrain_loss: 0.1737,\tval_loss: 0.1433\n",
            "53:\t[0s / 7s],\t\ttrain_loss: 0.1648,\tval_loss: 0.1425\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.1658,\tval_loss: 0.1453\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.1700,\tval_loss: 0.1414\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.1689,\tval_loss: 0.1414\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.1698,\tval_loss: 0.1432\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.1725,\tval_loss: 0.1416\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1684,\tval_loss: 0.1429\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.1669,\tval_loss: 0.1434\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.1693,\tval_loss: 0.1440\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.1652,\tval_loss: 0.1446\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.1674,\tval_loss: 0.1430\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.1673,\tval_loss: 0.1428\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.1695,\tval_loss: 0.1427\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1675,\tval_loss: 0.1460\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1729,\tval_loss: 0.1430\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1705,\tval_loss: 0.1445\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1760,\tval_loss: 0.1437\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.1715,\tval_loss: 0.1434\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.1723,\tval_loss: 0.1455\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.1699,\tval_loss: 0.1456\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.1794,\tval_loss: 0.1422\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1698,\tval_loss: 0.1464\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1668,\tval_loss: 0.1454\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1677,\tval_loss: 0.1420\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1706,\tval_loss: 0.1444\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1726,\tval_loss: 0.1429\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.1752,\tval_loss: 0.1453\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.1751,\tval_loss: 0.1457\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.1655,\tval_loss: 0.1443\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.1678,\tval_loss: 0.1506\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.1774,\tval_loss: 0.1430\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.1736,\tval_loss: 0.1443\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.1711,\tval_loss: 0.1465\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1798,\tval_loss: 0.1438\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1663,\tval_loss: 0.1468\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1711,\tval_loss: 0.1464\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.1680,\tval_loss: 0.1436\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.1701,\tval_loss: 0.1453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2293,\tval_loss: 0.1554\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2028,\tval_loss: 0.1428\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1421\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1403\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1479,\tval_loss: 0.1417\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1496,\tval_loss: 0.1405\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1486,\tval_loss: 0.1400\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1483,\tval_loss: 0.1406\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1530,\tval_loss: 0.1404\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1434,\tval_loss: 0.1421\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1449,\tval_loss: 0.1427\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1456,\tval_loss: 0.1407\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1470,\tval_loss: 0.1395\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1461,\tval_loss: 0.1411\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1473,\tval_loss: 0.1398\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1497,\tval_loss: 0.1408\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1456,\tval_loss: 0.1412\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1452,\tval_loss: 0.1399\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.1471,\tval_loss: 0.1402\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1468,\tval_loss: 0.1428\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1486,\tval_loss: 0.1415\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1499,\tval_loss: 0.1404\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1463,\tval_loss: 0.1402\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1405\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1504,\tval_loss: 0.1398\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1488,\tval_loss: 0.1397\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1498,\tval_loss: 0.1410\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1469,\tval_loss: 0.1397\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1491,\tval_loss: 0.1404\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1408\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1464,\tval_loss: 0.1411\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1390\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1485,\tval_loss: 0.1410\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1406\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1501,\tval_loss: 0.1412\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1485,\tval_loss: 0.1404\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.1478,\tval_loss: 0.1397\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.1463,\tval_loss: 0.1410\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1500,\tval_loss: 0.1397\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1411\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1433,\tval_loss: 0.1403\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1492,\tval_loss: 0.1404\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1514,\tval_loss: 0.1414\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1476,\tval_loss: 0.1393\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1470,\tval_loss: 0.1425\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.1485,\tval_loss: 0.1408\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.1460,\tval_loss: 0.1418\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1487,\tval_loss: 0.1395\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1468,\tval_loss: 0.1395\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1443,\tval_loss: 0.1401\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1474,\tval_loss: 0.1400\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1443,\tval_loss: 0.1435\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1508,\tval_loss: 0.1410\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1514,\tval_loss: 0.1398\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.1507,\tval_loss: 0.1402\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1394\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1499,\tval_loss: 0.1399\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1471,\tval_loss: 0.1427\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1399\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1471,\tval_loss: 0.1397\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1462,\tval_loss: 0.1393\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.1446,\tval_loss: 0.1398\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.1488,\tval_loss: 0.1398\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.1458,\tval_loss: 0.1397\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.1446,\tval_loss: 0.1412\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.1437,\tval_loss: 0.1413\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.1492,\tval_loss: 0.1405\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1518,\tval_loss: 0.1392\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1478,\tval_loss: 0.1416\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1489,\tval_loss: 0.1411\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1433\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.1557,\tval_loss: 0.1408\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.1491,\tval_loss: 0.1400\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.1434,\tval_loss: 0.1421\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1455,\tval_loss: 0.1413\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1462,\tval_loss: 0.1420\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1505,\tval_loss: 0.1396\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1505,\tval_loss: 0.1405\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1505,\tval_loss: 0.1400\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.1489,\tval_loss: 0.1407\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.1436,\tval_loss: 0.1399\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.1451,\tval_loss: 0.1402\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.1459,\tval_loss: 0.1414\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.1447,\tval_loss: 0.1389\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.1500,\tval_loss: 0.1404\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.1443,\tval_loss: 0.1411\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1447,\tval_loss: 0.1408\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1491,\tval_loss: 0.1412\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1441\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.1507,\tval_loss: 0.1404\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.1516,\tval_loss: 0.1386\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.1468,\tval_loss: 0.1426\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.1483,\tval_loss: 0.1415\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.1521,\tval_loss: 0.1427\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1397\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1428\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.1489,\tval_loss: 0.1448\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1515,\tval_loss: 0.1419\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.1498,\tval_loss: 0.1409\n",
            "99:\t[0s / 11s],\t\ttrain_loss: 0.1481,\tval_loss: 0.1448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2474,\tval_loss: 0.1589\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2268,\tval_loss: 0.1458\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1736,\tval_loss: 0.1413\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1648,\tval_loss: 0.1401\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1674,\tval_loss: 0.1403\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1408\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1584,\tval_loss: 0.1404\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1411\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1399\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1404\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1400\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1603,\tval_loss: 0.1404\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1404\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1396\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1403\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1563,\tval_loss: 0.1401\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1393\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1582,\tval_loss: 0.1392\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1393\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1584,\tval_loss: 0.1392\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1591,\tval_loss: 0.1415\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1398\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1403\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1617,\tval_loss: 0.1399\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1388\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1555,\tval_loss: 0.1393\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1399\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1591,\tval_loss: 0.1397\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1397\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1399\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1386\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1402\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1562,\tval_loss: 0.1397\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1405\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1404\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1402\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1412\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.1596,\tval_loss: 0.1422\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1660,\tval_loss: 0.1396\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1404\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1629,\tval_loss: 0.1386\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1406\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1400\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1392\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1587,\tval_loss: 0.1397\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1388\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.1557,\tval_loss: 0.1399\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1637,\tval_loss: 0.1391\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1596,\tval_loss: 0.1395\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1643,\tval_loss: 0.1386\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1394\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1394\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1379\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1650,\tval_loss: 0.1408\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1379\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.1643,\tval_loss: 0.1396\n",
            "56:\t[0s / 5s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1394\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1383\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1395\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1396\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1377\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1393\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1396\n",
            "63:\t[0s / 6s],\t\ttrain_loss: 0.1641,\tval_loss: 0.1405\n",
            "64:\t[0s / 6s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1389\n",
            "65:\t[0s / 6s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1385\n",
            "66:\t[0s / 6s],\t\ttrain_loss: 0.1652,\tval_loss: 0.1380\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1565,\tval_loss: 0.1383\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1587,\tval_loss: 0.1396\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.1600,\tval_loss: 0.1397\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1391\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.1591,\tval_loss: 0.1407\n",
            "72:\t[0s / 7s],\t\ttrain_loss: 0.1596,\tval_loss: 0.1381\n",
            "73:\t[0s / 7s],\t\ttrain_loss: 0.1639,\tval_loss: 0.1396\n",
            "74:\t[0s / 7s],\t\ttrain_loss: 0.1607,\tval_loss: 0.1400\n",
            "75:\t[0s / 7s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1386\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.1624,\tval_loss: 0.1394\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1405\n",
            "78:\t[0s / 8s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1388\n",
            "79:\t[0s / 8s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1395\n",
            "80:\t[0s / 8s],\t\ttrain_loss: 0.1635,\tval_loss: 0.1414\n",
            "81:\t[0s / 8s],\t\ttrain_loss: 0.1552,\tval_loss: 0.1400\n",
            "82:\t[0s / 8s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1386\n",
            "83:\t[0s / 9s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1397\n",
            "84:\t[0s / 9s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1382\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1396\n",
            "86:\t[0s / 9s],\t\ttrain_loss: 0.1605,\tval_loss: 0.1394\n",
            "87:\t[0s / 9s],\t\ttrain_loss: 0.1551,\tval_loss: 0.1390\n",
            "88:\t[0s / 9s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1396\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1405\n",
            "90:\t[0s / 10s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1425\n",
            "91:\t[0s / 10s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1401\n",
            "92:\t[0s / 10s],\t\ttrain_loss: 0.1637,\tval_loss: 0.1404\n",
            "93:\t[0s / 10s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1407\n",
            "94:\t[0s / 10s],\t\ttrain_loss: 0.1579,\tval_loss: 0.1398\n",
            "95:\t[0s / 10s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1430\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.1621,\tval_loss: 0.1396\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1406\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.1691,\tval_loss: 0.1417\n",
            "99:\t[0s / 11s],\t\ttrain_loss: 0.1636,\tval_loss: 0.1392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2355,\tval_loss: 0.1587\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1964,\tval_loss: 0.1411\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1717,\tval_loss: 0.1458\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1577,\tval_loss: 0.1418\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1416\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1427\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1412\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1412\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1552,\tval_loss: 0.1416\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1541,\tval_loss: 0.1420\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1407\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1510,\tval_loss: 0.1419\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1503,\tval_loss: 0.1406\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1413\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.1494,\tval_loss: 0.1408\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.1512,\tval_loss: 0.1402\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.1521,\tval_loss: 0.1417\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1403\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1424\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1423\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1405\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1417\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1410\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1411\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1525,\tval_loss: 0.1409\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1570,\tval_loss: 0.1404\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1412\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1395\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1556,\tval_loss: 0.1434\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1395\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1579,\tval_loss: 0.1418\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1406\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1539,\tval_loss: 0.1427\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1424\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1417\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1448\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1507,\tval_loss: 0.1430\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1410\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1418\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1408\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1521,\tval_loss: 0.1417\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1418\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1397\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1505,\tval_loss: 0.1428\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1419\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1551,\tval_loss: 0.1404\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1553,\tval_loss: 0.1408\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1433\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1570,\tval_loss: 0.1412\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1432\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1409\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1413\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1412\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1421\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.1521,\tval_loss: 0.1414\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1419\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1412\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1412\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1508,\tval_loss: 0.1411\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1513,\tval_loss: 0.1411\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.1539,\tval_loss: 0.1424\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.1543,\tval_loss: 0.1417\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.1537,\tval_loss: 0.1413\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1431\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1442\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1416\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1427\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1434\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1562,\tval_loss: 0.1424\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1422\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1423\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.1523,\tval_loss: 0.1413\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.1541,\tval_loss: 0.1421\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1442\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1410\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1418\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1443\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1587,\tval_loss: 0.1411\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1508,\tval_loss: 0.1417\n",
            "79:\t[0s / 10s],\t\ttrain_loss: 0.1526,\tval_loss: 0.1426\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.1534,\tval_loss: 0.1420\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.1534,\tval_loss: 0.1433\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1427\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1443\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.1531,\tval_loss: 0.1423\n",
            "85:\t[0s / 11s],\t\ttrain_loss: 0.1530,\tval_loss: 0.1420\n",
            "86:\t[0s / 11s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1436\n",
            "87:\t[0s / 11s],\t\ttrain_loss: 0.1515,\tval_loss: 0.1410\n",
            "88:\t[0s / 11s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1475\n",
            "89:\t[0s / 11s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1453\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1434\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.1523,\tval_loss: 0.1436\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.1551,\tval_loss: 0.1432\n",
            "93:\t[0s / 12s],\t\ttrain_loss: 0.1553,\tval_loss: 0.1439\n",
            "94:\t[0s / 12s],\t\ttrain_loss: 0.1525,\tval_loss: 0.1433\n",
            "95:\t[0s / 12s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1441\n",
            "96:\t[0s / 12s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1436\n",
            "97:\t[0s / 12s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2189,\tval_loss: 0.1677\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2007,\tval_loss: 0.1443\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1422\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1507,\tval_loss: 0.1424\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1403,\tval_loss: 0.1421\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1432,\tval_loss: 0.1410\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1455,\tval_loss: 0.1414\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.1455,\tval_loss: 0.1411\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1401,\tval_loss: 0.1405\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1393,\tval_loss: 0.1417\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1437,\tval_loss: 0.1414\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1435,\tval_loss: 0.1407\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1401,\tval_loss: 0.1415\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.1423,\tval_loss: 0.1404\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.1423,\tval_loss: 0.1426\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.1406,\tval_loss: 0.1410\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.1428,\tval_loss: 0.1413\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1418,\tval_loss: 0.1405\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1439,\tval_loss: 0.1404\n",
            "19:\t[0s / 3s],\t\ttrain_loss: 0.1368,\tval_loss: 0.1414\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.1440,\tval_loss: 0.1406\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.1435,\tval_loss: 0.1425\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.1447,\tval_loss: 0.1401\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1398,\tval_loss: 0.1437\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1447,\tval_loss: 0.1413\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1425,\tval_loss: 0.1430\n",
            "26:\t[0s / 4s],\t\ttrain_loss: 0.1433,\tval_loss: 0.1448\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.1479,\tval_loss: 0.1437\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.1490,\tval_loss: 0.1435\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.1451,\tval_loss: 0.1412\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.1409,\tval_loss: 0.1427\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.1451,\tval_loss: 0.1416\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1385,\tval_loss: 0.1406\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.1403,\tval_loss: 0.1422\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.1462,\tval_loss: 0.1403\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1449,\tval_loss: 0.1429\n",
            "36:\t[0s / 5s],\t\ttrain_loss: 0.1422,\tval_loss: 0.1412\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.1419,\tval_loss: 0.1438\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.1443,\tval_loss: 0.1400\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.1461,\tval_loss: 0.1439\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.1443,\tval_loss: 0.1427\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1417,\tval_loss: 0.1413\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.1373,\tval_loss: 0.1434\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1388,\tval_loss: 0.1413\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1461,\tval_loss: 0.1410\n",
            "45:\t[0s / 6s],\t\ttrain_loss: 0.1444,\tval_loss: 0.1420\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.1453,\tval_loss: 0.1424\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.1422,\tval_loss: 0.1445\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.1458,\tval_loss: 0.1437\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1436,\tval_loss: 0.1402\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1427\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1461,\tval_loss: 0.1422\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.1487,\tval_loss: 0.1419\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.1439,\tval_loss: 0.1397\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.1436,\tval_loss: 0.1446\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.1461,\tval_loss: 0.1420\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.1422,\tval_loss: 0.1403\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.1446,\tval_loss: 0.1429\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.1407,\tval_loss: 0.1445\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1405,\tval_loss: 0.1409\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.1415,\tval_loss: 0.1414\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.1433,\tval_loss: 0.1422\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.1494,\tval_loss: 0.1413\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.1437,\tval_loss: 0.1438\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.1408,\tval_loss: 0.1419\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.1410,\tval_loss: 0.1422\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1394,\tval_loss: 0.1420\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1420,\tval_loss: 0.1425\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1392,\tval_loss: 0.1407\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1447,\tval_loss: 0.1437\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.1418,\tval_loss: 0.1416\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.1450,\tval_loss: 0.1435\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.1420,\tval_loss: 0.1411\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.1433,\tval_loss: 0.1416\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1414,\tval_loss: 0.1416\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1442,\tval_loss: 0.1413\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1404,\tval_loss: 0.1433\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1398,\tval_loss: 0.1460\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1389,\tval_loss: 0.1438\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.1414,\tval_loss: 0.1432\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.1459,\tval_loss: 0.1428\n",
            "81:\t[0s / 9s],\t\ttrain_loss: 0.1458,\tval_loss: 0.1454\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.1477,\tval_loss: 0.1442\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.1433,\tval_loss: 0.1449\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.1406,\tval_loss: 0.1487\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.1417,\tval_loss: 0.1486\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1483,\tval_loss: 0.1504\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1526,\tval_loss: 0.1515\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1494,\tval_loss: 0.1473\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.1470,\tval_loss: 0.1471\n",
            "90:\t[0s / 10s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1455\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1430\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.1567,\tval_loss: 0.1478\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1498\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.1496,\tval_loss: 0.1467\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.1443,\tval_loss: 0.1469\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1498\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1518,\tval_loss: 0.1461\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.1563,\tval_loss: 0.1471\n",
            "99:\t[0s / 11s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1502\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2446,\tval_loss: 0.1572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2181,\tval_loss: 0.1428\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1717,\tval_loss: 0.1429\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1680,\tval_loss: 0.1416\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1662,\tval_loss: 0.1412\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1596,\tval_loss: 0.1407\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1643,\tval_loss: 0.1412\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1407\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1629,\tval_loss: 0.1415\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1407\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1424\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1411\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1413\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1413\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1418\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1408\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1414\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1413\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1412\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1436\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1656,\tval_loss: 0.1402\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1413\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1418\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1416\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1411\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1642,\tval_loss: 0.1431\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1639,\tval_loss: 0.1415\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1427\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1662,\tval_loss: 0.1426\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1677,\tval_loss: 0.1413\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1415\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1425\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1414\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.1667,\tval_loss: 0.1430\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.1602,\tval_loss: 0.1418\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1415\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1424\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1413\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.1674,\tval_loss: 0.1425\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.1583,\tval_loss: 0.1416\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1414\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1413\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1415\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1567,\tval_loss: 0.1405\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1415\n",
            "45:\t[0s / 6s],\t\ttrain_loss: 0.1644,\tval_loss: 0.1414\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.1592,\tval_loss: 0.1421\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.1655,\tval_loss: 0.1429\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.1662,\tval_loss: 0.1422\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1659,\tval_loss: 0.1437\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1642,\tval_loss: 0.1430\n",
            "51:\t[0s / 7s],\t\ttrain_loss: 0.1663,\tval_loss: 0.1432\n",
            "52:\t[0s / 7s],\t\ttrain_loss: 0.1586,\tval_loss: 0.1430\n",
            "53:\t[0s / 7s],\t\ttrain_loss: 0.1621,\tval_loss: 0.1411\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1436\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.1666,\tval_loss: 0.1430\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.1629,\tval_loss: 0.1432\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.1654,\tval_loss: 0.1444\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.1650,\tval_loss: 0.1430\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1428\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1424\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.1673,\tval_loss: 0.1433\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.1585,\tval_loss: 0.1430\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.1661,\tval_loss: 0.1435\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.1644,\tval_loss: 0.1419\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.1658,\tval_loss: 0.1428\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1661,\tval_loss: 0.1446\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1656,\tval_loss: 0.1447\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1602,\tval_loss: 0.1413\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1432\n",
            "70:\t[0s / 9s],\t\ttrain_loss: 0.1660,\tval_loss: 0.1416\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.1607,\tval_loss: 0.1434\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.1591,\tval_loss: 0.1426\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1425\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1430\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1416\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1642,\tval_loss: 0.1426\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1430\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1574,\tval_loss: 0.1427\n",
            "79:\t[0s / 10s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1426\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.1610,\tval_loss: 0.1424\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.1587,\tval_loss: 0.1419\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1425\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1439\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1421\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1428\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1424\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1423\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2625,\tval_loss: 0.1708\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2229,\tval_loss: 0.1424\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1813,\tval_loss: 0.1413\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1742,\tval_loss: 0.1408\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1692,\tval_loss: 0.1401\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1678,\tval_loss: 0.1413\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1660,\tval_loss: 0.1408\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1644,\tval_loss: 0.1401\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1643,\tval_loss: 0.1406\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1723,\tval_loss: 0.1402\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1404\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1397\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1687,\tval_loss: 0.1401\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1657,\tval_loss: 0.1401\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1650,\tval_loss: 0.1401\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1686,\tval_loss: 0.1402\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1665,\tval_loss: 0.1396\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1417\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1652,\tval_loss: 0.1397\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1678,\tval_loss: 0.1399\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1659,\tval_loss: 0.1393\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1659,\tval_loss: 0.1406\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1698,\tval_loss: 0.1393\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1709,\tval_loss: 0.1407\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1652,\tval_loss: 0.1406\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1687,\tval_loss: 0.1407\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1707,\tval_loss: 0.1398\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1660,\tval_loss: 0.1394\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1727,\tval_loss: 0.1395\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1632,\tval_loss: 0.1405\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1682,\tval_loss: 0.1399\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1621,\tval_loss: 0.1392\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1695,\tval_loss: 0.1398\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1401\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1644,\tval_loss: 0.1402\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1655,\tval_loss: 0.1393\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.1652,\tval_loss: 0.1418\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1632,\tval_loss: 0.1396\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1671,\tval_loss: 0.1404\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1701,\tval_loss: 0.1401\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1730,\tval_loss: 0.1400\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1632,\tval_loss: 0.1397\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1679,\tval_loss: 0.1396\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1664,\tval_loss: 0.1401\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1668,\tval_loss: 0.1407\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.1639,\tval_loss: 0.1401\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1685,\tval_loss: 0.1399\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1610,\tval_loss: 0.1406\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1667,\tval_loss: 0.1389\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1676,\tval_loss: 0.1394\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1674,\tval_loss: 0.1405\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1734,\tval_loss: 0.1395\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1396\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1678,\tval_loss: 0.1401\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.1637,\tval_loss: 0.1386\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.1726,\tval_loss: 0.1391\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1684,\tval_loss: 0.1399\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1712,\tval_loss: 0.1393\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1672,\tval_loss: 0.1404\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1666,\tval_loss: 0.1394\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1685,\tval_loss: 0.1411\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.1719,\tval_loss: 0.1403\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.1655,\tval_loss: 0.1404\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.1683,\tval_loss: 0.1400\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.1654,\tval_loss: 0.1399\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1392\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.1642,\tval_loss: 0.1392\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1394\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1683,\tval_loss: 0.1408\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1680,\tval_loss: 0.1410\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.1651,\tval_loss: 0.1398\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.1673,\tval_loss: 0.1385\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1400\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.1687,\tval_loss: 0.1407\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1401\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1671,\tval_loss: 0.1384\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1656,\tval_loss: 0.1416\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1663,\tval_loss: 0.1408\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1639,\tval_loss: 0.1389\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1414\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.1688,\tval_loss: 0.1388\n",
            "81:\t[0s / 9s],\t\ttrain_loss: 0.1695,\tval_loss: 0.1389\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.1669,\tval_loss: 0.1407\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.1624,\tval_loss: 0.1393\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.1682,\tval_loss: 0.1421\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.1675,\tval_loss: 0.1406\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1716,\tval_loss: 0.1404\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1639,\tval_loss: 0.1400\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1688,\tval_loss: 0.1404\n",
            "89:\t[0s / 11s],\t\ttrain_loss: 0.1665,\tval_loss: 0.1400\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.1642,\tval_loss: 0.1419\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.1694,\tval_loss: 0.1394\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.1655,\tval_loss: 0.1395\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.1677,\tval_loss: 0.1393\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.1654,\tval_loss: 0.1401\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.1632,\tval_loss: 0.1408\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1419\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1660,\tval_loss: 0.1404\n",
            "98:\t[0s / 12s],\t\ttrain_loss: 0.1639,\tval_loss: 0.1409\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.1607,\tval_loss: 0.1393\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2459,\tval_loss: 0.1525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2118,\tval_loss: 0.1469\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1805,\tval_loss: 0.1412\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1400\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1404\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1404\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1404\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1403\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1644,\tval_loss: 0.1398\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1624,\tval_loss: 0.1403\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1403\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1391\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1394\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1395\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1656,\tval_loss: 0.1402\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1401\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1680,\tval_loss: 0.1400\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1400\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.1656,\tval_loss: 0.1415\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1637,\tval_loss: 0.1399\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1655,\tval_loss: 0.1392\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1657,\tval_loss: 0.1411\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1671,\tval_loss: 0.1403\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1421\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1617,\tval_loss: 0.1416\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1648,\tval_loss: 0.1405\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1686,\tval_loss: 0.1414\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1657,\tval_loss: 0.1419\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1641,\tval_loss: 0.1407\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1660,\tval_loss: 0.1403\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1405\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1635,\tval_loss: 0.1404\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1413\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1425\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1404\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1677,\tval_loss: 0.1399\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.1666,\tval_loss: 0.1394\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1406\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1637,\tval_loss: 0.1409\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1402\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1675,\tval_loss: 0.1399\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1430\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1596,\tval_loss: 0.1410\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1441\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1421\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.1629,\tval_loss: 0.1423\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.1681,\tval_loss: 0.1411\n",
            "47:\t[0s / 4s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1412\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1597,\tval_loss: 0.1412\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1404\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1657,\tval_loss: 0.1404\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1624,\tval_loss: 0.1417\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1667,\tval_loss: 0.1410\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1395\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.1667,\tval_loss: 0.1403\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1408\n",
            "56:\t[0s / 5s],\t\ttrain_loss: 0.1603,\tval_loss: 0.1409\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1398\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1698,\tval_loss: 0.1409\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1658,\tval_loss: 0.1414\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1641,\tval_loss: 0.1418\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.1672,\tval_loss: 0.1418\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1422\n",
            "63:\t[0s / 6s],\t\ttrain_loss: 0.1684,\tval_loss: 0.1404\n",
            "64:\t[0s / 6s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1411\n",
            "65:\t[0s / 6s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1393\n",
            "66:\t[0s / 6s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1440\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1637,\tval_loss: 0.1404\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1680,\tval_loss: 0.1413\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.1653,\tval_loss: 0.1405\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.1605,\tval_loss: 0.1429\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.1672,\tval_loss: 0.1415\n",
            "72:\t[0s / 7s],\t\ttrain_loss: 0.1658,\tval_loss: 0.1410\n",
            "73:\t[0s / 7s],\t\ttrain_loss: 0.1587,\tval_loss: 0.1406\n",
            "74:\t[0s / 7s],\t\ttrain_loss: 0.1635,\tval_loss: 0.1411\n",
            "75:\t[0s / 7s],\t\ttrain_loss: 0.1617,\tval_loss: 0.1402\n",
            "76:\t[0s / 7s],\t\ttrain_loss: 0.1602,\tval_loss: 0.1395\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1411\n",
            "78:\t[0s / 8s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1412\n",
            "79:\t[0s / 8s],\t\ttrain_loss: 0.1675,\tval_loss: 0.1396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2339,\tval_loss: 0.1491\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1891,\tval_loss: 0.1419\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1639,\tval_loss: 0.1424\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1523,\tval_loss: 0.1402\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1496,\tval_loss: 0.1405\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1463,\tval_loss: 0.1403\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1456,\tval_loss: 0.1395\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.1422,\tval_loss: 0.1419\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1442,\tval_loss: 0.1402\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1437,\tval_loss: 0.1403\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1469,\tval_loss: 0.1407\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1432,\tval_loss: 0.1409\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1461,\tval_loss: 0.1405\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1415,\tval_loss: 0.1403\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.1436,\tval_loss: 0.1414\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.1409,\tval_loss: 0.1407\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.1429,\tval_loss: 0.1415\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1420,\tval_loss: 0.1413\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1451,\tval_loss: 0.1402\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1437,\tval_loss: 0.1407\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1440,\tval_loss: 0.1412\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.1421,\tval_loss: 0.1424\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.1470,\tval_loss: 0.1406\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1454,\tval_loss: 0.1405\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1488,\tval_loss: 0.1412\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1460,\tval_loss: 0.1419\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1455,\tval_loss: 0.1400\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1423,\tval_loss: 0.1407\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.1434,\tval_loss: 0.1404\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.1465,\tval_loss: 0.1425\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.1422,\tval_loss: 0.1398\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.1436,\tval_loss: 0.1394\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1421,\tval_loss: 0.1401\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.1443,\tval_loss: 0.1395\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.1414,\tval_loss: 0.1397\n",
            "35:\t[0s / 5s],\t\ttrain_loss: 0.1437,\tval_loss: 0.1412\n",
            "36:\t[0s / 5s],\t\ttrain_loss: 0.1448,\tval_loss: 0.1424\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.1479,\tval_loss: 0.1402\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.1434,\tval_loss: 0.1453\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.1463,\tval_loss: 0.1401\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.1461,\tval_loss: 0.1396\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1460,\tval_loss: 0.1407\n",
            "42:\t[0s / 6s],\t\ttrain_loss: 0.1400,\tval_loss: 0.1397\n",
            "43:\t[0s / 6s],\t\ttrain_loss: 0.1430,\tval_loss: 0.1394\n",
            "44:\t[0s / 6s],\t\ttrain_loss: 0.1451,\tval_loss: 0.1406\n",
            "45:\t[0s / 6s],\t\ttrain_loss: 0.1449,\tval_loss: 0.1396\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.1458,\tval_loss: 0.1413\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.1473,\tval_loss: 0.1433\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.1438,\tval_loss: 0.1440\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1460,\tval_loss: 0.1395\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1442,\tval_loss: 0.1392\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1439,\tval_loss: 0.1402\n",
            "52:\t[0s / 7s],\t\ttrain_loss: 0.1437,\tval_loss: 0.1442\n",
            "53:\t[0s / 7s],\t\ttrain_loss: 0.1426,\tval_loss: 0.1392\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.1415,\tval_loss: 0.1410\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.1469,\tval_loss: 0.1399\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.1454,\tval_loss: 0.1387\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.1448,\tval_loss: 0.1400\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.1431,\tval_loss: 0.1409\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1446,\tval_loss: 0.1396\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.1442,\tval_loss: 0.1399\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.1437,\tval_loss: 0.1398\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.1372,\tval_loss: 0.1430\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.1492,\tval_loss: 0.1417\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.1455,\tval_loss: 0.1395\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.1411,\tval_loss: 0.1398\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1454,\tval_loss: 0.1387\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1427,\tval_loss: 0.1398\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1508,\tval_loss: 0.1379\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1416,\tval_loss: 0.1390\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.1465,\tval_loss: 0.1407\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.1446,\tval_loss: 0.1380\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.1452,\tval_loss: 0.1384\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.1433,\tval_loss: 0.1367\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1392,\tval_loss: 0.1406\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1444,\tval_loss: 0.1395\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1404,\tval_loss: 0.1380\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1405,\tval_loss: 0.1387\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1431,\tval_loss: 0.1376\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.1485,\tval_loss: 0.1406\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.1422,\tval_loss: 0.1387\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.1461,\tval_loss: 0.1381\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.1471,\tval_loss: 0.1382\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.1437,\tval_loss: 0.1379\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.1433,\tval_loss: 0.1383\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.1413,\tval_loss: 0.1392\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1390,\tval_loss: 0.1405\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1458,\tval_loss: 0.1385\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1425,\tval_loss: 0.1385\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.1416,\tval_loss: 0.1392\n",
            "90:\t[0s / 10s],\t\ttrain_loss: 0.1425,\tval_loss: 0.1379\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.1444,\tval_loss: 0.1380\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.1415,\tval_loss: 0.1409\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.1420,\tval_loss: 0.1404\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.1463,\tval_loss: 0.1383\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.1454,\tval_loss: 0.1383\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.1440,\tval_loss: 0.1380\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1451,\tval_loss: 0.1380\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.1444,\tval_loss: 0.1391\n",
            "99:\t[0s / 11s],\t\ttrain_loss: 0.1456,\tval_loss: 0.1381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2144,\tval_loss: 0.1576\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1757,\tval_loss: 0.1436\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1410\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1442,\tval_loss: 0.1424\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1410,\tval_loss: 0.1419\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1393,\tval_loss: 0.1413\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1364,\tval_loss: 0.1422\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1346,\tval_loss: 0.1420\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1382,\tval_loss: 0.1420\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1374,\tval_loss: 0.1420\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1369,\tval_loss: 0.1407\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1388,\tval_loss: 0.1419\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1383,\tval_loss: 0.1405\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1401,\tval_loss: 0.1419\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1445,\tval_loss: 0.1404\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1386,\tval_loss: 0.1411\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1406,\tval_loss: 0.1416\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1415,\tval_loss: 0.1404\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1391,\tval_loss: 0.1411\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1376,\tval_loss: 0.1416\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1390,\tval_loss: 0.1401\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1394,\tval_loss: 0.1421\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1390,\tval_loss: 0.1411\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1415,\tval_loss: 0.1414\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1399,\tval_loss: 0.1419\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1367,\tval_loss: 0.1399\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1387,\tval_loss: 0.1414\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1395,\tval_loss: 0.1426\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1420,\tval_loss: 0.1431\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1396,\tval_loss: 0.1416\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1400,\tval_loss: 0.1420\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1384,\tval_loss: 0.1420\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1417,\tval_loss: 0.1440\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1397,\tval_loss: 0.1422\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1397,\tval_loss: 0.1460\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1387,\tval_loss: 0.1408\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1383,\tval_loss: 0.1430\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1488,\tval_loss: 0.1418\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1454,\tval_loss: 0.1432\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1388,\tval_loss: 0.1428\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1437,\tval_loss: 0.1428\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1456,\tval_loss: 0.1429\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.1452,\tval_loss: 0.1419\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1418,\tval_loss: 0.1437\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1404,\tval_loss: 0.1452\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1401,\tval_loss: 0.1403\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1426,\tval_loss: 0.1425\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1434,\tval_loss: 0.1437\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1437,\tval_loss: 0.1415\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1458,\tval_loss: 0.1430\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1450,\tval_loss: 0.1417\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1435,\tval_loss: 0.1428\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.1420,\tval_loss: 0.1441\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.1404,\tval_loss: 0.1418\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.1397,\tval_loss: 0.1437\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.1379,\tval_loss: 0.1420\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.1387,\tval_loss: 0.1417\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.1374,\tval_loss: 0.1413\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.1385,\tval_loss: 0.1413\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1376,\tval_loss: 0.1439\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.1380,\tval_loss: 0.1430\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.1409,\tval_loss: 0.1407\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.1383,\tval_loss: 0.1412\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.1415,\tval_loss: 0.1407\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.1384,\tval_loss: 0.1436\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.1424,\tval_loss: 0.1415\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1366,\tval_loss: 0.1432\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1369,\tval_loss: 0.1441\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1410,\tval_loss: 0.1429\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1363,\tval_loss: 0.1422\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.1417,\tval_loss: 0.1455\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.1376,\tval_loss: 0.1403\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.1394,\tval_loss: 0.1407\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.1416,\tval_loss: 0.1418\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1454,\tval_loss: 0.1419\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1417,\tval_loss: 0.1422\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1397,\tval_loss: 0.1435\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1405,\tval_loss: 0.1431\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1362,\tval_loss: 0.1462\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.1429,\tval_loss: 0.1415\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.1401,\tval_loss: 0.1437\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.1430,\tval_loss: 0.1419\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.1413,\tval_loss: 0.1475\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.1447,\tval_loss: 0.1458\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.1452,\tval_loss: 0.1443\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.1407,\tval_loss: 0.1465\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1403,\tval_loss: 0.1450\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1429,\tval_loss: 0.1427\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1486,\tval_loss: 0.1423\n",
            "89:\t[0s / 11s],\t\ttrain_loss: 0.1461,\tval_loss: 0.1423\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.1431,\tval_loss: 0.1409\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.1422,\tval_loss: 0.1430\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.1451,\tval_loss: 0.1416\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.1449,\tval_loss: 0.1479\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2234,\tval_loss: 0.1581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2080,\tval_loss: 0.1442\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1396\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1408\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1471,\tval_loss: 0.1410\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1470,\tval_loss: 0.1417\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1432,\tval_loss: 0.1405\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1450,\tval_loss: 0.1402\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1461,\tval_loss: 0.1403\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1457,\tval_loss: 0.1399\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1434,\tval_loss: 0.1398\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1463,\tval_loss: 0.1398\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1479,\tval_loss: 0.1400\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1455,\tval_loss: 0.1394\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1427,\tval_loss: 0.1413\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1451,\tval_loss: 0.1431\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1467,\tval_loss: 0.1423\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1479,\tval_loss: 0.1397\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.1412,\tval_loss: 0.1426\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1400\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1453,\tval_loss: 0.1424\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1418,\tval_loss: 0.1411\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1485,\tval_loss: 0.1405\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1459,\tval_loss: 0.1438\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1421\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1477,\tval_loss: 0.1395\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1476,\tval_loss: 0.1405\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1447,\tval_loss: 0.1423\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1467,\tval_loss: 0.1393\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1505,\tval_loss: 0.1404\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1434,\tval_loss: 0.1427\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1410\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1522,\tval_loss: 0.1406\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1483,\tval_loss: 0.1404\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1491,\tval_loss: 0.1387\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1461,\tval_loss: 0.1393\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.1490,\tval_loss: 0.1400\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.1471,\tval_loss: 0.1420\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1476,\tval_loss: 0.1410\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1492,\tval_loss: 0.1438\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1460,\tval_loss: 0.1438\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1479,\tval_loss: 0.1400\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1479,\tval_loss: 0.1406\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1461,\tval_loss: 0.1393\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1489,\tval_loss: 0.1438\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.1463,\tval_loss: 0.1415\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1394\n",
            "47:\t[0s / 4s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1395\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1417,\tval_loss: 0.1397\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1455,\tval_loss: 0.1397\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1426,\tval_loss: 0.1394\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1481,\tval_loss: 0.1400\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1424,\tval_loss: 0.1414\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1457,\tval_loss: 0.1438\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.1476,\tval_loss: 0.1424\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.1454,\tval_loss: 0.1393\n",
            "56:\t[0s / 5s],\t\ttrain_loss: 0.1454,\tval_loss: 0.1407\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1403\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1449,\tval_loss: 0.1420\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1469,\tval_loss: 0.1397\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1479,\tval_loss: 0.1391\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.1471,\tval_loss: 0.1403\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.1465,\tval_loss: 0.1392\n",
            "63:\t[0s / 6s],\t\ttrain_loss: 0.1412,\tval_loss: 0.1419\n",
            "64:\t[0s / 6s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1409\n",
            "65:\t[0s / 6s],\t\ttrain_loss: 0.1459,\tval_loss: 0.1407\n",
            "66:\t[0s / 6s],\t\ttrain_loss: 0.1498,\tval_loss: 0.1403\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1448,\tval_loss: 0.1420\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1474,\tval_loss: 0.1416\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.1402,\tval_loss: 0.1390\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.1432,\tval_loss: 0.1413\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.1428,\tval_loss: 0.1397\n",
            "72:\t[0s / 7s],\t\ttrain_loss: 0.1434,\tval_loss: 0.1403\n",
            "73:\t[0s / 7s],\t\ttrain_loss: 0.1487,\tval_loss: 0.1405\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.1508,\tval_loss: 0.1401\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.1482,\tval_loss: 0.1399\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.1440,\tval_loss: 0.1407\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.1440,\tval_loss: 0.1401\n",
            "78:\t[0s / 8s],\t\ttrain_loss: 0.1446,\tval_loss: 0.1396\n",
            "79:\t[0s / 8s],\t\ttrain_loss: 0.1423,\tval_loss: 0.1400\n",
            "80:\t[0s / 8s],\t\ttrain_loss: 0.1447,\tval_loss: 0.1405\n",
            "81:\t[0s / 9s],\t\ttrain_loss: 0.1453,\tval_loss: 0.1425\n",
            "82:\t[0s / 9s],\t\ttrain_loss: 0.1426,\tval_loss: 0.1406\n",
            "83:\t[0s / 9s],\t\ttrain_loss: 0.1446,\tval_loss: 0.1418\n",
            "84:\t[0s / 9s],\t\ttrain_loss: 0.1452,\tval_loss: 0.1395\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.1487,\tval_loss: 0.1399\n",
            "86:\t[0s / 9s],\t\ttrain_loss: 0.1420,\tval_loss: 0.1411\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1405,\tval_loss: 0.1422\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1411,\tval_loss: 0.1400\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.1417,\tval_loss: 0.1397\n",
            "90:\t[0s / 10s],\t\ttrain_loss: 0.1488,\tval_loss: 0.1409\n",
            "91:\t[0s / 10s],\t\ttrain_loss: 0.1409,\tval_loss: 0.1432\n",
            "92:\t[0s / 10s],\t\ttrain_loss: 0.1468,\tval_loss: 0.1407\n",
            "93:\t[0s / 10s],\t\ttrain_loss: 0.1432,\tval_loss: 0.1405\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.1419,\tval_loss: 0.1390\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.1435,\tval_loss: 0.1404\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.1456,\tval_loss: 0.1406\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1456,\tval_loss: 0.1394\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.1468,\tval_loss: 0.1406\n",
            "99:\t[0s / 11s],\t\ttrain_loss: 0.1426,\tval_loss: 0.1395\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2410,\tval_loss: 0.1555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1985,\tval_loss: 0.1465\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1702,\tval_loss: 0.1411\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1402\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1416\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1398\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1551,\tval_loss: 0.1408\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1395\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1411\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1587,\tval_loss: 0.1406\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1562,\tval_loss: 0.1407\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1398\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1552,\tval_loss: 0.1410\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1405\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1556,\tval_loss: 0.1409\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1396\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1399\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1565,\tval_loss: 0.1398\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1543,\tval_loss: 0.1407\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1582,\tval_loss: 0.1398\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1567,\tval_loss: 0.1403\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1556,\tval_loss: 0.1390\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1402\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1408\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1557,\tval_loss: 0.1401\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1397\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1410\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1574,\tval_loss: 0.1401\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1406\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1567,\tval_loss: 0.1397\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1407\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1567,\tval_loss: 0.1404\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1401\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1419\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1406\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1574,\tval_loss: 0.1414\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.1519,\tval_loss: 0.1405\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1409\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1423\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1402\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1415\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1415\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1409\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1424\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1414\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.1547,\tval_loss: 0.1410\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1407\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1419\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1596,\tval_loss: 0.1414\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1421\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1553,\tval_loss: 0.1399\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1424\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1428\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1547,\tval_loss: 0.1403\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.1591,\tval_loss: 0.1409\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1436\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1411\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1583,\tval_loss: 0.1411\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1439\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1556,\tval_loss: 0.1430\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1552,\tval_loss: 0.1415\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1471\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.1596,\tval_loss: 0.1461\n",
            "63:\t[0s / 6s],\t\ttrain_loss: 0.1559,\tval_loss: 0.1487\n",
            "64:\t[0s / 6s],\t\ttrain_loss: 0.1677,\tval_loss: 0.1419\n",
            "65:\t[0s / 6s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1428\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.1621,\tval_loss: 0.1426\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1429\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1635,\tval_loss: 0.1438\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.1555,\tval_loss: 0.1475\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.1624,\tval_loss: 0.1434\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1434\n",
            "72:\t[0s / 7s],\t\ttrain_loss: 0.1696,\tval_loss: 0.1406\n",
            "73:\t[0s / 7s],\t\ttrain_loss: 0.1600,\tval_loss: 0.1431\n",
            "74:\t[0s / 7s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1453\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.1694,\tval_loss: 0.1463\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1529\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1589\n",
            "78:\t[0s / 8s],\t\ttrain_loss: 0.1681,\tval_loss: 0.1498\n",
            "79:\t[0s / 8s],\t\ttrain_loss: 0.1603,\tval_loss: 0.1532\n",
            "80:\t[0s / 8s],\t\ttrain_loss: 0.1636,\tval_loss: 0.1506\n",
            "81:\t[0s / 8s],\t\ttrain_loss: 0.1703,\tval_loss: 0.1414\n",
            "82:\t[0s / 8s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1424\n",
            "83:\t[0s / 8s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1498\n",
            "84:\t[0s / 8s],\t\ttrain_loss: 0.1684,\tval_loss: 0.1496\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.1656,\tval_loss: 0.1471\n",
            "86:\t[0s / 9s],\t\ttrain_loss: 0.1570,\tval_loss: 0.1461\n",
            "87:\t[0s / 9s],\t\ttrain_loss: 0.1654,\tval_loss: 0.1470\n",
            "88:\t[0s / 9s],\t\ttrain_loss: 0.1592,\tval_loss: 0.1451\n",
            "89:\t[0s / 9s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1428\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2514,\tval_loss: 0.1546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2134,\tval_loss: 0.1467\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1781,\tval_loss: 0.1406\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1663,\tval_loss: 0.1419\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1409\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1580,\tval_loss: 0.1446\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1653,\tval_loss: 0.1417\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.1610,\tval_loss: 0.1412\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1621,\tval_loss: 0.1400\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1402\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1422\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1421\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1404\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1410\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1411\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1417\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1410\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1410\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1418\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1404\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1403\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.1567,\tval_loss: 0.1397\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.1607,\tval_loss: 0.1412\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1408\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1404\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1416\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1401\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1412\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1408\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1400\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.1592,\tval_loss: 0.1420\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.1632,\tval_loss: 0.1405\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1591,\tval_loss: 0.1410\n",
            "33:\t[0s / 5s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1401\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1425\n",
            "35:\t[0s / 5s],\t\ttrain_loss: 0.1636,\tval_loss: 0.1400\n",
            "36:\t[0s / 5s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1395\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.1635,\tval_loss: 0.1404\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1414\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.1632,\tval_loss: 0.1415\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1404\n",
            "41:\t[0s / 6s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1405\n",
            "42:\t[0s / 6s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1420\n",
            "43:\t[0s / 6s],\t\ttrain_loss: 0.1585,\tval_loss: 0.1407\n",
            "44:\t[0s / 6s],\t\ttrain_loss: 0.1603,\tval_loss: 0.1391\n",
            "45:\t[0s / 6s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1402\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1397\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.1635,\tval_loss: 0.1401\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.1577,\tval_loss: 0.1415\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1401\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1412\n",
            "51:\t[0s / 7s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1410\n",
            "52:\t[0s / 7s],\t\ttrain_loss: 0.1591,\tval_loss: 0.1403\n",
            "53:\t[0s / 7s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1430\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1433\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.1621,\tval_loss: 0.1408\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.1571,\tval_loss: 0.1412\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1438\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1422\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1597,\tval_loss: 0.1415\n",
            "60:\t[0s / 8s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1415\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.1602,\tval_loss: 0.1418\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1414\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.1571,\tval_loss: 0.1441\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1424\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1418\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1425\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1419\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1446\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1603,\tval_loss: 0.1422\n",
            "70:\t[0s / 9s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1409\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1456\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.1643,\tval_loss: 0.1430\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1430\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1424\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1605,\tval_loss: 0.1415\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1404\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1637,\tval_loss: 0.1428\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1424\n",
            "79:\t[0s / 10s],\t\ttrain_loss: 0.1605,\tval_loss: 0.1424\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1457\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.1587,\tval_loss: 0.1427\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1415\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1452\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.1637,\tval_loss: 0.1428\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1434\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1450\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1617,\tval_loss: 0.1433\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1580,\tval_loss: 0.1441\n",
            "89:\t[0s / 11s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1455\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1448\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.1566,\tval_loss: 0.1445\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1442\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1442\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1448\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.1571,\tval_loss: 0.1431\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1463\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1574,\tval_loss: 0.1443\n",
            "98:\t[0s / 12s],\t\ttrain_loss: 0.1580,\tval_loss: 0.1447\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2320,\tval_loss: 0.1617\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1899,\tval_loss: 0.1463\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1669,\tval_loss: 0.1421\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1413\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1414\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1514,\tval_loss: 0.1420\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1405\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1500,\tval_loss: 0.1408\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1516,\tval_loss: 0.1422\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1508,\tval_loss: 0.1424\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1417\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1474,\tval_loss: 0.1410\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1502,\tval_loss: 0.1407\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1513,\tval_loss: 0.1408\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1421\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1493,\tval_loss: 0.1397\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1477,\tval_loss: 0.1413\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1499,\tval_loss: 0.1414\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1416\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1468,\tval_loss: 0.1410\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1474,\tval_loss: 0.1423\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1508,\tval_loss: 0.1409\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1553,\tval_loss: 0.1405\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1421\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1553,\tval_loss: 0.1395\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1411\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1409\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1477,\tval_loss: 0.1406\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1504,\tval_loss: 0.1409\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1497,\tval_loss: 0.1414\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1426\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1500,\tval_loss: 0.1409\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1429\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1424\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1505,\tval_loss: 0.1431\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1413\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1509,\tval_loss: 0.1412\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1440\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1422\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1404\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1414\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1526,\tval_loss: 0.1413\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.1509,\tval_loss: 0.1407\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1513,\tval_loss: 0.1451\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1500,\tval_loss: 0.1420\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1406\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1402\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.1493,\tval_loss: 0.1424\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.1494,\tval_loss: 0.1435\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1509,\tval_loss: 0.1421\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1403\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1516,\tval_loss: 0.1416\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1421\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1410\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.1487,\tval_loss: 0.1423\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1402\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.1505,\tval_loss: 0.1407\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1415\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.1519,\tval_loss: 0.1426\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1508,\tval_loss: 0.1415\n",
            "60:\t[0s / 8s],\t\ttrain_loss: 0.1525,\tval_loss: 0.1414\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1428\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.1507,\tval_loss: 0.1426\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.1507,\tval_loss: 0.1411\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.1525,\tval_loss: 0.1423\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1411\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1476,\tval_loss: 0.1432\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1498,\tval_loss: 0.1407\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1491,\tval_loss: 0.1417\n",
            "69:\t[0s / 9s],\t\ttrain_loss: 0.1511,\tval_loss: 0.1425\n",
            "70:\t[0s / 9s],\t\ttrain_loss: 0.1511,\tval_loss: 0.1432\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.1502,\tval_loss: 0.1413\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.1505,\tval_loss: 0.1418\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.1606,\tval_loss: 0.1442\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1547,\tval_loss: 0.1425\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1602,\tval_loss: 0.1422\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1423\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1426\n",
            "78:\t[0s / 10s],\t\ttrain_loss: 0.1484,\tval_loss: 0.1420\n",
            "79:\t[0s / 10s],\t\ttrain_loss: 0.1541,\tval_loss: 0.1414\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1418\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.1552,\tval_loss: 0.1440\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.1566,\tval_loss: 0.1417\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.1493,\tval_loss: 0.1420\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1413\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.1531,\tval_loss: 0.1424\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1523,\tval_loss: 0.1427\n",
            "87:\t[0s / 11s],\t\ttrain_loss: 0.1567,\tval_loss: 0.1434\n",
            "88:\t[0s / 11s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1418\n",
            "89:\t[0s / 11s],\t\ttrain_loss: 0.1498,\tval_loss: 0.1436\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1428\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1418\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.1499,\tval_loss: 0.1448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2322,\tval_loss: 0.1628\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2110,\tval_loss: 0.1470\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1701,\tval_loss: 0.1420\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1409\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1406\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1584,\tval_loss: 0.1406\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1416\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1401\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1562,\tval_loss: 0.1408\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1402\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1410\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1567,\tval_loss: 0.1398\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1417\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1557,\tval_loss: 0.1399\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1390\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1507,\tval_loss: 0.1406\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1541,\tval_loss: 0.1404\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1402\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1557,\tval_loss: 0.1404\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1404\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1410\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1543,\tval_loss: 0.1405\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1399\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1406\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1554,\tval_loss: 0.1415\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1567,\tval_loss: 0.1403\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1557,\tval_loss: 0.1390\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1571,\tval_loss: 0.1399\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1398\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1393\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1592,\tval_loss: 0.1403\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1617,\tval_loss: 0.1389\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1400\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1552,\tval_loss: 0.1434\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1414\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1411\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1562,\tval_loss: 0.1401\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1547,\tval_loss: 0.1402\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1618,\tval_loss: 0.1405\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1409\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1419\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1565,\tval_loss: 0.1397\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1566,\tval_loss: 0.1416\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1555,\tval_loss: 0.1403\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1409\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1566,\tval_loss: 0.1408\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1562,\tval_loss: 0.1408\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1597,\tval_loss: 0.1405\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1426\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1557,\tval_loss: 0.1397\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1407\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1553,\tval_loss: 0.1399\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1567,\tval_loss: 0.1403\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1553,\tval_loss: 0.1413\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.1530,\tval_loss: 0.1397\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.1554,\tval_loss: 0.1412\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1563,\tval_loss: 0.1406\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1414\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1563,\tval_loss: 0.1405\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1565,\tval_loss: 0.1403\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1407\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.1566,\tval_loss: 0.1412\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.1580,\tval_loss: 0.1413\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1406\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1409\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.1556,\tval_loss: 0.1412\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1400\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1404\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1406\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1419\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1415\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1429\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.1596,\tval_loss: 0.1410\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.1582,\tval_loss: 0.1419\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1428\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1406\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1421\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1410\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1415\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1417\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1441\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1404\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.1587,\tval_loss: 0.1421\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.1616,\tval_loss: 0.1413\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1422\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1425\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1686,\tval_loss: 0.1442\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1432\n",
            "88:\t[0s / 11s],\t\ttrain_loss: 0.1614,\tval_loss: 0.1442\n",
            "89:\t[0s / 11s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1427\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.1607,\tval_loss: 0.1432\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.1585,\tval_loss: 0.1433\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.1605,\tval_loss: 0.1427\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1430\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1435\n",
            "95:\t[0s / 12s],\t\ttrain_loss: 0.1693,\tval_loss: 0.1420\n",
            "96:\t[0s / 12s],\t\ttrain_loss: 0.1685,\tval_loss: 0.1426\n",
            "97:\t[0s / 12s],\t\ttrain_loss: 0.1636,\tval_loss: 0.1421\n",
            "98:\t[0s / 12s],\t\ttrain_loss: 0.1571,\tval_loss: 0.1442\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.1659,\tval_loss: 0.1433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2575,\tval_loss: 0.1625\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2246,\tval_loss: 0.1419\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1922,\tval_loss: 0.1426\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1819,\tval_loss: 0.1413\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1778,\tval_loss: 0.1418\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1706,\tval_loss: 0.1427\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1727,\tval_loss: 0.1420\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1704,\tval_loss: 0.1406\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1756,\tval_loss: 0.1433\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1717,\tval_loss: 0.1420\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1715,\tval_loss: 0.1408\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1725,\tval_loss: 0.1415\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1708,\tval_loss: 0.1405\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1710,\tval_loss: 0.1418\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1712,\tval_loss: 0.1417\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1757,\tval_loss: 0.1406\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1724,\tval_loss: 0.1411\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1715,\tval_loss: 0.1419\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1737,\tval_loss: 0.1406\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1766,\tval_loss: 0.1423\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1797,\tval_loss: 0.1407\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1729,\tval_loss: 0.1423\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1755,\tval_loss: 0.1419\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1773,\tval_loss: 0.1415\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1763,\tval_loss: 0.1418\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1737,\tval_loss: 0.1423\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1740,\tval_loss: 0.1422\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1744,\tval_loss: 0.1402\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1737,\tval_loss: 0.1443\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1725,\tval_loss: 0.1417\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1746,\tval_loss: 0.1412\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1743,\tval_loss: 0.1441\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1728,\tval_loss: 0.1406\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1711,\tval_loss: 0.1412\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1744,\tval_loss: 0.1404\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1753,\tval_loss: 0.1419\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1736,\tval_loss: 0.1431\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1762,\tval_loss: 0.1413\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1732,\tval_loss: 0.1418\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1748,\tval_loss: 0.1429\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1722,\tval_loss: 0.1398\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1745,\tval_loss: 0.1414\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1740,\tval_loss: 0.1423\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1704,\tval_loss: 0.1402\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1774,\tval_loss: 0.1419\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.1734,\tval_loss: 0.1409\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1761,\tval_loss: 0.1423\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1821,\tval_loss: 0.1422\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1726,\tval_loss: 0.1409\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1751,\tval_loss: 0.1420\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1760,\tval_loss: 0.1434\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1747,\tval_loss: 0.1406\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1735,\tval_loss: 0.1423\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1761,\tval_loss: 0.1435\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.1773,\tval_loss: 0.1420\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.1723,\tval_loss: 0.1411\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1711,\tval_loss: 0.1429\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1737,\tval_loss: 0.1440\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1769,\tval_loss: 0.1423\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1716,\tval_loss: 0.1423\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1753,\tval_loss: 0.1420\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.1718,\tval_loss: 0.1421\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.1740,\tval_loss: 0.1411\n",
            "63:\t[0s / 6s],\t\ttrain_loss: 0.1828,\tval_loss: 0.1418\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.1740,\tval_loss: 0.1450\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.1749,\tval_loss: 0.1414\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.1699,\tval_loss: 0.1423\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1781,\tval_loss: 0.1435\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1761,\tval_loss: 0.1424\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.1724,\tval_loss: 0.1425\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.1748,\tval_loss: 0.1453\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.1684,\tval_loss: 0.1416\n",
            "72:\t[0s / 7s],\t\ttrain_loss: 0.1719,\tval_loss: 0.1430\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.1750,\tval_loss: 0.1423\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.1711,\tval_loss: 0.1433\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.1739,\tval_loss: 0.1412\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.1733,\tval_loss: 0.1413\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.1727,\tval_loss: 0.1453\n",
            "78:\t[0s / 8s],\t\ttrain_loss: 0.1694,\tval_loss: 0.1441\n",
            "79:\t[0s / 8s],\t\ttrain_loss: 0.1709,\tval_loss: 0.1433\n",
            "80:\t[0s / 8s],\t\ttrain_loss: 0.1710,\tval_loss: 0.1419\n",
            "81:\t[0s / 8s],\t\ttrain_loss: 0.1714,\tval_loss: 0.1435\n",
            "82:\t[0s / 8s],\t\ttrain_loss: 0.1675,\tval_loss: 0.1408\n",
            "83:\t[0s / 9s],\t\ttrain_loss: 0.1735,\tval_loss: 0.1422\n",
            "84:\t[0s / 9s],\t\ttrain_loss: 0.1672,\tval_loss: 0.1441\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.1720,\tval_loss: 0.1455\n",
            "86:\t[0s / 9s],\t\ttrain_loss: 0.1786,\tval_loss: 0.1412\n",
            "87:\t[0s / 9s],\t\ttrain_loss: 0.1744,\tval_loss: 0.1419\n",
            "88:\t[0s / 9s],\t\ttrain_loss: 0.1745,\tval_loss: 0.1430\n",
            "89:\t[0s / 9s],\t\ttrain_loss: 0.1738,\tval_loss: 0.1470\n",
            "90:\t[0s / 10s],\t\ttrain_loss: 0.1793,\tval_loss: 0.1447\n",
            "91:\t[0s / 10s],\t\ttrain_loss: 0.1743,\tval_loss: 0.1426\n",
            "92:\t[0s / 10s],\t\ttrain_loss: 0.1725,\tval_loss: 0.1425\n",
            "93:\t[0s / 10s],\t\ttrain_loss: 0.1721,\tval_loss: 0.1442\n",
            "94:\t[0s / 10s],\t\ttrain_loss: 0.1749,\tval_loss: 0.1431\n",
            "95:\t[0s / 10s],\t\ttrain_loss: 0.1757,\tval_loss: 0.1440\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.1710,\tval_loss: 0.1426\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1731,\tval_loss: 0.1419\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.1738,\tval_loss: 0.1444\n",
            "99:\t[0s / 11s],\t\ttrain_loss: 0.1669,\tval_loss: 0.1474\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2343,\tval_loss: 0.1474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2024,\tval_loss: 0.1399\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1756,\tval_loss: 0.1412\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1419\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1419\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1426\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1556,\tval_loss: 0.1424\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.1487,\tval_loss: 0.1426\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1504,\tval_loss: 0.1417\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1507,\tval_loss: 0.1411\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1510,\tval_loss: 0.1405\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1551,\tval_loss: 0.1424\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1407\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.1511,\tval_loss: 0.1439\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1413\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.1526,\tval_loss: 0.1410\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.1522,\tval_loss: 0.1435\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1556,\tval_loss: 0.1431\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1507,\tval_loss: 0.1418\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1403\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1431\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.1554,\tval_loss: 0.1413\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.1585,\tval_loss: 0.1416\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1534,\tval_loss: 0.1415\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1407\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1580,\tval_loss: 0.1413\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1492,\tval_loss: 0.1415\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1539,\tval_loss: 0.1408\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1417\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1409\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.1557,\tval_loss: 0.1393\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1398\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1417\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1412\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1420\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1507,\tval_loss: 0.1414\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1420\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1419\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1553,\tval_loss: 0.1442\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.1571,\tval_loss: 0.1445\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.1543,\tval_loss: 0.1410\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1555,\tval_loss: 0.1408\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1457\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1585,\tval_loss: 0.1427\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.1580,\tval_loss: 0.1409\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1411\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.1563,\tval_loss: 0.1417\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1523,\tval_loss: 0.1409\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1408\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1433\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1537,\tval_loss: 0.1422\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1431\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.1530,\tval_loss: 0.1404\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1415\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1430\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.1577,\tval_loss: 0.1415\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1583,\tval_loss: 0.1437\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1565,\tval_loss: 0.1410\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1521,\tval_loss: 0.1422\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1414\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1418\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.1556,\tval_loss: 0.1420\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1438\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1419\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.1562,\tval_loss: 0.1406\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.1559,\tval_loss: 0.1427\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.1583,\tval_loss: 0.1406\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1409\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1562,\tval_loss: 0.1432\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1426\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.1606,\tval_loss: 0.1425\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1424\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.1518,\tval_loss: 0.1427\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1436\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.1557,\tval_loss: 0.1420\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1444\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1434\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.1605,\tval_loss: 0.1445\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1519,\tval_loss: 0.1425\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.1548,\tval_loss: 0.1441\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1419\n",
            "81:\t[0s / 9s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1447\n",
            "82:\t[0s / 9s],\t\ttrain_loss: 0.1600,\tval_loss: 0.1415\n",
            "83:\t[0s / 9s],\t\ttrain_loss: 0.1636,\tval_loss: 0.1424\n",
            "84:\t[0s / 9s],\t\ttrain_loss: 0.1555,\tval_loss: 0.1445\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.1567,\tval_loss: 0.1434\n",
            "86:\t[0s / 9s],\t\ttrain_loss: 0.1582,\tval_loss: 0.1437\n",
            "87:\t[0s / 9s],\t\ttrain_loss: 0.1559,\tval_loss: 0.1445\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1601,\tval_loss: 0.1447\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1482\n",
            "90:\t[0s / 10s],\t\ttrain_loss: 0.1686,\tval_loss: 0.1455\n",
            "91:\t[0s / 10s],\t\ttrain_loss: 0.1592,\tval_loss: 0.1429\n",
            "92:\t[0s / 10s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1469\n",
            "93:\t[0s / 10s],\t\ttrain_loss: 0.1687,\tval_loss: 0.1475\n",
            "94:\t[0s / 10s],\t\ttrain_loss: 0.1563,\tval_loss: 0.1425\n",
            "95:\t[0s / 10s],\t\ttrain_loss: 0.1602,\tval_loss: 0.1492\n",
            "96:\t[0s / 10s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1481\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1574,\tval_loss: 0.1462\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2325,\tval_loss: 0.1628\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2120,\tval_loss: 0.1444\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1445\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1408\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1422\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1478,\tval_loss: 0.1421\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1483,\tval_loss: 0.1401\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1497,\tval_loss: 0.1413\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1501,\tval_loss: 0.1409\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1507,\tval_loss: 0.1407\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1480,\tval_loss: 0.1421\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1497,\tval_loss: 0.1408\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1483,\tval_loss: 0.1412\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1482,\tval_loss: 0.1407\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1503,\tval_loss: 0.1420\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1414\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1410\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1474,\tval_loss: 0.1405\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1474,\tval_loss: 0.1409\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1484,\tval_loss: 0.1423\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1468,\tval_loss: 0.1421\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1534,\tval_loss: 0.1407\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1473,\tval_loss: 0.1428\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1485,\tval_loss: 0.1405\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1490,\tval_loss: 0.1417\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1485,\tval_loss: 0.1429\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1500,\tval_loss: 0.1407\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1493,\tval_loss: 0.1441\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1562,\tval_loss: 0.1405\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1514,\tval_loss: 0.1414\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1511,\tval_loss: 0.1423\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.1486,\tval_loss: 0.1435\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1478,\tval_loss: 0.1413\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.1473,\tval_loss: 0.1420\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.1460,\tval_loss: 0.1433\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.1487,\tval_loss: 0.1435\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.1464,\tval_loss: 0.1424\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.1474,\tval_loss: 0.1438\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.1493,\tval_loss: 0.1416\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.1493,\tval_loss: 0.1435\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.1486,\tval_loss: 0.1414\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1482,\tval_loss: 0.1422\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.1476,\tval_loss: 0.1431\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.1468,\tval_loss: 0.1442\n",
            "44:\t[0s / 6s],\t\ttrain_loss: 0.1486,\tval_loss: 0.1421\n",
            "45:\t[0s / 6s],\t\ttrain_loss: 0.1438,\tval_loss: 0.1436\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.1504,\tval_loss: 0.1424\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1436\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.1496,\tval_loss: 0.1429\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1496,\tval_loss: 0.1425\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1489,\tval_loss: 0.1456\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1448\n",
            "52:\t[0s / 7s],\t\ttrain_loss: 0.1510,\tval_loss: 0.1423\n",
            "53:\t[0s / 7s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1464\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1445\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.1522,\tval_loss: 0.1440\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.1530,\tval_loss: 0.1419\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.1466,\tval_loss: 0.1447\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.1463,\tval_loss: 0.1446\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1488,\tval_loss: 0.1447\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.1541,\tval_loss: 0.1422\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.1476,\tval_loss: 0.1436\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1439\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.1496,\tval_loss: 0.1466\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.1526,\tval_loss: 0.1440\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.1484,\tval_loss: 0.1442\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1510,\tval_loss: 0.1447\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1462,\tval_loss: 0.1440\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1430\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1445\n",
            "70:\t[0s / 9s],\t\ttrain_loss: 0.1508,\tval_loss: 0.1459\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.1543,\tval_loss: 0.1471\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.1489,\tval_loss: 0.1490\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1451\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1520,\tval_loss: 0.1446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2602,\tval_loss: 0.1517\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2148,\tval_loss: 0.1461\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1796,\tval_loss: 0.1415\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1701,\tval_loss: 0.1418\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1733,\tval_loss: 0.1401\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1666,\tval_loss: 0.1404\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1642,\tval_loss: 0.1404\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1650,\tval_loss: 0.1411\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1414\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1666,\tval_loss: 0.1405\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1406\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1682,\tval_loss: 0.1410\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1606,\tval_loss: 0.1416\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1687,\tval_loss: 0.1411\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1715,\tval_loss: 0.1414\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1693,\tval_loss: 0.1411\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1656,\tval_loss: 0.1395\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1413\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1669,\tval_loss: 0.1404\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1651,\tval_loss: 0.1404\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1408\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1666,\tval_loss: 0.1408\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1661,\tval_loss: 0.1411\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1677,\tval_loss: 0.1399\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1681,\tval_loss: 0.1408\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1667,\tval_loss: 0.1405\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1713,\tval_loss: 0.1405\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1671,\tval_loss: 0.1416\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1701,\tval_loss: 0.1413\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1676,\tval_loss: 0.1427\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1674,\tval_loss: 0.1404\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1695,\tval_loss: 0.1407\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1760,\tval_loss: 0.1398\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1656,\tval_loss: 0.1434\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1762,\tval_loss: 0.1417\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1705,\tval_loss: 0.1406\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.1656,\tval_loss: 0.1396\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1670,\tval_loss: 0.1409\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1689,\tval_loss: 0.1398\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1722,\tval_loss: 0.1400\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1704,\tval_loss: 0.1418\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1728,\tval_loss: 0.1419\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1799,\tval_loss: 0.1400\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1695,\tval_loss: 0.1409\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1732,\tval_loss: 0.1408\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.1705,\tval_loss: 0.1423\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.1782,\tval_loss: 0.1401\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1723,\tval_loss: 0.1423\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1691,\tval_loss: 0.1408\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1760,\tval_loss: 0.1416\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1707,\tval_loss: 0.1410\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1729,\tval_loss: 0.1408\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1717,\tval_loss: 0.1396\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1670,\tval_loss: 0.1411\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.1681,\tval_loss: 0.1427\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.1715,\tval_loss: 0.1394\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1670,\tval_loss: 0.1409\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1715,\tval_loss: 0.1445\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1693,\tval_loss: 0.1420\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1407\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1668,\tval_loss: 0.1418\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.1670,\tval_loss: 0.1414\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.1670,\tval_loss: 0.1405\n",
            "63:\t[0s / 6s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1394\n",
            "64:\t[0s / 6s],\t\ttrain_loss: 0.1658,\tval_loss: 0.1406\n",
            "65:\t[0s / 6s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1404\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1397\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1399\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1617,\tval_loss: 0.1405\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.1617,\tval_loss: 0.1394\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.1652,\tval_loss: 0.1409\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.1671,\tval_loss: 0.1394\n",
            "72:\t[0s / 7s],\t\ttrain_loss: 0.1696,\tval_loss: 0.1400\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.1721,\tval_loss: 0.1400\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.1641,\tval_loss: 0.1399\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.1654,\tval_loss: 0.1407\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.1665,\tval_loss: 0.1400\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1387\n",
            "78:\t[0s / 8s],\t\ttrain_loss: 0.1635,\tval_loss: 0.1404\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.1607,\tval_loss: 0.1399\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.1678,\tval_loss: 0.1399\n",
            "81:\t[0s / 9s],\t\ttrain_loss: 0.1643,\tval_loss: 0.1401\n",
            "82:\t[0s / 9s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1397\n",
            "83:\t[0s / 9s],\t\ttrain_loss: 0.1652,\tval_loss: 0.1405\n",
            "84:\t[0s / 9s],\t\ttrain_loss: 0.1651,\tval_loss: 0.1399\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1416\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1635,\tval_loss: 0.1400\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1419\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1638,\tval_loss: 0.1424\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.1665,\tval_loss: 0.1397\n",
            "90:\t[0s / 10s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1392\n",
            "91:\t[0s / 10s],\t\ttrain_loss: 0.1622,\tval_loss: 0.1414\n",
            "92:\t[0s / 10s],\t\ttrain_loss: 0.1665,\tval_loss: 0.1400\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1413\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.1693,\tval_loss: 0.1415\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.1681,\tval_loss: 0.1397\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.1661,\tval_loss: 0.1401\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.1667,\tval_loss: 0.1394\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1421\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.1659,\tval_loss: 0.1398\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2362,\tval_loss: 0.1713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2238,\tval_loss: 0.1433\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1677,\tval_loss: 0.1436\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1580,\tval_loss: 0.1413\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1581,\tval_loss: 0.1408\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1530,\tval_loss: 0.1408\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1552,\tval_loss: 0.1410\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1489,\tval_loss: 0.1403\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1502,\tval_loss: 0.1411\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1516,\tval_loss: 0.1413\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1555,\tval_loss: 0.1417\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1482,\tval_loss: 0.1423\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1515,\tval_loss: 0.1408\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1401\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1591,\tval_loss: 0.1415\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1511,\tval_loss: 0.1411\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1495,\tval_loss: 0.1406\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1547,\tval_loss: 0.1418\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.1486,\tval_loss: 0.1425\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1530,\tval_loss: 0.1400\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1518,\tval_loss: 0.1416\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1519,\tval_loss: 0.1398\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1408\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1508,\tval_loss: 0.1407\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1547,\tval_loss: 0.1394\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1482,\tval_loss: 0.1419\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1400\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1499,\tval_loss: 0.1405\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1409\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1567,\tval_loss: 0.1408\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1502,\tval_loss: 0.1414\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1522,\tval_loss: 0.1420\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1406\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1512,\tval_loss: 0.1403\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1419\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1512,\tval_loss: 0.1403\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.1555,\tval_loss: 0.1408\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1406\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1554,\tval_loss: 0.1398\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1424\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1525,\tval_loss: 0.1409\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1430\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1403\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1407\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1587,\tval_loss: 0.1424\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1397\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.1500,\tval_loss: 0.1413\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1503,\tval_loss: 0.1418\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1497,\tval_loss: 0.1406\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1406\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1516,\tval_loss: 0.1413\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1477,\tval_loss: 0.1410\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1442\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1514,\tval_loss: 0.1414\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1415\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1416\n",
            "56:\t[0s / 5s],\t\ttrain_loss: 0.1515,\tval_loss: 0.1412\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1419\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1502,\tval_loss: 0.1414\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1556,\tval_loss: 0.1415\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1401\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1446\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1391\n",
            "63:\t[0s / 6s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1397\n",
            "64:\t[0s / 6s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1403\n",
            "65:\t[0s / 6s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1405\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.1596,\tval_loss: 0.1411\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1565,\tval_loss: 0.1409\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1487\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1427\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1447\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.1547,\tval_loss: 0.1414\n",
            "72:\t[0s / 7s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1405\n",
            "73:\t[0s / 7s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1394\n",
            "74:\t[0s / 7s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1415\n",
            "75:\t[0s / 7s],\t\ttrain_loss: 0.1543,\tval_loss: 0.1421\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.1585,\tval_loss: 0.1399\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1401\n",
            "78:\t[0s / 8s],\t\ttrain_loss: 0.1539,\tval_loss: 0.1393\n",
            "79:\t[0s / 8s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1393\n",
            "80:\t[0s / 8s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1422\n",
            "81:\t[0s / 8s],\t\ttrain_loss: 0.1530,\tval_loss: 0.1382\n",
            "82:\t[0s / 8s],\t\ttrain_loss: 0.1492,\tval_loss: 0.1415\n",
            "83:\t[0s / 8s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1405\n",
            "84:\t[0s / 8s],\t\ttrain_loss: 0.1541,\tval_loss: 0.1401\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.1502,\tval_loss: 0.1423\n",
            "86:\t[0s / 9s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1403\n",
            "87:\t[0s / 9s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1403\n",
            "88:\t[0s / 9s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1420\n",
            "89:\t[0s / 9s],\t\ttrain_loss: 0.1479,\tval_loss: 0.1400\n",
            "90:\t[0s / 9s],\t\ttrain_loss: 0.1518,\tval_loss: 0.1398\n",
            "91:\t[0s / 9s],\t\ttrain_loss: 0.1489,\tval_loss: 0.1407\n",
            "92:\t[0s / 9s],\t\ttrain_loss: 0.1482,\tval_loss: 0.1416\n",
            "93:\t[0s / 9s],\t\ttrain_loss: 0.1543,\tval_loss: 0.1407\n",
            "94:\t[0s / 10s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1395\n",
            "95:\t[0s / 10s],\t\ttrain_loss: 0.1505,\tval_loss: 0.1405\n",
            "96:\t[0s / 10s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1409\n",
            "97:\t[0s / 10s],\t\ttrain_loss: 0.1559,\tval_loss: 0.1401\n",
            "98:\t[0s / 10s],\t\ttrain_loss: 0.1591,\tval_loss: 0.1415\n",
            "99:\t[0s / 10s],\t\ttrain_loss: 0.1499,\tval_loss: 0.1420\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2433,\tval_loss: 0.1556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2118,\tval_loss: 0.1441\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1794,\tval_loss: 0.1442\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1653,\tval_loss: 0.1419\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1407\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1410\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1633,\tval_loss: 0.1407\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.1617,\tval_loss: 0.1406\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1579,\tval_loss: 0.1414\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1415\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1413\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1416\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1414\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1402\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.1559,\tval_loss: 0.1431\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1411\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1417\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1403\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1603,\tval_loss: 0.1407\n",
            "19:\t[0s / 3s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1413\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.1606,\tval_loss: 0.1409\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.1663,\tval_loss: 0.1404\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1413\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1399\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1417\n",
            "25:\t[0s / 4s],\t\ttrain_loss: 0.1603,\tval_loss: 0.1414\n",
            "26:\t[0s / 4s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1420\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.1658,\tval_loss: 0.1409\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1402\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.1678,\tval_loss: 0.1427\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1401\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.1603,\tval_loss: 0.1418\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1644,\tval_loss: 0.1409\n",
            "33:\t[0s / 5s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1405\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1416\n",
            "35:\t[0s / 5s],\t\ttrain_loss: 0.1641,\tval_loss: 0.1422\n",
            "36:\t[0s / 5s],\t\ttrain_loss: 0.1582,\tval_loss: 0.1436\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.1667,\tval_loss: 0.1410\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.1629,\tval_loss: 0.1415\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1398\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.1610,\tval_loss: 0.1415\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1410\n",
            "42:\t[0s / 6s],\t\ttrain_loss: 0.1605,\tval_loss: 0.1409\n",
            "43:\t[0s / 6s],\t\ttrain_loss: 0.1621,\tval_loss: 0.1414\n",
            "44:\t[0s / 6s],\t\ttrain_loss: 0.1642,\tval_loss: 0.1416\n",
            "45:\t[0s / 6s],\t\ttrain_loss: 0.1651,\tval_loss: 0.1403\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.1685,\tval_loss: 0.1420\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.1685,\tval_loss: 0.1408\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.1655,\tval_loss: 0.1415\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.1662,\tval_loss: 0.1440\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.1652,\tval_loss: 0.1416\n",
            "51:\t[0s / 7s],\t\ttrain_loss: 0.1639,\tval_loss: 0.1412\n",
            "52:\t[0s / 7s],\t\ttrain_loss: 0.1655,\tval_loss: 0.1413\n",
            "53:\t[0s / 7s],\t\ttrain_loss: 0.1675,\tval_loss: 0.1431\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.1646,\tval_loss: 0.1418\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.1663,\tval_loss: 0.1406\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.1606,\tval_loss: 0.1429\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.1587,\tval_loss: 0.1413\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1441\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1430\n",
            "60:\t[0s / 8s],\t\ttrain_loss: 0.1654,\tval_loss: 0.1398\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1423\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.1619,\tval_loss: 0.1400\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.1629,\tval_loss: 0.1419\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1416\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1413\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.1605,\tval_loss: 0.1420\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.1637,\tval_loss: 0.1406\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.1660,\tval_loss: 0.1402\n",
            "69:\t[0s / 9s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1433\n",
            "70:\t[0s / 9s],\t\ttrain_loss: 0.1628,\tval_loss: 0.1418\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.1688,\tval_loss: 0.1419\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.1670,\tval_loss: 0.1404\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1417\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.1700,\tval_loss: 0.1445\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1417\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1423\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.1630,\tval_loss: 0.1434\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1737,\tval_loss: 0.1405\n",
            "79:\t[0s / 10s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1412\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1419\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1408\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1425\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.1609,\tval_loss: 0.1428\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1433\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.1656,\tval_loss: 0.1414\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1442\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1409\n",
            "88:\t[0s / 11s],\t\ttrain_loss: 0.1640,\tval_loss: 0.1426\n",
            "89:\t[0s / 11s],\t\ttrain_loss: 0.1653,\tval_loss: 0.1434\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.1651,\tval_loss: 0.1402\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1419\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.1685,\tval_loss: 0.1440\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.1661,\tval_loss: 0.1412\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.1705,\tval_loss: 0.1433\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.1675,\tval_loss: 0.1414\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.1680,\tval_loss: 0.1424\n",
            "97:\t[0s / 12s],\t\ttrain_loss: 0.1592,\tval_loss: 0.1424\n",
            "98:\t[0s / 12s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1418\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.1682,\tval_loss: 0.1438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2521,\tval_loss: 0.1497\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2159,\tval_loss: 0.1432\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1742,\tval_loss: 0.1435\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1632,\tval_loss: 0.1413\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1408\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1414\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1592,\tval_loss: 0.1412\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1416\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1526,\tval_loss: 0.1408\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1406\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1537,\tval_loss: 0.1422\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1404\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1634,\tval_loss: 0.1423\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1418\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1586,\tval_loss: 0.1398\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1413\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1658,\tval_loss: 0.1406\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1602,\tval_loss: 0.1408\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1409\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1407\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1570,\tval_loss: 0.1406\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1587,\tval_loss: 0.1399\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1607,\tval_loss: 0.1427\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1391\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1555,\tval_loss: 0.1427\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1574,\tval_loss: 0.1403\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1597,\tval_loss: 0.1409\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.1602,\tval_loss: 0.1410\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1407\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.1585,\tval_loss: 0.1406\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1403\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.1580,\tval_loss: 0.1419\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1418\n",
            "33:\t[0s / 5s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1403\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1399\n",
            "35:\t[0s / 5s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1407\n",
            "36:\t[0s / 5s],\t\ttrain_loss: 0.1604,\tval_loss: 0.1437\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.1559,\tval_loss: 0.1402\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.1590,\tval_loss: 0.1399\n",
            "39:\t[0s / 6s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1413\n",
            "40:\t[0s / 6s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1398\n",
            "41:\t[0s / 6s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1433\n",
            "42:\t[0s / 6s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1419\n",
            "43:\t[0s / 6s],\t\ttrain_loss: 0.1580,\tval_loss: 0.1393\n",
            "44:\t[0s / 6s],\t\ttrain_loss: 0.1596,\tval_loss: 0.1408\n",
            "45:\t[0s / 7s],\t\ttrain_loss: 0.1577,\tval_loss: 0.1406\n",
            "46:\t[0s / 7s],\t\ttrain_loss: 0.1555,\tval_loss: 0.1458\n",
            "47:\t[0s / 7s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1393\n",
            "48:\t[0s / 7s],\t\ttrain_loss: 0.1624,\tval_loss: 0.1415\n",
            "49:\t[0s / 7s],\t\ttrain_loss: 0.1624,\tval_loss: 0.1393\n",
            "50:\t[0s / 7s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1431\n",
            "51:\t[0s / 8s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1382\n",
            "52:\t[0s / 8s],\t\ttrain_loss: 0.1577,\tval_loss: 0.1414\n",
            "53:\t[0s / 8s],\t\ttrain_loss: 0.1543,\tval_loss: 0.1440\n",
            "54:\t[0s / 8s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1402\n",
            "55:\t[0s / 8s],\t\ttrain_loss: 0.1570,\tval_loss: 0.1415\n",
            "56:\t[0s / 8s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1429\n",
            "57:\t[0s / 8s],\t\ttrain_loss: 0.1556,\tval_loss: 0.1403\n",
            "58:\t[0s / 9s],\t\ttrain_loss: 0.1592,\tval_loss: 0.1402\n",
            "59:\t[0s / 9s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1412\n",
            "60:\t[0s / 9s],\t\ttrain_loss: 0.1537,\tval_loss: 0.1402\n",
            "61:\t[0s / 9s],\t\ttrain_loss: 0.1553,\tval_loss: 0.1411\n",
            "62:\t[0s / 9s],\t\ttrain_loss: 0.1612,\tval_loss: 0.1412\n",
            "63:\t[0s / 10s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1422\n",
            "64:\t[0s / 10s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1426\n",
            "65:\t[0s / 10s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1432\n",
            "66:\t[0s / 10s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1469\n",
            "67:\t[0s / 10s],\t\ttrain_loss: 0.1549,\tval_loss: 0.1453\n",
            "68:\t[0s / 10s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1417\n",
            "69:\t[0s / 11s],\t\ttrain_loss: 0.1627,\tval_loss: 0.1426\n",
            "70:\t[0s / 11s],\t\ttrain_loss: 0.1554,\tval_loss: 0.1417\n",
            "71:\t[0s / 11s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1438\n",
            "72:\t[0s / 11s],\t\ttrain_loss: 0.1576,\tval_loss: 0.1422\n",
            "73:\t[0s / 11s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1466\n",
            "74:\t[0s / 11s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1420\n",
            "75:\t[0s / 11s],\t\ttrain_loss: 0.1556,\tval_loss: 0.1435\n",
            "76:\t[0s / 11s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1411\n",
            "77:\t[0s / 12s],\t\ttrain_loss: 0.1583,\tval_loss: 0.1415\n",
            "78:\t[0s / 12s],\t\ttrain_loss: 0.1596,\tval_loss: 0.1404\n",
            "79:\t[0s / 12s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1416\n",
            "80:\t[0s / 12s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1422\n",
            "81:\t[0s / 12s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1421\n",
            "82:\t[0s / 12s],\t\ttrain_loss: 0.1583,\tval_loss: 0.1471\n",
            "83:\t[0s / 12s],\t\ttrain_loss: 0.1553,\tval_loss: 0.1417\n",
            "84:\t[0s / 12s],\t\ttrain_loss: 0.1530,\tval_loss: 0.1417\n",
            "85:\t[0s / 12s],\t\ttrain_loss: 0.1546,\tval_loss: 0.1404\n",
            "86:\t[0s / 13s],\t\ttrain_loss: 0.1551,\tval_loss: 0.1425\n",
            "87:\t[0s / 13s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1401\n",
            "88:\t[0s / 13s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1431\n",
            "89:\t[0s / 13s],\t\ttrain_loss: 0.1558,\tval_loss: 0.1439\n",
            "90:\t[0s / 13s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1436\n",
            "91:\t[0s / 13s],\t\ttrain_loss: 0.1548,\tval_loss: 0.1432\n",
            "92:\t[0s / 13s],\t\ttrain_loss: 0.1575,\tval_loss: 0.1420\n",
            "93:\t[0s / 13s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1432\n",
            "94:\t[0s / 13s],\t\ttrain_loss: 0.1570,\tval_loss: 0.1468\n",
            "95:\t[0s / 13s],\t\ttrain_loss: 0.1583,\tval_loss: 0.1440\n",
            "96:\t[0s / 14s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1463\n",
            "97:\t[0s / 14s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1407\n",
            "98:\t[0s / 14s],\t\ttrain_loss: 0.1569,\tval_loss: 0.1462\n",
            "99:\t[0s / 14s],\t\ttrain_loss: 0.1594,\tval_loss: 0.1444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2191,\tval_loss: 0.1535\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1840,\tval_loss: 0.1554\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1583,\tval_loss: 0.1437\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1431,\tval_loss: 0.1444\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1370,\tval_loss: 0.1407\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1325,\tval_loss: 0.1418\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1354,\tval_loss: 0.1411\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1331,\tval_loss: 0.1420\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1337,\tval_loss: 0.1407\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1349,\tval_loss: 0.1397\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1341,\tval_loss: 0.1412\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1365,\tval_loss: 0.1422\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1340,\tval_loss: 0.1442\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1329,\tval_loss: 0.1424\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1353,\tval_loss: 0.1408\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1364,\tval_loss: 0.1417\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1324,\tval_loss: 0.1433\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1324,\tval_loss: 0.1455\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1372,\tval_loss: 0.1402\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1335,\tval_loss: 0.1400\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.1334,\tval_loss: 0.1402\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.1338,\tval_loss: 0.1394\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.1321,\tval_loss: 0.1403\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.1369,\tval_loss: 0.1400\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.1312,\tval_loss: 0.1424\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.1330,\tval_loss: 0.1410\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.1346,\tval_loss: 0.1414\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.1348,\tval_loss: 0.1413\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.1347,\tval_loss: 0.1424\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.1355,\tval_loss: 0.1398\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.1372,\tval_loss: 0.1424\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.1324,\tval_loss: 0.1410\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.1334,\tval_loss: 0.1487\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.1359,\tval_loss: 0.1418\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.1363,\tval_loss: 0.1431\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.1332,\tval_loss: 0.1405\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.1326,\tval_loss: 0.1440\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.1381,\tval_loss: 0.1414\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.1364,\tval_loss: 0.1426\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.1402,\tval_loss: 0.1403\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.1338,\tval_loss: 0.1411\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.1328,\tval_loss: 0.1408\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.1350,\tval_loss: 0.1413\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.1350,\tval_loss: 0.1415\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.1375,\tval_loss: 0.1423\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.1378,\tval_loss: 0.1409\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.1359,\tval_loss: 0.1434\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.1337,\tval_loss: 0.1452\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.1330,\tval_loss: 0.1404\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.1357,\tval_loss: 0.1396\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.1322,\tval_loss: 0.1413\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.1387,\tval_loss: 0.1421\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.1351,\tval_loss: 0.1417\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.1321,\tval_loss: 0.1405\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.1373,\tval_loss: 0.1401\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.1412,\tval_loss: 0.1415\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.1346,\tval_loss: 0.1419\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.1381,\tval_loss: 0.1419\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.1372,\tval_loss: 0.1411\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.1327,\tval_loss: 0.1406\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.1321,\tval_loss: 0.1411\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.1350,\tval_loss: 0.1420\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.1340,\tval_loss: 0.1401\n",
            "63:\t[0s / 6s],\t\ttrain_loss: 0.1347,\tval_loss: 0.1407\n",
            "64:\t[0s / 6s],\t\ttrain_loss: 0.1344,\tval_loss: 0.1420\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.1345,\tval_loss: 0.1423\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.1327,\tval_loss: 0.1400\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.1336,\tval_loss: 0.1417\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.1365,\tval_loss: 0.1412\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.1374,\tval_loss: 0.1403\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.1339,\tval_loss: 0.1429\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.1438,\tval_loss: 0.1426\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.1418,\tval_loss: 0.1456\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.1425,\tval_loss: 0.1410\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.1372,\tval_loss: 0.1422\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.1432,\tval_loss: 0.1406\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.1365,\tval_loss: 0.1429\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.1396,\tval_loss: 0.1400\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.1356,\tval_loss: 0.1413\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.1395,\tval_loss: 0.1412\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.1400,\tval_loss: 0.1404\n",
            "81:\t[0s / 9s],\t\ttrain_loss: 0.1360,\tval_loss: 0.1406\n",
            "82:\t[0s / 9s],\t\ttrain_loss: 0.1362,\tval_loss: 0.1434\n",
            "83:\t[0s / 9s],\t\ttrain_loss: 0.1352,\tval_loss: 0.1405\n",
            "84:\t[0s / 9s],\t\ttrain_loss: 0.1399,\tval_loss: 0.1414\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.1378,\tval_loss: 0.1426\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.1387,\tval_loss: 0.1401\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.1378,\tval_loss: 0.1451\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.1427,\tval_loss: 0.1422\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.1398,\tval_loss: 0.1418\n",
            "Bootstrap 95% confidence interval for the C-index: (0.47, 0.68)\n",
            "Bootstrap 95% confidence interval for the IBS: (0.08, 0.09)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7y6LPowsllpi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "outputId": "60bf67e3-7103-4268-b07a-9a317b3bfb02"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABWgAAAJICAYAAAD8eA38AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACC/klEQVR4nOzdeVxV1f7/8fdBGQIFIxEVNUQD53CWMFTSciqHNMkynIiSLDG71b1+Ta+WStccsMIBRLGrpWWmqVdtuKZW95qWZmgqpiZF5sAgwUHYvz/8ea4nBgHRjfp6Ph4+HrDOWnt/9j4OyzfrrG0xDMMQAAAAAAAAAOC6czC7AAAAAAAAAAC4VRHQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAqh0AgICFBsba3YZdvbu3auwsDAFBgYqICBAycnJZpeESiI2NlYBAQF2baGhoXrppZdMqggAAFQmzG0BAFdS1ewCAFw/H3zwgV5++WW7Nk9PTzVu3FijR49Wly5dTKqsYhw+fFgbN27UgAEDVK9evQo7bl5ensaNGycnJye9/PLLcnFxUd26dYvs+/XXX+uJJ56wa/Pw8JCvr68ef/xxPfTQQxVWV1HWrVun06dPa/jw4WUeu3v3bu3YsUPh4eFyd3ev+OIqQFZWlhITE7V582adOHFC+fn5atCggbp06aInnnhC3t7eJY4fNmyYzp49q/Xr11+nigEAwLXC3LZ8mNua7+eff9Z9992nv/zlLxo1apSkst/rM2fO6K233tL27duVmpoqNzc3+fj4qGPHjhozZozc3NxKrOHgwYN68803tW/fPv3++++qUaOGGjdurNDQUA0bNqxiLxjAFRHQAregZ599VvXq1ZNhGDp9+rTWrFmjJ598UnFxcerWrZvZ5ZXb4cOHNX/+fHXo0KFCJ7HHjx/XyZMnNW3aNA0ePLhUY4YNG6aWLVtKks6dO6eNGzfqhRdeUGZmph577LEKq+3P1q9fr0OHDpVrErtnzx7Nnz9fAwYMqHSTWEk6ceKEhg8frl9++UU9e/bUkCFD5OjoqIMHD2r16tXaunWr/vWvf5ldpiRp06ZNslgsZpcBAMAtgblt2TC3rdxKc6/PnTunhx9+WFlZWXr44Yfl5+enc+fO6eDBg1qxYoUeffTREgPa3bt364knnlDdunU1ePBgeXl56ZdfftF3332nZcuWEdACJiCgBW5BISEhtn/0JWnQoEEKDg7W+vXrb+hJ7LVy5swZSVL16tVLPaZdu3bq2bOn7ftHH31U3bt317p1667pJPZ6KSgoUF5enpydna/L+S5cuKBnnnlGp0+f1rJly9SuXTu716Ojo7Vo0aLrUktpODk5mV0CAAC3DOa2ZcPctrDrPbctSWnu9erVq5WamqoVK1aoTZs2duOzsrLk6OhY4jni4uJUvXp1rV69ulB4ffr06Qq6ktL5448/dNttt13XcwKVEXvQApC7u7ucnZ1Vtar9z2yys7M1Y8YMdenSRS1atNADDzyg+Ph4GYYhScrJyVHPnj3Vs2dP5eTk2MadO3dOnTt3VlhYmPLz8yVJL730klq3bq0TJ05o1KhRCgwMVOfOnTV//nzb8Uryww8/aPTo0WrTpo1at26t8PBwffvtt7bXP/jgAz333HOSpCeeeEIBAQEKCAjQ119/XeJxv/zySw0dOlSBgYFq166dnn76aR05csT2+ksvvaTHH39ckvTcc88pICCgXD9RdnJykoeHR6F7fOHCBb355pvq3r27WrRoodDQUL3xxhuyWq2FjvHOO++oT58+atGihTp37qwpU6YoIyPD9vqwYcP0+eef6+TJk7brDw0Ntb2elJSkPn366O6771b79u01cOBArVu3TtLFfVRjYmIkSffdd59t/M8//yzp4t5pf//73/XRRx+pT58+atmypb744gtJUnx8vMLCwtSxY0e1atVKAwcO1KZNmwrVf/kxHnjgAbVs2VIDBw7Uf//73yvev82bN+vAgQN66qmnCoWzklStWjVFR0df8ThFuVTX1q1b1bdvX7Vo0UJ9+vTRtm3bCvXdtWuXHn74YbVs2VLdu3fXypUrizxmUXvQZmRk6LXXXlNoaKhatGihkJAQ/eUvf7H9J0mSrFar5s2bpx49eqhFixbq0qWLYmJiCv1+2LFjhx599FG1a9dOrVu31gMPPKA33nijXNcPAMDNhrktc9vKPrcti6Lu9fHjx1WlShUFBgYW6l+tWrUrBs3Hjx9X48aNi1xZfMcddxRqW7t2rQYNGmS714899pi2b99u1+dK76d08T3t27evvv/+ez322GO6++67bXNY5sG41bGCFrgFZWVl2UKh06dPKykpSdnZ2Xb7GhmGoaefflpff/21Bg0apKZNm+qLL75QTEyM0tLS9Ne//lUuLi6aOXOmHn30Uc2ePdu2B9jf//53ZWZmavr06apSpYrtmPn5+Ro9erTuvvtuvfDCC/riiy8UGxur/Px82wS0KIcOHdJjjz0mNzc3jR49WlWrVtW7776rYcOGafny5baJwrBhw5SUlKSnnnpKfn5+kqRGjRoVe9ydO3cqIiJC9erV0zPPPKOcnBwtX75cjz76qD744APVq1dPQ4YMkbe3t+Li4mwfN6pZs+YV7/H58+dt9zg9PV3r16/Xjz/+qFdffdWu38SJE7VmzRo98MADGjFihPbu3asFCxboyJEjevPNN239YmNjNX/+fN1zzz169NFHdfToUa1YsUL79u3TihUr5OjoqKeeekqZmZn69ddfbe/FpY82vffee5o2bZoeeOABPfHEE8rNzdXBgwf13Xff6cEHH1SPHj30008/af369Xr55Zd1++23S7q4j9slX331lTZu3KjHHntMt99+u3x8fCRJy5YtU2hoqB588EHl5eXp448/1nPPPacFCxaoa9eudtf73//+Vxs2bNCwYcPk5OSkFStWaPTo0Vq1apX8/f2LvZ+ffPKJJKlfv35XvPfl8c0332jz5s0aOnSo3NzclJSUpGeffVafffaZ7V4cPHhQo0aNkqenp8aOHasLFy4oNja2yEnsn50/f16PPfaYjhw5oocffljNmjXT2bNn9emnnyotLU2enp4qKCjQ008/rW+++UaPPPKIGjVqpB9//FFLly7VTz/9pLfeekvSxT8PkZGRCggI0LPPPisnJycdO3ZMu3fvvib3BgCAyo657UXMbW+cue3V3msfHx/l5+dr7dq1GjBgQJnP4ePjoz179ujHH3+8Yp3z589XbGysWrdurWeffVaOjo767rvv9NVXX6lz586SSvd+XnLu3DlFRESoT58+euihh3THHXcwDwYkyQBwy3j//fcNf3//Qr9atGhhfPDBB3Z9t2zZYvj7+xtvvfWWXfvYsWONgIAA49ixY7a2WbNmGU2aNDH++9//Ghs3bjT8/f2NxMREu3Evvvii4e/vb0ydOtXWVlBQYDz55JNG8+bNjdOnT9va/f39jXnz5tm+HzNmjNG8eXPj+PHjtra0tDSjdevWxmOPPWZru3Tur776qlT3o1+/fkZQUJBx9uxZW1tycrLRpEkT4y9/+Yut7auvvjL8/f2NjRs3XvGYl/r++VeTJk2Mt99+265vcnKy4e/vb/ztb3+za58xY4bh7+9vfPnll4ZhGMbp06eN5s2bGyNHjjTy8/Nt/ZYvX274+/sbq1evtrU9+eSTRrdu3QrV9fTTTxt9+vQpsfbFixcb/v7+xokTJwq9dukaDh06VOi1P/74w+57q9Vq9O3b13jiiScKHcPf39/Yt2+fre3kyZNGy5YtjaioqBJr69+/v9G2bdsS+5TG448/Xug++Pv7G82bN7f7PX3pvUlKSrK1jRkzxmjZsqVx8uRJW9vhw4eNpk2bGv7+/nbH7Natm/Hiiy/avp87d67h7+9vbN68uVBNBQUFhmEYxocffmj7c3S5FStWGP7+/sY333xjGIZhLFmyxPD397f7MwMAwK2Iua095rb2KvPc9sSJE4a/v7+xePFiW1tZ7vWpU6eMTp06Gf7+/kbPnj2NSZMmGevWrTMyMjJKPO8l27dvN5o2bWo0bdrUGDJkiBETE2N88cUXhtVqtev3008/GU2aNDGioqLs3ivD+N8ctizv5+OPP274+/sbK1assDsW82DAMNjiALgFTZo0SUuWLNGSJUv0+uuvq2PHjpo4caI2b95s67Nt2zZVqVKl0EeeRo4cKcMw7D7+/cwzz6hx48Z68cUXNWXKFHXo0KHQE0gvuXyPKovFoscee0x5eXn68ssvi+yfn5+vHTt2qHv37qpfv76tvVatWurbt6+++eYbZWVllfke/Pbbb0pOTtaAAQNUo0YNW3uTJk10zz336N///neZj3m5qKgo2z2ePXu2+vTpo9mzZ2vp0qW2PpfOMWLECLuxI0eOtHt9586dysvL0xNPPCEHh//9tT148GBVq1atVLW6u7vr119/1d69e8t9Te3bt1fjxo0Ltbu4uNi+Tk9PV2Zmptq2basffvihUN/WrVurRYsWtu/r1q2r++67T9u3b7d9ZLAoWVlZV3wS7dW455571KBBA9v3TZo0UbVq1XTixAlJF38fbt++Xd27d7d7ynGjRo1sKwdKsnnzZjVp0kQ9evQo9Nqlh4lt2rRJjRo1kp+fn86cOWP71alTJ0myfaTx0kfRPvnkExUUFJTzigEAuHkwt2VuWx5mzm1LUpp7XbNmTa1du1ZhYWHKyMjQypUr9fzzzysoKEhvvvnmFbfZCA4O1sqVKxUaGqoDBw5o8eLFGjVqlEJCQmyfXJOkrVu3qqCgQFFRUXbvlfS/OWxZ308nJycNHDjQro15MMAWB8AtqVWrVnYPUujbt6/69++vv//97+rataucnJx08uRJ1apVS9WqVbMbe+ljVSdPnrS1OTk56bXXXtOgQYPk7Oys1157rcgn2Ds4ONhNRCWpYcOGhY53uTNnzuiPP/6w9ftzLQUFBfrll1901113lfLqL0pNTbU7/5+Pu337dmVnZ8vV1bVMx73E399f99xzj+373r17KysrS7NmzdKDDz4oT09PnTx5Ug4ODnbBoCR5eXnJ3d3ddk8u1Xrpo22XODk5qX79+sXeu8tFRERo586dGjx4sO68804FBwerb9++atu2bamvqbinB3/22Wd6++23lZycbLdHVFG/B+68885Cbb6+vvrjjz905swZeXl5FXmOy8PSKzl//ryys7Nt31epUsXu42xFqVOnTqE2Dw8P275ZZ86cUU5OTpH1N2zY8Ir/kTh+/Ljuv//+EvscO3ZMR44cUVBQUJGvX3pgQ+/evbVq1SpNnDhRs2bNUlBQkHr06KGePXsWmjgDAHArYG7L3PZGm9uWpDT3WroY6k+ZMkWTJ0/WTz/9pO3bt2vRokWaN2+eatWqpcGDB5d4nlatWmn+/PmyWq06cOCAtm7dqsTERD333HP68MMP1bhxYx0/flwODg4lbq1R1vfT29u70AN1mQcDBLQAdHFy2bFjRy1btkzHjh0r84RQkm2T+NzcXB07dqzQZBVSp06d9Nlnn2nv3r12+1cVNdmraI0aNdKmTZv0+eef64svvtDmzZv1z3/+U1FRUXr22WdLdYzLVxNcsmvXLj399NNq3769XnnlFXl5ecnR0VHvv/++1q9fX2H1+/n56YcfftAvv/xSZJh6uYSEBM2fP9/2vY+Pjz799NMSx1y+n9zlrrT6oCIVFBTI39/ftsfan9WuXVvSxffhnXfe0ddff217Pzds2KB3331XCQkJxV4LAAC3Cua21wdz2+unuHstXbzfDRs2VMOGDdW1a1fdf//9+uijj64Y0F7i5OSkVq1aqVWrVvL19dXLL7+sTZs26ZlnnrkGV1L0fWceDBDQAvj/Ln0E59LKQx8fH3355ZfKysqyW2mQkpJie/2SAwcO6M0339TAgQN14MABTZw4UevWrVP16tXtzlFQUKATJ07Y/WT/6NGjhY53OU9PT9122222fpdLSUmRg4ODLbAry2Tw0sfUizvu7bffXu4VBsUp6h4XFBTo2LFjdj+V/v3335WRkWG7J5dqTUlJsfvPgdVq1c8//2z3E/aS7oGrq6t69+6t3r17y2q1auzYsYqLi1NkZKScnZ3LNZn+17/+JWdnZ8XHx9v9JPz9998vsv+xY8cKtf3000+67bbbSlzl2q1bN61fv14fffSRIiMjS6ypf//+dqsnrvQU29Lw9PSUi4tLkfUX9Xvozxo0aKBDhw5dsc+BAwcUFBR0xffCwcFBQUFBCgoK0ssvv6y4uDjNnj1bX3/9td3vBwAAblXMbe2Py9y2dK7X3Las/nyvi1O/fn25u7vr1KlT5TrPpe0afvvtN0kX56cFBQU6cuSImjZtWuSYsryfxWEeDEisAQegvLw87dixQ46OjrbJVEhIiPLz8/XOO+/Y9U1MTJTFYlFISIht7Msvv6xatWrpb3/7m6ZPn67ff/9dr732WpHnuvx4hmHonXfekaOjY7EfZ6lSpYqCg4P1ySef6Oeff7a1//7771q/fr3atm1rm2TfdtttkqTMzMwrXnOtWrXUtGlTffjhh7aPsUvSjz/+qB07dqhLly5XPEZZff7555KkgIAASbKd4/L9pCRpyZIldq/fc889cnR0VFJSkt2KztWrVyszM9Ou1ttuu63I6z979qzd905OTmrUqJEMw1BeXp5trFS6+3dJlSpVZLFY7PbY+vnnn+32rrrcnj17tH//ftv3v/zyiz755BMFBweX+BPvBx54QP7+/oqLi9OePXsKvZ6VlaXZs2dLujgxveeee2y/yvJRt+JUqVJFnTt31tatW20f45KkI0eO2FbYlOT+++/XgQMHtGXLlkKvXXpPe/XqpbS0NL333nuF+uTk5Ngm5OfOnSv0+qUJ8+UfwwMA4FbF3Ja57aWxUuWc25bVn+/1d999V2RYu3fvXp07d67IrS4u99VXXxX5SbFL23Zd2q6ge/fucnBw0Jtvvlloz9dL48vyfhaHeTDAClrglrRt2zbbaoEzZ85o3bp1+umnn/Tkk0/aJoShoaHq2LGjZs+erZMnTyogIEA7duzQJ598ovDwcNveUpf2Z0pMTFS1atXUpEkTRUVFac6cOerZs6fdP8jOzs764osv9OKLL6pVq1b64osv9Pnnn+upp54q8SfM48aN086dOzV06FANHTpUVapU0bvvviur1aoXXnjB1q9p06aqUqWKFi1apMzMTDk5OalTp0664447ijzuX/7yF0VERGjIkCEaNGiQcnJytHz5clWvXv2qP9Kza9cu5ebmSrr4cIFPP/1U//nPf9SnTx/bfxSaNGmiAQMG6N1331VGRobat2+vffv2ac2aNerevbttU3xPT09FRkZq/vz5Gj16tEJDQ3X06FH985//VMuWLfXQQw/Zztu8eXNt2LBB06dPV8uWLeXq6qrQ0FCNGjVKNWvWVJs2bXTHHXcoJSVFy5cvV5cuXWzvefPmzSVJs2fPVu/eveXo6Khu3bqVuNqiS5cuWrJkiUaPHq2+ffvq9OnT+uc//6kGDRro4MGDhfr7+/tr1KhRGjZsmJycnLRixQpJ0tixY0u8n46Ojpo/f75GjBihxx9/XD179lSbNm3k6OioQ4cOaf369XJ3d1d0dHRp36IyGzt2rL744gs99thjevTRR5Wfn6/ly5ercePGRV7r5UaNGqV//etfeu655/Twww+refPmtt8XU6ZMUZMmTdSvXz9t3LhRr7zyir7++mu1adNG+fn5SklJ0aZNm7R48WK1bNlSb775pnbt2qUuXbrIx8fHds9r165dIWE0AAA3Gua2FzG3vXHmtld7r9euXat169ape/fuatGihRwdHXXkyBG9//77cnZ21lNPPVXiOaZNm6Y//vhDPXr0kJ+fn/Ly8rR7925t3LhRPj4+tod43XnnnXrqqaf01ltvaejQobr//vvl5OSkffv2qVatWnr++efL9H4Wh3kwQEAL3JLmzZtn+9rZ2Vl+fn6aPHmywsLCbO0ODg56++23NW/ePG3YsEEffPCBfHx89Je//MX2JNb9+/drwYIFevzxx20TLkl68skn9cknn2jixIn6+OOPbU/brFKlihYvXqzJkyfr9ddfl5ubm5555hlFRUWVWO9dd92ld955R7NmzdKCBQtkGIZatWql119/XXfffbetn5eXl6ZMmaIFCxbob3/7m/Lz87Vs2bJiJ7H33HOPFi9erHnz5mnevHmqWrWq2rdvrxdeeOGq9xlLSkqyfe3o6Kj69esrOjpao0aNsus3bdo01atXT2vWrNHWrVtVs2ZNRUZGFppEjx07Vp6enlq+fLmmT58uDw8PPfLIIxo/frwcHR1t/YYOHark5GR98MEHSkxMlI+Pj0JDQzVkyBCtW7dOS5YsUXZ2tmrXrq1hw4ZpzJgxtrGtWrXSc889p5UrV+qLL75QQUGBPvnkkxInsUFBQXr11Ve1aNEivfbaa6pXr54mTJigkydPFjmJbd++vQIDA/Xmm28qNTVVjRs31vTp09WkSZMr3tM777xTH374oRITE7Vlyxbb01vvvPNODR48uNBTmStakyZNFB8fr+nTp2vevHmqXbu2xo4dq1OnTl0xoHVzc9M777yj2NhYbdmyRWvWrNEdd9yhoKAgeXt7S5JtdUJiYqLWrl2rLVu26LbbblO9evU0bNgw20qI0NBQnTx5Uu+//77Onj2r22+/XR06dNDYsWMLffQSAIBbAXPbi5jb3lhz2+KU5l4PGTJELi4u+uqrr/Tpp58qKytLt99+u4KDgxUZGalmzZqVeI6//OUv2rRpk/7973/r3XffVV5enurWrauhQ4fq6aeftv0el6TnnntO9erV0/LlyzV79mzddtttCggIUL9+/Wx9Svt+Fod5MCBZjOv5BBQAt6yXXnpJ//rXv4r8eDpuDQEBAXrsscc0adIks0sBAAC4KsxtwdwWQEViD1oAAAAAAAAAMAkBLQAAAAAAAACYhIAWAAAAAAAAAEzCHrQAAAAAAAAAYBJW0AIAAAAAAACASQhoAQAAAAAAAMAkVc0u4Ea3Z88eGYYhR0dHs0sBAAC4IeTl5clisah169Zml4JSYL4LAABQdmWZ8xLQXiXDMMQ2vgAAAKXH3OnGwnwXAACg7MoyfyKgvUqXVhK0bNnS5EoAAABuDPv27TO7BJQB810AAICyK8uclz1oAQAAAAAAAMAkBLQAAAAAAAAAYBICWgAAAAAAAAAwCQEtAAAAAAAAAJiEgBYAAAAAAAAATEJACwAAAAAAAAAmIaAFAAAAAAAAAJMQ0AIAAAAAAACASQhoAQAAAAAAAMAkBLQAAAAAAAAAYBICWgAAAAAAAAAwCQEtAAAAAAAAAJiEgBYAAAAAAAAATEJACwAAAAAAAAAmIaAFAAAAAAAAAJMQ0AIAAAAAAACASQhoAQAAAAAAAMAkBLQAAAAAAAAAYBICWgAAAAAAAAAwCQEtAAAAAAAAAJiEgBYAAAAAAAAATFLV7AIAmMswDOXm5ppdBq4BwzAkSRaLxeRKcC04Ozvz3gIAUErMeW9ezHlvXsx3cSshoAVuYYZh6MUXX1RycrLZpQAoo6ZNm2rmzJlMWoHr5MiRI5o2bZr27NkjNzc39evXT+PGjZOTk1OJ4wzD0KJFi/TPf/5TZ86cUdOmTfXyyy8rMDDQrt+uXbs0d+5cHThwQA4ODmrZsqWef/55NW3a1NbnpZde0po1awqdY9GiRQoJCbF9HxAQUKhPzZo1tWPHjjJeNXBzYM4L3JiY7+JWQkALAAAAlCA9PV3h4eHy9fVVbGys0tLSNGPGDOXk5GjSpEkljl20aJHmzZunCRMmKCAgQO+8845GjhyptWvXqn79+pKklJQUjRo1Sp06ddKsWbNktVq1YMECDR8+XOvXr5eXl5ftePXr19c//vEPu3M0atSo0HmHDRumvn372r53dHS8mlsAAACAa4iAFriFWSwWzZw5k4973YRycnI0bNgwSVJSUpJcXFxMrggVjY98AdfPypUrdf78ec2fP181atSQJOXn52vKlCmKjIyUt7d3keNyc3O1YMECjRw5UsOHD5cktW3bVj179lR8fLwmT54sSdq6dasMw9DcuXNtf18HBASoe/fu2rFjh/r37287pouLS6HVt0WpU6dOqfoBtwLmvDcv5rw3N+a7uJUQ0AK3OIvFwkTmJufi4sJ7DABXYdu2bQoKCrKFs5LUq1cvvfLKK9qxY4cGDhxY5Ljdu3crKytLvXr1srU5OTmpR48e2rJli60tLy9PTk5OcnZ2trVVr1694i8EuIUx5735MecFcCNzMLsAAAAAoDJLSUmRn5+fXZu7u7u8vLyUkpJS4jhJhcY2atRIqampysnJkST16dNH+fn5mjNnjs6ePau0tDRNnz5dderU0X333Wc39tixY2rbtq1atGihgQMHauvWrUWee+HChWrevLnatWuncePGKTU1tczXDQAAgOuDFbQAAABACTIyMuTu7l6o3cPDQ+np6SWO+/PKWOliuGsYhtLT0+Xi4iJfX18lJiZqzJgxiouLkyT5+PhoyZIlditpmzZtqpYtW6px48bKzMzUihUrFBUVpblz56pnz562fv3791fXrl1Vs2ZN/fjjj3r77bc1dOhQrV27Vh4eHuW6B4ZhKDs7u1xjAeBaufSDLknKzs5WQUGBidUAgD3DMEq9TQcBLQAAAGCio0ePauzYsQoODlb//v2Vm5urhIQERUREaOXKlapZs6YkKTw83G5caGiowsLCNG/ePLuAdubMmbav27dvr7Zt22rgwIF67733FBERUa4a8/LylJycXK6xAHCtWK1W29cHDx6Uk5OTidUAQGGl/XuJgBYAAAAogbu7uzIzMwu1p6enl7gi1d3dXVarVbm5uXaraDMyMmSxWGxjZ8+erZo1ayomJsbWp0OHDurWrZuWLVum8ePHF3l8BwcH3X///Xr99deVk5NT7N6LTZo0UcOGDbV///5SXW9RHB0d1bhx43KPB4Br4fIVtAEBAexBC6BSOXz4cKn7EtACAAAAJfDz8yu012xmZqZOnTpVaH/ZP4+TLq6QbdKkia09JSVFdevWtQUJhw8fVmBgoN1YNzc3NWjQQMePH6+gq7g6FotFrq6uZpcBAHYcHP73WB1XV1cCWgCVSmm3N5B4SBgAAABQopCQEO3cuVMZGRm2tk2bNsnBwUHBwcHFjmvTpo2qVaumjRs32try8vK0efNmhYSE2Nrq1q2r5ORkGYZha8vKytKxY8fk4+NT7PELCgq0adMm3XXXXSWGEsnJyTp69Khatmx5xWsFAADA9ccKWgAAAKAEYWFhSkpKUlRUlCIjI5WWlqaYmBiFhYXJ29vb1i88PFypqanasmWLJMnZ2VmRkZGKjY2Vp6en/P39tWLFCp07d06jRo2yO35UVJQmTJigfv36yWq1KiEhQVarVYMHD5YknTx5Ui+99JL69OmjO++8U+np6VqxYoW+//57xcbG2o4VHx+v48ePq2PHjvL09NShQ4cUFxen2rVr244FAACAyoWAFgAAACiBh4eHli5dqqlTpyoqKkpubm4aNGiQoqOj7foVFBQoPz/fri0iIkKGYSghIUFnzpxR06ZNFR8fr/r169v6dO/eXXPmzFF8fLyio6Pl6OioZs2aadmyZfL19ZV0ccuDatWq6e2339bp06fl6OioFi1aaNGiRbr33nttx2rYsKE2b96sjRs36vz587r99tvVpUsXjRs3Tu7u7tfuJgEAAKDcLMbln6VCme3bt0+S+MgYgEolJyfHtlJq1apV7McFoFJh/nRj4f0CUFkx5wVQmZVlDsUetAAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmKSq2QX82ZEjRzRt2jTt2bNHbm5u6tevn8aNGycnJ6crjk1LS9Mbb7yhf//738rOzpaPj4+efvppPfTQQ5Kkn3/+Wffdd1+hcXfffbfee++9Cr8WAAAAAAAAAChJpQpo09PTFR4eLl9fX8XGxiotLU0zZsxQTk6OJk2aVOLY3377TUOGDFHDhg01depUVatWTYcOHZLVai3Ud/z48erYsaPtezc3twq/FgAAAAAAAAC4kkoV0K5cuVLnz5/X/PnzVaNGDUlSfn6+pkyZosjISHl7exc79vXXX1ft2rW1ePFiValSRZIUFBRUZN8777xTgYGBFV0+AAAAAAAAAJRJpdqDdtu2bQoKCrKFs5LUq1cvFRQUaMeOHcWOy8rK0saNGzV06FBbOAsAAAAAAAAAlV2lCmhTUlLk5+dn1+bu7i4vLy+lpKQUO27//v3Ky8tT1apV9fjjj6t58+YKDg7W66+/rry8vEL9J0+erKZNmyooKEgTJ07UuXPnKvpSAAAAAAAAAOCKKtUWBxkZGXJ3dy/U7uHhofT09GLH/f7775KkiRMn6pFHHtEzzzyjvXv3at68eXJwcNDzzz8vSXJyctKjjz6qzp07y93dXd99953i4uL0/fffa9WqVXJ0dCxX3YZhKDs7u1xjAeBayMnJsX2dnZ2tgoICE6sBAHuGYchisZhdBgAAAFApVKqAtrwuBQ/33HOPXnrpJUlSp06ddP78eSUkJCgqKkouLi6qVauWJk+ebBvXoUMH3XXXXYqMjNSWLVvUu3fvcp0/Ly9PycnJV30dAFBRLn9A4sGDB+Xk5GRiNQBQGH8vAQAAABdVqoDW3d1dmZmZhdrT09Pl4eFR4jjpYih7uaCgIMXFxenYsWMKCAgocmyXLl3k6uqq/fv3lzugdXR0VOPGjcs1FgCuhctX0AYEBMjFxcXEagDA3uHDh80uAQAAAKg0KlVA6+fnV2iv2czMTJ06darQ3rSXu1I4mpubWyH1FcdiscjV1fWangMAysLB4X9bjLu6uhLQAqhU2N4AAAAA+J9K9ZCwkJAQ7dy5UxkZGba2TZs2ycHBQcHBwcWO8/Hxkb+/v3bu3GnXvnPnTrm4uJQY4H722WfKzs5Wy5Ytr/4CAAAAAAAAAKAMKlVAGxYWJjc3N0VFRWn79u16//33FRMTo7CwMHl7e9v6hYeHq0ePHnZjo6Oj9emnn+rVV1/Vjh07FBcXp4SEBA0fPty2unXGjBmaOXOm/vWvf+nLL7/UggULNGHCBLVo0ULdu3e/rtcKAACAG8eRI0c0YsQIBQYGKjg4WDExMXb7fRfHMAwtXLhQXbt2VatWrTRkyBB9++23hfrt2rVLw4YNU/v27dWxY0eNHj260DMOXnrpJQUEBBT6tW3bNrt+VqtVM2fOVHBwsAIDAzVixIhCn1IDAABA5VGptjjw8PDQ0qVLNXXqVEVFRcnNzU2DBg1SdHS0Xb+CggLl5+fbtYWGhuqNN97QW2+9pRUrVqhWrVoaO3asnnzySVufRo0aacWKFXrvvfeUk5Mjb29vDRo0SM8++6yqVq1UtwIAAACVRHp6usLDw+Xr66vY2FilpaVpxowZysnJ0aRJk0ocu2jRIs2bN08TJkxQQECA3nnnHY0cOVJr165V/fr1JUkpKSkaNWqUOnXqpFmzZslqtWrBggUaPny41q9fLy8vL9vx6tevr3/84x9252jUqJHd99OmTdOGDRv00ksvydvbW3FxcRo+fLg+/vhjVa9evYLuCgAAACpKpUslGzVqpMTExBL7JCUlFdneu3fvEh/0NXjwYA0ePPhqygMAAMAtZuXKlTp//rzmz5+vGjVqSJLy8/M1ZcoURUZG2n3S63K5ublasGCBRo4cqeHDh0uS2rZtq549eyo+Pl6TJ0+WJG3dulWGYWju3Lm2PcMDAgLUvXt37dixQ/3797cd08XFRYGBgcXW+uuvv2r16tV65ZVXNGjQIElSy5Yt1a1bN61cuVIRERFXdS8AAABQ8SrVFgcAAABAZbNt2zYFBQXZwllJ6tWrlwoKCrRjx45ix+3evVtZWVnq1auXrc3JyUk9evSw25YgLy9PTk5OcnZ2trWVd6Xr9u3bVVBQoJ49e9raatSooeDg4EJbIQAAAKByIKAFAAAASpCSkiI/Pz+7Nnd3d3l5eZW4t+ul1/48tlGjRkpNTVVOTo4kqU+fPsrPz9ecOXN09uxZpaWlafr06apTp47uu+8+u7HHjh1T27Zt1aJFCw0cOFBbt24tdM477rhDHh4ehc7JPrQAAACVU6Xb4gAAAACoTDIyMuTu7l6o3cPDQ+np6SWO+/PKWOliuGsYhtLT0+Xi4iJfX18lJiZqzJgxiouLkyT5+PhoyZIlditpmzZtqpYtW6px48bKzMzUihUrFBUVpblz59pWzGZkZBS5+tbd3b3EWq/EMAxlZ2eXezwAXAuXftAlSdnZ2SooKDCxGgCwZxiGLBZLqfoS0AIAAAAmOnr0qMaOHavg4GD1799fubm5SkhIUEREhFauXKmaNWtKksLDw+3GhYaGKiwsTPPmzbPb0uBayMvLU3Jy8jU9BwCUldVqtX198OBBOTk5mVgNABRW2r+XCGgBAACAEri7uyszM7NQe3p6eqGtBP48zmq1Kjc3124VbUZGhiwWi23s7NmzVbNmTcXExNj6dOjQQd26ddOyZcs0fvz4Io/v4OCg+++/X6+//rpycnLk4uIid3d3ZWVlFeqbkZFRYq1X4ujoqMaNG5d7PABcC5evoA0ICLA9aBEAKoPDhw+Xui8BLQAAAFACPz+/Qvu3ZmZm6tSpU4X2l/3zOOniCtkmTZrY2lNSUlS3bl1bkHD48GEFBgbajXVzc1ODBg10/PjxMtf6+++/FwqPi9pHtywsFotcXV3LPR4ArgUHh/89VsfV1ZWAFkClUtrtDSQeEgYAAACUKCQkRDt37lRGRoatbdOmTXJwcFBwcHCx49q0aaNq1app48aNtra8vDxt3rxZISEhtra6desqOTlZhmHY2rKysnTs2DH5+PgUe/yCggJt2rRJd911ly2U6Ny5sxwcHLR582Zbv/T0dG3fvt3unAAAAKg8WEELAAAAlCAsLExJSUmKiopSZGSk0tLSFBMTo7CwMHl7e9v6hYeHKzU1VVu2bJEkOTs7KzIyUrGxsfL09JS/v79WrFihc+fOadSoUXbHj4qK0oQJE9SvXz9ZrVYlJCTIarVq8ODBkqSTJ0/qpZdeUp8+fXTnnXcqPT1dK1as0Pfff6/Y2FjbsWrXrq1BgwYpJiZGDg4O8vb21oIFC1S9enWFhYVdpzsGAACAsiCgBQAAAErg4eGhpUuXaurUqYqKipKbm5sGDRqk6Ohou34FBQXKz8+3a4uIiJBhGEpISNCZM2fUtGlTxcfHq379+rY+3bt315w5cxQfH6/o6Gg5OjqqWbNmWrZsmXx9fSVd3PKgWrVqevvtt3X69Gk5OjqqRYsWWrRoke699167c06cOFFubm6aNWuWzp8/rzZt2mjJkiWqXr36tblBAAAAuCoW4/LPUqHM9u3bJ0lq2bKlyZUAwP/k5OTYVl2tWrWK/bgAVCrMn24svF8AKivmvAAqs7LModiDFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCRVzS4ANwbDMJSbm2t2GQBKKScnp8ivAVR+zs7OslgsZpcBAAAA4DohoEWp5ObmavDgwWaXAaAchg0bZnYJAMpg1apVcnFxMbsMAAAAANcJWxwAAAAAAAAAgElYQYsyc7urvywO/NYBKjvDMCSJj0oDNwCj4ILOH/rQ7DIAAAAAmICUDWVmcahKQAvcAIhlAQAAAACo/NjiAAAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMUtXsAgAAAACgMjAMQ7m5uWaXAaCUcnJyivwaQOXn7Owsi8VidhmVBgEtAAAAAEjKzc3V4MGDzS4DQDkMGzbM7BIAlMGqVavk4uJidhmVBlscAAAAAAAAAIBJWEELAAAAAH/idld/WRz47xJQ2RmGIUl8VBq4ARgFF3T+0Idml1EpMeMAAAAAgD+xOFQloAVuAMSyAG4GbHEAAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCRVzS4ANx6j4ILZJQAAcFPh31YAAADg1kVAi1IxDMP29flDH5pXCAAAN7nL/80FAAAAcPNjiwMAAAAAAAAAMAkraFEqFovF9rXbXf1lceC3DgAAFcUouGD7hMrl/+YCAAAAuPmRsqHMLA5VCWgBAAAAAACACsAWBwAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAXMGRI0c0YsQIBQYGKjg4WDExMbJarVccZxiGFi5cqK5du6pVq1YaMmSIvv3220L9du3apWHDhql9+/bq2LGjRo8ereTk5GKP+/3336tp06Zq3bp1odcCAgIK/QoODi7T9QIAAOD6qWp2AQAAAEBllp6ervDwcPn6+io2NlZpaWmaMWOGcnJyNGnSpBLHLlq0SPPmzdOECRMUEBCgd955RyNHjtTatWtVv359SVJKSopGjRqlTp06adasWbJarVqwYIGGDx+u9evXy8vLy+6YhmFo6tSp8vT0VHZ2dpHnHTZsmPr27Wv73tHR8SrvAgAAAK4VAloAAACgBCtXrtT58+c1f/581ahRQ5KUn5+vKVOmKDIyUt7e3kWOy83N1YIFCzRy5EgNHz5cktS2bVv17NlT8fHxmjx5siRp69atMgxDc+fOlYuLi6SLq2C7d++uHTt2qH///nbHff/993X27Fk9/PDDSkpKKvLcderUUWBg4NVeOgAAAK4DtjgAAAAASrBt2zYFBQXZwllJ6tWrlwoKCrRjx45ix+3evVtZWVnq1auXrc3JyUk9evTQtm3bbG15eXlycnKSs7Ozra169epFHjMjI0OzZs3Syy+/zKpYAACAmwQBLQAAAFCClJQU+fn52bW5u7vLy8tLKSkpJY6TVGhso0aNlJqaqpycHElSnz59lJ+frzlz5ujs2bNKS0vT9OnTVadOHd133312Y+fMmaPmzZurW7duJda8cOFCNW/eXO3atdO4ceOUmppa6usFAADA9cUWBwAAAEAJMjIy5O7uXqjdw8ND6enpJY7788pY6WK4axiG0tPT5eLiIl9fXyUmJmrMmDGKi4uTJPn4+GjJkiV2K2mTk5O1evVqrVmzpsR6+/fvr65du6pmzZr68ccf9fbbb2vo0KFau3atPDw8ynLpNoZhFLvf7c3kUmgOAACurezsbBUUFJhdxjVlGIYsFkup+hLQAgAAACY6evSoxo4dq+DgYPXv31+5ublKSEhQRESEVq5cqZo1a8owDE2ZMkVDhw5Vo0aNSjzezJkzbV+3b99ebdu21cCBA/Xee+8pIiKiXDXm5eUpOTm5XGNvJFar1ewSAAC4JRw8eFBOTk5ml3HNlfYaCWgBAACAEri7uyszM7NQe3p6eokrUt3d3WW1WpWbm2u3ijYjI0MWi8U2dvbs2apZs6ZiYmJsfTp06KBu3bpp2bJlGj9+vDZs2KCUlBTNmjVLGRkZki4+hOzS8ZydnQut1L2kSZMmatiwofbv31/2i///HB0d1bhx43KPv1GwghYAgOsjICDA9nDUm9Xhw4dL3ZeAFgAAACiBn59fob1mMzMzderUqUL7y/55nHRxhWyTJk1s7SkpKapbt67tPyWHDx9WYGCg3Vg3Nzc1aNBAx48ft41JT09XaGhoofO0b99eERERmjBhQrmurzQsFotcXV2v2fErCwcHHtEBAMD14OrqetMHtKXd3kAioAUAAABKFBISori4OLu9aDdt2iQHBwcFBwcXO65NmzaqVq2aNm7caAto8/LytHnzZoWEhNj61a1bV8nJyXb7lGVlZenYsWPq2LGjJGnAgAHq0KGD3fHXrFmjDRs2aNGiRapbt26xdSQnJ+vo0aMaOHBg+W4AAAAArikCWgAAAKAEYWFhSkpKUlRUlCIjI5WWlqaYmBiFhYXJ29vb1i88PFypqanasmWLJMnZ2VmRkZGKjY2Vp6en/P39tWLFCp07d06jRo2yO35UVJQmTJigfv36yWq1KiEhQVarVYMHD5Yk1atXT/Xq1bOr6z//+Y+qVKliC3ElKT4+XsePH1fHjh3l6empQ4cOKS4uTrVr17YdCwAAAJULAS0AAABQAg8PDy1dulRTp05VVFSU3NzcNGjQIEVHR9v1KygoUH5+vl1bRESEDMNQQkKCzpw5o6ZNmyo+Pl7169e39enevbvmzJmj+Ph4RUdHy9HRUc2aNdOyZcvk6+tbplobNmyozZs3a+PGjTp//rxuv/12denSRePGjbOt/gUAAEDlYjEMwzC7iBvZvn37JEktW7Y0uZJrKycnx7bqolrAIFkcyPYBAKgoRsEFZR1cLUlatWrVTb8f160yf7pZ3ErvF3NeAACuHea8xWMXfAAAAAAAAAAwCQEtAAAAAAAAAJiEgBYAAAAAAAAATEJACwAAAAAAAAAmIaAFAAAAAAAAAJMQ0AIAAAAAAACASQhoAQAAAAAAAMAkBLQAAAAAAAAAYBICWgAAAAAAAAAwCQEtAAAAAAAAAJiEgBYAAAAAAAAATEJACwAAAAAAAAAmIaAFAAAAAAAAAJMQ0AIAAAAAAACASQhoAQAAAAAAAMAkBLQAAAAAAAAAYBICWgAAAAAAAAAwSaULaI8cOaIRI0YoMDBQwcHBiomJkdVqLdXYtLQ0vfjii+rUqZNatWqlXr166aOPPrLrk5mZqb/+9a/q0KGDWrdurWeffVa//fbbtbgUAAAAAAAAAChRVbMLuFx6errCw8Pl6+ur2NhYpaWlacaMGcrJydGkSZNKHPvbb79pyJAhatiwoaZOnapq1arp0KFDhcLdcePG6fDhw5o8ebKcnZ01Z84cRURE6P3331fVqpXqdgAAAAAAAAC4yVWqRHLlypU6f/685s+frxo1akiS8vPzNWXKFEVGRsrb27vYsa+//rpq166txYsXq0qVKpKkoKAguz579uzR9u3bFR8fr86dO0uSGjZsqN69e2vz5s3q3bv3tbkwAAAAAAAAAChCpdriYNu2bQoKCrKFs5LUq1cvFRQUaMeOHcWOy8rK0saNGzV06FBbOFvc8d3d3RUcHGxr8/PzU9OmTbVt27YKuQYAAAAAAAAAKK1KFdCmpKTIz8/Prs3d3V1eXl5KSUkpdtz+/fuVl5enqlWr6vHHH1fz5s0VHBys119/XXl5eXbHb9iwoSwWi914Pz+/Eo8PAAAAAAAAANdCpdriICMjQ+7u7oXaPTw8lJ6eXuy433//XZI0ceJEPfLII3rmmWe0d+9ezZs3Tw4ODnr++edtx69evXqRx//+++/LXbdhGMrOzi73+BtBTk6O2SUAAHBLyM7OVkFBgdllXFOGYRT6gTkAAABwq6pUAW15XfpPzD333KOXXnpJktSpUyedP39eCQkJioqKkouLyzU7f15enpKTk6/Z8SuDPz9sDQAAXBsHDx6Uk5OT2WVcc7fCNQIAAAClUakCWnd3d2VmZhZqT09Pl4eHR4njpIuh7OWCgoIUFxenY8eOKSAgQO7u7vr111/LfPwrcXR0VOPGjcs9/kbACloAAK6PgICAa/qD5crg8OHDZpcAXJFRcMHsEgAAuKnwb2vxKlVAW9ResJmZmTp16lShvWkvd6VwNDc313b8L7/8stDH6o4ePSp/f/9y122xWOTq6lru8TcCB4dKtV0xAAA3LVdX15s+oGV7A1RWhmHYvj5/6EPzCgEA4CZ3+b+5qGQPCQsJCdHOnTuVkZFha9u0aZMcHBwUHBxc7DgfHx/5+/tr586ddu07d+6Ui4uLLcANCQlRenq6vvzyS1ufo0eP6ocfflBISEgFXw0AAAAAAAAAlKxSraANCwtTUlKSoqKiFBkZqbS0NMXExCgsLEze3t62fuHh4UpNTdWWLVtsbdHR0RozZoxeffVVde3aVfv27VNCQoJGjRplW93aunVrde7cWX/961/14osvytnZWbNnz1ZAQIDuv//+6369AAAAACqPy1d3u93VXxaHSvXfJQAAbmhGwQXbJ1T4RJW9SjXj8PDw0NKlSzV16lRFRUXJzc1NgwYNUnR0tF2/goIC5efn27WFhobqjTfe0FtvvaUVK1aoVq1aGjt2rJ588km7fnPmzNH06dM1adIkXbhwQZ07d9bEiRNVtWqluhUAAAAATGRxqEpACwAArotKN+No1KiREhMTS+yTlJRUZHvv3r3Vu3fvEsdWr15dr732ml577bXylggAAAAAAAAAFaJS7UELAAAAAAAAALcSAloAAAAAAAAAMAkBLQAAAAAAAACYhIAWAAAAAAAAAExCQAsAAAAAAAAAJiGgBQAAAAAAAACTENACAAAAAAAAgEkIaAEAAAAAAADAJAS0AAAAAAAAAGASAloAAAAAAAAAMAkBLQAAAAAAAACYhIAWAAAAAAAAAExCQAsAAAAAAAAAJiGgBQAAAAAAAACTENACAAAAAAAAgEkIaAEAAAAAAADAJAS0AAAAAAAAAGASAloAAAAAAAAAMAkBLQAAAAAAAACYhIAWAAAAAAAAAExCQAsAAAAAAAAAJiGgBQAAAAAAAACTENACAAAAAAAAgEkIaAEAAIArOHLkiEaMGKHAwEAFBwcrJiZGVqv1iuMMw9DChQvVtWtXtWrVSkOGDNG3335bqN+uXbs0bNgwtW/fXh07dtTo0aOVnJxc7HG///57NW3aVK1bty70mtVq1cyZMxUcHKzAwECNGDFCKSkpZbpeAAAAXD8EtAAAAEAJ0tPTFR4erry8PMXGxio6OlrvvfeeZsyYccWxixYt0rx58zR8+HAtWLBAXl5eGjlypE6cOGHrk5KSolGjRsnV1VWzZs3Sq6++qvT0dA0fPlynTp0qdEzDMDR16lR5enoWec5p06Zp1apVio6OVmxsrKxWq4YPH67MzMzy3wQAAABcMwS0AAAAQAlWrlyp8+fPa/78+br33ns1aNAgvfDCC1q5cqXS0tKKHZebm6sFCxZo5MiRGj58uIKCgvTGG2+oRo0aio+Pt/XbunWrDMPQ3LlzFRISou7du+uNN97QuXPntGPHjkLHff/993X27Fk9/PDDhV779ddftXr1ar3wwgsaNGiQ7r33Xr355pvKzMzUypUrK+aGAAAAoEIR0AIAAAAl2LZtm4KCglSjRg1bW69evVRQUFBkgHrJ7t27lZWVpV69etnanJyc1KNHD23bts3WlpeXJycnJzk7O9vaqlevXuQxMzIyNGvWLL388stydHQs9Pr27dtVUFCgnj172tpq1Kih4OBgu3MCAACg8iCgBQAAAEqQkpIiPz8/uzZ3d3d5eXmVuLfrpdf+PLZRo0ZKTU1VTk6OJKlPnz7Kz8/XnDlzdPbsWaWlpWn69OmqU6eO7rvvPruxc+bMUfPmzdWtW7diz3nHHXfIw8Oj0DnZhxYAAKByqmp2AQAAAEBllpGRIXd390LtHh4eSk9PL3Hcn1fGShfDXcMwlJ6eLhcXF/n6+ioxMVFjxoxRXFycJMnHx0dLliyxW0mbnJys1atXa82aNSWes6jVt+7u7iXWeiWGYSg7O7vc428Ul0JzAABwbWVnZ6ugoMDsMq4pwzBksVhK1ZeAFgAAADDR0aNHNXbsWAUHB6t///7Kzc1VQkKCIiIitHLlStWsWVOGYWjKlCkaOnSoGjVqdN1rzMvLU3Jy8nU/7/VmtVrNLgEAgFvCwYMH5eTkZHYZ11xpr5GAFgAAACiBu7u7MjMzC7Wnp6cX2krgz+OsVqtyc3PtVtFmZGTIYrHYxs6ePVs1a9ZUTEyMrU+HDh3UrVs3LVu2TOPHj9eGDRuUkpKiWbNmKSMjQ9LFh5BdOp6zs7OcnZ3l7u6urKysQrVkZGSUWOuVODo6qnHjxuUef6NgBS0AANdHQECAXFxczC7jmjp8+HCp+xLQAgAAACXw8/MrtH9rZmamTp06VWh/2T+Pky6ukG3SpImtPSUlRXXr1rX9p+Tw4cMKDAy0G+vm5qYGDRro+PHjtjHp6ekKDQ0tdJ727dsrIiJCEyZMkJ+fn37//fdC4XFR++iWhcVikaura7nH3ygcHHhEBwAA14Orq+tNH9CWdnsDiYAWAAAAKFFISIji4uLs9qLdtGmTHBwcFBwcXOy4Nm3aqFq1atq4caMtoM3Ly9PmzZsVEhJi61e3bl0lJyfb7VOWlZWlY8eOqWPHjpKkAQMGqEOHDnbHX7NmjTZs2KBFixapbt26kqTOnTvLwcFBmzdv1uDBgyVdXOm7fft2jRkzpoLuCAAAACoSAS0AAABQgrCwMCUlJSkqKkqRkZFKS0tTTEyMwsLC5O3tbesXHh6u1NRUbdmyRZLk7OysyMhIxcbGytPTU/7+/lqxYoXOnTunUaNG2R0/KipKEyZMUL9+/WS1WpWQkCCr1WoLWevVq6d69erZ1fWf//xHVapUsYW4klS7dm0NGjRIMTExcnBwkLe3txYsWKDq1asrLCzsWt4mAAAAlBMBLQAAAG4qVqtV+/fv1+nTp9WmTRt5enpe1fE8PDy0dOlSTZ06VVFRUXJzc9OgQYMUHR1t16+goED5+fl2bRERETIMQwkJCTpz5oyaNm2q+Ph41a9f39ane/fumjNnjuLj4xUdHS1HR0c1a9ZMy5Ytk6+vb5nrnThxotzc3DRr1iydP39ebdq00ZIlS1S9evVyXT8AAACuLYthGIbZRdzI9u3bJ0lq2bKlyZVcWzk5ObYVHNUCBsniQLYPAEBFMQouKOvgaknSqlWrbvr9uK7l/GnZsmWaP3++7aFeCQkJCgoK0pkzZ9SrVy+98MILGjRoUIWf92Z2q8x3Jea8AABcS8x5i8cu+AAAALgpvP/++3rttdd077336tVXX9Xl6xA8PT3VqVMnbdiwwcQKAQAAgMIIaAEAAHBTWLJkie677z7NmjVL3bp1K/R68+bNdejQIRMqAwAAAIpHQAsAAICbwrFjxxQSElLs6zVq1NC5c+euX0EAAABAKRDQAgAA4Kbg7u6us2fPFvv64cOH5eXldR0rAgAAAK6MgBYAAAA3hZCQEL333nvKyMgo9NqhQ4e0atUqhYaGmlAZAAAAUDweSwoAAICbwrhx4/TII4+ob9++6tatmywWiz788EO9//772rx5s7y8vDRmzBizywQAAADssIIWAAAANwVvb2998MEHuvfee7Vx40YZhqG1a9fqs88+U58+ffTee+/J09PT7DIBAAAAO+VeQXvq1Kkr7uG1d+9etWrVqrynQCVlFFwwuwQApWAYhiTJYrGYXAmAK+Hf1qtntVr1xRdfyMfHR6+++qpeffVVnTlzRgUFBfL09JSDA+sSAAAAUDmVO6Dt27ev/u///k99+/Yt9FpeXp7mzJmjxMRE7d+//6oKROVz/tCHZpcAAABgx9HRUc8995z+9re/qUmTJpLEalkAAADcEMq9lKBFixZ64YUX9Oyzz+rMmTO29u+//14DBgzQkiVLNGzYsAopEgAAACiJxWKRr6+vzp49a3YpAAAAQJmUewVtfHy8Vq5cqZiYGPXt21cTJ07UwYMHtXjxYvn4+GjZsmVq165dRdYKEzk7O2vVqlVmlwGglHJycmw/JEtKSpKLi4vJFQEoLWdnZ7NLuGFFRkZqxowZ6tmzp/z8/MwuBwAAACiVcge0khQWFqbOnTtr7Nixev755yVJjzzyiF566SXddtttFVIgKgeLxULAA9ygXFxc+PML4Jbw3XffqUaNGnrwwQfVoUMH+fj4FPn338SJE02oDgAAACjaVQW0hmHo448/1uHDh3XHHXfozJkz2rNnj44dO2bb+wsAAAC4HpYvX277+ssvvyyyj8ViIaAFAABApVLugDYlJUUvvfSS9u7dqyFDhujFF1/UDz/8oJdfflmDBw/W008/raeeeoon5gIAAOC6OHDggNklAAAAAGVW7vS0f//++u233xQfH68pU6bI1dVV7dq100cffaTBgwcrNjZWjzzySEXWCgAAAAAAAAA3lXKvoO3du7f+9re/qXr16nbtt912myZNmqQePXrob3/721UXCAAAAJTFiRMntG3bNqWmpkqS6tatq5CQENWvX9/kygAAAIDCyh3Qzpgxo8TXg4KCtG7duvIeHgAAACizGTNmaNmyZSooKLBrd3BwUHh4uF588UWTKgMAAACKdlUPCZOkb7/9Vl9//bVOnz6toUOHytfXV3/88YdSUlLk6+tbASUCAAAAV5aQkKDExEQ98MADGjlypBo1aiRJOnLkiBITE5WYmChvb28NHz7c3EIBAACAy5Q7oLVarRo/frw++eQTGYYhi8Wibt26ydfXVw4ODho5cqSGDx+up59+uiLrBQAAAIr03nvvKTQ0VHPnzrVrv/vuuzV79mzl5uZq5cqVBLQAAACoVMr9kLC5c+fq888/1+TJk7Vp0yYZhmF7zdnZWT179tQnn3xSIUUCAAAAV3Ly5El17ty52Nc7d+6skydPXseKAAAAgCsrd0D78ccfKywsTEOGDJGHh0eh1xs1aqQTJ05cVXEAAABAad1xxx06cOBAsa8fOHBAnp6e17EiAAAA4MrKHdCePn1aAQEBxb5epUoV5eTklPfwAAAAQJn07NlTq1ev1sKFC5WdnW1rz87O1sKFC7V69Wr17t3bxAoBAACAwsq9B22dOnWUkpJS7Ou7d+9WgwYNynt4AAAAoEyee+45JScn64033tC8efNUq1YtSdJvv/2mCxcuqGPHjnr22WdNrhIAAACwV+6Atm/fvlqyZInuv/9++fr6SpIsFoukiw9o2Lhxo55//vkKKRIAAAC4kttuu01Lly7V1q1btW3bNqWmpkq6uPdsly5dFBoaapuvAgAAAJVFuQPap556St99950ef/xx+fn5yWKxaPr06UpPT9evv/6qLl268IRcAAAAXHfdu3dX9+7dzS4DAAAAKJVy70Hr5OSkxYsX67XXXlP9+vXl5+cnq9WqgIAAzZgxQ3FxcapSpUpF1goAAAAU68SJE/r000+Lff3TTz/Vzz//fB0rAgAAAK6s3CtopYtbGvTr10/9+vWrqHoAAACAcomJiVFWVpZCQ0OLfP2dd96Ru7u7Zs+efZ0rAwAAAIpX7hW0AAAAQGWyZ88e3XPPPcW+HhQUpF27dl3HigAAAIArK/UK2ieeeKLMB7dYLFq6dGmZxwEAAABllZGRITc3t2Jfd3V11blz565fQQAAAEAplHoFrWEYhX798ssv+s9//qPk5GRlZWUpKytLBw4c0H/+8x/9+uuvMgzjWtYOAAAA2NSpU0e7d+8u9vVvvvlGtWvXvo4VAQAAAFdW6hW0SUlJdt/v2rVLY8aM0dSpUzVgwABVrXrxUBcuXNAHH3ygf/zjH5o+fXrFVgsAAAAUo2/fvnrrrbfUqlUrPf7443JwuLgWIT8/X8uXL9eGDRv01FNPmVwlAAAAYK/cDwmLiYnRwIEDNXjwYPsDVq2qRx55RCkpKZoxY4ZWrVp11UUCAAAAVxIZGalvvvlGr732muLi4tSwYUNJ0tGjR3XmzBl16NBBTz/9tMlVAgAAAPbK/ZCwgwcPqn79+sW+Xq9ePf3444/lPTwAAABQJk5OTkpISNCrr76qVq1a6ezZszp79qxatWql1157TYmJiXJycjK7TAAAAMBOuVfQ1qpVSxs2bNCQIUNs2xtccuHCBW3YsEG1atW66gIBAACA0nJwcNDDDz+shx9+2OxSAAAAgFIpd0A7evRovfLKK3rkkUf06KOPqkGDBpKkY8eOaeXKlUpOTtYrr7xSYYUCAAAAZWG1WrV371799ttv8vPzU5MmTcwuCQAAACik3AHtkCFD5ODgoDlz5uj//u//ZLFYJEmGYcjT01NTpkzRI488UmGFAgAAAH/2xRdfaMOGDXrhhRfk6elpaz9y5IjGjBmj48eP29p69OihN954o9CnvwAAAAAzXdXsdPDgwRowYIC+//57paamSpLq1q2rFi1aMPEFAADANff+++/r+PHjduGsJL3wwgs6duyYBgwYoBYtWujf//63tmzZouXLl2v48OHmFAsAAAAU4apT1KpVqyowMFCBgYEVUA4AAABQet9//70eeOABu7YffvhBP/zwgx588EFNnz5dkvTYY4/p8ccf10cffURACwAAgErlqgPaw4cP68SJE0pPTy/y9f79+1/tKQAAAIAi/f7777rzzjvt2r744gtZLBYNHDjQrr179+6aO3fu9SwPAAAAuKJyB7THjx/XCy+8oL1798owjCL7WCwWAloAAABcM66urvrjjz/s2r755hs5ODioVatWdu3Vq1dXQUHB9SwPAAAAuKJyB7STJk3Sjz/+qL/+9a9q166d3N3dK7IuAAAA4IoaNWqkTz75ROHh4ZKk9PR0/fe//1Xr1q3l5uZm1/eXX35RzZo1zSgTAAAAKFa5A9rdu3crMjJSw4YNq8h6AAAAgFIbMWKExowZo9GjR6t169b67LPPlJOTo6FDhxbqu337djVr1syEKgEAAIDiOZR34O23367q1atXZC0AAABAmYSGhuqFF17Qt99+q9jYWB0+fFhjxoxR79697fp9++23+vbbb9WlSxeTKgUAAACKVu4VtGFhYfroo4/02GOPqUqVKhVZEwAAAFBqo0aN0vDhw3X27Fndcccdslgshfo0adJEX375JdtyAQAAoNIpd0Dr6+urgoIC9evXTw8//LBq165dZFB7//33X1WBAAAAwJVUqVKlxP1lXVxc5OLich0rAgAAAEqn3AFtdHS07euZM2cW2cdisSg5Obm8pwAAAAAAAACAm1q5A9ply5ZVZB0AAAAAAAAAcMspd0DboUOHiqwDAAAAAAAAAG45DmYXAAAAAAAAAAC3qjKtoJ02bVqZTzBx4sQyjwEAAAAAAACAW0GZAtrly5eX6eAWi4WAFgAAAKY4cuSINm3apFOnTsnPz08DBw5UtWrVzC4LAAAAsFOmgPbAgQPXqg4AAACgzJYvX66kpCStWLFCnp6etvZPP/1Uzz33nPLy8mxtSUlJevfdd+36AQAAAGZjD1oAAADcsD799FPVr1/fLnS9cOGCJk6cqCpVqmj69Olat26dnn/+eaWmpiouLq5c5zly5IhGjBihwMBABQcHKyYmRlar9YrjDMPQwoUL1bVrV7Vq1UpDhgzRt99+W6jfrl27NGzYMLVv314dO3bU6NGjlZycbNdn8eLF6t+/v9q1a6fAwEA9+OCDWr58uQzDsOsXGhqqgICAQr9yc3PLde0AAAC4tsq0grYkWVlZevXVVzV69Gg1atSoog4LAAAAFOvw4cN65JFH7Nq+/vprnTlzRpGRkRowYIAk6a677tKBAwf073//W3/961/LdI709HSFh4fL19dXsbGxSktL04wZM5STk6NJkyaVOHbRokWaN2+eJkyYoICAAL3zzjsaOXKk1q5dq/r160uSUlJSNGrUKHXq1EmzZs2S1WrVggULNHz4cK1fv15eXl6SpMzMTPXu3Vt33XWXnJ2d9eWXX2ratGnKysrSU089ZXfeBx54QCNHjrRrc3JyKtN1AwAA4PqosIA2JydHH374oR566CECWgAAAFwX586dU+3ate3avvzyS1ksFvXo0cOuvU2bNtqyZUuZz7Fy5UqdP39e8+fPV40aNSRJ+fn5mjJliiIjI+Xt7V3kuNzcXC1YsEAjR47U8OHDJUlt27ZVz549FR8fr8mTJ0uStm7dKsMwNHfuXLm4uEiSAgIC1L17d+3YsUP9+/eXJEVHR9sd/5577lFqaqrWrFlTKKCtWbOmAgMDy3yt+B+j4ILZJQAohUufIrBYLCZXAuBK+Le1eBUW0Eoq9PEqAAAA4FqqWbOmfv/9d7u2Xbt2ycXFRU2aNLFrd3JykqOjY5nPsW3bNgUFBdnCWUnq1auXXnnlFe3YsUMDBw4sctzu3buVlZWlXr162dXQo0cPu6A4Ly9PTk5OcnZ2trVVr169VLXdfvvtdvvsouKcP/Sh2SUAAIBbBHvQAgAA4IbVokULrVmzRllZWZKkQ4cOad++fbr33ntVtar9WoSUlJRCq21LIyUlRX5+fnZt7u7u8vLyUkpKSonjJBUa26hRI6WmpionJ0eS1KdPH+Xn52vOnDk6e/as0tLSNH36dNWpU0f33XdfoeNeuHBBWVlZ+vzzz/Xhhx/qiSeeKNRn3bp1atGihVq3bq2IiAgdPHiwzNcNAACA66PCVtA6Ojqqffv28vDwuKrjHDlyRNOmTdOePXvk5uamfv36ady4cVfcMys0NFQnT54s1L53717baoSvv/66yAls7969NXv27KuqGwAAANdfVFSUBg0apAceeECNGzfW/v37ZbFY9OSTTxbqu2XLFnXq1KnM58jIyJC7u3uhdg8PD6Wnp5c47s8rY6WL4a5hGEpPT5eLi4t8fX2VmJioMWPG2B5i5uPjoyVLlhRaSXvs2DHdf//9tu+ffvpp2/YJl4SGhqpVq1aqW7euTpw4obi4OA0dOlQffvihbd/bsjIMQ9nZ2eUaeyMxDENLly41uwwApZSbm2v7+37hwoWF/r4FUHnl5+ff9HMLwzBKvf1KmQLa3Nxcvfrqq7rrrrs0bNgwu9c8PDyUlJQkSVq2bJmOHDmiiRMnluljZFfzAAap9A9DmD59ut1Khttvv73UNQIAAKDyCAgI0NKlSxUXF6cTJ07o7rvv1qhRo9SiRQu7fl9//bVuu+029ezZ06RKi3f06FGNHTtWwcHB6t+/v3Jzc5WQkKCIiAitXLlSNWvWtPWtU6eOVq9erezsbO3atUuLFi2Sg4ODnn32WVufiRMn2r5u166dgoOD1atXL7t9b8sqLy9PycnJ5b5GALgWrFar7euffvqJhyECqHRK+/dSmQLad999V2vWrNGGDRtK7Ne1a1e9/vrrCggI0NChQ0t9/PI+gOGS0j4M4a677lLLli1LXRcAAAAqrzZt2mjhwoUl9unYsaPWrVtXruO7u7srMzOzUHt6enqJnx5zd3eX1WpVbm6u3aqujIwMWSwW29jZs2erZs2aiomJsfXp0KGDunXrpmXLlmn8+PG2dicnJ9s8tmPHjqpWrZpmzpypRx99VF5eXkXWUatWLbVt21b79+8v24VfxtHRUY0bNy73eAC4Fi5tFSNd/IHdpQctAkBlcPjw4VL3LVNAu3HjRt1///1X/GhUgwYN1LNnT3388cdlCmjL+wAGAAAAoCg5OTnKzs6Wp6dnuY/h5+dXaK/ZzMxMnTp1qtD+sn8eJ11cIXv5A8tSUlJUt25dW5Bw+PDhQosM3Nzc1KBBAx0/frzE2po3b678/HydPHmy2IC2IlgsFrm6ul6z4wNAeTg4/O+xOq6urgS0ACqV0m5vIJXxIWE//vij2rZtW6q+rVu3LvPDCMr7AIZLSvswhCeffFJNmzZVSEiIZs6cafdTNwAAANxYDhw4oDlz5mj+/Pk6cuSIJOnbb7/Vww8/rNatWys4OFj33nuvVq1aVa7jh4SEaOfOncrIyLC1bdq0SQ4ODgoODi52XJs2bVStWjVt3LjR1paXl6fNmzcrJCTE1la3bl0lJyfLMAxbW1ZWlo4dOyYfH58Sa9u9e7csFovq1atXbJ+0tDR98803fIIMAACgkirTCtq8vLxS7ynr6Ohotx9MaZT3AQxS6R6GUL16dY0ePVrt27eXs7OzvvrqKyUkJCglJUULFiwoU62Xu1UemgDgxnH5D56ys7NVUFBgYjUAYK8sD0y4ku+++06PP/648vLyJEmLFy/Wm2++qWeeeUZubm4KDQ1Vfn6+9uzZo0mTJsnDw8PuIVulERYWpqSkJEVFRSkyMlJpaWmKiYlRWFiY3RZc4eHhSk1N1ZYtWyRJzs7OioyMVGxsrDw9PeXv768VK1bo3LlzGjVqlN3xo6KiNGHCBPXr109Wq1UJCQmyWq0aPHiwpIsrdiMiIvTQQw/pzjvv1IULF/T1119r2bJlGjJkiG2f2vXr1+uzzz5Tly5dVKtWLZ04cUILFy5UlSpVNGLEiKu61wAAALg2yhTQ1qpVS4cOHSpV30OHDqlWrVrlKqo8SvMwhGbNmqlZs2a2fkFBQapVq5b+/ve/a+/evWrVqlW5zs1DEwBUNpf/gOzgwYM8MAFApVNRfy+9/fbb8vLy0sKFC3XHHXfo//7v/zR+/Hj5+/tryZIlto/lnzt3TkOGDNGSJUvKHNB6eHho6dKlmjp1qqKiouTm5qZBgwYpOjrarl9BQYHy8/Pt2iIiImQYhhISEnTmzBk1bdpU8fHxdluGde/eXXPmzFF8fLyio6Pl6OioZs2aadmyZfL19ZV0Mext2LChEhMTlZaWJhcXFzVo0EBTpkxR//79bceqV6+efvvtN7322mvKzMxU9erV1alTJz377LNX3KYMAAAA5ihTQHvPPfdo7dq1ioyM1B133FFsv9OnT2vt2rV64IEHylRMeR/AUJTSPgyhV69e+vvf/67vv/++3AEtD00AUNnwwAQAlVlZHphwJd9//72GDRtmm4uNGTNGAwcO1KOPPmq3Z2qNGjX08MMPKy4urlznadSokRITE0vsk5SUVKjNYrEoMjJSkZGRJY7t1auXevXqVezrTk5Omj59+hXrDAwMLLIOAAAAVF5lCmgjIiL00UcfKTw8XK+++qruvvvuQn2+++47TZw4Ubm5uRo9enSZiinvAxjMxkMTAFQ2PDABQGVWUdsbSBcXBtSuXdv2/aWvL9964BJvb2/98ccfFXZuAAAAoCKUKaCtX7++5syZo/HjxyssLEz169eXv7+/3NzcdP78eR06dEjHjx+Xi4uL3njjDTVo0KBMxYSEhCguLs5uL9rSPIChKJcehtCvX78S+3388ceSxEMTAAAAbkCGYdj9UKqk8Lcig2EAAACgopQpoJWkrl276qOPPtKiRYv0+eefa+vWrbbXatWqpcGDBysiIqJce1yV9wEMpX0YwoQJE3TnnXeqWbNmtoeEJSYmqnv37gS0AAAAN6g//vhD586dkyTbg2XPnz9va7uEh7oCAACgMipzQCtdfPjAlClTJElZWVk6f/683NzcVK1atasqprwPYCjtwxDuuusurVu3TgkJCcrLy5OPj4+eeuopPfnkk1dVNwAAAMzzyiuv6JVXXrFrGzt2bKF+hmGwihYAAACVTrkC2stVq1btqoPZy5XnAQylfRhCaR7QAAAAgBvHM888Y3YJAAAAwFW56oAWAAAAMAsBLQAAAG50DlfuAgAAAAAAAAC4FlhBCwAAgBvW/v37yzymefPm16ASAAAAoHwIaAEAAHDDevjhh0v94K9LDwlLTk6+xlUBAAAApUdACwAAgBvW9OnTzS4BAAAAuCoEtAAAALhhDRgwwOwSAAAAgKvCQ8IAAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAA4AqOHDmiESNGKDAwUMHBwYqJiZHVar3iOMMwtHDhQnXt2lWtWrXSkCFD9O233xbqt2vXLg0bNkzt27dXx44dNXr0aCUnJ9v1Wbx4sfr376927dopMDBQDz74oJYvXy7DMMp1TgAAAFQOBLQAAABACdLT0xUeHq68vDzFxsYqOjpa7733nmbMmHHFsYsWLdK8efM0fPhwLViwQF5eXho5cqROnDhh65OSkqJRo0bJ1dVVs2bN0quvvqr09HQNHz5cp06dsvXLzMxU79699frrr+utt95S165dNW3aNC1YsKDM5wQAAEDlUdXsAgAAAIDKbOXKlTp//rzmz5+vGjVqSJLy8/M1ZcoURUZGytvbu8hxubm5WrBggUaOHKnhw4dLktq2bauePXsqPj5ekydPliRt3bpVhmFo7ty5cnFxkSQFBASoe/fu2rFjh/r37y9Jio6Otjv+Pffco9TUVK1Zs0ZPPfVUmc4JAACAyoMVtAAAAEAJtm3bpqCgIFs4K0m9evVSQUGBduzYUey43bt3KysrS7169bK1OTk5qUePHtq2bZutLS8vT05OTnJ2dra1Va9evVS13X777crLyyvzOQEAAFB5ENACAAAAJUhJSZGfn59dm7u7u7y8vJSSklLiOEmFxjZq1EipqanKycmRJPXp00f5+fmaM2eOzp49q7S0NE2fPl116tTRfffdV+i4Fy5cUFZWlj7//HN9+OGHeuKJJ8p8TgAAAFQebHEAAAAAlCAjI0Pu7u6F2j08PJSenl7iuD+vjJUuhruGYSg9PV0uLi7y9fVVYmKixowZo7i4OEmSj4+PlixZUmgl7bFjx3T//ffbvn/66adtWxmU5ZxlZRiGsrOzyzwOAK6ly3/olJ2drYKCAhOrAQB7hmHIYrGUqi8BLQAAAGCio0ePauzYsQoODlb//v2Vm5urhIQERUREaOXKlapZs6atb506dbR69WplZ2dr165dWrRokRwcHPTss89e0xrz8vKUnJx8Tc8BAGVltVptXx88eFBOTk4mVgMAhZX27yUCWgAAAKAE7u7uyszMLNSenp4uDw+PEsdZrVbl5ubarWjNyMiQxWKxjZ09e7Zq1qypmJgYW58OHTqoW7duWrZsmcaPH29rd3JyUsuWLSVJHTt2VLVq1TRz5kw9+uij8vLyKvU5y8rR0VGNGzcu11gAuFYuX0EbEBBQrk8IAMC1cvjw4VL3JaAFAAAASuDn51dor9nMzEydOnWq0F6vfx4nXVwh26RJE1t7SkqK6tatawsSDh8+rMDAQLuxbm5uatCggY4fP15ibc2bN1d+fr5OnjwpLy+vUp+zrCwWi1xdXcs1FgCuFQeH/z1Wx9XVlYAWQKVS2u0NJB4SBgAAAJQoJCREO3fuVEZGhq1t06ZNcnBwUHBwcLHj2rRpo2rVqmnjxo22try8PG3evFkhISG2trp16yo5OVmGYdjasrKydOzYMfn4+JRY2+7du2WxWFSvXr0ynRMAAACVBytoAQAAgBKEhYUpKSlJUVFRioyMVFpammJiYhQWFiZvb29bv/DwcKWmpmrLli2SJGdnZ0VGRio2Nlaenp7y9/fXihUrdO7cOY0aNcru+FFRUZowYYL69esnq9WqhIQEWa1WDR48WNLFFbsRERF66KGHdOedd+rChQv6+uuvtWzZMg0ZMsS2T21pzwkAAIDKg4AWAAAAKIGHh4eWLl2qqVOnKioqSm5ubho0aJCio6Pt+hUUFCg/P9+uLSIiQoZhKCEhQWfOnFHTpk0VHx+v+vXr2/p0795dc+bMUXx8vKKjo+Xo6KhmzZpp2bJl8vX1lXQxeG3YsKESExOVlpYmFxcXNWjQQFOmTFH//v3LfE4AAABUHhbj8s9Socz27dsnSbaHNQBAZZCTk2NbdbVq1Sr24wJQqTB/urHwfgGorJjzAqjMyjKHYg9aAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgkqpmF/BnR44c0bRp07Rnzx65ubmpX79+GjdunJycnEocFxoaqpMnTxZq37t3r5ydnW3fp6Wladq0adq+fbscHR3Vo0cPvfzyy6pWrVqFXwsAAAAAAAAAlKRSBbTp6ekKDw+Xr6+vYmNjlZaWphkzZignJ0eTJk264vgHHnhAI0eOtGu7PNjNy8vT6NGjJUmzZs1STk6OZs6cqeeff14LFiyo2IsBAAAAAAAAgCuoVAHtypUrdf78ec2fP181atSQJOXn52vKlCmKjIyUt7d3ieNr1qypwMDAYl//17/+pUOHDmnDhg3y8/OTJLm7u2vUqFHau3evWrVqVVGXAgAAAAAAAABXVKn2oN22bZuCgoJs4awk9erVSwUFBdqxY0eFHD8gIMAWzkpScHCwatSooX//+99XfXwAAAAAAAAAKItKFdCmpKTYhafSxRWuXl5eSklJueL4devWqUWLFmrdurUiIiJ08ODBKx7fYrGoYcOGpTo+AAAAAAAAAFSkSrXFQUZGhtzd3Qu1e3h4KD09vcSxoaGhatWqlerWrasTJ04oLi5OQ4cO1Ycffqj69evbjl+9evVyHb8khmEoOzu73OMBoKLl5OTYvs7OzlZBQYGJ1QCAPcMwZLFYzC4DAAAAqBQqVUB7NSZOnGj7ul27dgoODlavXr0UHx+vyZMnX9Nz5+XlKTk5+ZqeAwDKwmq12r4+ePCg3QMTAaAy4O8lAAAA4KJKFdC6u7srMzOzUHt6ero8PDzKdKxatWqpbdu22r9/v93xs7Kyijx+nTp1yl7w/+fo6KjGjRuXezwAVLTLV9AGBATIxcXFxGoAwN7hw4fNLgEAAACoNCpVQOvn51doL9jMzEydOnWq0N6x5T3+jz/+aNdmGIaOHj2q4ODgch/XYrHI1dX1assDgArj4PC/LcZdXV0JaAFUKmxvAAAAAPxPpXpIWEhIiHbu3KmMjAxb26ZNm+Tg4FDmADUtLU3ffPONWrZsaXf8AwcO6KeffrK1ffnllzp37py6dOly1fUDAAAAAAAAQFlUqhW0YWFhSkpKUlRUlCIjI5WWlqaYmBiFhYXJ29vb1i88PFypqanasmWLJGn9+vX67LPP1KVLF9WqVUsnTpzQwoULVaVKFY0YMcI27oEHHtCCBQs0duxYjR8/Xn/88YdiYmLUtWtXtWrV6rpfLwAAAAAAAIBbW6UKaD08PLR06VJNnTpVUVFRcnNz06BBgxQdHW3Xr6CgQPn5+bbv69Wrp99++02vvfaaMjMzVb16dXXq1EnPPvus6tevb+vn6OioxYsXa9q0aRo/fryqVq2qHj166K9//et1u0YAAAAAAAAAuKRSBbSS1KhRIyUmJpbYJykpye77wMDAQm3F8fb2VmxsbHnLAwAAAAAAAIAKU6n2oAUAAAAAAACAWwkBLQAAAAAAAACYhIAWAAAAAAAAAExCQAsAAAAAAAAAJiGgBQAAAAAAAACTENACAAAAAAAAgEkIaAEAAAAAAADAJAS0AAAAAAAAAGCSqmYXAAAAAFR2R44c0bRp07Rnzx65ubmpX79+GjdunJycnEocZxiGFi1apH/+8586c+aMmjZtqpdfflmBgYF2/Xbt2qW5c+fqwIEDcnBwUMuWLfX888+radOmkqT8/HwlJCTo888/1+HDh2UYhgICAvTcc8+pXbt2dscKCAgoVEfNmjW1Y8eOq7sJAAAAuCYIaAEAAIASpKenKzw8XL6+voqNjVVaWppmzJihnJwcTZo0qcSxixYt0rx58zRhwgQFBATonXfe0ciRI7V27VrVr19fkpSSkqJRo0apU6dOmjVrlqxWqxYsWKDhw4dr/fr18vLyUk5OjhYuXKgBAwYoIiJCDg4Oeu+99/TEE08oPj5eQUFBducdNmyY+vbta/ve0dGx4m8MAAAAKgQBLQAAAFCClStX6vz585o/f75q1Kgh6eKK1ilTpigyMlLe3t5FjsvNzdWCBQs0cuRIDR8+XJLUtm1b9ezZU/Hx8Zo8ebIkaevWrTIMQ3PnzpWLi4uki6tgu3fvrh07dqh///5ycXHR1q1b5eHhYTt+cHCw+vbtq6VLlxYKaOvUqVNolS4AAAAqJ/agBQAAAEqwbds2BQUF2cJZSerVq5cKCgpK3DZg9+7dysrKUq9evWxtTk5O6tGjh7Zt22Zry8vLk5OTk5ydnW1t1atXtztWlSpV7MLZS20BAQH67bffyntpAAAAqAQIaAEAAIASpKSkyM/Pz67N3d1dXl5eSklJKXGcpEJjGzVqpNTUVOXk5EiS+vTpo/z8fM2ZM0dnz55VWlqapk+frjp16ui+++4r9vgXLlzQd999V+j4krRw4UI1b95c7dq107hx45Samlrq6wUAAMD1xRYHAAAAQAkyMjLk7u5eqN3Dw0Pp6ekljvvzyljpYrhrGIbS09Pl4uIiX19fJSYmasyYMYqLi5Mk+fj4aMmSJYVW0l5u8eLFSktLs22fcEn//v3VtWtX1axZUz/++KPefvttDR06VGvXri20Cre0DMNQdnZ2ucYCwLVy6QddkpSdna2CggITqwEAe4ZhyGKxlKovAS0AAABgoqNHj2rs2LEKDg5W//79lZubq4SEBEVERGjlypWqWbNmoTE7duxQbGysxowZoxYtWti9NnPmTNvX7du3V9u2bTVw4EC99957ioiIKFeNeXl5Sk5OLtdYALhWrFar7euDBw/KycnJxGoAoLDS/r1EQAvc4gzDUG5urtlloIJdvprg8q9x83B2di71T2MBXB13d3dlZmYWak9PTy9xRaq7u7usVqtyc3PtVtFmZGTIYrHYxs6ePVs1a9ZUTEyMrU+HDh3UrVs3LVu2TOPHj7c77v79+zV27Fj17dtXzzzzzBXrb9KkiRo2bKj9+/dfsW9xHB0d1bhx43KPB4Br4fJ5bkBAgO1BiwBQGRw+fLjUfQlogVuYYRh68cUXWRFzkxs2bJjZJeAaaNq0qWbOnElIC1wHfn5+hfaazczM1KlTp4rc//XycdLFFbJNmjSxtaekpKhu3bq2IOHw4cMKDAy0G+vm5qYGDRro+PHjdu3Hjh1TRESEWrdurWnTpl3NZZWJxWKRq6vrdTsfAJSGg8P/Hqvj6upKQAugUinL/9V4SBgAAABQgpCQEO3cuVMZGRm2tk2bNsnBwUHBwcHFjmvTpo2qVaumjRs32try8vK0efNmhYSE2Nrq1q2r5ORkGYZha8vKytKxY8fk4+Nja/vtt980cuRI1alTR/PmzZOjo2Op6k9OTtbRo0fVsmXLUvUHAADA9cUKWuAWZrFYNHPmTLY4uEld+o8+KyxvTmxxAFw/YWFhSkpKUlRUlCIjI5WWlqaYmBiFhYXJ29vb1i88PFypqanasmWLpIt/TiMjIxUbGytPT0/5+/trxYoVOnfunEaNGmV3/KioKE2YMEH9+vWT1WpVQkKCrFarBg8eLOnix3gjIiJ09uxZ/e1vf9OhQ4ds452cnNSsWTNJUnx8vI4fP66OHTvK09NThw4dUlxcnGrXrm07FgAAACoXAlrgFmexWPgoEAAAJfDw8NDSpUs1depURUVFyc3NTYMGDVJ0dLRdv4KCAuXn59u1RUREyDAMJSQk6MyZM2ratKni4+NVv359W5/u3btrzpw5io+PV3R0tBwdHdWsWTMtW7ZMvr6+kqTff/9dBw4ckCQ9/fTTdufw8fHRp59+Kklq2LChNm/erI0bN+r8+fO6/fbb1aVLF40bN07u7u4VfWsAAABQASzG5Z+lQpnt27dPkvjIGAAAQCkxf7qx8H4BqKxycnJsnw5YtWoVC08AVCplmUOxBy0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAAAAAAADAJAS0AAAAAAAAAmISAFgAAAAAAAABMQkALAAAAAAAAACYhoAUAAAAAAAAAkxDQAgAAAAAAAIBJCGgBAAAAAAAAwCQEtAAAAAAAAABgEgJaAAAAAMD/a+9uY6s86z+Af08d0IC0yMaQB5WwzQoKAkoJqSFuYjLiEveiRhKdPGwMLO5F5xITNU7GdKO6uMEkMITBlihxfWeMy0Z8QYYPSMSJBo2sy5Q0MjZmy4OlhZ7/i2Xnv1Jgg4F36T6fpEn7O9d13b9zTtLc/fa+rwMAFERACwAAAABQEAEtAAAAAEBBBLQAAAAAAAUR0AIAAAAAFERACwAAAABQEAEtAAAAAEBBBLQAAAAAAAUR0AIAAAAAFERACwAAAABQEAEtAAAAAEBBBLQAAAAAAAUR0AIMUrt3787SpUuze/fuolsBAAAAzkFACzAIdXV1Zf369Tl8+HDWr1+frq6uolsCAAAAzkJACzAItba25siRI0mSI0eOpLW1teCOAAAAgLMR0AIMMu3t7WltbU25XE6SlMvltLa2pr29veDOAAAAgDMJaAEGkXK5nA0bNlTC2beqAwAAAMUS0AIMIgcPHszevXvT29vbp97b25u9e/fm4MGDBXUGAAAAnI2AFmAQmThxYmbOnJmqqr6/3quqqjJr1qxMnDixoM4AAACAsxHQAgwipVIpK1asSKlUelt1AAAAoFgCWoBBZvz48WlsbKyEsaVSKY2NjRk3blzBnQEAAABnEtACDEKNjY0ZPXp0kmT06NFpbGwsuCOAK9sLL7yQJUuWZMaMGWloaEhLS0u6u7vfcl65XM5jjz2WT3/605k+fXq++MUv5k9/+lO/cXv27Mltt92W2bNnZ86cObnjjjuyf//+yuOnT5/Opk2b8qUvfSlz5sxJfX19brvttuzZs6ffWt3d3VmzZk0aGhoyY8aMLFmyJG1tbe/o+QMAcPkIaAEGoerq6jQ1NWXMmDFpampKdXV10S0BXLE6OjqyaNGi9PT0ZN26dWlubs7Pf/7zPPjgg285d9OmTVm7dm0WL16cjRs3ZsyYMVm6dGn+9a9/Vca0tbXl9ttvz/Dhw/PQQw/le9/7Xjo6OrJ48eIcPnw4SdLV1ZXHHnssH/3oR7NmzZr88Ic/TG1tbb7yla/kt7/9bZ9j3n///XnqqafS3NycdevWpbu7O4sXL87Ro0cv7QsDAMAlcVXRDQBwedTX16e+vr7oNgCueNu3b8/x48fz6KOPZtSoUUlev6J11apVWb58ecaOHXvWeSdPnszGjRuzdOnSLF68OEnyiU98IjfffHM2b96c7373u0mSHTt2pFwu55FHHqn8Q62uri7z58/Prl27cuutt6a6ujo7duxIbW1tZf2Ghobccsst2bZtW+bOnZsk+fe//53W1tbce++9lbsnpk2blhtvvDHbt2/PsmXLLsMrBADAO+EKWgAAOI+dO3dm7ty5lXA2SRYsWJDe3t7s2rXrnPP++Mc/5tixY1mwYEGlNnTo0Hz2s5/Nzp07K7Wenp4MHTo0w4YNq9RGjhzZZ633vOc9fcLZN2p1dXV5+eWXK7Xnnnsuvb29ufnmmyu1UaNGpaGhoc8xAQAYOAS0AABwHm1tbZk8eXKfWk1NTcaMGXPevV3feOzMudddd13a29vT1dWVJPnc5z6X06dP5+GHH85rr72WQ4cO5YEHHsi4cePymc985pzrnzp1Ks8//3yf9dva2nL11Vf3C3Ovu+46+9ACAAxQtjgAAIDz6OzsTE1NTb96bW1tOjo6zjvvzCtjk9fD3XK5nI6OjlRXV2fSpEnZunVrmpqasmHDhiTJhAkT8vjjj/e7kvbNfvKTn+TQoUOV7RPeOObZ5tTU1Jy317dSLpdz4sSJi54PcDm88Y+uJDlx4kR6e3sL7Aagr3K5nFKp9LbGCmgBAKBAL774Yu666640NDTk1ltvzcmTJ7Nly5YsW7Ys27dvzzXXXNNvzq5du7Ju3bo0NTXlYx/72GXvsaenJ/v377/sxwG4EN3d3ZXv//73v2fo0KEFdgPQ39v9vSSgBQCA86ipqcnRo0f71Ts6OvptJXDmvO7u7pw8ebLPVbSdnZ0plUqVuT/60Y9yzTXXpKWlpTKmvr4+N954Y5544oncfffdfdb961//mrvuuiu33HJLvva1r/U75rFjx/r10tnZed5e38qQIUNy/fXXX/R8gMvhzVfQ1tXVVT5oEWAgOHDgwNseK6AFAIDzmDx5cr/9W48ePZrDhw/321/2zHnJ61fIfuQjH6nU29raMn78+EqQcODAgcyYMaPP3BEjRuSDH/xg/vnPf/apv/TSS1m2bFlmzpyZ+++//6zHfOWVV/qFx2fbR/dClEqlDB8+/KLnA1wOVVX//7E6w4cPF9ACA8rb3d4g8SFhAABwXvPmzctvfvObdHZ2VmpPP/10qqqq0tDQcM55s2bNynvf+9786le/qtR6enryzDPPZN68eZXa+PHjs3///pTL5Urt2LFjeemllzJhwoRK7eWXX87SpUszbty4rF27NkOGDOl3zE996lOpqqrKM888U6l1dHTkueee63NMAAAGDlfQAgDAeSxcuDBPPvlkVq5cmeXLl+fQoUNpaWnJwoULM3bs2Mq4RYsWpb29Pc8++2ySZNiwYVm+fHnWrVuX0aNH58Mf/nB+9rOf5T//+U9uv/32PuuvXLky99xzTz7/+c+nu7s7W7ZsSXd3d77whS8kef023mXLluW1117Lt771rfzjH/+ozB86dGimTp2aJHn/+9+fxsbGtLS0pKqqKmPHjs3GjRszcuTILFy48H/xcgEAcIEEtAAAcB61tbXZtm1bVq9enZUrV2bEiBFpbGxMc3Nzn3G9vb05ffp0n9qyZctSLpezZcuWHDlyJFOmTMnmzZvzgQ98oDJm/vz5efjhh7N58+Y0NzdnyJAhmTp1ap544olMmjQpSfLKK6/kb3/7W5Lkq1/9ap9jTJgwIb/+9a8rP3/729/OiBEj8tBDD+X48eOZNWtWHn/88YwcOfJSviwAAFwipfKb76Xigu3bty9JMm3atII7AQC4Mjh/urJ4v4CBqqurq3KnwVNPPWUPWmBAuZBzKHvQAgAAAAAUREALAAAAAFAQAS0AAAAAQEEEtAAAAAAABRHQAgAAAAAUREALAAAAAFAQAS0AAAAAQEEGXED7wgsvZMmSJZkxY0YaGhrS0tKS7u7uC1pj69atqaury/Lly/vUf//736eurq7fV3Nz86V8CgAAAAAAb8tVRTfwZh0dHVm0aFEmTZqUdevW5dChQ3nwwQfT1dWV73znO29rjcOHD+fHP/5xrr766nOOeeCBBzJ58uTKz+973/vece8AAAAAABdqQAW027dvz/Hjx/Poo49m1KhRSZLTp09n1apVWb58ecaOHfuWa/zgBz/ITTfdlPb29nOOueGGGzJt2rRL1TYAAAAAwEUZUFsc7Ny5M3Pnzq2Es0myYMGC9Pb2ZteuXW85f8+ePdmxY0e+/vWvX8YuAQAAAAAujQEV0La1tfXZeiBJampqMmbMmLS1tZ137unTp7N69eqsWLEi11577XnH3nnnnZkyZUrmzZuXNWvWpKur6x33DgAAAABwoQbUFgednZ2pqanpV6+trU1HR8d55/70pz/Nf//73yxevPicY0aOHJk77rgjs2fPzrBhw/K73/0uW7ZsSVtbWzZu3HjRfZfL5Zw4ceKi5wMAvJuUy+WUSqWi2wAAgAFhQAW0F+vVV1/N2rVrs2bNmgwdOvSc46ZOnZqpU6dWfp47d26uvfba3Hffffnzn/+c6dOnX9Txe3p6sn///ouaCwDwbnS+czYAAHg3GVABbU1NTY4ePdqv3tHRkdra2nPOe+SRR1JXV5dPfvKT6ezsTJKcOnUqp06dSmdnZ4YPH56rrjr7U12wYEHuu+++/OUvf7nogHbIkCG5/vrrL2ouAMC7zYEDB4puAQAABowBFdBOnjy5316zR48ezeHDh/vtTftmL774Yv7whz9k9uzZ/R6bPXt2Nm3alHnz5l3yft9QKpUyfPjwy7Y+wMXYvXt3NmzYkBUrVqS+vr7odgAqbG8AAAD/b0AFtPPmzcuGDRv67EX79NNPp6qqKg0NDeec981vfrNy5ewbvv/976e6ujp333136urqzjn3l7/8ZZJk2rRpl+AZAAwMXV1dWb9+fV599dWsX78+06dPT3V1ddFtAQAAAGcYUAHtwoUL8+STT2blypVZvnx5Dh06lJaWlixcuDBjx46tjFu0aFHa29vz7LPPJkmmTJnSb62ampoMHz48c+bMqdTuueeefOhDH8rUqVMrHxK2devWzJ8/X0ALDCqtra05cuRIkuTIkSNpbW3Nl7/85YK7AgAAAM40oALa2trabNu2LatXr87KlSszYsSINDY2prm5uc+43t7enD59+oLXv+GGG/KLX/wiW7ZsSU9PTyZMmJAVK1bkzjvvvFRPAaBw7e3taW1tTblcTvL6p6W3trbmpptuyvjx4wvuDgDgf69cLufkyZNFt8El1tXVddbvGRyGDRtmWyTeNUrlN/6C56Ls27cviS0SgIGhXC7n3nvvzfPPP5/e3t5KvaqqKh//+MezatUqJzlA4Zw/XVm8X1zpyuVyvvGNb2T//v1FtwJcgClTpmTNmjX+fuGKdSHnUFWXuxkA/ncOHjyYvXv39glnk9fvPNi7d28OHjxYUGcAAADA2QyoLQ4AeGcmTpyYmTNnnvUK2hkzZmTixIkFdgcA8L9XKpWyZs0aWxwMUm/cFOwqy8HHFge8mwhoAQaRUqmUFStWpKmp6ax1JzgAwLtRqVRKdXV10W0AwFnZ4gBgkBk/fnwaGxsrYWypVEpjY2PGjRtXcGcAAADAmQS0AINQY2NjRo8enSQZPXp0GhsbC+4IAAAAOBsBLcAgVF1dnaampowZMyZNTU1u6QMAAIAByh60AINUfX196uvri24DAAAAOA9X0AIAAAAAFERACwAAAABQEAEtAAAAAEBBBLQAAAAAAAUR0AIAAAAAFERACwAAAABQEAEtAAAAAEBBBLQAAAAAAAUR0AIAAAAAFERACwAAAABQEAEtAAAAAEBBBLQAAAAAAAUR0AIAAAAAFERACwAAAABQEAEtAAAAAEBBBLQAAAAAAAUR0AIAAAAAFOSqohu40vX09KRcLmffvn1FtwIAcEXo7u5OqVQqug3eJue7AAAX7kLOeQW075A/LgAALkypVHIOdQXxXgEAXLgLOectlcvl8mXuBwAAAACAs7AHLQAAAABAQQS0AAAAAAAFEdACAAAAABREQAsAAAAAUBABLQAAAABAQQS0AAAAAAAFEdACAAAAABREQAsAAAAAUJD/A5j98W5LrCiyAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 15/8/23 - Lets go with this. Boostrapped estimates. THIS IS THE ONE TATS CURRENTLY SAVED 17/8/23\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the style for seaborn\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create a figure\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Subplot for C-index\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot(y=bootstrap_c_indices_deephit)\n",
        "plt.title(\"Boxplot of Bootstrap C-Indices\")\n",
        "plt.ylabel(\"C-Index\")\n",
        "\n",
        "# Subplot for IBS\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(y=bootstrap_ibs_scores_deep_hit)\n",
        "plt.title(\"Boxplot of Bootstrap IBS Scores\")\n",
        "plt.ylabel(\"IBS Score\")\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjfmmO9xllmG"
      },
      "outputs": [],
      "source": [
        "# 15/8/23 - Lets go with this.\n",
        "import numpy as np\n",
        "\n",
        "# save the numpy arrays to the specified directory\n",
        "np.save('/content/drive/MyDrive/MSc_summer_project/Clinical_trial_data/Breast/Confidence_intervals_breast_IBS_cindex/bootstrap_c_indices_deephit.npy', bootstrap_c_indices_deephit)\n",
        "np.save('/content/drive/MyDrive/MSc_summer_project/Clinical_trial_data/Breast/Confidence_intervals_breast_IBS_cindex/bootstrap_ibs_scores_deep_hit.npy', bootstrap_ibs_scores_deep_hit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xbQD-hZSxwcd",
        "outputId": "a072725a-3594-41d0-a04a-a56f192b556e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.5481,\tval_loss: 0.5000\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5148,\tval_loss: 0.4731\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.4913,\tval_loss: 0.4492\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.4657,\tval_loss: 0.4278\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.4447,\tval_loss: 0.4085\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4215,\tval_loss: 0.3910\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.4073,\tval_loss: 0.3754\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.3902,\tval_loss: 0.3618\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.3797,\tval_loss: 0.3499\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.3636,\tval_loss: 0.3397\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.3564,\tval_loss: 0.3307\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.3507,\tval_loss: 0.3233\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.3440,\tval_loss: 0.3173\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.3275,\tval_loss: 0.3122\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.3227,\tval_loss: 0.3079\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.3281,\tval_loss: 0.3043\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.3206,\tval_loss: 0.3012\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.3187,\tval_loss: 0.2988\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.3130,\tval_loss: 0.2969\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.3116,\tval_loss: 0.2952\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.3107,\tval_loss: 0.2936\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.3139,\tval_loss: 0.2925\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.3111,\tval_loss: 0.2912\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.3016,\tval_loss: 0.2903\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.3098,\tval_loss: 0.2894\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.3024,\tval_loss: 0.2886\n",
            "26:\t[0s / 4s],\t\ttrain_loss: 0.3021,\tval_loss: 0.2878\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.2932,\tval_loss: 0.2873\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.3044,\tval_loss: 0.2867\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.2993,\tval_loss: 0.2862\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.3014,\tval_loss: 0.2857\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.2932,\tval_loss: 0.2853\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.2976,\tval_loss: 0.2848\n",
            "33:\t[0s / 5s],\t\ttrain_loss: 0.2919,\tval_loss: 0.2844\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.2942,\tval_loss: 0.2840\n",
            "35:\t[0s / 5s],\t\ttrain_loss: 0.2915,\tval_loss: 0.2836\n",
            "36:\t[0s / 5s],\t\ttrain_loss: 0.3017,\tval_loss: 0.2832\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.3021,\tval_loss: 0.2829\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.2905,\tval_loss: 0.2826\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.2871,\tval_loss: 0.2823\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.2922,\tval_loss: 0.2820\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.2980,\tval_loss: 0.2818\n",
            "42:\t[0s / 6s],\t\ttrain_loss: 0.3004,\tval_loss: 0.2814\n",
            "43:\t[0s / 6s],\t\ttrain_loss: 0.2905,\tval_loss: 0.2812\n",
            "44:\t[0s / 6s],\t\ttrain_loss: 0.2907,\tval_loss: 0.2810\n",
            "45:\t[0s / 6s],\t\ttrain_loss: 0.2954,\tval_loss: 0.2807\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.2849,\tval_loss: 0.2805\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.2870,\tval_loss: 0.2803\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.2881,\tval_loss: 0.2800\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.2888,\tval_loss: 0.2799\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.2980,\tval_loss: 0.2797\n",
            "51:\t[0s / 7s],\t\ttrain_loss: 0.2944,\tval_loss: 0.2795\n",
            "52:\t[0s / 7s],\t\ttrain_loss: 0.2942,\tval_loss: 0.2793\n",
            "53:\t[0s / 7s],\t\ttrain_loss: 0.2860,\tval_loss: 0.2792\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.2854,\tval_loss: 0.2790\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.2839,\tval_loss: 0.2790\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.2863,\tval_loss: 0.2788\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.2881,\tval_loss: 0.2787\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.2898,\tval_loss: 0.2785\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.2934,\tval_loss: 0.2784\n",
            "60:\t[0s / 8s],\t\ttrain_loss: 0.2846,\tval_loss: 0.2784\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.2868,\tval_loss: 0.2783\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.2838,\tval_loss: 0.2781\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.2868,\tval_loss: 0.2781\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.2853,\tval_loss: 0.2780\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.2836,\tval_loss: 0.2778\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.2831,\tval_loss: 0.2778\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.2875,\tval_loss: 0.2776\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.2801,\tval_loss: 0.2774\n",
            "69:\t[0s / 9s],\t\ttrain_loss: 0.2841,\tval_loss: 0.2775\n",
            "70:\t[0s / 9s],\t\ttrain_loss: 0.2774,\tval_loss: 0.2773\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.2921,\tval_loss: 0.2773\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.2889,\tval_loss: 0.2771\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.2818,\tval_loss: 0.2772\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.2817,\tval_loss: 0.2770\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.2846,\tval_loss: 0.2769\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.2763,\tval_loss: 0.2769\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.2882,\tval_loss: 0.2769\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.2874,\tval_loss: 0.2769\n",
            "79:\t[0s / 10s],\t\ttrain_loss: 0.2792,\tval_loss: 0.2768\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.2834,\tval_loss: 0.2768\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.2872,\tval_loss: 0.2768\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.2758,\tval_loss: 0.2767\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.2802,\tval_loss: 0.2767\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.2852,\tval_loss: 0.2767\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.2856,\tval_loss: 0.2765\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.2738,\tval_loss: 0.2764\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.2817,\tval_loss: 0.2764\n",
            "88:\t[0s / 11s],\t\ttrain_loss: 0.2765,\tval_loss: 0.2764\n",
            "89:\t[0s / 11s],\t\ttrain_loss: 0.2769,\tval_loss: 0.2764\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.2787,\tval_loss: 0.2764\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.2767,\tval_loss: 0.2764\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.2807,\tval_loss: 0.2764\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.2775,\tval_loss: 0.2762\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.2767,\tval_loss: 0.2763\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.2787,\tval_loss: 0.2763\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.2803,\tval_loss: 0.2761\n",
            "97:\t[0s / 12s],\t\ttrain_loss: 0.2775,\tval_loss: 0.2760\n",
            "98:\t[0s / 12s],\t\ttrain_loss: 0.2786,\tval_loss: 0.2761\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.2779,\tval_loss: 0.2758\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Concordance index on test set: 0.6085536503646142\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_nodes = [best_hyperparameters['nodes']] * best_hyperparameters['layers']\n",
        "batch_norm = True if best_hyperparameters['activation_fn'] == 'relu' else False\n",
        "dropout = [best_hyperparameters['dropout']]\n",
        "\n",
        "best_net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
        "\n",
        "best_model = DeepHitSingle(best_net, tt.optim.Adam, alpha=best_hyperparameters['alpha'], sigma=best_hyperparameters['sigma'], duration_index=labtrans.cuts)\n",
        "\n",
        "batch_size = best_hyperparameters['batch_size']\n",
        "best_model.optimizer.set_lr(best_hyperparameters['lr'])\n",
        "\n",
        "# Train on the entire training set\n",
        "epochs = 100\n",
        "callbacks = [tt.callbacks.EarlyStopping()]\n",
        "log = best_model.fit(x_train, y_train, batch_size, epochs, callbacks, val_data=val)\n",
        "_ = log.plot()\n",
        "\n",
        "# Evaluate on the test set\n",
        "surv = best_model.predict_surv_df(x_test)\n",
        "ev_test = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
        "c_index_test = ev_test.concordance_td('antolini')\n",
        "\n",
        "print(f'Concordance index on test set: {c_index_test}')\n",
        "\n",
        "# Calculate the integrated Brier score\n",
        "ibs = ev_test.integrated_brier_score(time_grid=np.linspace(0, durations_test.max(), 100))\n",
        "\n",
        "print(f'Integrated Brier Score on test set: {ibs}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LcBPN0_xwZt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSxj5lx_xwHp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7cqVljWvf3h",
        "outputId": "06a7193b-dcdd-44bc-b1d8-3058b18dcadd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'batch_size': 32, 'layers': 5, 'nodes': 50, 'activation_fn': 'elu', 'alpha': 0.1, 'sigma': 0.1, 'lr': 0.01}\n"
          ]
        }
      ],
      "source": [
        "### This is good. This is without tuning early stopping, dropout or epochs. OR n_iterations, presumably\n",
        "print(best_hyperparameters)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943
        },
        "id": "9FxVMNJslpDy",
        "outputId": "b7f93c62-fbb7-4abf-fc43-50f685c01860"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.7319,\tval_loss: 0.5296\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5435,\tval_loss: 0.4984\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5187,\tval_loss: 0.4898\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.5116,\tval_loss: 0.4852\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.5077,\tval_loss: 0.4818\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.4968,\tval_loss: 0.4802\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.4960,\tval_loss: 0.4790\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.4852,\tval_loss: 0.4799\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.4853,\tval_loss: 0.4778\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.4761,\tval_loss: 0.4794\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.4731,\tval_loss: 0.4770\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.4663,\tval_loss: 0.4780\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.4723,\tval_loss: 0.4773\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 0.4642,\tval_loss: 0.4805\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.4600,\tval_loss: 0.4762\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.4591,\tval_loss: 0.4789\n",
            "16:\t[0s / 5s],\t\ttrain_loss: 0.4519,\tval_loss: 0.4768\n",
            "17:\t[0s / 5s],\t\ttrain_loss: 0.4538,\tval_loss: 0.4791\n",
            "18:\t[0s / 5s],\t\ttrain_loss: 0.4540,\tval_loss: 0.4772\n",
            "19:\t[0s / 5s],\t\ttrain_loss: 0.4493,\tval_loss: 0.4783\n",
            "20:\t[0s / 5s],\t\ttrain_loss: 0.4460,\tval_loss: 0.4778\n",
            "21:\t[0s / 6s],\t\ttrain_loss: 0.4378,\tval_loss: 0.4781\n",
            "22:\t[0s / 6s],\t\ttrain_loss: 0.4376,\tval_loss: 0.4791\n",
            "23:\t[0s / 6s],\t\ttrain_loss: 0.4459,\tval_loss: 0.4802\n",
            "24:\t[0s / 6s],\t\ttrain_loss: 0.4344,\tval_loss: 0.4802\n",
            "Concordance index on test set: 0.6484781935411211\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Integrated Brier Score on test set: 0.0830719720523155\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "###This is good. This is without tuning early stopping, dropout or epochs\n",
        "# Use the best hyperparameters to create a new model\n",
        "num_nodes = [best_hyperparameters['nodes']] * best_hyperparameters['layers']\n",
        "batch_norm = True if best_hyperparameters['activation_fn'] == 'relu' else False\n",
        "dropout = 0.4\n",
        "\n",
        "best_net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
        "\n",
        "best_model = DeepHitSingle(best_net, tt.optim.Adam, alpha=best_hyperparameters['alpha'], sigma=best_hyperparameters['sigma'], duration_index=labtrans.cuts)\n",
        "\n",
        "batch_size = best_hyperparameters['batch_size']\n",
        "best_model.optimizer.set_lr(best_hyperparameters['lr'])\n",
        "\n",
        "# Train on the entire training set\n",
        "epochs = 100\n",
        "callbacks = [tt.callbacks.EarlyStopping()]\n",
        "log = best_model.fit(x_train, y_train, batch_size, epochs, callbacks, val_data=val)\n",
        "_ = log.plot()\n",
        "\n",
        "# Evaluate on the test set\n",
        "surv = best_model.predict_surv_df(x_test)\n",
        "ev_test = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
        "c_index_test = ev_test.concordance_td('antolini')\n",
        "\n",
        "print(f'Concordance index on test set: {c_index_test}')\n",
        "\n",
        "# Calculate the integrated Brier score\n",
        "ibs = ev_test.integrated_brier_score(time_grid=np.linspace(0, durations_test.max(), 100))\n",
        "\n",
        "print(f'Integrated Brier Score on test set: {ibs}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwGlxuWXV-iS"
      },
      "outputs": [],
      "source": [
        "best_hyperparameters = {'batch_size': 32, 'layers': 1, 'nodes': 100, 'activation_fn': 'elu', 'alpha': 1.0, 'sigma': 0.1, 'lr': 0.001, 'dropout': 0.4, 'patience': 10}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UddXKgmzuJDW",
        "outputId": "980aad90-2449-4666-fd4a-9578ad5c7d5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random search... itr: 0\n",
            "{'batch_size': 32, 'batch_norm': True, 'layers': 2, 'nodes': 200, 'alpha': 1.0, 'sigma': 1.0, 'lr': 0.01, 'dropout': 0.2, 'patience': 30}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.7214,\tval_loss: 0.6440\n",
            "1:\t[0s / 1s],\t\ttrain_loss: 0.5786,\tval_loss: 0.5553\n",
            "2:\t[0s / 2s],\t\ttrain_loss: 0.5196,\tval_loss: 0.5399\n",
            "3:\t[0s / 3s],\t\ttrain_loss: 0.4894,\tval_loss: 0.5359\n",
            "4:\t[0s / 3s],\t\ttrain_loss: 0.4622,\tval_loss: 0.5584\n",
            "5:\t[0s / 3s],\t\ttrain_loss: 0.4486,\tval_loss: 0.6016\n",
            "6:\t[0s / 4s],\t\ttrain_loss: 0.4490,\tval_loss: 0.5686\n",
            "7:\t[0s / 4s],\t\ttrain_loss: 0.4259,\tval_loss: 0.5587\n",
            "8:\t[0s / 4s],\t\ttrain_loss: 0.4136,\tval_loss: 0.5975\n",
            "9:\t[0s / 5s],\t\ttrain_loss: 0.4111,\tval_loss: 0.5988\n",
            "10:\t[0s / 5s],\t\ttrain_loss: 0.4010,\tval_loss: 0.5950\n",
            "11:\t[0s / 6s],\t\ttrain_loss: 0.3864,\tval_loss: 0.6049\n",
            "12:\t[0s / 6s],\t\ttrain_loss: 0.3651,\tval_loss: 0.6068\n",
            "13:\t[0s / 7s],\t\ttrain_loss: 0.3722,\tval_loss: 0.6276\n",
            "14:\t[0s / 7s],\t\ttrain_loss: 0.3751,\tval_loss: 0.6436\n",
            "15:\t[0s / 7s],\t\ttrain_loss: 0.3506,\tval_loss: 0.6499\n",
            "16:\t[0s / 8s],\t\ttrain_loss: 0.3521,\tval_loss: 0.6541\n",
            "17:\t[0s / 8s],\t\ttrain_loss: 0.3438,\tval_loss: 0.6422\n",
            "18:\t[0s / 9s],\t\ttrain_loss: 0.3469,\tval_loss: 0.6698\n",
            "19:\t[0s / 9s],\t\ttrain_loss: 0.3479,\tval_loss: 0.6889\n",
            "20:\t[0s / 10s],\t\ttrain_loss: 0.3341,\tval_loss: 0.6595\n",
            "21:\t[0s / 10s],\t\ttrain_loss: 0.3323,\tval_loss: 0.6890\n",
            "22:\t[0s / 10s],\t\ttrain_loss: 0.3289,\tval_loss: 0.6828\n",
            "23:\t[0s / 11s],\t\ttrain_loss: 0.3376,\tval_loss: 0.7340\n",
            "24:\t[0s / 11s],\t\ttrain_loss: 0.3233,\tval_loss: 0.7466\n",
            "25:\t[0s / 11s],\t\ttrain_loss: 0.3049,\tval_loss: 0.7392\n",
            "26:\t[0s / 12s],\t\ttrain_loss: 0.3112,\tval_loss: 0.7825\n",
            "27:\t[0s / 12s],\t\ttrain_loss: 0.3035,\tval_loss: 0.7225\n",
            "28:\t[0s / 12s],\t\ttrain_loss: 0.3117,\tval_loss: 0.7391\n",
            "29:\t[0s / 12s],\t\ttrain_loss: 0.2904,\tval_loss: 0.7580\n",
            "30:\t[0s / 13s],\t\ttrain_loss: 0.3086,\tval_loss: 0.7653\n",
            "31:\t[0s / 13s],\t\ttrain_loss: 0.2965,\tval_loss: 0.7494\n",
            "32:\t[0s / 13s],\t\ttrain_loss: 0.3067,\tval_loss: 0.7383\n",
            "33:\t[0s / 14s],\t\ttrain_loss: 0.2978,\tval_loss: 0.8288\n",
            "Current best c-index: 0.550837076357697\n",
            "Random search... itr: 1\n",
            "{'batch_size': 256, 'batch_norm': True, 'layers': 2, 'nodes': 50, 'alpha': 1.0, 'sigma': 0.1, 'lr': 0.0001, 'dropout': 0.4, 'patience': 20}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 1.0339,\tval_loss: 0.8937\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 1.0387,\tval_loss: 0.9251\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 1.0336,\tval_loss: 0.9385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 1.0295,\tval_loss: 0.9426\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 1.0311,\tval_loss: 0.9428\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 1.0073,\tval_loss: 0.9413\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 1.0255,\tval_loss: 0.9394\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 1.0139,\tval_loss: 0.9376\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 1.0196,\tval_loss: 0.9370\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.9988,\tval_loss: 0.9342\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 1.0019,\tval_loss: 0.9317\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.9996,\tval_loss: 0.9292\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 1.0103,\tval_loss: 0.9258\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.9960,\tval_loss: 0.9241\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.9910,\tval_loss: 0.9212\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.9802,\tval_loss: 0.9211\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.9787,\tval_loss: 0.9195\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.9709,\tval_loss: 0.9177\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.9845,\tval_loss: 0.9135\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.9691,\tval_loss: 0.9108\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.9780,\tval_loss: 0.9092\n",
            "Current best c-index: 0.5514495712535729\n",
            "Random search... itr: 2\n",
            "{'batch_size': 256, 'batch_norm': False, 'layers': 2, 'nodes': 50, 'alpha': 0.5, 'sigma': 0.5, 'lr': 0.01, 'dropout': 0.2, 'patience': 30}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.4014,\tval_loss: 0.3116\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.3134,\tval_loss: 0.2951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 0.2989,\tval_loss: 0.2868\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.2890,\tval_loss: 0.2846\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.2843,\tval_loss: 0.2835\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.2750,\tval_loss: 0.2831\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.2742,\tval_loss: 0.2821\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.2725,\tval_loss: 0.2819\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.2662,\tval_loss: 0.2812\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.2602,\tval_loss: 0.2846\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.2559,\tval_loss: 0.2833\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.2583,\tval_loss: 0.2809\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.2558,\tval_loss: 0.2854\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.2555,\tval_loss: 0.2888\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.2429,\tval_loss: 0.2848\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.2481,\tval_loss: 0.2841\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 0.2439,\tval_loss: 0.2872\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 0.2360,\tval_loss: 0.2927\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 0.2323,\tval_loss: 0.2937\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.2305,\tval_loss: 0.2961\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.2373,\tval_loss: 0.3024\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.2245,\tval_loss: 0.3030\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.2386,\tval_loss: 0.3068\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.2256,\tval_loss: 0.3059\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.2275,\tval_loss: 0.3101\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.2218,\tval_loss: 0.3060\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.2163,\tval_loss: 0.3091\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.2201,\tval_loss: 0.3123\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.2122,\tval_loss: 0.3175\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 0.2140,\tval_loss: 0.3168\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 0.2096,\tval_loss: 0.3144\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 0.2136,\tval_loss: 0.3157\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 0.2128,\tval_loss: 0.3230\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 0.2072,\tval_loss: 0.3298\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 0.2086,\tval_loss: 0.3279\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 0.2063,\tval_loss: 0.3332\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 0.2052,\tval_loss: 0.3269\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 0.2034,\tval_loss: 0.3358\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.2094,\tval_loss: 0.3320\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.1982,\tval_loss: 0.3278\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 0.1937,\tval_loss: 0.3344\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 0.1962,\tval_loss: 0.3347\n",
            "Current best c-index: 0.5802368313597387\n",
            "Random search... itr: 3\n",
            "{'batch_size': 64, 'batch_norm': True, 'layers': 3, 'nodes': 100, 'alpha': 0.1, 'sigma': 0.1, 'lr': 0.001, 'dropout': 0.1, 'patience': 40}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2242,\tval_loss: 0.1540\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1712,\tval_loss: 0.1526\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1683,\tval_loss: 0.1535\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1484,\tval_loss: 0.1508\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1487,\tval_loss: 0.1478\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1445,\tval_loss: 0.1480\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1398,\tval_loss: 0.1465\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.1335,\tval_loss: 0.1451\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1365,\tval_loss: 0.1495\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1230,\tval_loss: 0.1503\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.1259,\tval_loss: 0.1480\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 0.1231,\tval_loss: 0.1456\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 0.1155,\tval_loss: 0.1501\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.1158,\tval_loss: 0.1456\n",
            "14:\t[0s / 3s],\t\ttrain_loss: 0.1114,\tval_loss: 0.1454\n",
            "15:\t[0s / 3s],\t\ttrain_loss: 0.1099,\tval_loss: 0.1451\n",
            "16:\t[0s / 3s],\t\ttrain_loss: 0.1057,\tval_loss: 0.1474\n",
            "17:\t[0s / 3s],\t\ttrain_loss: 0.1013,\tval_loss: 0.1486\n",
            "18:\t[0s / 4s],\t\ttrain_loss: 0.0986,\tval_loss: 0.1509\n",
            "19:\t[0s / 4s],\t\ttrain_loss: 0.0947,\tval_loss: 0.1478\n",
            "20:\t[0s / 4s],\t\ttrain_loss: 0.0976,\tval_loss: 0.1480\n",
            "21:\t[0s / 5s],\t\ttrain_loss: 0.0954,\tval_loss: 0.1537\n",
            "22:\t[0s / 5s],\t\ttrain_loss: 0.0913,\tval_loss: 0.1462\n",
            "23:\t[0s / 5s],\t\ttrain_loss: 0.0935,\tval_loss: 0.1491\n",
            "24:\t[0s / 5s],\t\ttrain_loss: 0.0887,\tval_loss: 0.1459\n",
            "25:\t[0s / 6s],\t\ttrain_loss: 0.0929,\tval_loss: 0.1397\n",
            "26:\t[0s / 6s],\t\ttrain_loss: 0.0934,\tval_loss: 0.1392\n",
            "27:\t[0s / 6s],\t\ttrain_loss: 0.0995,\tval_loss: 0.1436\n",
            "28:\t[0s / 6s],\t\ttrain_loss: 0.0907,\tval_loss: 0.1466\n",
            "29:\t[0s / 6s],\t\ttrain_loss: 0.0878,\tval_loss: 0.1492\n",
            "30:\t[0s / 7s],\t\ttrain_loss: 0.0867,\tval_loss: 0.1547\n",
            "31:\t[0s / 7s],\t\ttrain_loss: 0.0812,\tval_loss: 0.1451\n",
            "32:\t[0s / 7s],\t\ttrain_loss: 0.0856,\tval_loss: 0.1624\n",
            "33:\t[0s / 7s],\t\ttrain_loss: 0.0892,\tval_loss: 0.1638\n",
            "34:\t[0s / 7s],\t\ttrain_loss: 0.0859,\tval_loss: 0.1531\n",
            "35:\t[0s / 8s],\t\ttrain_loss: 0.0819,\tval_loss: 0.1541\n",
            "36:\t[0s / 8s],\t\ttrain_loss: 0.0799,\tval_loss: 0.1644\n",
            "37:\t[0s / 8s],\t\ttrain_loss: 0.0786,\tval_loss: 0.1660\n",
            "38:\t[0s / 8s],\t\ttrain_loss: 0.0769,\tval_loss: 0.1588\n",
            "39:\t[0s / 8s],\t\ttrain_loss: 0.0732,\tval_loss: 0.1576\n",
            "40:\t[0s / 8s],\t\ttrain_loss: 0.0793,\tval_loss: 0.1671\n",
            "41:\t[0s / 9s],\t\ttrain_loss: 0.0769,\tval_loss: 0.1674\n",
            "42:\t[0s / 9s],\t\ttrain_loss: 0.0774,\tval_loss: 0.1628\n",
            "43:\t[0s / 9s],\t\ttrain_loss: 0.0791,\tval_loss: 0.1592\n",
            "44:\t[0s / 9s],\t\ttrain_loss: 0.0736,\tval_loss: 0.1616\n",
            "45:\t[0s / 9s],\t\ttrain_loss: 0.0716,\tval_loss: 0.1560\n",
            "46:\t[0s / 10s],\t\ttrain_loss: 0.0769,\tval_loss: 0.1509\n",
            "47:\t[0s / 10s],\t\ttrain_loss: 0.0760,\tval_loss: 0.1618\n",
            "48:\t[0s / 10s],\t\ttrain_loss: 0.0750,\tval_loss: 0.1580\n",
            "49:\t[0s / 10s],\t\ttrain_loss: 0.0729,\tval_loss: 0.1549\n",
            "50:\t[0s / 10s],\t\ttrain_loss: 0.0755,\tval_loss: 0.1549\n",
            "51:\t[0s / 10s],\t\ttrain_loss: 0.0707,\tval_loss: 0.1556\n",
            "52:\t[0s / 11s],\t\ttrain_loss: 0.0686,\tval_loss: 0.1555\n",
            "53:\t[0s / 11s],\t\ttrain_loss: 0.0675,\tval_loss: 0.1626\n",
            "54:\t[0s / 11s],\t\ttrain_loss: 0.0698,\tval_loss: 0.1555\n",
            "55:\t[0s / 11s],\t\ttrain_loss: 0.0689,\tval_loss: 0.1546\n",
            "56:\t[0s / 11s],\t\ttrain_loss: 0.0681,\tval_loss: 0.1569\n",
            "57:\t[0s / 12s],\t\ttrain_loss: 0.0737,\tval_loss: 0.1631\n",
            "58:\t[0s / 12s],\t\ttrain_loss: 0.0749,\tval_loss: 0.1636\n",
            "59:\t[0s / 12s],\t\ttrain_loss: 0.0670,\tval_loss: 0.1544\n",
            "60:\t[0s / 12s],\t\ttrain_loss: 0.0734,\tval_loss: 0.1595\n",
            "61:\t[0s / 12s],\t\ttrain_loss: 0.0694,\tval_loss: 0.1600\n",
            "62:\t[0s / 12s],\t\ttrain_loss: 0.0646,\tval_loss: 0.1719\n",
            "63:\t[0s / 13s],\t\ttrain_loss: 0.0622,\tval_loss: 0.1707\n",
            "64:\t[0s / 13s],\t\ttrain_loss: 0.0642,\tval_loss: 0.1640\n",
            "65:\t[0s / 13s],\t\ttrain_loss: 0.0613,\tval_loss: 0.1712\n",
            "66:\t[0s / 13s],\t\ttrain_loss: 0.0688,\tval_loss: 0.1789\n",
            "Current best c-index: 0.5802368313597387\n",
            "Random search... itr: 4\n",
            "{'batch_size': 32, 'batch_norm': False, 'layers': 1, 'nodes': 200, 'alpha': 1.0, 'sigma': 1.0, 'lr': 0.01, 'dropout': 0.2, 'patience': 50}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6443,\tval_loss: 0.5275\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5385,\tval_loss: 0.5304\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5017,\tval_loss: 0.5365\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.4619,\tval_loss: 0.5326\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.4557,\tval_loss: 0.5538\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.4337,\tval_loss: 0.5867\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.4175,\tval_loss: 0.6091\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.4022,\tval_loss: 0.5910\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.3769,\tval_loss: 0.6113\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.3663,\tval_loss: 0.6598\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.3595,\tval_loss: 0.6466\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 0.3406,\tval_loss: 0.6677\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 0.3440,\tval_loss: 0.7082\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.3248,\tval_loss: 0.7629\n",
            "14:\t[0s / 3s],\t\ttrain_loss: 0.3319,\tval_loss: 0.7041\n",
            "15:\t[0s / 3s],\t\ttrain_loss: 0.3048,\tval_loss: 0.7509\n",
            "16:\t[0s / 3s],\t\ttrain_loss: 0.3071,\tval_loss: 0.7505\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.3096,\tval_loss: 0.7637\n",
            "18:\t[0s / 4s],\t\ttrain_loss: 0.3022,\tval_loss: 0.7552\n",
            "19:\t[0s / 4s],\t\ttrain_loss: 0.2983,\tval_loss: 0.7849\n",
            "20:\t[0s / 4s],\t\ttrain_loss: 0.2781,\tval_loss: 0.7831\n",
            "21:\t[0s / 5s],\t\ttrain_loss: 0.2840,\tval_loss: 0.7916\n",
            "22:\t[0s / 5s],\t\ttrain_loss: 0.2860,\tval_loss: 0.7963\n",
            "23:\t[0s / 5s],\t\ttrain_loss: 0.2629,\tval_loss: 0.8012\n",
            "24:\t[0s / 6s],\t\ttrain_loss: 0.2913,\tval_loss: 0.8359\n",
            "25:\t[0s / 6s],\t\ttrain_loss: 0.2729,\tval_loss: 0.8617\n",
            "26:\t[0s / 6s],\t\ttrain_loss: 0.2617,\tval_loss: 0.8708\n",
            "27:\t[0s / 7s],\t\ttrain_loss: 0.2515,\tval_loss: 0.9166\n",
            "28:\t[0s / 7s],\t\ttrain_loss: 0.2511,\tval_loss: 0.9060\n",
            "29:\t[0s / 7s],\t\ttrain_loss: 0.2608,\tval_loss: 0.9345\n",
            "30:\t[0s / 7s],\t\ttrain_loss: 0.2381,\tval_loss: 0.9401\n",
            "31:\t[0s / 8s],\t\ttrain_loss: 0.2334,\tval_loss: 0.9406\n",
            "32:\t[0s / 8s],\t\ttrain_loss: 0.2453,\tval_loss: 0.9503\n",
            "33:\t[0s / 8s],\t\ttrain_loss: 0.2633,\tval_loss: 0.9986\n",
            "34:\t[0s / 8s],\t\ttrain_loss: 0.2559,\tval_loss: 0.9967\n",
            "35:\t[0s / 8s],\t\ttrain_loss: 0.2392,\tval_loss: 0.9921\n",
            "36:\t[0s / 9s],\t\ttrain_loss: 0.2323,\tval_loss: 0.9928\n",
            "37:\t[0s / 9s],\t\ttrain_loss: 0.2390,\tval_loss: 1.0111\n",
            "38:\t[0s / 9s],\t\ttrain_loss: 0.2366,\tval_loss: 1.0452\n",
            "39:\t[0s / 9s],\t\ttrain_loss: 0.2174,\tval_loss: 1.0615\n",
            "40:\t[0s / 9s],\t\ttrain_loss: 0.2314,\tval_loss: 1.0770\n",
            "41:\t[0s / 10s],\t\ttrain_loss: 0.2366,\tval_loss: 1.0373\n",
            "42:\t[0s / 10s],\t\ttrain_loss: 0.2201,\tval_loss: 1.1191\n",
            "43:\t[0s / 10s],\t\ttrain_loss: 0.2132,\tval_loss: 1.1306\n",
            "44:\t[0s / 10s],\t\ttrain_loss: 0.2151,\tval_loss: 1.1551\n",
            "45:\t[0s / 10s],\t\ttrain_loss: 0.2358,\tval_loss: 1.1185\n",
            "46:\t[0s / 11s],\t\ttrain_loss: 0.2131,\tval_loss: 1.1188\n",
            "47:\t[0s / 11s],\t\ttrain_loss: 0.2141,\tval_loss: 1.1244\n",
            "48:\t[0s / 11s],\t\ttrain_loss: 0.2119,\tval_loss: 1.1928\n",
            "49:\t[0s / 11s],\t\ttrain_loss: 0.2263,\tval_loss: 1.1300\n",
            "50:\t[0s / 11s],\t\ttrain_loss: 0.2163,\tval_loss: 1.1335\n",
            "Current best c-index: 0.6006022866476113\n",
            "Random search... itr: 5\n",
            "{'batch_size': 256, 'batch_norm': True, 'layers': 3, 'nodes': 100, 'alpha': 0.5, 'sigma': 1.0, 'lr': 0.0001, 'dropout': 0.5, 'patience': 30}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.5677,\tval_loss: 0.4974\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5585,\tval_loss: 0.5094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5624,\tval_loss: 0.5120\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5589,\tval_loss: 0.5116\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5606,\tval_loss: 0.5100\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5538,\tval_loss: 0.5088\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.5494,\tval_loss: 0.5060\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.5458,\tval_loss: 0.5031\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.5507,\tval_loss: 0.5015\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.5479,\tval_loss: 0.5001\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.5479,\tval_loss: 0.4975\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.5417,\tval_loss: 0.4953\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.5353,\tval_loss: 0.4939\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.5395,\tval_loss: 0.4918\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.5463,\tval_loss: 0.4907\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.5342,\tval_loss: 0.4889\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.5320,\tval_loss: 0.4864\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.5430,\tval_loss: 0.4845\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.5298,\tval_loss: 0.4830\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.5298,\tval_loss: 0.4803\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.5348,\tval_loss: 0.4778\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.5273,\tval_loss: 0.4771\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.5193,\tval_loss: 0.4755\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.5164,\tval_loss: 0.4738\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.5232,\tval_loss: 0.4714\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.5194,\tval_loss: 0.4697\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.5074,\tval_loss: 0.4673\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.5144,\tval_loss: 0.4666\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.5212,\tval_loss: 0.4643\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.5100,\tval_loss: 0.4632\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.5109,\tval_loss: 0.4611\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.5080,\tval_loss: 0.4590\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.5063,\tval_loss: 0.4560\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.5098,\tval_loss: 0.4541\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.5020,\tval_loss: 0.4518\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.5098,\tval_loss: 0.4511\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.4946,\tval_loss: 0.4484\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.4956,\tval_loss: 0.4469\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.4878,\tval_loss: 0.4446\n",
            "39:\t[0s / 3s],\t\ttrain_loss: 0.4928,\tval_loss: 0.4433\n",
            "40:\t[0s / 3s],\t\ttrain_loss: 0.4970,\tval_loss: 0.4404\n",
            "41:\t[0s / 3s],\t\ttrain_loss: 0.4832,\tval_loss: 0.4377\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 0.4983,\tval_loss: 0.4346\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 0.4858,\tval_loss: 0.4336\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 0.4729,\tval_loss: 0.4312\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 0.4882,\tval_loss: 0.4282\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 0.4847,\tval_loss: 0.4254\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 0.4748,\tval_loss: 0.4233\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 0.4797,\tval_loss: 0.4217\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 0.4745,\tval_loss: 0.4192\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 0.4744,\tval_loss: 0.4170\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 0.4727,\tval_loss: 0.4141\n",
            "52:\t[0s / 4s],\t\ttrain_loss: 0.4656,\tval_loss: 0.4113\n",
            "53:\t[0s / 4s],\t\ttrain_loss: 0.4685,\tval_loss: 0.4095\n",
            "54:\t[0s / 4s],\t\ttrain_loss: 0.4743,\tval_loss: 0.4059\n",
            "55:\t[0s / 4s],\t\ttrain_loss: 0.4679,\tval_loss: 0.4037\n",
            "56:\t[0s / 4s],\t\ttrain_loss: 0.4603,\tval_loss: 0.4029\n",
            "57:\t[0s / 4s],\t\ttrain_loss: 0.4632,\tval_loss: 0.3999\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 0.4537,\tval_loss: 0.3970\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 0.4547,\tval_loss: 0.3934\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 0.4474,\tval_loss: 0.3919\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 0.4534,\tval_loss: 0.3894\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 0.4538,\tval_loss: 0.3864\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 0.4499,\tval_loss: 0.3828\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 0.4523,\tval_loss: 0.3815\n",
            "65:\t[0s / 5s],\t\ttrain_loss: 0.4448,\tval_loss: 0.3788\n",
            "66:\t[0s / 5s],\t\ttrain_loss: 0.4474,\tval_loss: 0.3772\n",
            "67:\t[0s / 5s],\t\ttrain_loss: 0.4458,\tval_loss: 0.3740\n",
            "68:\t[0s / 5s],\t\ttrain_loss: 0.4478,\tval_loss: 0.3713\n",
            "69:\t[0s / 5s],\t\ttrain_loss: 0.4410,\tval_loss: 0.3678\n",
            "70:\t[0s / 5s],\t\ttrain_loss: 0.4326,\tval_loss: 0.3666\n",
            "71:\t[0s / 5s],\t\ttrain_loss: 0.4263,\tval_loss: 0.3632\n",
            "72:\t[0s / 5s],\t\ttrain_loss: 0.4297,\tval_loss: 0.3622\n",
            "73:\t[0s / 5s],\t\ttrain_loss: 0.4285,\tval_loss: 0.3599\n",
            "74:\t[0s / 5s],\t\ttrain_loss: 0.4279,\tval_loss: 0.3572\n",
            "75:\t[0s / 5s],\t\ttrain_loss: 0.4228,\tval_loss: 0.3550\n",
            "76:\t[0s / 6s],\t\ttrain_loss: 0.4265,\tval_loss: 0.3528\n",
            "77:\t[0s / 6s],\t\ttrain_loss: 0.4395,\tval_loss: 0.3502\n",
            "78:\t[0s / 6s],\t\ttrain_loss: 0.4148,\tval_loss: 0.3477\n",
            "79:\t[0s / 6s],\t\ttrain_loss: 0.4221,\tval_loss: 0.3450\n",
            "80:\t[0s / 6s],\t\ttrain_loss: 0.4200,\tval_loss: 0.3429\n",
            "81:\t[0s / 6s],\t\ttrain_loss: 0.4155,\tval_loss: 0.3417\n",
            "82:\t[0s / 6s],\t\ttrain_loss: 0.4090,\tval_loss: 0.3402\n",
            "83:\t[0s / 6s],\t\ttrain_loss: 0.4071,\tval_loss: 0.3387\n",
            "84:\t[0s / 6s],\t\ttrain_loss: 0.4086,\tval_loss: 0.3369\n",
            "85:\t[0s / 7s],\t\ttrain_loss: 0.4091,\tval_loss: 0.3363\n",
            "86:\t[0s / 7s],\t\ttrain_loss: 0.4021,\tval_loss: 0.3345\n",
            "87:\t[0s / 7s],\t\ttrain_loss: 0.4022,\tval_loss: 0.3322\n",
            "88:\t[0s / 7s],\t\ttrain_loss: 0.4008,\tval_loss: 0.3317\n",
            "89:\t[0s / 7s],\t\ttrain_loss: 0.4019,\tval_loss: 0.3303\n",
            "90:\t[0s / 7s],\t\ttrain_loss: 0.3995,\tval_loss: 0.3283\n",
            "91:\t[0s / 7s],\t\ttrain_loss: 0.4055,\tval_loss: 0.3272\n",
            "92:\t[0s / 7s],\t\ttrain_loss: 0.4002,\tval_loss: 0.3267\n",
            "93:\t[0s / 7s],\t\ttrain_loss: 0.3971,\tval_loss: 0.3263\n",
            "94:\t[0s / 8s],\t\ttrain_loss: 0.3872,\tval_loss: 0.3240\n",
            "95:\t[0s / 8s],\t\ttrain_loss: 0.3917,\tval_loss: 0.3230\n",
            "96:\t[0s / 8s],\t\ttrain_loss: 0.3904,\tval_loss: 0.3220\n",
            "97:\t[0s / 8s],\t\ttrain_loss: 0.3900,\tval_loss: 0.3208\n",
            "98:\t[0s / 8s],\t\ttrain_loss: 0.3879,\tval_loss: 0.3207\n",
            "99:\t[0s / 8s],\t\ttrain_loss: 0.3838,\tval_loss: 0.3203\n",
            "Current best c-index: 0.6006022866476113\n",
            "Random search... itr: 6\n",
            "{'batch_size': 256, 'batch_norm': True, 'layers': 2, 'nodes': 100, 'alpha': 1.0, 'sigma': 0.1, 'lr': 0.001, 'dropout': 0.5, 'patience': 10}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 1.0200,\tval_loss: 0.9227\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.9855,\tval_loss: 0.8762\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.9427,\tval_loss: 0.8326\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.9031,\tval_loss: 0.7964\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.8738,\tval_loss: 0.7634\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.8405,\tval_loss: 0.7322\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.8126,\tval_loss: 0.7014\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.7680,\tval_loss: 0.6715\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.7267,\tval_loss: 0.6494\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.7218,\tval_loss: 0.6281\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.6882,\tval_loss: 0.6158\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.6734,\tval_loss: 0.6053\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.6533,\tval_loss: 0.5985\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.6205,\tval_loss: 0.5935\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.6226,\tval_loss: 0.5880\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.6316,\tval_loss: 0.5825\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.6011,\tval_loss: 0.5767\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.5803,\tval_loss: 0.5742\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.5882,\tval_loss: 0.5703\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.5868,\tval_loss: 0.5645\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.5783,\tval_loss: 0.5603\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.5865,\tval_loss: 0.5563\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.5656,\tval_loss: 0.5538\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.5674,\tval_loss: 0.5508\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.5463,\tval_loss: 0.5473\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.5492,\tval_loss: 0.5446\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.5434,\tval_loss: 0.5410\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.5343,\tval_loss: 0.5380\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.5491,\tval_loss: 0.5360\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.5333,\tval_loss: 0.5340\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.5438,\tval_loss: 0.5324\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.5387,\tval_loss: 0.5320\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.5326,\tval_loss: 0.5304\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.5283,\tval_loss: 0.5298\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.5403,\tval_loss: 0.5279\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.5265,\tval_loss: 0.5261\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.5107,\tval_loss: 0.5242\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.5193,\tval_loss: 0.5216\n",
            "38:\t[0s / 3s],\t\ttrain_loss: 0.5232,\tval_loss: 0.5193\n",
            "39:\t[0s / 3s],\t\ttrain_loss: 0.5162,\tval_loss: 0.5184\n",
            "40:\t[0s / 3s],\t\ttrain_loss: 0.5092,\tval_loss: 0.5183\n",
            "41:\t[0s / 3s],\t\ttrain_loss: 0.5125,\tval_loss: 0.5174\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 0.5095,\tval_loss: 0.5176\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 0.5054,\tval_loss: 0.5168\n",
            "44:\t[0s / 3s],\t\ttrain_loss: 0.4922,\tval_loss: 0.5148\n",
            "45:\t[0s / 3s],\t\ttrain_loss: 0.5083,\tval_loss: 0.5143\n",
            "46:\t[0s / 3s],\t\ttrain_loss: 0.4927,\tval_loss: 0.5148\n",
            "47:\t[0s / 3s],\t\ttrain_loss: 0.4944,\tval_loss: 0.5147\n",
            "48:\t[0s / 3s],\t\ttrain_loss: 0.5045,\tval_loss: 0.5141\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 0.4908,\tval_loss: 0.5136\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 0.4939,\tval_loss: 0.5131\n",
            "51:\t[0s / 4s],\t\ttrain_loss: 0.4792,\tval_loss: 0.5127\n",
            "52:\t[0s / 4s],\t\ttrain_loss: 0.4822,\tval_loss: 0.5107\n",
            "53:\t[0s / 4s],\t\ttrain_loss: 0.5045,\tval_loss: 0.5109\n",
            "54:\t[0s / 4s],\t\ttrain_loss: 0.4846,\tval_loss: 0.5097\n",
            "55:\t[0s / 4s],\t\ttrain_loss: 0.5024,\tval_loss: 0.5099\n",
            "56:\t[0s / 4s],\t\ttrain_loss: 0.4919,\tval_loss: 0.5092\n",
            "57:\t[0s / 4s],\t\ttrain_loss: 0.4862,\tval_loss: 0.5083\n",
            "58:\t[0s / 4s],\t\ttrain_loss: 0.4747,\tval_loss: 0.5065\n",
            "59:\t[0s / 4s],\t\ttrain_loss: 0.4896,\tval_loss: 0.5060\n",
            "60:\t[0s / 4s],\t\ttrain_loss: 0.4815,\tval_loss: 0.5044\n",
            "61:\t[0s / 4s],\t\ttrain_loss: 0.4894,\tval_loss: 0.5042\n",
            "62:\t[0s / 4s],\t\ttrain_loss: 0.4832,\tval_loss: 0.5034\n",
            "63:\t[0s / 4s],\t\ttrain_loss: 0.4841,\tval_loss: 0.5021\n",
            "64:\t[0s / 4s],\t\ttrain_loss: 0.4748,\tval_loss: 0.5012\n",
            "65:\t[0s / 4s],\t\ttrain_loss: 0.4785,\tval_loss: 0.5015\n",
            "66:\t[0s / 5s],\t\ttrain_loss: 0.4787,\tval_loss: 0.5019\n",
            "67:\t[0s / 5s],\t\ttrain_loss: 0.4754,\tval_loss: 0.5019\n",
            "68:\t[0s / 5s],\t\ttrain_loss: 0.4681,\tval_loss: 0.5030\n",
            "69:\t[0s / 5s],\t\ttrain_loss: 0.4749,\tval_loss: 0.5035\n",
            "70:\t[0s / 5s],\t\ttrain_loss: 0.4745,\tval_loss: 0.5033\n",
            "71:\t[0s / 5s],\t\ttrain_loss: 0.4768,\tval_loss: 0.5023\n",
            "72:\t[0s / 5s],\t\ttrain_loss: 0.4674,\tval_loss: 0.5023\n",
            "73:\t[0s / 5s],\t\ttrain_loss: 0.4622,\tval_loss: 0.5022\n",
            "74:\t[0s / 5s],\t\ttrain_loss: 0.4706,\tval_loss: 0.5023\n",
            "Current best c-index: 0.6129542670477746\n",
            "Random search... itr: 7\n",
            "{'batch_size': 32, 'batch_norm': True, 'layers': 2, 'nodes': 100, 'alpha': 0.5, 'sigma': 0.5, 'lr': 0.0001, 'dropout': 0.2, 'patience': 40}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.5562,\tval_loss: 0.5122\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5449,\tval_loss: 0.5023\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5259,\tval_loss: 0.4955\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.5164,\tval_loss: 0.4858\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.5073,\tval_loss: 0.4743\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.4925,\tval_loss: 0.4601\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.4793,\tval_loss: 0.4489\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.4564,\tval_loss: 0.4391\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.4440,\tval_loss: 0.4298\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.4318,\tval_loss: 0.4154\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.4152,\tval_loss: 0.4054\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.4026,\tval_loss: 0.3951\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.3927,\tval_loss: 0.3849\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.3838,\tval_loss: 0.3769\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.3835,\tval_loss: 0.3754\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.3629,\tval_loss: 0.3665\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.3621,\tval_loss: 0.3605\n",
            "17:\t[0s / 5s],\t\ttrain_loss: 0.3496,\tval_loss: 0.3580\n",
            "18:\t[0s / 5s],\t\ttrain_loss: 0.3513,\tval_loss: 0.3496\n",
            "19:\t[0s / 5s],\t\ttrain_loss: 0.3445,\tval_loss: 0.3459\n",
            "20:\t[0s / 5s],\t\ttrain_loss: 0.3437,\tval_loss: 0.3483\n",
            "21:\t[0s / 6s],\t\ttrain_loss: 0.3397,\tval_loss: 0.3414\n",
            "22:\t[0s / 6s],\t\ttrain_loss: 0.3346,\tval_loss: 0.3406\n",
            "23:\t[0s / 6s],\t\ttrain_loss: 0.3273,\tval_loss: 0.3403\n",
            "24:\t[0s / 7s],\t\ttrain_loss: 0.3250,\tval_loss: 0.3415\n",
            "25:\t[0s / 7s],\t\ttrain_loss: 0.3270,\tval_loss: 0.3338\n",
            "26:\t[0s / 7s],\t\ttrain_loss: 0.3266,\tval_loss: 0.3322\n",
            "27:\t[0s / 8s],\t\ttrain_loss: 0.3212,\tval_loss: 0.3310\n",
            "28:\t[0s / 8s],\t\ttrain_loss: 0.3166,\tval_loss: 0.3319\n",
            "29:\t[0s / 9s],\t\ttrain_loss: 0.3214,\tval_loss: 0.3289\n",
            "30:\t[0s / 9s],\t\ttrain_loss: 0.3135,\tval_loss: 0.3289\n",
            "31:\t[0s / 9s],\t\ttrain_loss: 0.3104,\tval_loss: 0.3263\n",
            "32:\t[0s / 10s],\t\ttrain_loss: 0.3076,\tval_loss: 0.3276\n",
            "33:\t[0s / 10s],\t\ttrain_loss: 0.3130,\tval_loss: 0.3242\n",
            "34:\t[0s / 11s],\t\ttrain_loss: 0.3081,\tval_loss: 0.3221\n",
            "35:\t[0s / 11s],\t\ttrain_loss: 0.3055,\tval_loss: 0.3222\n",
            "36:\t[0s / 11s],\t\ttrain_loss: 0.3005,\tval_loss: 0.3203\n",
            "37:\t[0s / 12s],\t\ttrain_loss: 0.3023,\tval_loss: 0.3237\n",
            "38:\t[0s / 12s],\t\ttrain_loss: 0.2981,\tval_loss: 0.3191\n",
            "39:\t[0s / 12s],\t\ttrain_loss: 0.3031,\tval_loss: 0.3165\n",
            "40:\t[0s / 12s],\t\ttrain_loss: 0.2955,\tval_loss: 0.3159\n",
            "41:\t[0s / 13s],\t\ttrain_loss: 0.2928,\tval_loss: 0.3164\n",
            "42:\t[0s / 13s],\t\ttrain_loss: 0.2938,\tval_loss: 0.3183\n",
            "43:\t[0s / 13s],\t\ttrain_loss: 0.2938,\tval_loss: 0.3154\n",
            "44:\t[0s / 13s],\t\ttrain_loss: 0.2925,\tval_loss: 0.3132\n",
            "45:\t[0s / 14s],\t\ttrain_loss: 0.2915,\tval_loss: 0.3150\n",
            "46:\t[0s / 14s],\t\ttrain_loss: 0.2957,\tval_loss: 0.3124\n",
            "47:\t[0s / 14s],\t\ttrain_loss: 0.2887,\tval_loss: 0.3153\n",
            "48:\t[0s / 15s],\t\ttrain_loss: 0.2888,\tval_loss: 0.3137\n",
            "49:\t[0s / 15s],\t\ttrain_loss: 0.2837,\tval_loss: 0.3130\n",
            "50:\t[0s / 15s],\t\ttrain_loss: 0.2824,\tval_loss: 0.3146\n",
            "51:\t[0s / 15s],\t\ttrain_loss: 0.2857,\tval_loss: 0.3146\n",
            "52:\t[0s / 16s],\t\ttrain_loss: 0.2825,\tval_loss: 0.3120\n",
            "53:\t[0s / 16s],\t\ttrain_loss: 0.2842,\tval_loss: 0.3101\n",
            "54:\t[0s / 16s],\t\ttrain_loss: 0.2860,\tval_loss: 0.3101\n",
            "55:\t[0s / 16s],\t\ttrain_loss: 0.2825,\tval_loss: 0.3077\n",
            "56:\t[0s / 17s],\t\ttrain_loss: 0.2828,\tval_loss: 0.3085\n",
            "57:\t[0s / 17s],\t\ttrain_loss: 0.2820,\tval_loss: 0.3077\n",
            "58:\t[0s / 17s],\t\ttrain_loss: 0.2829,\tval_loss: 0.3097\n",
            "59:\t[0s / 18s],\t\ttrain_loss: 0.2794,\tval_loss: 0.3092\n",
            "60:\t[0s / 18s],\t\ttrain_loss: 0.2816,\tval_loss: 0.3054\n",
            "61:\t[0s / 18s],\t\ttrain_loss: 0.2731,\tval_loss: 0.3082\n",
            "62:\t[0s / 18s],\t\ttrain_loss: 0.2756,\tval_loss: 0.3066\n",
            "63:\t[0s / 19s],\t\ttrain_loss: 0.2746,\tval_loss: 0.3065\n",
            "64:\t[0s / 19s],\t\ttrain_loss: 0.2771,\tval_loss: 0.3066\n",
            "65:\t[0s / 19s],\t\ttrain_loss: 0.2775,\tval_loss: 0.3073\n",
            "66:\t[0s / 19s],\t\ttrain_loss: 0.2757,\tval_loss: 0.3060\n",
            "67:\t[0s / 20s],\t\ttrain_loss: 0.2738,\tval_loss: 0.3044\n",
            "68:\t[0s / 20s],\t\ttrain_loss: 0.2677,\tval_loss: 0.3044\n",
            "69:\t[0s / 20s],\t\ttrain_loss: 0.2703,\tval_loss: 0.3026\n",
            "70:\t[0s / 20s],\t\ttrain_loss: 0.2748,\tval_loss: 0.3026\n",
            "71:\t[0s / 21s],\t\ttrain_loss: 0.2731,\tval_loss: 0.3023\n",
            "72:\t[0s / 21s],\t\ttrain_loss: 0.2702,\tval_loss: 0.3018\n",
            "73:\t[0s / 22s],\t\ttrain_loss: 0.2697,\tval_loss: 0.3038\n",
            "74:\t[0s / 22s],\t\ttrain_loss: 0.2624,\tval_loss: 0.3005\n",
            "75:\t[0s / 22s],\t\ttrain_loss: 0.2682,\tval_loss: 0.3028\n",
            "76:\t[0s / 23s],\t\ttrain_loss: 0.2604,\tval_loss: 0.3009\n",
            "77:\t[0s / 23s],\t\ttrain_loss: 0.2612,\tval_loss: 0.3011\n",
            "78:\t[0s / 23s],\t\ttrain_loss: 0.2692,\tval_loss: 0.2995\n",
            "79:\t[0s / 24s],\t\ttrain_loss: 0.2647,\tval_loss: 0.3006\n",
            "80:\t[0s / 24s],\t\ttrain_loss: 0.2652,\tval_loss: 0.3005\n",
            "81:\t[0s / 25s],\t\ttrain_loss: 0.2659,\tval_loss: 0.2984\n",
            "82:\t[0s / 25s],\t\ttrain_loss: 0.2635,\tval_loss: 0.3001\n",
            "83:\t[0s / 26s],\t\ttrain_loss: 0.2677,\tval_loss: 0.2984\n",
            "84:\t[0s / 26s],\t\ttrain_loss: 0.2666,\tval_loss: 0.3005\n",
            "85:\t[0s / 26s],\t\ttrain_loss: 0.2611,\tval_loss: 0.3002\n",
            "86:\t[0s / 26s],\t\ttrain_loss: 0.2641,\tval_loss: 0.2990\n",
            "87:\t[0s / 27s],\t\ttrain_loss: 0.2594,\tval_loss: 0.2986\n",
            "88:\t[0s / 27s],\t\ttrain_loss: 0.2571,\tval_loss: 0.2986\n",
            "89:\t[0s / 27s],\t\ttrain_loss: 0.2549,\tval_loss: 0.2974\n",
            "90:\t[0s / 28s],\t\ttrain_loss: 0.2522,\tval_loss: 0.2975\n",
            "91:\t[0s / 28s],\t\ttrain_loss: 0.2542,\tval_loss: 0.2994\n",
            "92:\t[0s / 28s],\t\ttrain_loss: 0.2556,\tval_loss: 0.2990\n",
            "93:\t[0s / 28s],\t\ttrain_loss: 0.2597,\tval_loss: 0.2983\n",
            "94:\t[0s / 29s],\t\ttrain_loss: 0.2598,\tval_loss: 0.2980\n",
            "95:\t[0s / 29s],\t\ttrain_loss: 0.2533,\tval_loss: 0.2975\n",
            "96:\t[0s / 29s],\t\ttrain_loss: 0.2570,\tval_loss: 0.2986\n",
            "97:\t[0s / 29s],\t\ttrain_loss: 0.2514,\tval_loss: 0.2983\n",
            "98:\t[0s / 30s],\t\ttrain_loss: 0.2575,\tval_loss: 0.2980\n",
            "99:\t[0s / 30s],\t\ttrain_loss: 0.2516,\tval_loss: 0.2989\n",
            "Current best c-index: 0.6129542670477746\n",
            "Random search... itr: 8\n",
            "{'batch_size': 128, 'batch_norm': False, 'layers': 3, 'nodes': 100, 'alpha': 0.1, 'sigma': 0.5, 'lr': 0.01, 'dropout': 0.0, 'patience': 5}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1315,\tval_loss: 0.1209\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1164,\tval_loss: 0.1176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1105,\tval_loss: 0.1226\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1059,\tval_loss: 0.1220\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.0990,\tval_loss: 0.1236\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.0947,\tval_loss: 0.1229\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.0909,\tval_loss: 0.1334\n",
            "Current best c-index: 0.6129542670477746\n",
            "Random search... itr: 9\n",
            "{'batch_size': 256, 'batch_norm': True, 'layers': 5, 'nodes': 200, 'alpha': 1.0, 'sigma': 1.0, 'lr': 0.001, 'dropout': 0.3, 'patience': 20}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 1.0319,\tval_loss: 0.9024\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.9759,\tval_loss: 0.8574\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.9319,\tval_loss: 0.7902\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.8642,\tval_loss: 0.6900\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.7741,\tval_loss: 0.6105\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.7061,\tval_loss: 0.5976\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.6534,\tval_loss: 0.6031\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.6039,\tval_loss: 0.5983\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.5750,\tval_loss: 0.5929\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.5634,\tval_loss: 0.5708\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.5417,\tval_loss: 0.5637\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.5304,\tval_loss: 0.5566\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.5308,\tval_loss: 0.5536\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.5243,\tval_loss: 0.5457\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.5075,\tval_loss: 0.5421\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.4999,\tval_loss: 0.5393\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.5119,\tval_loss: 0.5393\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.4881,\tval_loss: 0.5364\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.4973,\tval_loss: 0.5350\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.4874,\tval_loss: 0.5397\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.4930,\tval_loss: 0.5376\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.4903,\tval_loss: 0.5327\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.4794,\tval_loss: 0.5309\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.4813,\tval_loss: 0.5285\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.4735,\tval_loss: 0.5324\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.4807,\tval_loss: 0.5338\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.4769,\tval_loss: 0.5321\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.4577,\tval_loss: 0.5381\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.4652,\tval_loss: 0.5411\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.4701,\tval_loss: 0.5397\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.4718,\tval_loss: 0.5419\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.4575,\tval_loss: 0.5424\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.4623,\tval_loss: 0.5413\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.4586,\tval_loss: 0.5374\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.4518,\tval_loss: 0.5419\n",
            "35:\t[0s / 5s],\t\ttrain_loss: 0.4542,\tval_loss: 0.5459\n",
            "36:\t[0s / 5s],\t\ttrain_loss: 0.4450,\tval_loss: 0.5481\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.4391,\tval_loss: 0.5456\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.4395,\tval_loss: 0.5510\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.4420,\tval_loss: 0.5545\n",
            "40:\t[0s / 6s],\t\ttrain_loss: 0.4458,\tval_loss: 0.5553\n",
            "41:\t[0s / 6s],\t\ttrain_loss: 0.4335,\tval_loss: 0.5488\n",
            "42:\t[0s / 6s],\t\ttrain_loss: 0.4371,\tval_loss: 0.5475\n",
            "43:\t[0s / 6s],\t\ttrain_loss: 0.4406,\tval_loss: 0.5560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current best c-index: 0.6129542670477746\n",
            "Random search... itr: 10\n",
            "{'batch_size': 32, 'batch_norm': False, 'layers': 1, 'nodes': 100, 'alpha': 0.1, 'sigma': 0.5, 'lr': 0.001, 'dropout': 0.0, 'patience': 40}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1459,\tval_loss: 0.1220\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1249,\tval_loss: 0.1163\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1186,\tval_loss: 0.1142\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1151,\tval_loss: 0.1140\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1128,\tval_loss: 0.1135\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1111,\tval_loss: 0.1138\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1080,\tval_loss: 0.1139\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1084,\tval_loss: 0.1139\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1057,\tval_loss: 0.1140\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1061,\tval_loss: 0.1144\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1037,\tval_loss: 0.1146\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1045,\tval_loss: 0.1152\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1024,\tval_loss: 0.1157\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1017,\tval_loss: 0.1159\n",
            "14:\t[0s / 3s],\t\ttrain_loss: 0.1008,\tval_loss: 0.1157\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1004,\tval_loss: 0.1159\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.0984,\tval_loss: 0.1165\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.0988,\tval_loss: 0.1172\n",
            "18:\t[0s / 4s],\t\ttrain_loss: 0.0967,\tval_loss: 0.1164\n",
            "19:\t[0s / 4s],\t\ttrain_loss: 0.0964,\tval_loss: 0.1183\n",
            "20:\t[0s / 5s],\t\ttrain_loss: 0.0970,\tval_loss: 0.1172\n",
            "21:\t[0s / 5s],\t\ttrain_loss: 0.0960,\tval_loss: 0.1194\n",
            "22:\t[0s / 5s],\t\ttrain_loss: 0.0942,\tval_loss: 0.1189\n",
            "23:\t[0s / 6s],\t\ttrain_loss: 0.0945,\tval_loss: 0.1191\n",
            "24:\t[0s / 6s],\t\ttrain_loss: 0.0924,\tval_loss: 0.1188\n",
            "25:\t[0s / 6s],\t\ttrain_loss: 0.0909,\tval_loss: 0.1188\n",
            "26:\t[0s / 6s],\t\ttrain_loss: 0.0916,\tval_loss: 0.1198\n",
            "27:\t[0s / 6s],\t\ttrain_loss: 0.0904,\tval_loss: 0.1192\n",
            "28:\t[0s / 7s],\t\ttrain_loss: 0.0901,\tval_loss: 0.1207\n",
            "29:\t[0s / 7s],\t\ttrain_loss: 0.0900,\tval_loss: 0.1200\n",
            "30:\t[0s / 7s],\t\ttrain_loss: 0.0893,\tval_loss: 0.1203\n",
            "31:\t[0s / 7s],\t\ttrain_loss: 0.0884,\tval_loss: 0.1214\n",
            "32:\t[0s / 7s],\t\ttrain_loss: 0.0887,\tval_loss: 0.1210\n",
            "33:\t[0s / 8s],\t\ttrain_loss: 0.0866,\tval_loss: 0.1218\n",
            "34:\t[0s / 8s],\t\ttrain_loss: 0.0878,\tval_loss: 0.1221\n",
            "35:\t[0s / 8s],\t\ttrain_loss: 0.0852,\tval_loss: 0.1226\n",
            "36:\t[0s / 8s],\t\ttrain_loss: 0.0849,\tval_loss: 0.1231\n",
            "37:\t[0s / 8s],\t\ttrain_loss: 0.0845,\tval_loss: 0.1234\n",
            "38:\t[0s / 9s],\t\ttrain_loss: 0.0843,\tval_loss: 0.1232\n",
            "39:\t[0s / 9s],\t\ttrain_loss: 0.0833,\tval_loss: 0.1243\n",
            "40:\t[0s / 9s],\t\ttrain_loss: 0.0825,\tval_loss: 0.1252\n",
            "41:\t[0s / 9s],\t\ttrain_loss: 0.0819,\tval_loss: 0.1239\n",
            "42:\t[0s / 9s],\t\ttrain_loss: 0.0814,\tval_loss: 0.1240\n",
            "43:\t[0s / 10s],\t\ttrain_loss: 0.0811,\tval_loss: 0.1247\n",
            "44:\t[0s / 10s],\t\ttrain_loss: 0.0808,\tval_loss: 0.1257\n",
            "Current best c-index: 0.6129542670477746\n",
            "Random search... itr: 11\n",
            "{'batch_size': 256, 'batch_norm': True, 'layers': 5, 'nodes': 200, 'alpha': 0.1, 'sigma': 0.5, 'lr': 0.0001, 'dropout': 0.2, 'patience': 40}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1727,\tval_loss: 0.1571\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1706,\tval_loss: 0.1556\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1692,\tval_loss: 0.1545\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1711,\tval_loss: 0.1540\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1687,\tval_loss: 0.1533\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1658,\tval_loss: 0.1527\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1680,\tval_loss: 0.1519\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.1658,\tval_loss: 0.1511\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1637,\tval_loss: 0.1506\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1655,\tval_loss: 0.1499\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1661,\tval_loss: 0.1493\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1635,\tval_loss: 0.1486\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1632,\tval_loss: 0.1481\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1608,\tval_loss: 0.1472\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.1596,\tval_loss: 0.1466\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.1598,\tval_loss: 0.1458\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1448\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1577,\tval_loss: 0.1440\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1434\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1426\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.1543,\tval_loss: 0.1416\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.1540,\tval_loss: 0.1408\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1399\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1515,\tval_loss: 0.1390\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1510,\tval_loss: 0.1382\n",
            "25:\t[0s / 4s],\t\ttrain_loss: 0.1458,\tval_loss: 0.1374\n",
            "26:\t[0s / 4s],\t\ttrain_loss: 0.1499,\tval_loss: 0.1367\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.1472,\tval_loss: 0.1357\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.1462,\tval_loss: 0.1351\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.1450,\tval_loss: 0.1342\n",
            "30:\t[0s / 5s],\t\ttrain_loss: 0.1428,\tval_loss: 0.1335\n",
            "31:\t[0s / 5s],\t\ttrain_loss: 0.1427,\tval_loss: 0.1326\n",
            "32:\t[0s / 5s],\t\ttrain_loss: 0.1433,\tval_loss: 0.1320\n",
            "33:\t[0s / 5s],\t\ttrain_loss: 0.1417,\tval_loss: 0.1316\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.1436,\tval_loss: 0.1312\n",
            "35:\t[0s / 6s],\t\ttrain_loss: 0.1390,\tval_loss: 0.1302\n",
            "36:\t[0s / 6s],\t\ttrain_loss: 0.1373,\tval_loss: 0.1299\n",
            "37:\t[0s / 6s],\t\ttrain_loss: 0.1382,\tval_loss: 0.1295\n",
            "38:\t[0s / 6s],\t\ttrain_loss: 0.1373,\tval_loss: 0.1287\n",
            "39:\t[0s / 6s],\t\ttrain_loss: 0.1344,\tval_loss: 0.1281\n",
            "40:\t[0s / 7s],\t\ttrain_loss: 0.1344,\tval_loss: 0.1278\n",
            "41:\t[0s / 7s],\t\ttrain_loss: 0.1335,\tval_loss: 0.1276\n",
            "42:\t[0s / 7s],\t\ttrain_loss: 0.1323,\tval_loss: 0.1272\n",
            "43:\t[0s / 7s],\t\ttrain_loss: 0.1351,\tval_loss: 0.1270\n",
            "44:\t[0s / 8s],\t\ttrain_loss: 0.1331,\tval_loss: 0.1267\n",
            "45:\t[0s / 8s],\t\ttrain_loss: 0.1315,\tval_loss: 0.1267\n",
            "46:\t[0s / 8s],\t\ttrain_loss: 0.1279,\tval_loss: 0.1263\n",
            "47:\t[0s / 8s],\t\ttrain_loss: 0.1300,\tval_loss: 0.1260\n",
            "48:\t[0s / 8s],\t\ttrain_loss: 0.1274,\tval_loss: 0.1258\n",
            "49:\t[0s / 8s],\t\ttrain_loss: 0.1276,\tval_loss: 0.1255\n",
            "50:\t[0s / 8s],\t\ttrain_loss: 0.1267,\tval_loss: 0.1252\n",
            "51:\t[0s / 9s],\t\ttrain_loss: 0.1255,\tval_loss: 0.1249\n",
            "52:\t[0s / 9s],\t\ttrain_loss: 0.1244,\tval_loss: 0.1248\n",
            "53:\t[0s / 9s],\t\ttrain_loss: 0.1261,\tval_loss: 0.1248\n",
            "54:\t[0s / 9s],\t\ttrain_loss: 0.1269,\tval_loss: 0.1246\n",
            "55:\t[0s / 9s],\t\ttrain_loss: 0.1243,\tval_loss: 0.1244\n",
            "56:\t[0s / 9s],\t\ttrain_loss: 0.1259,\tval_loss: 0.1244\n",
            "57:\t[0s / 9s],\t\ttrain_loss: 0.1219,\tval_loss: 0.1241\n",
            "58:\t[0s / 10s],\t\ttrain_loss: 0.1232,\tval_loss: 0.1242\n",
            "59:\t[0s / 10s],\t\ttrain_loss: 0.1234,\tval_loss: 0.1239\n",
            "60:\t[0s / 10s],\t\ttrain_loss: 0.1239,\tval_loss: 0.1241\n",
            "61:\t[0s / 10s],\t\ttrain_loss: 0.1257,\tval_loss: 0.1239\n",
            "62:\t[0s / 10s],\t\ttrain_loss: 0.1223,\tval_loss: 0.1236\n",
            "63:\t[0s / 10s],\t\ttrain_loss: 0.1204,\tval_loss: 0.1237\n",
            "64:\t[0s / 10s],\t\ttrain_loss: 0.1210,\tval_loss: 0.1237\n",
            "65:\t[0s / 10s],\t\ttrain_loss: 0.1244,\tval_loss: 0.1236\n",
            "66:\t[0s / 11s],\t\ttrain_loss: 0.1218,\tval_loss: 0.1233\n",
            "67:\t[0s / 11s],\t\ttrain_loss: 0.1191,\tval_loss: 0.1234\n",
            "68:\t[0s / 11s],\t\ttrain_loss: 0.1190,\tval_loss: 0.1234\n",
            "69:\t[0s / 11s],\t\ttrain_loss: 0.1196,\tval_loss: 0.1232\n",
            "70:\t[0s / 11s],\t\ttrain_loss: 0.1189,\tval_loss: 0.1233\n",
            "71:\t[0s / 11s],\t\ttrain_loss: 0.1186,\tval_loss: 0.1233\n",
            "72:\t[0s / 11s],\t\ttrain_loss: 0.1175,\tval_loss: 0.1234\n",
            "73:\t[0s / 12s],\t\ttrain_loss: 0.1170,\tval_loss: 0.1232\n",
            "74:\t[0s / 12s],\t\ttrain_loss: 0.1170,\tval_loss: 0.1232\n",
            "75:\t[0s / 12s],\t\ttrain_loss: 0.1175,\tval_loss: 0.1231\n",
            "76:\t[0s / 12s],\t\ttrain_loss: 0.1164,\tval_loss: 0.1233\n",
            "77:\t[0s / 12s],\t\ttrain_loss: 0.1147,\tval_loss: 0.1232\n",
            "78:\t[0s / 12s],\t\ttrain_loss: 0.1186,\tval_loss: 0.1230\n",
            "79:\t[0s / 12s],\t\ttrain_loss: 0.1184,\tval_loss: 0.1229\n",
            "80:\t[0s / 13s],\t\ttrain_loss: 0.1162,\tval_loss: 0.1231\n",
            "81:\t[0s / 13s],\t\ttrain_loss: 0.1140,\tval_loss: 0.1230\n",
            "82:\t[0s / 13s],\t\ttrain_loss: 0.1163,\tval_loss: 0.1229\n",
            "83:\t[0s / 13s],\t\ttrain_loss: 0.1159,\tval_loss: 0.1229\n",
            "84:\t[0s / 13s],\t\ttrain_loss: 0.1155,\tval_loss: 0.1229\n",
            "85:\t[0s / 13s],\t\ttrain_loss: 0.1182,\tval_loss: 0.1228\n",
            "86:\t[0s / 13s],\t\ttrain_loss: 0.1144,\tval_loss: 0.1227\n",
            "87:\t[0s / 14s],\t\ttrain_loss: 0.1128,\tval_loss: 0.1228\n",
            "88:\t[0s / 14s],\t\ttrain_loss: 0.1134,\tval_loss: 0.1229\n",
            "89:\t[0s / 14s],\t\ttrain_loss: 0.1133,\tval_loss: 0.1229\n",
            "90:\t[0s / 14s],\t\ttrain_loss: 0.1120,\tval_loss: 0.1226\n",
            "91:\t[0s / 14s],\t\ttrain_loss: 0.1163,\tval_loss: 0.1227\n",
            "92:\t[0s / 14s],\t\ttrain_loss: 0.1121,\tval_loss: 0.1227\n",
            "93:\t[0s / 14s],\t\ttrain_loss: 0.1146,\tval_loss: 0.1227\n",
            "94:\t[0s / 15s],\t\ttrain_loss: 0.1135,\tval_loss: 0.1227\n",
            "95:\t[0s / 15s],\t\ttrain_loss: 0.1145,\tval_loss: 0.1226\n",
            "96:\t[0s / 15s],\t\ttrain_loss: 0.1140,\tval_loss: 0.1226\n",
            "97:\t[0s / 15s],\t\ttrain_loss: 0.1133,\tval_loss: 0.1227\n",
            "98:\t[0s / 15s],\t\ttrain_loss: 0.1129,\tval_loss: 0.1227\n",
            "99:\t[0s / 15s],\t\ttrain_loss: 0.1133,\tval_loss: 0.1223\n",
            "Current best c-index: 0.6129542670477746\n",
            "Random search... itr: 12\n",
            "{'batch_size': 32, 'batch_norm': False, 'layers': 5, 'nodes': 200, 'alpha': 0.5, 'sigma': 0.1, 'lr': 0.0001, 'dropout': 0.2, 'patience': 10}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.4470,\tval_loss: 0.3396\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.3777,\tval_loss: 0.3144\n",
            "2:\t[0s / 1s],\t\ttrain_loss: 0.3462,\tval_loss: 0.3058\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.3531,\tval_loss: 0.3012\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.3283,\tval_loss: 0.2999\n",
            "5:\t[0s / 2s],\t\ttrain_loss: 0.3351,\tval_loss: 0.2960\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.3286,\tval_loss: 0.2939\n",
            "7:\t[0s / 3s],\t\ttrain_loss: 0.3254,\tval_loss: 0.2943\n",
            "8:\t[0s / 4s],\t\ttrain_loss: 0.3228,\tval_loss: 0.2914\n",
            "9:\t[0s / 4s],\t\ttrain_loss: 0.3247,\tval_loss: 0.2899\n",
            "10:\t[0s / 5s],\t\ttrain_loss: 0.3210,\tval_loss: 0.2898\n",
            "11:\t[0s / 5s],\t\ttrain_loss: 0.3121,\tval_loss: 0.2896\n",
            "12:\t[0s / 6s],\t\ttrain_loss: 0.3113,\tval_loss: 0.2917\n",
            "13:\t[0s / 7s],\t\ttrain_loss: 0.3036,\tval_loss: 0.2902\n",
            "14:\t[0s / 7s],\t\ttrain_loss: 0.3032,\tval_loss: 0.2885\n",
            "15:\t[0s / 7s],\t\ttrain_loss: 0.3145,\tval_loss: 0.2889\n",
            "16:\t[0s / 8s],\t\ttrain_loss: 0.3053,\tval_loss: 0.2902\n",
            "17:\t[0s / 8s],\t\ttrain_loss: 0.3044,\tval_loss: 0.2893\n",
            "18:\t[0s / 9s],\t\ttrain_loss: 0.3040,\tval_loss: 0.2898\n",
            "19:\t[0s / 9s],\t\ttrain_loss: 0.3031,\tval_loss: 0.2942\n",
            "20:\t[0s / 9s],\t\ttrain_loss: 0.3008,\tval_loss: 0.2912\n",
            "21:\t[0s / 10s],\t\ttrain_loss: 0.3030,\tval_loss: 0.2905\n",
            "22:\t[0s / 10s],\t\ttrain_loss: 0.2973,\tval_loss: 0.2920\n",
            "23:\t[0s / 11s],\t\ttrain_loss: 0.2994,\tval_loss: 0.2912\n",
            "24:\t[0s / 11s],\t\ttrain_loss: 0.2942,\tval_loss: 0.2933\n",
            "Current best c-index: 0.6129542670477746\n",
            "Random search... itr: 13\n",
            "{'batch_size': 256, 'batch_norm': True, 'layers': 1, 'nodes': 200, 'alpha': 0.1, 'sigma': 1.0, 'lr': 0.0001, 'dropout': 0.4, 'patience': 20}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1704,\tval_loss: 0.1618\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1706,\tval_loss: 0.1594\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1687,\tval_loss: 0.1582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1669,\tval_loss: 0.1574\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1677,\tval_loss: 0.1567\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1661,\tval_loss: 0.1561\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1663,\tval_loss: 0.1555\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1649,\tval_loss: 0.1550\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1545\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.1645,\tval_loss: 0.1540\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1533\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.1641,\tval_loss: 0.1529\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.1615,\tval_loss: 0.1525\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1520\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1515\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.1602,\tval_loss: 0.1510\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 0.1595,\tval_loss: 0.1504\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 0.1583,\tval_loss: 0.1501\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.1588,\tval_loss: 0.1497\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1493\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.1577,\tval_loss: 0.1487\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1482\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.1567,\tval_loss: 0.1478\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.1554,\tval_loss: 0.1473\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1469\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1464\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.1545,\tval_loss: 0.1459\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.1529,\tval_loss: 0.1455\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.1525,\tval_loss: 0.1450\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 0.1517,\tval_loss: 0.1446\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 0.1505,\tval_loss: 0.1441\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 0.1498,\tval_loss: 0.1437\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 0.1494,\tval_loss: 0.1432\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 0.1493,\tval_loss: 0.1427\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 0.1488,\tval_loss: 0.1422\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.1476,\tval_loss: 0.1418\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.1472,\tval_loss: 0.1413\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.1471,\tval_loss: 0.1408\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.1464,\tval_loss: 0.1405\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.1448,\tval_loss: 0.1400\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 0.1443,\tval_loss: 0.1395\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 0.1433,\tval_loss: 0.1391\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 0.1433,\tval_loss: 0.1387\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 0.1422,\tval_loss: 0.1382\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 0.1446,\tval_loss: 0.1377\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 0.1422,\tval_loss: 0.1374\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 0.1403,\tval_loss: 0.1370\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 0.1420,\tval_loss: 0.1366\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 0.1399,\tval_loss: 0.1363\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 0.1403,\tval_loss: 0.1359\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 0.1395,\tval_loss: 0.1354\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 0.1390,\tval_loss: 0.1350\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 0.1380,\tval_loss: 0.1348\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 0.1382,\tval_loss: 0.1345\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 0.1364,\tval_loss: 0.1342\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 0.1375,\tval_loss: 0.1339\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 0.1363,\tval_loss: 0.1335\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 0.1356,\tval_loss: 0.1332\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 0.1353,\tval_loss: 0.1331\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 0.1342,\tval_loss: 0.1328\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 0.1342,\tval_loss: 0.1325\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 0.1347,\tval_loss: 0.1321\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 0.1348,\tval_loss: 0.1320\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 0.1329,\tval_loss: 0.1317\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 0.1335,\tval_loss: 0.1316\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 0.1340,\tval_loss: 0.1313\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 0.1324,\tval_loss: 0.1311\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 0.1321,\tval_loss: 0.1308\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 0.1321,\tval_loss: 0.1308\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 0.1329,\tval_loss: 0.1306\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 0.1320,\tval_loss: 0.1304\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 0.1326,\tval_loss: 0.1302\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 0.1305,\tval_loss: 0.1301\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 0.1301,\tval_loss: 0.1300\n",
            "74:\t[0s / 4s],\t\ttrain_loss: 0.1304,\tval_loss: 0.1298\n",
            "75:\t[0s / 4s],\t\ttrain_loss: 0.1295,\tval_loss: 0.1296\n",
            "76:\t[0s / 4s],\t\ttrain_loss: 0.1278,\tval_loss: 0.1295\n",
            "77:\t[0s / 4s],\t\ttrain_loss: 0.1281,\tval_loss: 0.1293\n",
            "78:\t[0s / 4s],\t\ttrain_loss: 0.1287,\tval_loss: 0.1292\n",
            "79:\t[0s / 4s],\t\ttrain_loss: 0.1286,\tval_loss: 0.1291\n",
            "80:\t[0s / 4s],\t\ttrain_loss: 0.1293,\tval_loss: 0.1291\n",
            "81:\t[0s / 4s],\t\ttrain_loss: 0.1298,\tval_loss: 0.1290\n",
            "82:\t[0s / 4s],\t\ttrain_loss: 0.1260,\tval_loss: 0.1289\n",
            "83:\t[0s / 4s],\t\ttrain_loss: 0.1265,\tval_loss: 0.1288\n",
            "84:\t[0s / 4s],\t\ttrain_loss: 0.1293,\tval_loss: 0.1286\n",
            "85:\t[0s / 4s],\t\ttrain_loss: 0.1256,\tval_loss: 0.1285\n",
            "86:\t[0s / 4s],\t\ttrain_loss: 0.1269,\tval_loss: 0.1285\n",
            "87:\t[0s / 5s],\t\ttrain_loss: 0.1259,\tval_loss: 0.1284\n",
            "88:\t[0s / 5s],\t\ttrain_loss: 0.1268,\tval_loss: 0.1282\n",
            "89:\t[0s / 5s],\t\ttrain_loss: 0.1265,\tval_loss: 0.1281\n",
            "90:\t[0s / 5s],\t\ttrain_loss: 0.1283,\tval_loss: 0.1279\n",
            "91:\t[0s / 5s],\t\ttrain_loss: 0.1258,\tval_loss: 0.1279\n",
            "92:\t[0s / 5s],\t\ttrain_loss: 0.1253,\tval_loss: 0.1279\n",
            "93:\t[0s / 5s],\t\ttrain_loss: 0.1249,\tval_loss: 0.1278\n",
            "94:\t[0s / 5s],\t\ttrain_loss: 0.1252,\tval_loss: 0.1278\n",
            "95:\t[0s / 5s],\t\ttrain_loss: 0.1256,\tval_loss: 0.1276\n",
            "96:\t[0s / 5s],\t\ttrain_loss: 0.1259,\tval_loss: 0.1276\n",
            "97:\t[0s / 5s],\t\ttrain_loss: 0.1250,\tval_loss: 0.1276\n",
            "98:\t[0s / 5s],\t\ttrain_loss: 0.1233,\tval_loss: 0.1275\n",
            "99:\t[0s / 5s],\t\ttrain_loss: 0.1241,\tval_loss: 0.1274\n",
            "Current best c-index: 0.6129542670477746\n",
            "Random search... itr: 14\n",
            "{'batch_size': 128, 'batch_norm': True, 'layers': 3, 'nodes': 100, 'alpha': 0.5, 'sigma': 0.1, 'lr': 0.0001, 'dropout': 0.2, 'patience': 40}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6015,\tval_loss: 0.5145\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.6155,\tval_loss: 0.5098\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5906,\tval_loss: 0.5055\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5731,\tval_loss: 0.5003\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5787,\tval_loss: 0.4976\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5665,\tval_loss: 0.4961\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.5668,\tval_loss: 0.4941\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.5574,\tval_loss: 0.4905\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.5526,\tval_loss: 0.4877\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.5528,\tval_loss: 0.4835\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.5425,\tval_loss: 0.4834\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 0.5355,\tval_loss: 0.4808\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 0.5453,\tval_loss: 0.4795\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.5263,\tval_loss: 0.4778\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.5246,\tval_loss: 0.4766\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.5314,\tval_loss: 0.4737\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.5216,\tval_loss: 0.4715\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.5209,\tval_loss: 0.4687\n",
            "18:\t[0s / 3s],\t\ttrain_loss: 0.5322,\tval_loss: 0.4672\n",
            "19:\t[0s / 3s],\t\ttrain_loss: 0.5117,\tval_loss: 0.4661\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.5217,\tval_loss: 0.4619\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.5126,\tval_loss: 0.4596\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.5045,\tval_loss: 0.4583\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.5104,\tval_loss: 0.4561\n",
            "24:\t[0s / 4s],\t\ttrain_loss: 0.5049,\tval_loss: 0.4532\n",
            "25:\t[0s / 4s],\t\ttrain_loss: 0.5011,\tval_loss: 0.4507\n",
            "26:\t[0s / 4s],\t\ttrain_loss: 0.4910,\tval_loss: 0.4505\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.4981,\tval_loss: 0.4465\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.4826,\tval_loss: 0.4435\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.4843,\tval_loss: 0.4410\n",
            "30:\t[0s / 5s],\t\ttrain_loss: 0.4870,\tval_loss: 0.4382\n",
            "31:\t[0s / 5s],\t\ttrain_loss: 0.4782,\tval_loss: 0.4373\n",
            "32:\t[0s / 5s],\t\ttrain_loss: 0.4773,\tval_loss: 0.4360\n",
            "33:\t[0s / 5s],\t\ttrain_loss: 0.4774,\tval_loss: 0.4328\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.4723,\tval_loss: 0.4304\n",
            "35:\t[0s / 5s],\t\ttrain_loss: 0.4685,\tval_loss: 0.4272\n",
            "36:\t[0s / 6s],\t\ttrain_loss: 0.4763,\tval_loss: 0.4257\n",
            "37:\t[0s / 6s],\t\ttrain_loss: 0.4666,\tval_loss: 0.4226\n",
            "38:\t[0s / 6s],\t\ttrain_loss: 0.4603,\tval_loss: 0.4216\n",
            "39:\t[0s / 6s],\t\ttrain_loss: 0.4591,\tval_loss: 0.4174\n",
            "40:\t[0s / 6s],\t\ttrain_loss: 0.4577,\tval_loss: 0.4146\n",
            "41:\t[0s / 7s],\t\ttrain_loss: 0.4525,\tval_loss: 0.4116\n",
            "42:\t[0s / 7s],\t\ttrain_loss: 0.4550,\tval_loss: 0.4094\n",
            "43:\t[0s / 7s],\t\ttrain_loss: 0.4442,\tval_loss: 0.4072\n",
            "44:\t[0s / 7s],\t\ttrain_loss: 0.4482,\tval_loss: 0.4033\n",
            "45:\t[0s / 7s],\t\ttrain_loss: 0.4416,\tval_loss: 0.4012\n",
            "46:\t[0s / 7s],\t\ttrain_loss: 0.4409,\tval_loss: 0.3996\n",
            "47:\t[0s / 8s],\t\ttrain_loss: 0.4314,\tval_loss: 0.3969\n",
            "48:\t[0s / 8s],\t\ttrain_loss: 0.4272,\tval_loss: 0.3950\n",
            "49:\t[0s / 8s],\t\ttrain_loss: 0.4238,\tval_loss: 0.3921\n",
            "50:\t[0s / 8s],\t\ttrain_loss: 0.4260,\tval_loss: 0.3891\n",
            "51:\t[0s / 8s],\t\ttrain_loss: 0.4198,\tval_loss: 0.3863\n",
            "52:\t[0s / 8s],\t\ttrain_loss: 0.4176,\tval_loss: 0.3836\n",
            "53:\t[0s / 9s],\t\ttrain_loss: 0.4148,\tval_loss: 0.3813\n",
            "54:\t[0s / 9s],\t\ttrain_loss: 0.4122,\tval_loss: 0.3794\n",
            "55:\t[0s / 9s],\t\ttrain_loss: 0.4125,\tval_loss: 0.3773\n",
            "56:\t[0s / 9s],\t\ttrain_loss: 0.4047,\tval_loss: 0.3749\n",
            "57:\t[0s / 9s],\t\ttrain_loss: 0.4130,\tval_loss: 0.3733\n",
            "58:\t[0s / 9s],\t\ttrain_loss: 0.3958,\tval_loss: 0.3697\n",
            "59:\t[0s / 9s],\t\ttrain_loss: 0.3999,\tval_loss: 0.3676\n",
            "60:\t[0s / 10s],\t\ttrain_loss: 0.3973,\tval_loss: 0.3644\n",
            "61:\t[0s / 10s],\t\ttrain_loss: 0.3985,\tval_loss: 0.3617\n",
            "62:\t[0s / 10s],\t\ttrain_loss: 0.3883,\tval_loss: 0.3616\n",
            "63:\t[0s / 10s],\t\ttrain_loss: 0.3839,\tval_loss: 0.3583\n",
            "64:\t[0s / 10s],\t\ttrain_loss: 0.3842,\tval_loss: 0.3553\n",
            "65:\t[0s / 10s],\t\ttrain_loss: 0.3924,\tval_loss: 0.3540\n",
            "66:\t[0s / 10s],\t\ttrain_loss: 0.3910,\tval_loss: 0.3523\n",
            "67:\t[0s / 10s],\t\ttrain_loss: 0.3842,\tval_loss: 0.3518\n",
            "68:\t[0s / 10s],\t\ttrain_loss: 0.3804,\tval_loss: 0.3508\n",
            "69:\t[0s / 11s],\t\ttrain_loss: 0.3824,\tval_loss: 0.3493\n",
            "70:\t[0s / 11s],\t\ttrain_loss: 0.3748,\tval_loss: 0.3472\n",
            "71:\t[0s / 11s],\t\ttrain_loss: 0.3765,\tval_loss: 0.3447\n",
            "72:\t[0s / 11s],\t\ttrain_loss: 0.3781,\tval_loss: 0.3427\n",
            "73:\t[0s / 11s],\t\ttrain_loss: 0.3676,\tval_loss: 0.3420\n",
            "74:\t[0s / 11s],\t\ttrain_loss: 0.3704,\tval_loss: 0.3409\n",
            "75:\t[0s / 11s],\t\ttrain_loss: 0.3618,\tval_loss: 0.3382\n",
            "76:\t[0s / 11s],\t\ttrain_loss: 0.3668,\tval_loss: 0.3375\n",
            "77:\t[0s / 11s],\t\ttrain_loss: 0.3685,\tval_loss: 0.3349\n",
            "78:\t[0s / 12s],\t\ttrain_loss: 0.3511,\tval_loss: 0.3344\n",
            "79:\t[0s / 12s],\t\ttrain_loss: 0.3661,\tval_loss: 0.3335\n",
            "80:\t[0s / 12s],\t\ttrain_loss: 0.3526,\tval_loss: 0.3333\n",
            "81:\t[0s / 12s],\t\ttrain_loss: 0.3553,\tval_loss: 0.3318\n",
            "82:\t[0s / 12s],\t\ttrain_loss: 0.3442,\tval_loss: 0.3303\n",
            "83:\t[0s / 12s],\t\ttrain_loss: 0.3527,\tval_loss: 0.3291\n",
            "84:\t[0s / 12s],\t\ttrain_loss: 0.3451,\tval_loss: 0.3278\n",
            "85:\t[0s / 12s],\t\ttrain_loss: 0.3488,\tval_loss: 0.3281\n",
            "86:\t[0s / 12s],\t\ttrain_loss: 0.3443,\tval_loss: 0.3266\n",
            "87:\t[0s / 13s],\t\ttrain_loss: 0.3418,\tval_loss: 0.3251\n",
            "88:\t[0s / 13s],\t\ttrain_loss: 0.3316,\tval_loss: 0.3248\n",
            "89:\t[0s / 13s],\t\ttrain_loss: 0.3351,\tval_loss: 0.3230\n",
            "90:\t[0s / 13s],\t\ttrain_loss: 0.3414,\tval_loss: 0.3227\n",
            "91:\t[0s / 13s],\t\ttrain_loss: 0.3350,\tval_loss: 0.3229\n",
            "92:\t[0s / 13s],\t\ttrain_loss: 0.3371,\tval_loss: 0.3216\n",
            "93:\t[0s / 13s],\t\ttrain_loss: 0.3336,\tval_loss: 0.3213\n",
            "94:\t[0s / 13s],\t\ttrain_loss: 0.3317,\tval_loss: 0.3198\n",
            "95:\t[0s / 13s],\t\ttrain_loss: 0.3282,\tval_loss: 0.3197\n",
            "96:\t[0s / 14s],\t\ttrain_loss: 0.3285,\tval_loss: 0.3194\n",
            "97:\t[0s / 14s],\t\ttrain_loss: 0.3244,\tval_loss: 0.3189\n",
            "98:\t[0s / 14s],\t\ttrain_loss: 0.3289,\tval_loss: 0.3182\n",
            "99:\t[0s / 14s],\t\ttrain_loss: 0.3343,\tval_loss: 0.3183\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 15\n",
            "{'batch_size': 256, 'batch_norm': False, 'layers': 1, 'nodes': 300, 'alpha': 1.0, 'sigma': 0.5, 'lr': 0.001, 'dropout': 0.4, 'patience': 40}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.8209,\tval_loss: 0.5822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.6190,\tval_loss: 0.5502\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5919,\tval_loss: 0.5397\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5634,\tval_loss: 0.5230\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5381,\tval_loss: 0.5153\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5249,\tval_loss: 0.5098\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.5068,\tval_loss: 0.5068\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.5013,\tval_loss: 0.5072\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.4929,\tval_loss: 0.5058\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.4858,\tval_loss: 0.5043\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.4767,\tval_loss: 0.5040\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.4778,\tval_loss: 0.5057\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.4641,\tval_loss: 0.5057\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.4701,\tval_loss: 0.5048\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.4684,\tval_loss: 0.5053\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.4582,\tval_loss: 0.5023\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.4560,\tval_loss: 0.5030\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.4545,\tval_loss: 0.5050\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.4492,\tval_loss: 0.5048\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.4541,\tval_loss: 0.5027\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.4486,\tval_loss: 0.5017\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.4518,\tval_loss: 0.5007\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.4507,\tval_loss: 0.4999\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.4324,\tval_loss: 0.4999\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.4319,\tval_loss: 0.5026\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.4384,\tval_loss: 0.5053\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.4368,\tval_loss: 0.5021\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.4270,\tval_loss: 0.5023\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.4277,\tval_loss: 0.5033\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.4303,\tval_loss: 0.5042\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.4210,\tval_loss: 0.5032\n",
            "31:\t[0s / 5s],\t\ttrain_loss: 0.4216,\tval_loss: 0.5036\n",
            "32:\t[0s / 5s],\t\ttrain_loss: 0.4273,\tval_loss: 0.5017\n",
            "33:\t[0s / 5s],\t\ttrain_loss: 0.4241,\tval_loss: 0.5012\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.4134,\tval_loss: 0.5040\n",
            "35:\t[0s / 6s],\t\ttrain_loss: 0.4161,\tval_loss: 0.5023\n",
            "36:\t[0s / 6s],\t\ttrain_loss: 0.4166,\tval_loss: 0.5049\n",
            "37:\t[0s / 7s],\t\ttrain_loss: 0.4114,\tval_loss: 0.5046\n",
            "38:\t[0s / 7s],\t\ttrain_loss: 0.4168,\tval_loss: 0.5034\n",
            "39:\t[0s / 7s],\t\ttrain_loss: 0.4066,\tval_loss: 0.5031\n",
            "40:\t[0s / 7s],\t\ttrain_loss: 0.4122,\tval_loss: 0.5030\n",
            "41:\t[0s / 8s],\t\ttrain_loss: 0.4020,\tval_loss: 0.5055\n",
            "42:\t[0s / 8s],\t\ttrain_loss: 0.4099,\tval_loss: 0.5056\n",
            "43:\t[0s / 8s],\t\ttrain_loss: 0.4052,\tval_loss: 0.5045\n",
            "44:\t[0s / 8s],\t\ttrain_loss: 0.4104,\tval_loss: 0.5071\n",
            "45:\t[0s / 9s],\t\ttrain_loss: 0.4070,\tval_loss: 0.5071\n",
            "46:\t[0s / 9s],\t\ttrain_loss: 0.3949,\tval_loss: 0.5061\n",
            "47:\t[0s / 9s],\t\ttrain_loss: 0.3886,\tval_loss: 0.5091\n",
            "48:\t[0s / 9s],\t\ttrain_loss: 0.4041,\tval_loss: 0.5068\n",
            "49:\t[0s / 9s],\t\ttrain_loss: 0.3933,\tval_loss: 0.5069\n",
            "50:\t[0s / 9s],\t\ttrain_loss: 0.3916,\tval_loss: 0.5066\n",
            "51:\t[0s / 9s],\t\ttrain_loss: 0.3851,\tval_loss: 0.5083\n",
            "52:\t[0s / 10s],\t\ttrain_loss: 0.3955,\tval_loss: 0.5114\n",
            "53:\t[0s / 10s],\t\ttrain_loss: 0.3924,\tval_loss: 0.5094\n",
            "54:\t[0s / 10s],\t\ttrain_loss: 0.3924,\tval_loss: 0.5090\n",
            "55:\t[0s / 10s],\t\ttrain_loss: 0.3776,\tval_loss: 0.5091\n",
            "56:\t[0s / 10s],\t\ttrain_loss: 0.3818,\tval_loss: 0.5105\n",
            "57:\t[0s / 11s],\t\ttrain_loss: 0.3896,\tval_loss: 0.5096\n",
            "58:\t[0s / 11s],\t\ttrain_loss: 0.3807,\tval_loss: 0.5081\n",
            "59:\t[0s / 11s],\t\ttrain_loss: 0.3847,\tval_loss: 0.5119\n",
            "60:\t[0s / 12s],\t\ttrain_loss: 0.3881,\tval_loss: 0.5124\n",
            "61:\t[0s / 12s],\t\ttrain_loss: 0.3773,\tval_loss: 0.5129\n",
            "62:\t[0s / 12s],\t\ttrain_loss: 0.3845,\tval_loss: 0.5142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 16\n",
            "{'batch_size': 256, 'batch_norm': True, 'layers': 1, 'nodes': 50, 'alpha': 0.5, 'sigma': 0.5, 'lr': 0.001, 'dropout': 0.2, 'patience': 30}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.5370,\tval_loss: 0.4935\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5210,\tval_loss: 0.4800\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5028,\tval_loss: 0.4670\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.4872,\tval_loss: 0.4547\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.4725,\tval_loss: 0.4424\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4632,\tval_loss: 0.4314\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.4507,\tval_loss: 0.4205\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.4422,\tval_loss: 0.4102\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.4310,\tval_loss: 0.4002\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.4194,\tval_loss: 0.3907\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.4068,\tval_loss: 0.3817\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.3974,\tval_loss: 0.3736\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.3926,\tval_loss: 0.3664\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.3838,\tval_loss: 0.3595\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.3736,\tval_loss: 0.3528\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.3668,\tval_loss: 0.3469\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.3591,\tval_loss: 0.3412\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.3532,\tval_loss: 0.3361\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.3461,\tval_loss: 0.3313\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.3444,\tval_loss: 0.3272\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.3386,\tval_loss: 0.3231\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.3379,\tval_loss: 0.3201\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.3287,\tval_loss: 0.3167\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.3233,\tval_loss: 0.3138\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.3205,\tval_loss: 0.3117\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.3199,\tval_loss: 0.3095\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.3143,\tval_loss: 0.3071\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.3072,\tval_loss: 0.3053\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.3075,\tval_loss: 0.3036\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.3060,\tval_loss: 0.3024\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.3017,\tval_loss: 0.3011\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.2985,\tval_loss: 0.2994\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.3000,\tval_loss: 0.2975\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.2993,\tval_loss: 0.2962\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.2932,\tval_loss: 0.2949\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.2903,\tval_loss: 0.2936\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.2859,\tval_loss: 0.2925\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.2847,\tval_loss: 0.2915\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.2890,\tval_loss: 0.2905\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.2873,\tval_loss: 0.2898\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.2897,\tval_loss: 0.2889\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.2851,\tval_loss: 0.2884\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.2800,\tval_loss: 0.2877\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.2733,\tval_loss: 0.2875\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.2777,\tval_loss: 0.2871\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.2776,\tval_loss: 0.2863\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.2758,\tval_loss: 0.2859\n",
            "47:\t[0s / 4s],\t\ttrain_loss: 0.2723,\tval_loss: 0.2852\n",
            "48:\t[0s / 4s],\t\ttrain_loss: 0.2731,\tval_loss: 0.2853\n",
            "49:\t[0s / 4s],\t\ttrain_loss: 0.2729,\tval_loss: 0.2849\n",
            "50:\t[0s / 4s],\t\ttrain_loss: 0.2709,\tval_loss: 0.2848\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.2683,\tval_loss: 0.2848\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.2677,\tval_loss: 0.2849\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.2686,\tval_loss: 0.2848\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.2680,\tval_loss: 0.2842\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.2685,\tval_loss: 0.2842\n",
            "56:\t[0s / 5s],\t\ttrain_loss: 0.2662,\tval_loss: 0.2842\n",
            "57:\t[0s / 5s],\t\ttrain_loss: 0.2642,\tval_loss: 0.2840\n",
            "58:\t[0s / 5s],\t\ttrain_loss: 0.2653,\tval_loss: 0.2838\n",
            "59:\t[0s / 5s],\t\ttrain_loss: 0.2623,\tval_loss: 0.2837\n",
            "60:\t[0s / 5s],\t\ttrain_loss: 0.2654,\tval_loss: 0.2833\n",
            "61:\t[0s / 5s],\t\ttrain_loss: 0.2627,\tval_loss: 0.2833\n",
            "62:\t[0s / 5s],\t\ttrain_loss: 0.2619,\tval_loss: 0.2826\n",
            "63:\t[0s / 5s],\t\ttrain_loss: 0.2611,\tval_loss: 0.2825\n",
            "64:\t[0s / 5s],\t\ttrain_loss: 0.2594,\tval_loss: 0.2827\n",
            "65:\t[0s / 5s],\t\ttrain_loss: 0.2577,\tval_loss: 0.2825\n",
            "66:\t[0s / 5s],\t\ttrain_loss: 0.2582,\tval_loss: 0.2826\n",
            "67:\t[0s / 5s],\t\ttrain_loss: 0.2579,\tval_loss: 0.2826\n",
            "68:\t[0s / 5s],\t\ttrain_loss: 0.2554,\tval_loss: 0.2824\n",
            "69:\t[0s / 6s],\t\ttrain_loss: 0.2636,\tval_loss: 0.2822\n",
            "70:\t[0s / 6s],\t\ttrain_loss: 0.2594,\tval_loss: 0.2821\n",
            "71:\t[0s / 6s],\t\ttrain_loss: 0.2575,\tval_loss: 0.2821\n",
            "72:\t[0s / 6s],\t\ttrain_loss: 0.2533,\tval_loss: 0.2822\n",
            "73:\t[0s / 6s],\t\ttrain_loss: 0.2503,\tval_loss: 0.2822\n",
            "74:\t[0s / 6s],\t\ttrain_loss: 0.2543,\tval_loss: 0.2823\n",
            "75:\t[0s / 6s],\t\ttrain_loss: 0.2495,\tval_loss: 0.2824\n",
            "76:\t[0s / 6s],\t\ttrain_loss: 0.2496,\tval_loss: 0.2822\n",
            "77:\t[0s / 6s],\t\ttrain_loss: 0.2541,\tval_loss: 0.2822\n",
            "78:\t[0s / 6s],\t\ttrain_loss: 0.2497,\tval_loss: 0.2823\n",
            "79:\t[0s / 6s],\t\ttrain_loss: 0.2548,\tval_loss: 0.2825\n",
            "80:\t[0s / 6s],\t\ttrain_loss: 0.2503,\tval_loss: 0.2824\n",
            "81:\t[0s / 6s],\t\ttrain_loss: 0.2515,\tval_loss: 0.2821\n",
            "82:\t[0s / 6s],\t\ttrain_loss: 0.2502,\tval_loss: 0.2822\n",
            "83:\t[0s / 6s],\t\ttrain_loss: 0.2469,\tval_loss: 0.2825\n",
            "84:\t[0s / 6s],\t\ttrain_loss: 0.2454,\tval_loss: 0.2827\n",
            "85:\t[0s / 7s],\t\ttrain_loss: 0.2480,\tval_loss: 0.2828\n",
            "86:\t[0s / 7s],\t\ttrain_loss: 0.2503,\tval_loss: 0.2833\n",
            "87:\t[0s / 7s],\t\ttrain_loss: 0.2522,\tval_loss: 0.2838\n",
            "88:\t[0s / 7s],\t\ttrain_loss: 0.2468,\tval_loss: 0.2838\n",
            "89:\t[0s / 7s],\t\ttrain_loss: 0.2456,\tval_loss: 0.2838\n",
            "90:\t[0s / 7s],\t\ttrain_loss: 0.2431,\tval_loss: 0.2840\n",
            "91:\t[0s / 7s],\t\ttrain_loss: 0.2463,\tval_loss: 0.2840\n",
            "92:\t[0s / 7s],\t\ttrain_loss: 0.2462,\tval_loss: 0.2838\n",
            "93:\t[0s / 7s],\t\ttrain_loss: 0.2410,\tval_loss: 0.2840\n",
            "94:\t[0s / 7s],\t\ttrain_loss: 0.2465,\tval_loss: 0.2844\n",
            "95:\t[0s / 7s],\t\ttrain_loss: 0.2451,\tval_loss: 0.2844\n",
            "96:\t[0s / 7s],\t\ttrain_loss: 0.2434,\tval_loss: 0.2845\n",
            "97:\t[0s / 7s],\t\ttrain_loss: 0.2432,\tval_loss: 0.2851\n",
            "98:\t[0s / 7s],\t\ttrain_loss: 0.2429,\tval_loss: 0.2855\n",
            "99:\t[0s / 8s],\t\ttrain_loss: 0.2385,\tval_loss: 0.2858\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 17\n",
            "{'batch_size': 32, 'batch_norm': True, 'layers': 3, 'nodes': 300, 'alpha': 0.5, 'sigma': 0.5, 'lr': 0.0001, 'dropout': 0.1, 'patience': 20}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.5239,\tval_loss: 0.4737\n",
            "1:\t[0s / 1s],\t\ttrain_loss: 0.4912,\tval_loss: 0.4366\n",
            "2:\t[0s / 1s],\t\ttrain_loss: 0.4504,\tval_loss: 0.3960\n",
            "3:\t[0s / 2s],\t\ttrain_loss: 0.4079,\tval_loss: 0.3654\n",
            "4:\t[0s / 3s],\t\ttrain_loss: 0.3706,\tval_loss: 0.3451\n",
            "5:\t[0s / 3s],\t\ttrain_loss: 0.3458,\tval_loss: 0.3321\n",
            "6:\t[0s / 4s],\t\ttrain_loss: 0.3341,\tval_loss: 0.3208\n",
            "7:\t[0s / 4s],\t\ttrain_loss: 0.3219,\tval_loss: 0.3151\n",
            "8:\t[0s / 5s],\t\ttrain_loss: 0.3178,\tval_loss: 0.3129\n",
            "9:\t[0s / 5s],\t\ttrain_loss: 0.3058,\tval_loss: 0.3103\n",
            "10:\t[0s / 6s],\t\ttrain_loss: 0.3047,\tval_loss: 0.3111\n",
            "11:\t[0s / 6s],\t\ttrain_loss: 0.2894,\tval_loss: 0.3091\n",
            "12:\t[0s / 6s],\t\ttrain_loss: 0.2859,\tval_loss: 0.3083\n",
            "13:\t[0s / 7s],\t\ttrain_loss: 0.2817,\tval_loss: 0.3064\n",
            "14:\t[0s / 7s],\t\ttrain_loss: 0.2756,\tval_loss: 0.3063\n",
            "15:\t[0s / 8s],\t\ttrain_loss: 0.2745,\tval_loss: 0.3073\n",
            "16:\t[0s / 8s],\t\ttrain_loss: 0.2725,\tval_loss: 0.3065\n",
            "17:\t[0s / 9s],\t\ttrain_loss: 0.2620,\tval_loss: 0.3062\n",
            "18:\t[0s / 9s],\t\ttrain_loss: 0.2633,\tval_loss: 0.3073\n",
            "19:\t[0s / 10s],\t\ttrain_loss: 0.2536,\tval_loss: 0.3091\n",
            "20:\t[0s / 10s],\t\ttrain_loss: 0.2504,\tval_loss: 0.3060\n",
            "21:\t[0s / 11s],\t\ttrain_loss: 0.2463,\tval_loss: 0.3059\n",
            "22:\t[0s / 11s],\t\ttrain_loss: 0.2437,\tval_loss: 0.3076\n",
            "23:\t[0s / 11s],\t\ttrain_loss: 0.2493,\tval_loss: 0.3065\n",
            "24:\t[0s / 12s],\t\ttrain_loss: 0.2371,\tval_loss: 0.3053\n",
            "25:\t[0s / 12s],\t\ttrain_loss: 0.2384,\tval_loss: 0.3105\n",
            "26:\t[0s / 13s],\t\ttrain_loss: 0.2350,\tval_loss: 0.3073\n",
            "27:\t[0s / 14s],\t\ttrain_loss: 0.2301,\tval_loss: 0.3055\n",
            "28:\t[0s / 14s],\t\ttrain_loss: 0.2243,\tval_loss: 0.3047\n",
            "29:\t[0s / 15s],\t\ttrain_loss: 0.2265,\tval_loss: 0.3086\n",
            "30:\t[0s / 16s],\t\ttrain_loss: 0.2202,\tval_loss: 0.3096\n",
            "31:\t[0s / 16s],\t\ttrain_loss: 0.2234,\tval_loss: 0.3135\n",
            "32:\t[0s / 17s],\t\ttrain_loss: 0.2140,\tval_loss: 0.3111\n",
            "33:\t[0s / 18s],\t\ttrain_loss: 0.2156,\tval_loss: 0.3116\n",
            "34:\t[0s / 18s],\t\ttrain_loss: 0.2079,\tval_loss: 0.3115\n",
            "35:\t[0s / 18s],\t\ttrain_loss: 0.2143,\tval_loss: 0.3135\n",
            "36:\t[0s / 19s],\t\ttrain_loss: 0.2057,\tval_loss: 0.3105\n",
            "37:\t[0s / 19s],\t\ttrain_loss: 0.2077,\tval_loss: 0.3131\n",
            "38:\t[0s / 20s],\t\ttrain_loss: 0.2025,\tval_loss: 0.3121\n",
            "39:\t[0s / 20s],\t\ttrain_loss: 0.1991,\tval_loss: 0.3161\n",
            "40:\t[0s / 21s],\t\ttrain_loss: 0.2092,\tval_loss: 0.3136\n",
            "41:\t[0s / 21s],\t\ttrain_loss: 0.1939,\tval_loss: 0.3154\n",
            "42:\t[0s / 22s],\t\ttrain_loss: 0.1882,\tval_loss: 0.3165\n",
            "43:\t[0s / 22s],\t\ttrain_loss: 0.1928,\tval_loss: 0.3205\n",
            "44:\t[0s / 23s],\t\ttrain_loss: 0.1934,\tval_loss: 0.3210\n",
            "45:\t[0s / 23s],\t\ttrain_loss: 0.1888,\tval_loss: 0.3197\n",
            "46:\t[0s / 23s],\t\ttrain_loss: 0.1871,\tval_loss: 0.3204\n",
            "47:\t[0s / 24s],\t\ttrain_loss: 0.1815,\tval_loss: 0.3201\n",
            "48:\t[0s / 24s],\t\ttrain_loss: 0.1875,\tval_loss: 0.3215\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 18\n",
            "{'batch_size': 256, 'batch_norm': False, 'layers': 5, 'nodes': 300, 'alpha': 0.5, 'sigma': 0.1, 'lr': 0.0001, 'dropout': 0.1, 'patience': 30}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.5478,\tval_loss: 0.4133\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.4349,\tval_loss: 0.3509\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.3794,\tval_loss: 0.3158\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.3508,\tval_loss: 0.3025\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.3415,\tval_loss: 0.2959\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.3293,\tval_loss: 0.2905\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.3259,\tval_loss: 0.2876\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.3264,\tval_loss: 0.2862\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.3163,\tval_loss: 0.2849\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.3114,\tval_loss: 0.2840\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.3036,\tval_loss: 0.2830\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 0.3095,\tval_loss: 0.2826\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 0.3013,\tval_loss: 0.2827\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.2989,\tval_loss: 0.2833\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.2960,\tval_loss: 0.2830\n",
            "15:\t[0s / 3s],\t\ttrain_loss: 0.2926,\tval_loss: 0.2833\n",
            "16:\t[0s / 3s],\t\ttrain_loss: 0.2819,\tval_loss: 0.2841\n",
            "17:\t[0s / 3s],\t\ttrain_loss: 0.2844,\tval_loss: 0.2836\n",
            "18:\t[0s / 3s],\t\ttrain_loss: 0.2874,\tval_loss: 0.2831\n",
            "19:\t[0s / 4s],\t\ttrain_loss: 0.2827,\tval_loss: 0.2829\n",
            "20:\t[0s / 4s],\t\ttrain_loss: 0.2754,\tval_loss: 0.2834\n",
            "21:\t[0s / 4s],\t\ttrain_loss: 0.2855,\tval_loss: 0.2839\n",
            "22:\t[0s / 4s],\t\ttrain_loss: 0.2807,\tval_loss: 0.2844\n",
            "23:\t[0s / 5s],\t\ttrain_loss: 0.2765,\tval_loss: 0.2836\n",
            "24:\t[0s / 5s],\t\ttrain_loss: 0.2766,\tval_loss: 0.2834\n",
            "25:\t[0s / 5s],\t\ttrain_loss: 0.2745,\tval_loss: 0.2841\n",
            "26:\t[0s / 6s],\t\ttrain_loss: 0.2749,\tval_loss: 0.2841\n",
            "27:\t[0s / 6s],\t\ttrain_loss: 0.2708,\tval_loss: 0.2843\n",
            "28:\t[0s / 6s],\t\ttrain_loss: 0.2733,\tval_loss: 0.2838\n",
            "29:\t[0s / 6s],\t\ttrain_loss: 0.2780,\tval_loss: 0.2835\n",
            "30:\t[0s / 7s],\t\ttrain_loss: 0.2725,\tval_loss: 0.2840\n",
            "31:\t[0s / 7s],\t\ttrain_loss: 0.2712,\tval_loss: 0.2844\n",
            "32:\t[0s / 7s],\t\ttrain_loss: 0.2711,\tval_loss: 0.2846\n",
            "33:\t[0s / 7s],\t\ttrain_loss: 0.2599,\tval_loss: 0.2849\n",
            "34:\t[0s / 8s],\t\ttrain_loss: 0.2620,\tval_loss: 0.2861\n",
            "35:\t[0s / 8s],\t\ttrain_loss: 0.2626,\tval_loss: 0.2868\n",
            "36:\t[0s / 8s],\t\ttrain_loss: 0.2631,\tval_loss: 0.2879\n",
            "37:\t[0s / 8s],\t\ttrain_loss: 0.2595,\tval_loss: 0.2896\n",
            "38:\t[0s / 8s],\t\ttrain_loss: 0.2579,\tval_loss: 0.2893\n",
            "39:\t[0s / 9s],\t\ttrain_loss: 0.2689,\tval_loss: 0.2860\n",
            "40:\t[0s / 9s],\t\ttrain_loss: 0.2522,\tval_loss: 0.2861\n",
            "41:\t[0s / 9s],\t\ttrain_loss: 0.2575,\tval_loss: 0.2869\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 19\n",
            "{'batch_size': 64, 'batch_norm': False, 'layers': 3, 'nodes': 300, 'alpha': 1.0, 'sigma': 0.5, 'lr': 0.001, 'dropout': 0.4, 'patience': 40}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6651,\tval_loss: 0.5339\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5714,\tval_loss: 0.5487\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5692,\tval_loss: 0.5383\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5243,\tval_loss: 0.5097\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.5285,\tval_loss: 0.5368\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.4937,\tval_loss: 0.5288\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.5070,\tval_loss: 0.5184\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.5043,\tval_loss: 0.5179\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.4823,\tval_loss: 0.5211\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.4913,\tval_loss: 0.5122\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.4942,\tval_loss: 0.5180\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 0.4785,\tval_loss: 0.5394\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.4771,\tval_loss: 0.5212\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.4874,\tval_loss: 0.5221\n",
            "14:\t[0s / 3s],\t\ttrain_loss: 0.4726,\tval_loss: 0.5215\n",
            "15:\t[0s / 3s],\t\ttrain_loss: 0.4542,\tval_loss: 0.5247\n",
            "16:\t[0s / 3s],\t\ttrain_loss: 0.4587,\tval_loss: 0.5074\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.4550,\tval_loss: 0.5261\n",
            "18:\t[0s / 4s],\t\ttrain_loss: 0.4364,\tval_loss: 0.5176\n",
            "19:\t[0s / 4s],\t\ttrain_loss: 0.4491,\tval_loss: 0.5335\n",
            "20:\t[0s / 4s],\t\ttrain_loss: 0.4385,\tval_loss: 0.5489\n",
            "21:\t[0s / 5s],\t\ttrain_loss: 0.4563,\tval_loss: 0.5313\n",
            "22:\t[0s / 5s],\t\ttrain_loss: 0.4384,\tval_loss: 0.5261\n",
            "23:\t[0s / 5s],\t\ttrain_loss: 0.4279,\tval_loss: 0.5296\n",
            "24:\t[0s / 5s],\t\ttrain_loss: 0.4335,\tval_loss: 0.5223\n",
            "25:\t[0s / 6s],\t\ttrain_loss: 0.4345,\tval_loss: 0.5279\n",
            "26:\t[0s / 6s],\t\ttrain_loss: 0.4321,\tval_loss: 0.5322\n",
            "27:\t[0s / 6s],\t\ttrain_loss: 0.4153,\tval_loss: 0.5297\n",
            "28:\t[0s / 6s],\t\ttrain_loss: 0.4225,\tval_loss: 0.5393\n",
            "29:\t[0s / 6s],\t\ttrain_loss: 0.4211,\tval_loss: 0.5400\n",
            "30:\t[0s / 7s],\t\ttrain_loss: 0.4078,\tval_loss: 0.5260\n",
            "31:\t[0s / 7s],\t\ttrain_loss: 0.4051,\tval_loss: 0.5517\n",
            "32:\t[0s / 7s],\t\ttrain_loss: 0.4190,\tval_loss: 0.5352\n",
            "33:\t[0s / 7s],\t\ttrain_loss: 0.4112,\tval_loss: 0.5423\n",
            "34:\t[0s / 8s],\t\ttrain_loss: 0.4051,\tval_loss: 0.5486\n",
            "35:\t[0s / 8s],\t\ttrain_loss: 0.3980,\tval_loss: 0.5433\n",
            "36:\t[0s / 8s],\t\ttrain_loss: 0.4070,\tval_loss: 0.5406\n",
            "37:\t[0s / 8s],\t\ttrain_loss: 0.3859,\tval_loss: 0.5494\n",
            "38:\t[0s / 9s],\t\ttrain_loss: 0.3810,\tval_loss: 0.5522\n",
            "39:\t[0s / 9s],\t\ttrain_loss: 0.3929,\tval_loss: 0.5596\n",
            "40:\t[0s / 9s],\t\ttrain_loss: 0.3651,\tval_loss: 0.5618\n",
            "41:\t[0s / 10s],\t\ttrain_loss: 0.4122,\tval_loss: 0.5741\n",
            "42:\t[0s / 10s],\t\ttrain_loss: 0.3731,\tval_loss: 0.5658\n",
            "43:\t[0s / 10s],\t\ttrain_loss: 0.3652,\tval_loss: 0.5736\n",
            "44:\t[0s / 11s],\t\ttrain_loss: 0.3599,\tval_loss: 0.5685\n",
            "45:\t[0s / 11s],\t\ttrain_loss: 0.3675,\tval_loss: 0.5768\n",
            "46:\t[0s / 11s],\t\ttrain_loss: 0.3697,\tval_loss: 0.5654\n",
            "47:\t[0s / 12s],\t\ttrain_loss: 0.3478,\tval_loss: 0.5741\n",
            "48:\t[0s / 12s],\t\ttrain_loss: 0.3629,\tval_loss: 0.5898\n",
            "49:\t[0s / 12s],\t\ttrain_loss: 0.3590,\tval_loss: 0.5853\n",
            "50:\t[0s / 13s],\t\ttrain_loss: 0.3500,\tval_loss: 0.5788\n",
            "51:\t[0s / 13s],\t\ttrain_loss: 0.3509,\tval_loss: 0.5808\n",
            "52:\t[0s / 13s],\t\ttrain_loss: 0.3521,\tval_loss: 0.5900\n",
            "53:\t[0s / 14s],\t\ttrain_loss: 0.3595,\tval_loss: 0.5875\n",
            "54:\t[0s / 14s],\t\ttrain_loss: 0.3279,\tval_loss: 0.5823\n",
            "55:\t[0s / 14s],\t\ttrain_loss: 0.3318,\tval_loss: 0.5856\n",
            "56:\t[0s / 14s],\t\ttrain_loss: 0.3253,\tval_loss: 0.6011\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 20\n",
            "{'batch_size': 256, 'batch_norm': True, 'layers': 3, 'nodes': 300, 'alpha': 1.0, 'sigma': 0.1, 'lr': 0.001, 'dropout': 0.2, 'patience': 40}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.9946,\tval_loss: 0.9444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.8008,\tval_loss: 0.7428\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.6578,\tval_loss: 0.6558\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5611,\tval_loss: 0.6420\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5256,\tval_loss: 0.6160\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4956,\tval_loss: 0.5995\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.4867,\tval_loss: 0.5923\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.4570,\tval_loss: 0.5872\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.4535,\tval_loss: 0.5785\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.4398,\tval_loss: 0.5787\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.4253,\tval_loss: 0.5775\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.4056,\tval_loss: 0.5775\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.3947,\tval_loss: 0.5866\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.3987,\tval_loss: 0.5888\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.3777,\tval_loss: 0.5906\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.3681,\tval_loss: 0.5902\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.3626,\tval_loss: 0.5990\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.3493,\tval_loss: 0.6155\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.3397,\tval_loss: 0.6211\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.3234,\tval_loss: 0.6156\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.3332,\tval_loss: 0.6254\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.3181,\tval_loss: 0.6285\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.3242,\tval_loss: 0.6319\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.3155,\tval_loss: 0.6448\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.2970,\tval_loss: 0.6512\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.3013,\tval_loss: 0.6534\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.2910,\tval_loss: 0.6657\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.2883,\tval_loss: 0.6820\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.2768,\tval_loss: 0.6764\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.2689,\tval_loss: 0.6761\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.2733,\tval_loss: 0.6879\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.2847,\tval_loss: 0.6949\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.2667,\tval_loss: 0.6951\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.2605,\tval_loss: 0.6940\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.2649,\tval_loss: 0.6932\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.2616,\tval_loss: 0.7027\n",
            "36:\t[0s / 5s],\t\ttrain_loss: 0.2557,\tval_loss: 0.7068\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.2529,\tval_loss: 0.7029\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.2520,\tval_loss: 0.7201\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.2484,\tval_loss: 0.7290\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.2476,\tval_loss: 0.7284\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.2513,\tval_loss: 0.7356\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.2405,\tval_loss: 0.7369\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.2375,\tval_loss: 0.7370\n",
            "44:\t[0s / 6s],\t\ttrain_loss: 0.2290,\tval_loss: 0.7452\n",
            "45:\t[0s / 6s],\t\ttrain_loss: 0.2295,\tval_loss: 0.7490\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.2295,\tval_loss: 0.7763\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.2358,\tval_loss: 0.7841\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.2191,\tval_loss: 0.7800\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.2219,\tval_loss: 0.7847\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.2233,\tval_loss: 0.7959\n",
            "51:\t[0s / 7s],\t\ttrain_loss: 0.2192,\tval_loss: 0.8067\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 21\n",
            "{'batch_size': 128, 'batch_norm': True, 'layers': 2, 'nodes': 100, 'alpha': 0.5, 'sigma': 0.1, 'lr': 0.01, 'dropout': 0.4, 'patience': 40}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.5760,\tval_loss: 0.4279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.4504,\tval_loss: 0.3720\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.3508,\tval_loss: 0.3126\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.3411,\tval_loss: 0.2944\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.3343,\tval_loss: 0.2873\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.3034,\tval_loss: 0.3014\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.3133,\tval_loss: 0.2830\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.3066,\tval_loss: 0.2809\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.2913,\tval_loss: 0.2781\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.2868,\tval_loss: 0.2790\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.2787,\tval_loss: 0.2763\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.2808,\tval_loss: 0.2781\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.2773,\tval_loss: 0.2816\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.2695,\tval_loss: 0.2827\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.2781,\tval_loss: 0.2823\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.3090,\tval_loss: 0.2951\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.3116,\tval_loss: 0.3011\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.3685,\tval_loss: 0.2827\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.3037,\tval_loss: 0.2970\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.2939,\tval_loss: 0.2843\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.2876,\tval_loss: 0.2818\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.2757,\tval_loss: 0.2840\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.2899,\tval_loss: 0.2882\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.2800,\tval_loss: 0.2881\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.2762,\tval_loss: 0.2840\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.2739,\tval_loss: 0.2806\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.2658,\tval_loss: 0.2848\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.2666,\tval_loss: 0.2839\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.2521,\tval_loss: 0.2859\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.2572,\tval_loss: 0.2859\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.2562,\tval_loss: 0.2882\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.2746,\tval_loss: 0.2942\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.2609,\tval_loss: 0.3006\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.2634,\tval_loss: 0.2891\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.2640,\tval_loss: 0.2908\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.2484,\tval_loss: 0.2880\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.2690,\tval_loss: 0.2835\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.2576,\tval_loss: 0.2827\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.2682,\tval_loss: 0.2861\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.2751,\tval_loss: 0.2829\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.2661,\tval_loss: 0.2848\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.2670,\tval_loss: 0.2885\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.2585,\tval_loss: 0.2876\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.2496,\tval_loss: 0.2872\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.2470,\tval_loss: 0.2888\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.2506,\tval_loss: 0.2884\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.2479,\tval_loss: 0.2896\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.2454,\tval_loss: 0.2915\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.2390,\tval_loss: 0.2909\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.2434,\tval_loss: 0.2917\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.2433,\tval_loss: 0.2935\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 22\n",
            "{'batch_size': 256, 'batch_norm': True, 'layers': 2, 'nodes': 200, 'alpha': 1.0, 'sigma': 0.5, 'lr': 0.001, 'dropout': 0.0, 'patience': 5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.9607,\tval_loss: 0.8677\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.8024,\tval_loss: 0.7677\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.6883,\tval_loss: 0.6857\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.6118,\tval_loss: 0.6562\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5598,\tval_loss: 0.6376\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5155,\tval_loss: 0.6235\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.4880,\tval_loss: 0.6119\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.4621,\tval_loss: 0.6045\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.4399,\tval_loss: 0.6065\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.4232,\tval_loss: 0.6013\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.4084,\tval_loss: 0.6072\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.3891,\tval_loss: 0.6077\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.3807,\tval_loss: 0.6086\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.3679,\tval_loss: 0.6081\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.3541,\tval_loss: 0.6132\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 23\n",
            "{'batch_size': 128, 'batch_norm': True, 'layers': 5, 'nodes': 200, 'alpha': 0.5, 'sigma': 0.1, 'lr': 0.0001, 'dropout': 0.4, 'patience': 40}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6652,\tval_loss: 0.5086\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.6574,\tval_loss: 0.5048\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.6373,\tval_loss: 0.5048\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.6329,\tval_loss: 0.5004\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.6498,\tval_loss: 0.5014\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.6368,\tval_loss: 0.4972\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.6080,\tval_loss: 0.4963\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.6193,\tval_loss: 0.4916\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.6110,\tval_loss: 0.4918\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.6222,\tval_loss: 0.4910\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.5822,\tval_loss: 0.4899\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 0.5916,\tval_loss: 0.4853\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 0.6148,\tval_loss: 0.4814\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.6058,\tval_loss: 0.4812\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.6006,\tval_loss: 0.4763\n",
            "15:\t[0s / 3s],\t\ttrain_loss: 0.5889,\tval_loss: 0.4779\n",
            "16:\t[0s / 3s],\t\ttrain_loss: 0.5775,\tval_loss: 0.4734\n",
            "17:\t[0s / 3s],\t\ttrain_loss: 0.5858,\tval_loss: 0.4733\n",
            "18:\t[0s / 3s],\t\ttrain_loss: 0.5596,\tval_loss: 0.4710\n",
            "19:\t[0s / 3s],\t\ttrain_loss: 0.5630,\tval_loss: 0.4686\n",
            "20:\t[0s / 4s],\t\ttrain_loss: 0.5696,\tval_loss: 0.4662\n",
            "21:\t[0s / 4s],\t\ttrain_loss: 0.5647,\tval_loss: 0.4641\n",
            "22:\t[0s / 4s],\t\ttrain_loss: 0.5429,\tval_loss: 0.4623\n",
            "23:\t[0s / 4s],\t\ttrain_loss: 0.5588,\tval_loss: 0.4623\n",
            "24:\t[0s / 4s],\t\ttrain_loss: 0.5545,\tval_loss: 0.4586\n",
            "25:\t[0s / 5s],\t\ttrain_loss: 0.5621,\tval_loss: 0.4573\n",
            "26:\t[0s / 5s],\t\ttrain_loss: 0.5594,\tval_loss: 0.4552\n",
            "27:\t[0s / 5s],\t\ttrain_loss: 0.5459,\tval_loss: 0.4543\n",
            "28:\t[0s / 5s],\t\ttrain_loss: 0.5496,\tval_loss: 0.4523\n",
            "29:\t[0s / 5s],\t\ttrain_loss: 0.5391,\tval_loss: 0.4503\n",
            "30:\t[0s / 6s],\t\ttrain_loss: 0.5324,\tval_loss: 0.4483\n",
            "31:\t[0s / 6s],\t\ttrain_loss: 0.5417,\tval_loss: 0.4460\n",
            "32:\t[0s / 6s],\t\ttrain_loss: 0.5318,\tval_loss: 0.4446\n",
            "33:\t[0s / 6s],\t\ttrain_loss: 0.5452,\tval_loss: 0.4427\n",
            "34:\t[0s / 6s],\t\ttrain_loss: 0.5295,\tval_loss: 0.4385\n",
            "35:\t[0s / 6s],\t\ttrain_loss: 0.5346,\tval_loss: 0.4379\n",
            "36:\t[0s / 7s],\t\ttrain_loss: 0.5369,\tval_loss: 0.4378\n",
            "37:\t[0s / 7s],\t\ttrain_loss: 0.5190,\tval_loss: 0.4359\n",
            "38:\t[0s / 7s],\t\ttrain_loss: 0.5183,\tval_loss: 0.4343\n",
            "39:\t[0s / 7s],\t\ttrain_loss: 0.5286,\tval_loss: 0.4334\n",
            "40:\t[0s / 7s],\t\ttrain_loss: 0.5149,\tval_loss: 0.4309\n",
            "41:\t[0s / 8s],\t\ttrain_loss: 0.5327,\tval_loss: 0.4288\n",
            "42:\t[0s / 8s],\t\ttrain_loss: 0.5168,\tval_loss: 0.4285\n",
            "43:\t[0s / 8s],\t\ttrain_loss: 0.5110,\tval_loss: 0.4270\n",
            "44:\t[0s / 8s],\t\ttrain_loss: 0.5107,\tval_loss: 0.4276\n",
            "45:\t[0s / 8s],\t\ttrain_loss: 0.5097,\tval_loss: 0.4267\n",
            "46:\t[0s / 9s],\t\ttrain_loss: 0.5211,\tval_loss: 0.4269\n",
            "47:\t[0s / 9s],\t\ttrain_loss: 0.5076,\tval_loss: 0.4263\n",
            "48:\t[0s / 9s],\t\ttrain_loss: 0.5304,\tval_loss: 0.4231\n",
            "49:\t[0s / 9s],\t\ttrain_loss: 0.5082,\tval_loss: 0.4211\n",
            "50:\t[0s / 10s],\t\ttrain_loss: 0.4964,\tval_loss: 0.4202\n",
            "51:\t[0s / 10s],\t\ttrain_loss: 0.4948,\tval_loss: 0.4179\n",
            "52:\t[0s / 10s],\t\ttrain_loss: 0.4957,\tval_loss: 0.4167\n",
            "53:\t[0s / 10s],\t\ttrain_loss: 0.4924,\tval_loss: 0.4151\n",
            "54:\t[0s / 11s],\t\ttrain_loss: 0.5036,\tval_loss: 0.4119\n",
            "55:\t[0s / 11s],\t\ttrain_loss: 0.4879,\tval_loss: 0.4102\n",
            "56:\t[0s / 11s],\t\ttrain_loss: 0.4927,\tval_loss: 0.4061\n",
            "57:\t[0s / 12s],\t\ttrain_loss: 0.4879,\tval_loss: 0.4045\n",
            "58:\t[0s / 12s],\t\ttrain_loss: 0.4904,\tval_loss: 0.4019\n",
            "59:\t[0s / 12s],\t\ttrain_loss: 0.4886,\tval_loss: 0.4000\n",
            "60:\t[0s / 12s],\t\ttrain_loss: 0.4828,\tval_loss: 0.3990\n",
            "61:\t[0s / 13s],\t\ttrain_loss: 0.4895,\tval_loss: 0.3971\n",
            "62:\t[0s / 13s],\t\ttrain_loss: 0.4827,\tval_loss: 0.3947\n",
            "63:\t[0s / 13s],\t\ttrain_loss: 0.4813,\tval_loss: 0.3935\n",
            "64:\t[0s / 14s],\t\ttrain_loss: 0.4803,\tval_loss: 0.3928\n",
            "65:\t[0s / 14s],\t\ttrain_loss: 0.4897,\tval_loss: 0.3905\n",
            "66:\t[0s / 14s],\t\ttrain_loss: 0.4776,\tval_loss: 0.3878\n",
            "67:\t[0s / 14s],\t\ttrain_loss: 0.4801,\tval_loss: 0.3844\n",
            "68:\t[0s / 14s],\t\ttrain_loss: 0.4738,\tval_loss: 0.3825\n",
            "69:\t[0s / 15s],\t\ttrain_loss: 0.4816,\tval_loss: 0.3831\n",
            "70:\t[0s / 15s],\t\ttrain_loss: 0.4625,\tval_loss: 0.3815\n",
            "71:\t[0s / 15s],\t\ttrain_loss: 0.4721,\tval_loss: 0.3807\n",
            "72:\t[0s / 15s],\t\ttrain_loss: 0.4661,\tval_loss: 0.3785\n",
            "73:\t[0s / 15s],\t\ttrain_loss: 0.4620,\tval_loss: 0.3779\n",
            "74:\t[0s / 16s],\t\ttrain_loss: 0.4764,\tval_loss: 0.3761\n",
            "75:\t[0s / 16s],\t\ttrain_loss: 0.4594,\tval_loss: 0.3728\n",
            "76:\t[0s / 16s],\t\ttrain_loss: 0.4731,\tval_loss: 0.3732\n",
            "77:\t[0s / 16s],\t\ttrain_loss: 0.4602,\tval_loss: 0.3728\n",
            "78:\t[0s / 16s],\t\ttrain_loss: 0.4593,\tval_loss: 0.3710\n",
            "79:\t[0s / 17s],\t\ttrain_loss: 0.4525,\tval_loss: 0.3686\n",
            "80:\t[0s / 17s],\t\ttrain_loss: 0.4496,\tval_loss: 0.3679\n",
            "81:\t[0s / 17s],\t\ttrain_loss: 0.4499,\tval_loss: 0.3653\n",
            "82:\t[0s / 17s],\t\ttrain_loss: 0.4550,\tval_loss: 0.3656\n",
            "83:\t[0s / 17s],\t\ttrain_loss: 0.4425,\tval_loss: 0.3649\n",
            "84:\t[0s / 17s],\t\ttrain_loss: 0.4491,\tval_loss: 0.3634\n",
            "85:\t[0s / 18s],\t\ttrain_loss: 0.4506,\tval_loss: 0.3610\n",
            "86:\t[0s / 18s],\t\ttrain_loss: 0.4495,\tval_loss: 0.3608\n",
            "87:\t[0s / 18s],\t\ttrain_loss: 0.4405,\tval_loss: 0.3588\n",
            "88:\t[0s / 18s],\t\ttrain_loss: 0.4517,\tval_loss: 0.3576\n",
            "89:\t[0s / 18s],\t\ttrain_loss: 0.4427,\tval_loss: 0.3556\n",
            "90:\t[0s / 19s],\t\ttrain_loss: 0.4465,\tval_loss: 0.3528\n",
            "91:\t[0s / 19s],\t\ttrain_loss: 0.4469,\tval_loss: 0.3529\n",
            "92:\t[0s / 19s],\t\ttrain_loss: 0.4411,\tval_loss: 0.3529\n",
            "93:\t[0s / 19s],\t\ttrain_loss: 0.4307,\tval_loss: 0.3513\n",
            "94:\t[0s / 19s],\t\ttrain_loss: 0.4332,\tval_loss: 0.3491\n",
            "95:\t[0s / 20s],\t\ttrain_loss: 0.4340,\tval_loss: 0.3472\n",
            "96:\t[0s / 20s],\t\ttrain_loss: 0.4213,\tval_loss: 0.3476\n",
            "97:\t[0s / 20s],\t\ttrain_loss: 0.4281,\tval_loss: 0.3445\n",
            "98:\t[0s / 20s],\t\ttrain_loss: 0.4322,\tval_loss: 0.3441\n",
            "99:\t[0s / 20s],\t\ttrain_loss: 0.4278,\tval_loss: 0.3443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 24\n",
            "{'batch_size': 128, 'batch_norm': False, 'layers': 1, 'nodes': 200, 'alpha': 0.1, 'sigma': 0.5, 'lr': 0.001, 'dropout': 0.2, 'patience': 10}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1486,\tval_loss: 0.1233\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1277,\tval_loss: 0.1175\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1245,\tval_loss: 0.1153\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1195,\tval_loss: 0.1143\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1193,\tval_loss: 0.1142\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1134,\tval_loss: 0.1149\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1135,\tval_loss: 0.1145\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1121,\tval_loss: 0.1145\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1094,\tval_loss: 0.1148\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.1093,\tval_loss: 0.1147\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.1118,\tval_loss: 0.1152\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.1086,\tval_loss: 0.1150\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.1092,\tval_loss: 0.1148\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1060,\tval_loss: 0.1147\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1061,\tval_loss: 0.1150\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 25\n",
            "{'batch_size': 128, 'batch_norm': False, 'layers': 5, 'nodes': 50, 'alpha': 1.0, 'sigma': 0.1, 'lr': 0.0001, 'dropout': 0.5, 'patience': 20}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 1.5739,\tval_loss: 0.9151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 1.3970,\tval_loss: 0.8929\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 1.2909,\tval_loss: 0.8734\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 1.2296,\tval_loss: 0.8581\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 1.2295,\tval_loss: 0.8448\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 1.1343,\tval_loss: 0.8350\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 1.0990,\tval_loss: 0.8264\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 1.1250,\tval_loss: 0.8192\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 1.0214,\tval_loss: 0.8121\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 1.0005,\tval_loss: 0.8060\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 1.0075,\tval_loss: 0.8009\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 1.0023,\tval_loss: 0.7965\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.9287,\tval_loss: 0.7927\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.9356,\tval_loss: 0.7897\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.9341,\tval_loss: 0.7878\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.8754,\tval_loss: 0.7860\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.9076,\tval_loss: 0.7842\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.8885,\tval_loss: 0.7836\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.8817,\tval_loss: 0.7819\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.8471,\tval_loss: 0.7798\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.8800,\tval_loss: 0.7788\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.8562,\tval_loss: 0.7775\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.8609,\tval_loss: 0.7762\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.8545,\tval_loss: 0.7762\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.8620,\tval_loss: 0.7769\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.8216,\tval_loss: 0.7760\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.7592,\tval_loss: 0.7747\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.7856,\tval_loss: 0.7738\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.8439,\tval_loss: 0.7740\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.8244,\tval_loss: 0.7732\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.8185,\tval_loss: 0.7741\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.8164,\tval_loss: 0.7739\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.7954,\tval_loss: 0.7733\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.8183,\tval_loss: 0.7743\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.7499,\tval_loss: 0.7739\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.8088,\tval_loss: 0.7747\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.7318,\tval_loss: 0.7743\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.7850,\tval_loss: 0.7742\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.7797,\tval_loss: 0.7752\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.7357,\tval_loss: 0.7746\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.7727,\tval_loss: 0.7738\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.7736,\tval_loss: 0.7729\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.7344,\tval_loss: 0.7726\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.8049,\tval_loss: 0.7716\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.7481,\tval_loss: 0.7712\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.7355,\tval_loss: 0.7701\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.7306,\tval_loss: 0.7695\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.7599,\tval_loss: 0.7696\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.7747,\tval_loss: 0.7701\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.7646,\tval_loss: 0.7701\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.7284,\tval_loss: 0.7688\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.7366,\tval_loss: 0.7680\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.7626,\tval_loss: 0.7670\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.7225,\tval_loss: 0.7667\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.7551,\tval_loss: 0.7665\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.7315,\tval_loss: 0.7664\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.7242,\tval_loss: 0.7658\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.7131,\tval_loss: 0.7650\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.7141,\tval_loss: 0.7647\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.6958,\tval_loss: 0.7636\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.7312,\tval_loss: 0.7627\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.7494,\tval_loss: 0.7627\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.7131,\tval_loss: 0.7620\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.7434,\tval_loss: 0.7612\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.7165,\tval_loss: 0.7609\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.7135,\tval_loss: 0.7601\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.7381,\tval_loss: 0.7598\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.7220,\tval_loss: 0.7593\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.7341,\tval_loss: 0.7593\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.7113,\tval_loss: 0.7591\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.7203,\tval_loss: 0.7582\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.7072,\tval_loss: 0.7573\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.7197,\tval_loss: 0.7565\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.7077,\tval_loss: 0.7562\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.6939,\tval_loss: 0.7554\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.7161,\tval_loss: 0.7546\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.7090,\tval_loss: 0.7537\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.7050,\tval_loss: 0.7531\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.6772,\tval_loss: 0.7526\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.7364,\tval_loss: 0.7515\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.7106,\tval_loss: 0.7512\n",
            "81:\t[0s / 9s],\t\ttrain_loss: 0.6893,\tval_loss: 0.7498\n",
            "82:\t[0s / 9s],\t\ttrain_loss: 0.6971,\tval_loss: 0.7481\n",
            "83:\t[0s / 9s],\t\ttrain_loss: 0.7076,\tval_loss: 0.7473\n",
            "84:\t[0s / 9s],\t\ttrain_loss: 0.7121,\tval_loss: 0.7469\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.6725,\tval_loss: 0.7460\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.6886,\tval_loss: 0.7449\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.6895,\tval_loss: 0.7437\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.6739,\tval_loss: 0.7429\n",
            "89:\t[0s / 11s],\t\ttrain_loss: 0.6967,\tval_loss: 0.7419\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.6915,\tval_loss: 0.7416\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.6924,\tval_loss: 0.7413\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.6802,\tval_loss: 0.7404\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.6711,\tval_loss: 0.7399\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.6820,\tval_loss: 0.7388\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.6818,\tval_loss: 0.7375\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.6773,\tval_loss: 0.7362\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.6518,\tval_loss: 0.7357\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.6821,\tval_loss: 0.7349\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.6736,\tval_loss: 0.7343\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 26\n",
            "{'batch_size': 256, 'batch_norm': False, 'layers': 2, 'nodes': 50, 'alpha': 0.5, 'sigma': 1.0, 'lr': 0.0001, 'dropout': 0.3, 'patience': 40}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6108,\tval_loss: 0.5509\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5932,\tval_loss: 0.5377\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5747,\tval_loss: 0.5249\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5633,\tval_loss: 0.5126\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5489,\tval_loss: 0.5011\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5432,\tval_loss: 0.4903\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.5217,\tval_loss: 0.4800\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.5164,\tval_loss: 0.4703\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.5030,\tval_loss: 0.4612\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.4932,\tval_loss: 0.4526\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.4805,\tval_loss: 0.4445\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.4806,\tval_loss: 0.4369\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.4739,\tval_loss: 0.4297\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.4604,\tval_loss: 0.4227\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.4543,\tval_loss: 0.4163\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.4433,\tval_loss: 0.4102\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 0.4468,\tval_loss: 0.4044\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 0.4383,\tval_loss: 0.3990\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 0.4306,\tval_loss: 0.3938\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.4282,\tval_loss: 0.3889\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.4166,\tval_loss: 0.3841\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.4127,\tval_loss: 0.3797\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.4102,\tval_loss: 0.3755\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.4121,\tval_loss: 0.3714\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.4041,\tval_loss: 0.3675\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.3987,\tval_loss: 0.3638\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.3940,\tval_loss: 0.3604\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.3931,\tval_loss: 0.3570\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.3890,\tval_loss: 0.3540\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 0.3860,\tval_loss: 0.3510\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 0.3811,\tval_loss: 0.3483\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 0.3756,\tval_loss: 0.3456\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 0.3757,\tval_loss: 0.3432\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 0.3779,\tval_loss: 0.3408\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 0.3735,\tval_loss: 0.3386\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 0.3691,\tval_loss: 0.3364\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 0.3733,\tval_loss: 0.3344\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 0.3665,\tval_loss: 0.3326\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.3675,\tval_loss: 0.3308\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.3639,\tval_loss: 0.3292\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 0.3639,\tval_loss: 0.3275\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 0.3652,\tval_loss: 0.3259\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 0.3565,\tval_loss: 0.3244\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 0.3623,\tval_loss: 0.3230\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 0.3583,\tval_loss: 0.3217\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 0.3605,\tval_loss: 0.3205\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 0.3497,\tval_loss: 0.3192\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 0.3552,\tval_loss: 0.3180\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 0.3566,\tval_loss: 0.3169\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 0.3524,\tval_loss: 0.3159\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 0.3517,\tval_loss: 0.3149\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 0.3487,\tval_loss: 0.3140\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 0.3443,\tval_loss: 0.3131\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 0.3501,\tval_loss: 0.3123\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 0.3494,\tval_loss: 0.3115\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 0.3480,\tval_loss: 0.3107\n",
            "56:\t[0s / 2s],\t\ttrain_loss: 0.3391,\tval_loss: 0.3099\n",
            "57:\t[0s / 2s],\t\ttrain_loss: 0.3438,\tval_loss: 0.3092\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 0.3423,\tval_loss: 0.3085\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 0.3470,\tval_loss: 0.3079\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 0.3471,\tval_loss: 0.3073\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 0.3464,\tval_loss: 0.3067\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 0.3413,\tval_loss: 0.3061\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 0.3432,\tval_loss: 0.3056\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 0.3353,\tval_loss: 0.3050\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 0.3339,\tval_loss: 0.3044\n",
            "66:\t[0s / 3s],\t\ttrain_loss: 0.3308,\tval_loss: 0.3039\n",
            "67:\t[0s / 3s],\t\ttrain_loss: 0.3433,\tval_loss: 0.3034\n",
            "68:\t[0s / 3s],\t\ttrain_loss: 0.3351,\tval_loss: 0.3029\n",
            "69:\t[0s / 3s],\t\ttrain_loss: 0.3402,\tval_loss: 0.3024\n",
            "70:\t[0s / 3s],\t\ttrain_loss: 0.3342,\tval_loss: 0.3018\n",
            "71:\t[0s / 3s],\t\ttrain_loss: 0.3398,\tval_loss: 0.3014\n",
            "72:\t[0s / 3s],\t\ttrain_loss: 0.3359,\tval_loss: 0.3010\n",
            "73:\t[0s / 3s],\t\ttrain_loss: 0.3340,\tval_loss: 0.3006\n",
            "74:\t[0s / 3s],\t\ttrain_loss: 0.3369,\tval_loss: 0.3002\n",
            "75:\t[0s / 3s],\t\ttrain_loss: 0.3355,\tval_loss: 0.2999\n",
            "76:\t[0s / 3s],\t\ttrain_loss: 0.3347,\tval_loss: 0.2996\n",
            "77:\t[0s / 4s],\t\ttrain_loss: 0.3358,\tval_loss: 0.2992\n",
            "78:\t[0s / 4s],\t\ttrain_loss: 0.3313,\tval_loss: 0.2989\n",
            "79:\t[0s / 4s],\t\ttrain_loss: 0.3359,\tval_loss: 0.2985\n",
            "80:\t[0s / 4s],\t\ttrain_loss: 0.3342,\tval_loss: 0.2982\n",
            "81:\t[0s / 4s],\t\ttrain_loss: 0.3200,\tval_loss: 0.2979\n",
            "82:\t[0s / 4s],\t\ttrain_loss: 0.3306,\tval_loss: 0.2976\n",
            "83:\t[0s / 4s],\t\ttrain_loss: 0.3335,\tval_loss: 0.2973\n",
            "84:\t[0s / 4s],\t\ttrain_loss: 0.3402,\tval_loss: 0.2970\n",
            "85:\t[0s / 4s],\t\ttrain_loss: 0.3293,\tval_loss: 0.2968\n",
            "86:\t[0s / 4s],\t\ttrain_loss: 0.3340,\tval_loss: 0.2965\n",
            "87:\t[0s / 4s],\t\ttrain_loss: 0.3293,\tval_loss: 0.2962\n",
            "88:\t[0s / 4s],\t\ttrain_loss: 0.3307,\tval_loss: 0.2960\n",
            "89:\t[0s / 4s],\t\ttrain_loss: 0.3276,\tval_loss: 0.2957\n",
            "90:\t[0s / 4s],\t\ttrain_loss: 0.3312,\tval_loss: 0.2954\n",
            "91:\t[0s / 4s],\t\ttrain_loss: 0.3316,\tval_loss: 0.2952\n",
            "92:\t[0s / 4s],\t\ttrain_loss: 0.3369,\tval_loss: 0.2949\n",
            "93:\t[0s / 4s],\t\ttrain_loss: 0.3255,\tval_loss: 0.2946\n",
            "94:\t[0s / 4s],\t\ttrain_loss: 0.3288,\tval_loss: 0.2944\n",
            "95:\t[0s / 4s],\t\ttrain_loss: 0.3268,\tval_loss: 0.2942\n",
            "96:\t[0s / 5s],\t\ttrain_loss: 0.3343,\tval_loss: 0.2940\n",
            "97:\t[0s / 5s],\t\ttrain_loss: 0.3277,\tval_loss: 0.2938\n",
            "98:\t[0s / 5s],\t\ttrain_loss: 0.3215,\tval_loss: 0.2937\n",
            "99:\t[0s / 5s],\t\ttrain_loss: 0.3241,\tval_loss: 0.2935\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 27\n",
            "{'batch_size': 64, 'batch_norm': True, 'layers': 2, 'nodes': 200, 'alpha': 0.1, 'sigma': 0.1, 'lr': 0.0001, 'dropout': 0.3, 'patience': 40}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2566,\tval_loss: 0.1629\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2535,\tval_loss: 0.1597\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.2303,\tval_loss: 0.1591\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.2111,\tval_loss: 0.1580\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.2081,\tval_loss: 0.1576\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.2034,\tval_loss: 0.1556\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.2096,\tval_loss: 0.1561\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.2034,\tval_loss: 0.1564\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.2044,\tval_loss: 0.1556\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1964,\tval_loss: 0.1554\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.1912,\tval_loss: 0.1557\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 0.1834,\tval_loss: 0.1557\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1896,\tval_loss: 0.1543\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1824,\tval_loss: 0.1531\n",
            "14:\t[0s / 3s],\t\ttrain_loss: 0.1877,\tval_loss: 0.1540\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1807,\tval_loss: 0.1529\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1829,\tval_loss: 0.1527\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.1812,\tval_loss: 0.1513\n",
            "18:\t[0s / 4s],\t\ttrain_loss: 0.1719,\tval_loss: 0.1509\n",
            "19:\t[0s / 4s],\t\ttrain_loss: 0.1742,\tval_loss: 0.1502\n",
            "20:\t[0s / 5s],\t\ttrain_loss: 0.1675,\tval_loss: 0.1512\n",
            "21:\t[0s / 5s],\t\ttrain_loss: 0.1765,\tval_loss: 0.1507\n",
            "22:\t[0s / 5s],\t\ttrain_loss: 0.1718,\tval_loss: 0.1509\n",
            "23:\t[0s / 5s],\t\ttrain_loss: 0.1723,\tval_loss: 0.1507\n",
            "24:\t[0s / 5s],\t\ttrain_loss: 0.1714,\tval_loss: 0.1502\n",
            "25:\t[0s / 5s],\t\ttrain_loss: 0.1625,\tval_loss: 0.1496\n",
            "26:\t[0s / 6s],\t\ttrain_loss: 0.1740,\tval_loss: 0.1501\n",
            "27:\t[0s / 6s],\t\ttrain_loss: 0.1659,\tval_loss: 0.1491\n",
            "28:\t[0s / 6s],\t\ttrain_loss: 0.1687,\tval_loss: 0.1501\n",
            "29:\t[0s / 6s],\t\ttrain_loss: 0.1665,\tval_loss: 0.1504\n",
            "30:\t[0s / 6s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1503\n",
            "31:\t[0s / 6s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1504\n",
            "32:\t[0s / 7s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1506\n",
            "33:\t[0s / 7s],\t\ttrain_loss: 0.1582,\tval_loss: 0.1501\n",
            "34:\t[0s / 7s],\t\ttrain_loss: 0.1585,\tval_loss: 0.1501\n",
            "35:\t[0s / 7s],\t\ttrain_loss: 0.1611,\tval_loss: 0.1490\n",
            "36:\t[0s / 7s],\t\ttrain_loss: 0.1624,\tval_loss: 0.1491\n",
            "37:\t[0s / 7s],\t\ttrain_loss: 0.1599,\tval_loss: 0.1485\n",
            "38:\t[0s / 8s],\t\ttrain_loss: 0.1480,\tval_loss: 0.1484\n",
            "39:\t[0s / 8s],\t\ttrain_loss: 0.1541,\tval_loss: 0.1485\n",
            "40:\t[0s / 8s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1479\n",
            "41:\t[0s / 8s],\t\ttrain_loss: 0.1533,\tval_loss: 0.1478\n",
            "42:\t[0s / 8s],\t\ttrain_loss: 0.1559,\tval_loss: 0.1486\n",
            "43:\t[0s / 8s],\t\ttrain_loss: 0.1544,\tval_loss: 0.1477\n",
            "44:\t[0s / 9s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1487\n",
            "45:\t[0s / 9s],\t\ttrain_loss: 0.1510,\tval_loss: 0.1474\n",
            "46:\t[0s / 9s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1473\n",
            "47:\t[0s / 9s],\t\ttrain_loss: 0.1568,\tval_loss: 0.1477\n",
            "48:\t[0s / 9s],\t\ttrain_loss: 0.1510,\tval_loss: 0.1481\n",
            "49:\t[0s / 9s],\t\ttrain_loss: 0.1505,\tval_loss: 0.1481\n",
            "50:\t[0s / 10s],\t\ttrain_loss: 0.1511,\tval_loss: 0.1477\n",
            "51:\t[0s / 10s],\t\ttrain_loss: 0.1426,\tval_loss: 0.1473\n",
            "52:\t[0s / 10s],\t\ttrain_loss: 0.1463,\tval_loss: 0.1471\n",
            "53:\t[0s / 10s],\t\ttrain_loss: 0.1447,\tval_loss: 0.1475\n",
            "54:\t[0s / 10s],\t\ttrain_loss: 0.1485,\tval_loss: 0.1481\n",
            "55:\t[0s / 10s],\t\ttrain_loss: 0.1445,\tval_loss: 0.1479\n",
            "56:\t[0s / 11s],\t\ttrain_loss: 0.1453,\tval_loss: 0.1482\n",
            "57:\t[0s / 11s],\t\ttrain_loss: 0.1469,\tval_loss: 0.1484\n",
            "58:\t[0s / 11s],\t\ttrain_loss: 0.1413,\tval_loss: 0.1476\n",
            "59:\t[0s / 11s],\t\ttrain_loss: 0.1442,\tval_loss: 0.1478\n",
            "60:\t[0s / 11s],\t\ttrain_loss: 0.1429,\tval_loss: 0.1476\n",
            "61:\t[0s / 11s],\t\ttrain_loss: 0.1469,\tval_loss: 0.1470\n",
            "62:\t[0s / 12s],\t\ttrain_loss: 0.1457,\tval_loss: 0.1466\n",
            "63:\t[0s / 12s],\t\ttrain_loss: 0.1404,\tval_loss: 0.1463\n",
            "64:\t[0s / 12s],\t\ttrain_loss: 0.1429,\tval_loss: 0.1470\n",
            "65:\t[0s / 12s],\t\ttrain_loss: 0.1406,\tval_loss: 0.1464\n",
            "66:\t[0s / 12s],\t\ttrain_loss: 0.1447,\tval_loss: 0.1457\n",
            "67:\t[0s / 12s],\t\ttrain_loss: 0.1351,\tval_loss: 0.1457\n",
            "68:\t[0s / 13s],\t\ttrain_loss: 0.1390,\tval_loss: 0.1465\n",
            "69:\t[0s / 13s],\t\ttrain_loss: 0.1390,\tval_loss: 0.1461\n",
            "70:\t[0s / 13s],\t\ttrain_loss: 0.1364,\tval_loss: 0.1469\n",
            "71:\t[0s / 13s],\t\ttrain_loss: 0.1349,\tval_loss: 0.1471\n",
            "72:\t[0s / 13s],\t\ttrain_loss: 0.1382,\tval_loss: 0.1461\n",
            "73:\t[0s / 13s],\t\ttrain_loss: 0.1406,\tval_loss: 0.1466\n",
            "74:\t[0s / 14s],\t\ttrain_loss: 0.1405,\tval_loss: 0.1467\n",
            "75:\t[0s / 14s],\t\ttrain_loss: 0.1335,\tval_loss: 0.1466\n",
            "76:\t[0s / 14s],\t\ttrain_loss: 0.1359,\tval_loss: 0.1469\n",
            "77:\t[0s / 14s],\t\ttrain_loss: 0.1314,\tval_loss: 0.1466\n",
            "78:\t[0s / 14s],\t\ttrain_loss: 0.1391,\tval_loss: 0.1472\n",
            "79:\t[0s / 15s],\t\ttrain_loss: 0.1323,\tval_loss: 0.1468\n",
            "80:\t[0s / 15s],\t\ttrain_loss: 0.1373,\tval_loss: 0.1483\n",
            "81:\t[0s / 15s],\t\ttrain_loss: 0.1349,\tval_loss: 0.1473\n",
            "82:\t[0s / 15s],\t\ttrain_loss: 0.1337,\tval_loss: 0.1476\n",
            "83:\t[0s / 16s],\t\ttrain_loss: 0.1353,\tval_loss: 0.1475\n",
            "84:\t[0s / 16s],\t\ttrain_loss: 0.1306,\tval_loss: 0.1463\n",
            "85:\t[0s / 16s],\t\ttrain_loss: 0.1324,\tval_loss: 0.1477\n",
            "86:\t[0s / 16s],\t\ttrain_loss: 0.1317,\tval_loss: 0.1465\n",
            "87:\t[0s / 17s],\t\ttrain_loss: 0.1303,\tval_loss: 0.1468\n",
            "88:\t[0s / 17s],\t\ttrain_loss: 0.1331,\tval_loss: 0.1478\n",
            "89:\t[0s / 17s],\t\ttrain_loss: 0.1306,\tval_loss: 0.1468\n",
            "90:\t[0s / 17s],\t\ttrain_loss: 0.1271,\tval_loss: 0.1466\n",
            "91:\t[0s / 18s],\t\ttrain_loss: 0.1302,\tval_loss: 0.1467\n",
            "92:\t[0s / 18s],\t\ttrain_loss: 0.1263,\tval_loss: 0.1460\n",
            "93:\t[0s / 18s],\t\ttrain_loss: 0.1297,\tval_loss: 0.1467\n",
            "94:\t[0s / 18s],\t\ttrain_loss: 0.1269,\tval_loss: 0.1486\n",
            "95:\t[0s / 19s],\t\ttrain_loss: 0.1215,\tval_loss: 0.1458\n",
            "96:\t[0s / 19s],\t\ttrain_loss: 0.1277,\tval_loss: 0.1458\n",
            "97:\t[0s / 19s],\t\ttrain_loss: 0.1246,\tval_loss: 0.1459\n",
            "98:\t[0s / 19s],\t\ttrain_loss: 0.1326,\tval_loss: 0.1471\n",
            "99:\t[0s / 19s],\t\ttrain_loss: 0.1267,\tval_loss: 0.1461\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 28\n",
            "{'batch_size': 256, 'batch_norm': False, 'layers': 1, 'nodes': 50, 'alpha': 1.0, 'sigma': 1.0, 'lr': 0.01, 'dropout': 0.5, 'patience': 40}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.7392,\tval_loss: 0.5420\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5925,\tval_loss: 0.5292\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5549,\tval_loss: 0.5027\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5262,\tval_loss: 0.4896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5109,\tval_loss: 0.4834\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4939,\tval_loss: 0.4840\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.5025,\tval_loss: 0.4844\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.4801,\tval_loss: 0.4875\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.4894,\tval_loss: 0.4880\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.4880,\tval_loss: 0.4865\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.4780,\tval_loss: 0.4897\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.4710,\tval_loss: 0.4847\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.4694,\tval_loss: 0.4865\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.4731,\tval_loss: 0.4883\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.4720,\tval_loss: 0.4885\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.4596,\tval_loss: 0.4810\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 0.4655,\tval_loss: 0.4834\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 0.4619,\tval_loss: 0.4847\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 0.4556,\tval_loss: 0.4888\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 0.4540,\tval_loss: 0.4889\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.4429,\tval_loss: 0.4934\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.4468,\tval_loss: 0.4943\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.4465,\tval_loss: 0.5004\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.4457,\tval_loss: 0.5034\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.4478,\tval_loss: 0.4960\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.4435,\tval_loss: 0.4940\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.4407,\tval_loss: 0.4998\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.4384,\tval_loss: 0.5015\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.4267,\tval_loss: 0.5081\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 0.4362,\tval_loss: 0.5097\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 0.4307,\tval_loss: 0.5089\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 0.4277,\tval_loss: 0.5112\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 0.4279,\tval_loss: 0.5142\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 0.4175,\tval_loss: 0.5169\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 0.4311,\tval_loss: 0.5171\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 0.4250,\tval_loss: 0.5257\n",
            "36:\t[0s / 1s],\t\ttrain_loss: 0.4260,\tval_loss: 0.5243\n",
            "37:\t[0s / 1s],\t\ttrain_loss: 0.4303,\tval_loss: 0.5213\n",
            "38:\t[0s / 1s],\t\ttrain_loss: 0.4130,\tval_loss: 0.5277\n",
            "39:\t[0s / 1s],\t\ttrain_loss: 0.4139,\tval_loss: 0.5294\n",
            "40:\t[0s / 1s],\t\ttrain_loss: 0.4233,\tval_loss: 0.5250\n",
            "41:\t[0s / 1s],\t\ttrain_loss: 0.4215,\tval_loss: 0.5362\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 0.4121,\tval_loss: 0.5340\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 0.4201,\tval_loss: 0.5409\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 0.4113,\tval_loss: 0.5425\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 0.4185,\tval_loss: 0.5475\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 0.4148,\tval_loss: 0.5378\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 0.4045,\tval_loss: 0.5416\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 0.4072,\tval_loss: 0.5485\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 0.4086,\tval_loss: 0.5469\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 0.4142,\tval_loss: 0.5491\n",
            "51:\t[0s / 2s],\t\ttrain_loss: 0.3965,\tval_loss: 0.5471\n",
            "52:\t[0s / 2s],\t\ttrain_loss: 0.4077,\tval_loss: 0.5532\n",
            "53:\t[0s / 2s],\t\ttrain_loss: 0.3996,\tval_loss: 0.5576\n",
            "54:\t[0s / 2s],\t\ttrain_loss: 0.4050,\tval_loss: 0.5584\n",
            "55:\t[0s / 2s],\t\ttrain_loss: 0.4061,\tval_loss: 0.5497\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 29\n",
            "{'batch_size': 64, 'batch_norm': True, 'layers': 5, 'nodes': 300, 'alpha': 0.5, 'sigma': 0.5, 'lr': 0.0001, 'dropout': 0.4, 'patience': 20}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.5536,\tval_loss: 0.5090\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5539,\tval_loss: 0.4962\n",
            "2:\t[0s / 1s],\t\ttrain_loss: 0.5440,\tval_loss: 0.4812\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.5358,\tval_loss: 0.4702\n",
            "4:\t[0s / 2s],\t\ttrain_loss: 0.5331,\tval_loss: 0.4620\n",
            "5:\t[0s / 2s],\t\ttrain_loss: 0.5201,\tval_loss: 0.4472\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.5122,\tval_loss: 0.4341\n",
            "7:\t[0s / 3s],\t\ttrain_loss: 0.5009,\tval_loss: 0.4194\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 0.4949,\tval_loss: 0.4021\n",
            "9:\t[0s / 4s],\t\ttrain_loss: 0.4894,\tval_loss: 0.3818\n",
            "10:\t[0s / 4s],\t\ttrain_loss: 0.4770,\tval_loss: 0.3598\n",
            "11:\t[0s / 4s],\t\ttrain_loss: 0.4742,\tval_loss: 0.3427\n",
            "12:\t[0s / 5s],\t\ttrain_loss: 0.4534,\tval_loss: 0.3256\n",
            "13:\t[0s / 5s],\t\ttrain_loss: 0.4402,\tval_loss: 0.3123\n",
            "14:\t[0s / 6s],\t\ttrain_loss: 0.4372,\tval_loss: 0.3081\n",
            "15:\t[0s / 6s],\t\ttrain_loss: 0.4175,\tval_loss: 0.3056\n",
            "16:\t[0s / 6s],\t\ttrain_loss: 0.4057,\tval_loss: 0.3047\n",
            "17:\t[0s / 7s],\t\ttrain_loss: 0.4044,\tval_loss: 0.3063\n",
            "18:\t[0s / 8s],\t\ttrain_loss: 0.3885,\tval_loss: 0.3085\n",
            "19:\t[0s / 8s],\t\ttrain_loss: 0.3795,\tval_loss: 0.3084\n",
            "20:\t[0s / 9s],\t\ttrain_loss: 0.3773,\tval_loss: 0.3101\n",
            "21:\t[0s / 9s],\t\ttrain_loss: 0.3689,\tval_loss: 0.3116\n",
            "22:\t[0s / 10s],\t\ttrain_loss: 0.3620,\tval_loss: 0.3119\n",
            "23:\t[0s / 11s],\t\ttrain_loss: 0.3555,\tval_loss: 0.3154\n",
            "24:\t[0s / 11s],\t\ttrain_loss: 0.3622,\tval_loss: 0.3154\n",
            "25:\t[0s / 12s],\t\ttrain_loss: 0.3504,\tval_loss: 0.3151\n",
            "26:\t[0s / 12s],\t\ttrain_loss: 0.3533,\tval_loss: 0.3156\n",
            "27:\t[0s / 12s],\t\ttrain_loss: 0.3466,\tval_loss: 0.3160\n",
            "28:\t[0s / 13s],\t\ttrain_loss: 0.3425,\tval_loss: 0.3152\n",
            "29:\t[0s / 13s],\t\ttrain_loss: 0.3444,\tval_loss: 0.3180\n",
            "30:\t[0s / 14s],\t\ttrain_loss: 0.3363,\tval_loss: 0.3172\n",
            "31:\t[0s / 14s],\t\ttrain_loss: 0.3250,\tval_loss: 0.3143\n",
            "32:\t[0s / 14s],\t\ttrain_loss: 0.3300,\tval_loss: 0.3175\n",
            "33:\t[0s / 15s],\t\ttrain_loss: 0.3373,\tval_loss: 0.3157\n",
            "34:\t[0s / 15s],\t\ttrain_loss: 0.3371,\tval_loss: 0.3148\n",
            "35:\t[0s / 16s],\t\ttrain_loss: 0.3180,\tval_loss: 0.3134\n",
            "36:\t[0s / 16s],\t\ttrain_loss: 0.3180,\tval_loss: 0.3117\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 30\n",
            "{'batch_size': 256, 'batch_norm': True, 'layers': 1, 'nodes': 300, 'alpha': 1.0, 'sigma': 0.1, 'lr': 0.001, 'dropout': 0.2, 'patience': 50}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.9654,\tval_loss: 0.9417\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.8688,\tval_loss: 0.8521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 0.7893,\tval_loss: 0.7725\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.7158,\tval_loss: 0.7263\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.6683,\tval_loss: 0.7037\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.6428,\tval_loss: 0.6874\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.6115,\tval_loss: 0.6755\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.5873,\tval_loss: 0.6594\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.5718,\tval_loss: 0.6435\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.5551,\tval_loss: 0.6289\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.5362,\tval_loss: 0.6177\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.5195,\tval_loss: 0.6064\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.5154,\tval_loss: 0.5986\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.4967,\tval_loss: 0.5925\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.4937,\tval_loss: 0.5867\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.4732,\tval_loss: 0.5804\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.4685,\tval_loss: 0.5761\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.4578,\tval_loss: 0.5710\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.4564,\tval_loss: 0.5684\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.4453,\tval_loss: 0.5685\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.4422,\tval_loss: 0.5676\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.4372,\tval_loss: 0.5649\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.4291,\tval_loss: 0.5645\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.4301,\tval_loss: 0.5641\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.4271,\tval_loss: 0.5635\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.4168,\tval_loss: 0.5617\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.4076,\tval_loss: 0.5609\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.4096,\tval_loss: 0.5608\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.4004,\tval_loss: 0.5595\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 0.3999,\tval_loss: 0.5590\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 0.3894,\tval_loss: 0.5583\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 0.3960,\tval_loss: 0.5574\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 0.3917,\tval_loss: 0.5575\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.3861,\tval_loss: 0.5569\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.3955,\tval_loss: 0.5550\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.3789,\tval_loss: 0.5568\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.3775,\tval_loss: 0.5586\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.3734,\tval_loss: 0.5589\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.3746,\tval_loss: 0.5579\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 0.3660,\tval_loss: 0.5581\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 0.3795,\tval_loss: 0.5592\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 0.3698,\tval_loss: 0.5603\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 0.3652,\tval_loss: 0.5623\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 0.3647,\tval_loss: 0.5634\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 0.3557,\tval_loss: 0.5612\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 0.3514,\tval_loss: 0.5612\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 0.3595,\tval_loss: 0.5630\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 0.3548,\tval_loss: 0.5647\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 0.3534,\tval_loss: 0.5653\n",
            "49:\t[0s / 3s],\t\ttrain_loss: 0.3490,\tval_loss: 0.5679\n",
            "50:\t[0s / 3s],\t\ttrain_loss: 0.3468,\tval_loss: 0.5671\n",
            "51:\t[0s / 3s],\t\ttrain_loss: 0.3494,\tval_loss: 0.5660\n",
            "52:\t[0s / 3s],\t\ttrain_loss: 0.3406,\tval_loss: 0.5665\n",
            "53:\t[0s / 3s],\t\ttrain_loss: 0.3428,\tval_loss: 0.5667\n",
            "54:\t[0s / 3s],\t\ttrain_loss: 0.3332,\tval_loss: 0.5674\n",
            "55:\t[0s / 3s],\t\ttrain_loss: 0.3290,\tval_loss: 0.5695\n",
            "56:\t[0s / 3s],\t\ttrain_loss: 0.3371,\tval_loss: 0.5728\n",
            "57:\t[0s / 3s],\t\ttrain_loss: 0.3295,\tval_loss: 0.5730\n",
            "58:\t[0s / 3s],\t\ttrain_loss: 0.3309,\tval_loss: 0.5733\n",
            "59:\t[0s / 3s],\t\ttrain_loss: 0.3266,\tval_loss: 0.5739\n",
            "60:\t[0s / 3s],\t\ttrain_loss: 0.3173,\tval_loss: 0.5752\n",
            "61:\t[0s / 3s],\t\ttrain_loss: 0.3275,\tval_loss: 0.5758\n",
            "62:\t[0s / 3s],\t\ttrain_loss: 0.3265,\tval_loss: 0.5778\n",
            "63:\t[0s / 3s],\t\ttrain_loss: 0.3109,\tval_loss: 0.5812\n",
            "64:\t[0s / 3s],\t\ttrain_loss: 0.3090,\tval_loss: 0.5837\n",
            "65:\t[0s / 3s],\t\ttrain_loss: 0.3250,\tval_loss: 0.5829\n",
            "66:\t[0s / 4s],\t\ttrain_loss: 0.3179,\tval_loss: 0.5829\n",
            "67:\t[0s / 4s],\t\ttrain_loss: 0.3126,\tval_loss: 0.5846\n",
            "68:\t[0s / 4s],\t\ttrain_loss: 0.3047,\tval_loss: 0.5848\n",
            "69:\t[0s / 4s],\t\ttrain_loss: 0.3182,\tval_loss: 0.5862\n",
            "70:\t[0s / 4s],\t\ttrain_loss: 0.3084,\tval_loss: 0.5856\n",
            "71:\t[0s / 4s],\t\ttrain_loss: 0.3054,\tval_loss: 0.5878\n",
            "72:\t[0s / 4s],\t\ttrain_loss: 0.2958,\tval_loss: 0.5914\n",
            "73:\t[0s / 4s],\t\ttrain_loss: 0.3053,\tval_loss: 0.5929\n",
            "74:\t[0s / 4s],\t\ttrain_loss: 0.3045,\tval_loss: 0.5952\n",
            "75:\t[0s / 4s],\t\ttrain_loss: 0.2957,\tval_loss: 0.5983\n",
            "76:\t[0s / 4s],\t\ttrain_loss: 0.3026,\tval_loss: 0.5993\n",
            "77:\t[0s / 4s],\t\ttrain_loss: 0.2968,\tval_loss: 0.5997\n",
            "78:\t[0s / 4s],\t\ttrain_loss: 0.2982,\tval_loss: 0.6019\n",
            "79:\t[0s / 4s],\t\ttrain_loss: 0.2942,\tval_loss: 0.6021\n",
            "80:\t[0s / 4s],\t\ttrain_loss: 0.2953,\tval_loss: 0.6037\n",
            "81:\t[0s / 4s],\t\ttrain_loss: 0.2960,\tval_loss: 0.6065\n",
            "82:\t[0s / 4s],\t\ttrain_loss: 0.2958,\tval_loss: 0.6059\n",
            "83:\t[0s / 4s],\t\ttrain_loss: 0.2901,\tval_loss: 0.6074\n",
            "84:\t[0s / 5s],\t\ttrain_loss: 0.2916,\tval_loss: 0.6081\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 31\n",
            "{'batch_size': 128, 'batch_norm': False, 'layers': 1, 'nodes': 50, 'alpha': 0.5, 'sigma': 1.0, 'lr': 0.0001, 'dropout': 0.1, 'patience': 30}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.4904,\tval_loss: 0.4608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.4780,\tval_loss: 0.4508\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.4675,\tval_loss: 0.4414\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.4616,\tval_loss: 0.4326\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.4488,\tval_loss: 0.4244\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4430,\tval_loss: 0.4167\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.4372,\tval_loss: 0.4095\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.4263,\tval_loss: 0.4029\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.4209,\tval_loss: 0.3966\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.4135,\tval_loss: 0.3906\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.4052,\tval_loss: 0.3851\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.3997,\tval_loss: 0.3798\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.3957,\tval_loss: 0.3750\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.3927,\tval_loss: 0.3703\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.3844,\tval_loss: 0.3660\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.3812,\tval_loss: 0.3619\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.3789,\tval_loss: 0.3581\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.3708,\tval_loss: 0.3546\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.3733,\tval_loss: 0.3512\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.3661,\tval_loss: 0.3480\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.3643,\tval_loss: 0.3450\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.3580,\tval_loss: 0.3422\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.3579,\tval_loss: 0.3395\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.3505,\tval_loss: 0.3371\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.3536,\tval_loss: 0.3347\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.3503,\tval_loss: 0.3324\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.3446,\tval_loss: 0.3304\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.3447,\tval_loss: 0.3284\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.3398,\tval_loss: 0.3265\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.3416,\tval_loss: 0.3247\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.3368,\tval_loss: 0.3230\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.3334,\tval_loss: 0.3215\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.3342,\tval_loss: 0.3200\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.3371,\tval_loss: 0.3186\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.3275,\tval_loss: 0.3174\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.3273,\tval_loss: 0.3161\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.3254,\tval_loss: 0.3149\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.3286,\tval_loss: 0.3137\n",
            "38:\t[0s / 3s],\t\ttrain_loss: 0.3255,\tval_loss: 0.3127\n",
            "39:\t[0s / 3s],\t\ttrain_loss: 0.3279,\tval_loss: 0.3116\n",
            "40:\t[0s / 3s],\t\ttrain_loss: 0.3225,\tval_loss: 0.3107\n",
            "41:\t[0s / 3s],\t\ttrain_loss: 0.3184,\tval_loss: 0.3098\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 0.3205,\tval_loss: 0.3089\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.3219,\tval_loss: 0.3080\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.3213,\tval_loss: 0.3072\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.3176,\tval_loss: 0.3065\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.3175,\tval_loss: 0.3058\n",
            "47:\t[0s / 4s],\t\ttrain_loss: 0.3170,\tval_loss: 0.3051\n",
            "48:\t[0s / 4s],\t\ttrain_loss: 0.3155,\tval_loss: 0.3044\n",
            "49:\t[0s / 4s],\t\ttrain_loss: 0.3118,\tval_loss: 0.3038\n",
            "50:\t[0s / 4s],\t\ttrain_loss: 0.3150,\tval_loss: 0.3031\n",
            "51:\t[0s / 4s],\t\ttrain_loss: 0.3124,\tval_loss: 0.3026\n",
            "52:\t[0s / 4s],\t\ttrain_loss: 0.3131,\tval_loss: 0.3020\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.3105,\tval_loss: 0.3015\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.3112,\tval_loss: 0.3009\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.3109,\tval_loss: 0.3004\n",
            "56:\t[0s / 5s],\t\ttrain_loss: 0.3076,\tval_loss: 0.2999\n",
            "57:\t[0s / 5s],\t\ttrain_loss: 0.3082,\tval_loss: 0.2995\n",
            "58:\t[0s / 5s],\t\ttrain_loss: 0.3076,\tval_loss: 0.2990\n",
            "59:\t[0s / 5s],\t\ttrain_loss: 0.3052,\tval_loss: 0.2986\n",
            "60:\t[0s / 5s],\t\ttrain_loss: 0.3044,\tval_loss: 0.2982\n",
            "61:\t[0s / 5s],\t\ttrain_loss: 0.3041,\tval_loss: 0.2978\n",
            "62:\t[0s / 5s],\t\ttrain_loss: 0.3052,\tval_loss: 0.2973\n",
            "63:\t[0s / 5s],\t\ttrain_loss: 0.3020,\tval_loss: 0.2969\n",
            "64:\t[0s / 5s],\t\ttrain_loss: 0.3021,\tval_loss: 0.2966\n",
            "65:\t[0s / 5s],\t\ttrain_loss: 0.3007,\tval_loss: 0.2962\n",
            "66:\t[0s / 5s],\t\ttrain_loss: 0.3047,\tval_loss: 0.2959\n",
            "67:\t[0s / 5s],\t\ttrain_loss: 0.3020,\tval_loss: 0.2955\n",
            "68:\t[0s / 5s],\t\ttrain_loss: 0.3021,\tval_loss: 0.2952\n",
            "69:\t[0s / 6s],\t\ttrain_loss: 0.3007,\tval_loss: 0.2948\n",
            "70:\t[0s / 6s],\t\ttrain_loss: 0.3005,\tval_loss: 0.2945\n",
            "71:\t[0s / 6s],\t\ttrain_loss: 0.3007,\tval_loss: 0.2942\n",
            "72:\t[0s / 6s],\t\ttrain_loss: 0.2928,\tval_loss: 0.2939\n",
            "73:\t[0s / 6s],\t\ttrain_loss: 0.2994,\tval_loss: 0.2937\n",
            "74:\t[0s / 6s],\t\ttrain_loss: 0.3001,\tval_loss: 0.2934\n",
            "75:\t[0s / 6s],\t\ttrain_loss: 0.3011,\tval_loss: 0.2931\n",
            "76:\t[0s / 6s],\t\ttrain_loss: 0.2968,\tval_loss: 0.2928\n",
            "77:\t[0s / 6s],\t\ttrain_loss: 0.2987,\tval_loss: 0.2926\n",
            "78:\t[0s / 6s],\t\ttrain_loss: 0.2942,\tval_loss: 0.2923\n",
            "79:\t[0s / 6s],\t\ttrain_loss: 0.2977,\tval_loss: 0.2921\n",
            "80:\t[0s / 6s],\t\ttrain_loss: 0.2954,\tval_loss: 0.2918\n",
            "81:\t[0s / 6s],\t\ttrain_loss: 0.2961,\tval_loss: 0.2915\n",
            "82:\t[0s / 6s],\t\ttrain_loss: 0.2939,\tval_loss: 0.2913\n",
            "83:\t[0s / 7s],\t\ttrain_loss: 0.2959,\tval_loss: 0.2911\n",
            "84:\t[0s / 7s],\t\ttrain_loss: 0.2923,\tval_loss: 0.2909\n",
            "85:\t[0s / 7s],\t\ttrain_loss: 0.2928,\tval_loss: 0.2907\n",
            "86:\t[0s / 7s],\t\ttrain_loss: 0.2973,\tval_loss: 0.2905\n",
            "87:\t[0s / 7s],\t\ttrain_loss: 0.2957,\tval_loss: 0.2903\n",
            "88:\t[0s / 7s],\t\ttrain_loss: 0.2910,\tval_loss: 0.2901\n",
            "89:\t[0s / 7s],\t\ttrain_loss: 0.2917,\tval_loss: 0.2899\n",
            "90:\t[0s / 7s],\t\ttrain_loss: 0.2898,\tval_loss: 0.2897\n",
            "91:\t[0s / 7s],\t\ttrain_loss: 0.2902,\tval_loss: 0.2895\n",
            "92:\t[0s / 7s],\t\ttrain_loss: 0.2904,\tval_loss: 0.2894\n",
            "93:\t[0s / 7s],\t\ttrain_loss: 0.2914,\tval_loss: 0.2892\n",
            "94:\t[0s / 7s],\t\ttrain_loss: 0.2910,\tval_loss: 0.2890\n",
            "95:\t[0s / 7s],\t\ttrain_loss: 0.2889,\tval_loss: 0.2889\n",
            "96:\t[0s / 7s],\t\ttrain_loss: 0.2881,\tval_loss: 0.2887\n",
            "97:\t[0s / 7s],\t\ttrain_loss: 0.2890,\tval_loss: 0.2885\n",
            "98:\t[0s / 8s],\t\ttrain_loss: 0.2864,\tval_loss: 0.2884\n",
            "99:\t[0s / 8s],\t\ttrain_loss: 0.2882,\tval_loss: 0.2882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 32\n",
            "{'batch_size': 128, 'batch_norm': True, 'layers': 5, 'nodes': 200, 'alpha': 0.1, 'sigma': 0.1, 'lr': 0.0001, 'dropout': 0.5, 'patience': 30}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.4725,\tval_loss: 0.1587\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.3409,\tval_loss: 0.1596\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.3562,\tval_loss: 0.1590\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.3944,\tval_loss: 0.1595\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.3618,\tval_loss: 0.1601\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.4052,\tval_loss: 0.1603\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.3474,\tval_loss: 0.1603\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.3489,\tval_loss: 0.1606\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.3785,\tval_loss: 0.1607\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.3045,\tval_loss: 0.1600\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.3023,\tval_loss: 0.1599\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 0.3575,\tval_loss: 0.1594\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 0.2942,\tval_loss: 0.1589\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.3411,\tval_loss: 0.1594\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.3588,\tval_loss: 0.1592\n",
            "15:\t[0s / 3s],\t\ttrain_loss: 0.2979,\tval_loss: 0.1590\n",
            "16:\t[0s / 3s],\t\ttrain_loss: 0.3215,\tval_loss: 0.1584\n",
            "17:\t[0s / 3s],\t\ttrain_loss: 0.3391,\tval_loss: 0.1588\n",
            "18:\t[0s / 3s],\t\ttrain_loss: 0.2797,\tval_loss: 0.1590\n",
            "19:\t[0s / 3s],\t\ttrain_loss: 0.2682,\tval_loss: 0.1584\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.2839,\tval_loss: 0.1583\n",
            "21:\t[0s / 4s],\t\ttrain_loss: 0.3062,\tval_loss: 0.1584\n",
            "22:\t[0s / 4s],\t\ttrain_loss: 0.2926,\tval_loss: 0.1585\n",
            "23:\t[0s / 4s],\t\ttrain_loss: 0.2856,\tval_loss: 0.1586\n",
            "24:\t[0s / 4s],\t\ttrain_loss: 0.2799,\tval_loss: 0.1581\n",
            "25:\t[0s / 4s],\t\ttrain_loss: 0.2803,\tval_loss: 0.1580\n",
            "26:\t[0s / 5s],\t\ttrain_loss: 0.2945,\tval_loss: 0.1578\n",
            "27:\t[0s / 5s],\t\ttrain_loss: 0.2576,\tval_loss: 0.1574\n",
            "28:\t[0s / 5s],\t\ttrain_loss: 0.2688,\tval_loss: 0.1573\n",
            "29:\t[0s / 5s],\t\ttrain_loss: 0.2333,\tval_loss: 0.1574\n",
            "30:\t[0s / 5s],\t\ttrain_loss: 0.2504,\tval_loss: 0.1576\n",
            "31:\t[0s / 6s],\t\ttrain_loss: 0.2470,\tval_loss: 0.1570\n",
            "32:\t[0s / 6s],\t\ttrain_loss: 0.2542,\tval_loss: 0.1572\n",
            "33:\t[0s / 6s],\t\ttrain_loss: 0.2443,\tval_loss: 0.1572\n",
            "34:\t[0s / 6s],\t\ttrain_loss: 0.2552,\tval_loss: 0.1570\n",
            "35:\t[0s / 6s],\t\ttrain_loss: 0.2450,\tval_loss: 0.1568\n",
            "36:\t[0s / 7s],\t\ttrain_loss: 0.2601,\tval_loss: 0.1568\n",
            "37:\t[0s / 7s],\t\ttrain_loss: 0.2461,\tval_loss: 0.1569\n",
            "38:\t[0s / 7s],\t\ttrain_loss: 0.2711,\tval_loss: 0.1563\n",
            "39:\t[0s / 7s],\t\ttrain_loss: 0.2506,\tval_loss: 0.1564\n",
            "40:\t[0s / 8s],\t\ttrain_loss: 0.2341,\tval_loss: 0.1559\n",
            "41:\t[0s / 8s],\t\ttrain_loss: 0.2451,\tval_loss: 0.1561\n",
            "42:\t[0s / 8s],\t\ttrain_loss: 0.2383,\tval_loss: 0.1561\n",
            "43:\t[0s / 9s],\t\ttrain_loss: 0.2336,\tval_loss: 0.1558\n",
            "44:\t[0s / 9s],\t\ttrain_loss: 0.2400,\tval_loss: 0.1560\n",
            "45:\t[0s / 9s],\t\ttrain_loss: 0.2500,\tval_loss: 0.1560\n",
            "46:\t[0s / 9s],\t\ttrain_loss: 0.2239,\tval_loss: 0.1561\n",
            "47:\t[0s / 10s],\t\ttrain_loss: 0.2354,\tval_loss: 0.1559\n",
            "48:\t[0s / 10s],\t\ttrain_loss: 0.2403,\tval_loss: 0.1555\n",
            "49:\t[0s / 10s],\t\ttrain_loss: 0.2474,\tval_loss: 0.1549\n",
            "50:\t[0s / 11s],\t\ttrain_loss: 0.2351,\tval_loss: 0.1551\n",
            "51:\t[0s / 11s],\t\ttrain_loss: 0.2344,\tval_loss: 0.1549\n",
            "52:\t[0s / 11s],\t\ttrain_loss: 0.2232,\tval_loss: 0.1543\n",
            "53:\t[0s / 12s],\t\ttrain_loss: 0.2532,\tval_loss: 0.1540\n",
            "54:\t[0s / 12s],\t\ttrain_loss: 0.2100,\tval_loss: 0.1536\n",
            "55:\t[0s / 12s],\t\ttrain_loss: 0.2274,\tval_loss: 0.1536\n",
            "56:\t[0s / 13s],\t\ttrain_loss: 0.2116,\tval_loss: 0.1534\n",
            "57:\t[0s / 13s],\t\ttrain_loss: 0.2418,\tval_loss: 0.1531\n",
            "58:\t[0s / 13s],\t\ttrain_loss: 0.2262,\tval_loss: 0.1534\n",
            "59:\t[0s / 14s],\t\ttrain_loss: 0.2118,\tval_loss: 0.1531\n",
            "60:\t[0s / 14s],\t\ttrain_loss: 0.2161,\tval_loss: 0.1531\n",
            "61:\t[0s / 14s],\t\ttrain_loss: 0.2212,\tval_loss: 0.1529\n",
            "62:\t[0s / 14s],\t\ttrain_loss: 0.2173,\tval_loss: 0.1533\n",
            "63:\t[0s / 15s],\t\ttrain_loss: 0.2139,\tval_loss: 0.1529\n",
            "64:\t[0s / 15s],\t\ttrain_loss: 0.2027,\tval_loss: 0.1527\n",
            "65:\t[0s / 15s],\t\ttrain_loss: 0.2048,\tval_loss: 0.1527\n",
            "66:\t[0s / 16s],\t\ttrain_loss: 0.2051,\tval_loss: 0.1527\n",
            "67:\t[0s / 16s],\t\ttrain_loss: 0.2306,\tval_loss: 0.1526\n",
            "68:\t[0s / 16s],\t\ttrain_loss: 0.2077,\tval_loss: 0.1529\n",
            "69:\t[0s / 16s],\t\ttrain_loss: 0.2147,\tval_loss: 0.1526\n",
            "70:\t[0s / 16s],\t\ttrain_loss: 0.2057,\tval_loss: 0.1526\n",
            "71:\t[0s / 17s],\t\ttrain_loss: 0.2092,\tval_loss: 0.1523\n",
            "72:\t[0s / 17s],\t\ttrain_loss: 0.2133,\tval_loss: 0.1524\n",
            "73:\t[0s / 17s],\t\ttrain_loss: 0.2035,\tval_loss: 0.1526\n",
            "74:\t[0s / 17s],\t\ttrain_loss: 0.2072,\tval_loss: 0.1524\n",
            "75:\t[0s / 17s],\t\ttrain_loss: 0.2129,\tval_loss: 0.1523\n",
            "76:\t[0s / 18s],\t\ttrain_loss: 0.1975,\tval_loss: 0.1519\n",
            "77:\t[0s / 18s],\t\ttrain_loss: 0.2011,\tval_loss: 0.1521\n",
            "78:\t[0s / 18s],\t\ttrain_loss: 0.2119,\tval_loss: 0.1518\n",
            "79:\t[0s / 18s],\t\ttrain_loss: 0.1962,\tval_loss: 0.1516\n",
            "80:\t[0s / 18s],\t\ttrain_loss: 0.1984,\tval_loss: 0.1520\n",
            "81:\t[0s / 18s],\t\ttrain_loss: 0.2001,\tval_loss: 0.1521\n",
            "82:\t[0s / 19s],\t\ttrain_loss: 0.2059,\tval_loss: 0.1513\n",
            "83:\t[0s / 19s],\t\ttrain_loss: 0.2029,\tval_loss: 0.1516\n",
            "84:\t[0s / 19s],\t\ttrain_loss: 0.1935,\tval_loss: 0.1516\n",
            "85:\t[0s / 19s],\t\ttrain_loss: 0.2096,\tval_loss: 0.1515\n",
            "86:\t[0s / 19s],\t\ttrain_loss: 0.2052,\tval_loss: 0.1515\n",
            "87:\t[0s / 20s],\t\ttrain_loss: 0.2148,\tval_loss: 0.1515\n",
            "88:\t[0s / 20s],\t\ttrain_loss: 0.2128,\tval_loss: 0.1513\n",
            "89:\t[0s / 20s],\t\ttrain_loss: 0.2094,\tval_loss: 0.1512\n",
            "90:\t[0s / 20s],\t\ttrain_loss: 0.2016,\tval_loss: 0.1512\n",
            "91:\t[0s / 20s],\t\ttrain_loss: 0.2084,\tval_loss: 0.1511\n",
            "92:\t[0s / 21s],\t\ttrain_loss: 0.1963,\tval_loss: 0.1509\n",
            "93:\t[0s / 21s],\t\ttrain_loss: 0.2003,\tval_loss: 0.1505\n",
            "94:\t[0s / 21s],\t\ttrain_loss: 0.2050,\tval_loss: 0.1504\n",
            "95:\t[0s / 21s],\t\ttrain_loss: 0.2070,\tval_loss: 0.1505\n",
            "96:\t[0s / 21s],\t\ttrain_loss: 0.1846,\tval_loss: 0.1505\n",
            "97:\t[0s / 22s],\t\ttrain_loss: 0.1969,\tval_loss: 0.1504\n",
            "98:\t[0s / 22s],\t\ttrain_loss: 0.1988,\tval_loss: 0.1504\n",
            "99:\t[0s / 22s],\t\ttrain_loss: 0.1969,\tval_loss: 0.1504\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 33\n",
            "{'batch_size': 256, 'batch_norm': True, 'layers': 5, 'nodes': 200, 'alpha': 1.0, 'sigma': 0.1, 'lr': 0.01, 'dropout': 0.3, 'patience': 5}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.8523,\tval_loss: 1.0147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.6640,\tval_loss: 0.7790\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5784,\tval_loss: 0.6406\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5480,\tval_loss: 0.5980\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5111,\tval_loss: 0.5891\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5122,\tval_loss: 0.5502\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.4874,\tval_loss: 0.5370\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.4787,\tval_loss: 0.5408\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.4700,\tval_loss: 0.5432\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.4600,\tval_loss: 0.5051\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.4505,\tval_loss: 0.5259\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.4657,\tval_loss: 0.5404\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.4322,\tval_loss: 0.5524\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.4462,\tval_loss: 0.5667\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.4358,\tval_loss: 0.5505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 34\n",
            "{'batch_size': 32, 'batch_norm': True, 'layers': 3, 'nodes': 100, 'alpha': 0.1, 'sigma': 0.5, 'lr': 0.0001, 'dropout': 0.0, 'patience': 50}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1653,\tval_loss: 0.1561\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1631,\tval_loss: 0.1550\n",
            "2:\t[0s / 1s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1530\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1577,\tval_loss: 0.1522\n",
            "4:\t[0s / 2s],\t\ttrain_loss: 0.1534,\tval_loss: 0.1500\n",
            "5:\t[0s / 2s],\t\ttrain_loss: 0.1518,\tval_loss: 0.1485\n",
            "6:\t[0s / 3s],\t\ttrain_loss: 0.1476,\tval_loss: 0.1476\n",
            "7:\t[0s / 3s],\t\ttrain_loss: 0.1442,\tval_loss: 0.1454\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 0.1426,\tval_loss: 0.1442\n",
            "9:\t[0s / 4s],\t\ttrain_loss: 0.1401,\tval_loss: 0.1425\n",
            "10:\t[0s / 4s],\t\ttrain_loss: 0.1380,\tval_loss: 0.1392\n",
            "11:\t[0s / 4s],\t\ttrain_loss: 0.1350,\tval_loss: 0.1370\n",
            "12:\t[0s / 5s],\t\ttrain_loss: 0.1311,\tval_loss: 0.1370\n",
            "13:\t[0s / 5s],\t\ttrain_loss: 0.1297,\tval_loss: 0.1355\n",
            "14:\t[0s / 5s],\t\ttrain_loss: 0.1261,\tval_loss: 0.1333\n",
            "15:\t[0s / 6s],\t\ttrain_loss: 0.1249,\tval_loss: 0.1318\n",
            "16:\t[0s / 6s],\t\ttrain_loss: 0.1236,\tval_loss: 0.1304\n",
            "17:\t[0s / 6s],\t\ttrain_loss: 0.1197,\tval_loss: 0.1293\n",
            "18:\t[0s / 6s],\t\ttrain_loss: 0.1184,\tval_loss: 0.1294\n",
            "19:\t[0s / 7s],\t\ttrain_loss: 0.1174,\tval_loss: 0.1281\n",
            "20:\t[0s / 7s],\t\ttrain_loss: 0.1150,\tval_loss: 0.1276\n",
            "21:\t[0s / 7s],\t\ttrain_loss: 0.1130,\tval_loss: 0.1271\n",
            "22:\t[0s / 8s],\t\ttrain_loss: 0.1134,\tval_loss: 0.1262\n",
            "23:\t[0s / 8s],\t\ttrain_loss: 0.1111,\tval_loss: 0.1255\n",
            "24:\t[0s / 8s],\t\ttrain_loss: 0.1104,\tval_loss: 0.1254\n",
            "25:\t[0s / 8s],\t\ttrain_loss: 0.1076,\tval_loss: 0.1248\n",
            "26:\t[0s / 9s],\t\ttrain_loss: 0.1097,\tval_loss: 0.1240\n",
            "27:\t[0s / 9s],\t\ttrain_loss: 0.1079,\tval_loss: 0.1246\n",
            "28:\t[0s / 9s],\t\ttrain_loss: 0.1067,\tval_loss: 0.1245\n",
            "29:\t[0s / 10s],\t\ttrain_loss: 0.1047,\tval_loss: 0.1247\n",
            "30:\t[0s / 10s],\t\ttrain_loss: 0.1054,\tval_loss: 0.1245\n",
            "31:\t[0s / 10s],\t\ttrain_loss: 0.1061,\tval_loss: 0.1243\n",
            "32:\t[0s / 11s],\t\ttrain_loss: 0.1035,\tval_loss: 0.1244\n",
            "33:\t[0s / 11s],\t\ttrain_loss: 0.1026,\tval_loss: 0.1234\n",
            "34:\t[0s / 11s],\t\ttrain_loss: 0.0993,\tval_loss: 0.1240\n",
            "35:\t[0s / 11s],\t\ttrain_loss: 0.1004,\tval_loss: 0.1241\n",
            "36:\t[0s / 12s],\t\ttrain_loss: 0.1004,\tval_loss: 0.1250\n",
            "37:\t[0s / 12s],\t\ttrain_loss: 0.1007,\tval_loss: 0.1251\n",
            "38:\t[0s / 12s],\t\ttrain_loss: 0.0990,\tval_loss: 0.1244\n",
            "39:\t[0s / 13s],\t\ttrain_loss: 0.0986,\tval_loss: 0.1247\n",
            "40:\t[0s / 13s],\t\ttrain_loss: 0.0986,\tval_loss: 0.1246\n",
            "41:\t[0s / 13s],\t\ttrain_loss: 0.0961,\tval_loss: 0.1252\n",
            "42:\t[0s / 13s],\t\ttrain_loss: 0.0958,\tval_loss: 0.1251\n",
            "43:\t[0s / 14s],\t\ttrain_loss: 0.0955,\tval_loss: 0.1256\n",
            "44:\t[0s / 14s],\t\ttrain_loss: 0.0946,\tval_loss: 0.1252\n",
            "45:\t[0s / 15s],\t\ttrain_loss: 0.0932,\tval_loss: 0.1253\n",
            "46:\t[0s / 15s],\t\ttrain_loss: 0.0921,\tval_loss: 0.1248\n",
            "47:\t[0s / 16s],\t\ttrain_loss: 0.0938,\tval_loss: 0.1268\n",
            "48:\t[0s / 16s],\t\ttrain_loss: 0.0914,\tval_loss: 0.1259\n",
            "49:\t[0s / 16s],\t\ttrain_loss: 0.0903,\tval_loss: 0.1259\n",
            "50:\t[0s / 17s],\t\ttrain_loss: 0.0905,\tval_loss: 0.1263\n",
            "51:\t[0s / 17s],\t\ttrain_loss: 0.0928,\tval_loss: 0.1261\n",
            "52:\t[0s / 18s],\t\ttrain_loss: 0.0896,\tval_loss: 0.1260\n",
            "53:\t[0s / 18s],\t\ttrain_loss: 0.0884,\tval_loss: 0.1274\n",
            "54:\t[0s / 18s],\t\ttrain_loss: 0.0877,\tval_loss: 0.1257\n",
            "55:\t[0s / 19s],\t\ttrain_loss: 0.0875,\tval_loss: 0.1267\n",
            "56:\t[0s / 19s],\t\ttrain_loss: 0.0864,\tval_loss: 0.1275\n",
            "57:\t[0s / 19s],\t\ttrain_loss: 0.0886,\tval_loss: 0.1267\n",
            "58:\t[0s / 20s],\t\ttrain_loss: 0.0875,\tval_loss: 0.1278\n",
            "59:\t[0s / 20s],\t\ttrain_loss: 0.0855,\tval_loss: 0.1278\n",
            "60:\t[0s / 20s],\t\ttrain_loss: 0.0854,\tval_loss: 0.1277\n",
            "61:\t[0s / 21s],\t\ttrain_loss: 0.0846,\tval_loss: 0.1262\n",
            "62:\t[0s / 21s],\t\ttrain_loss: 0.0857,\tval_loss: 0.1280\n",
            "63:\t[0s / 21s],\t\ttrain_loss: 0.0830,\tval_loss: 0.1275\n",
            "64:\t[0s / 21s],\t\ttrain_loss: 0.0838,\tval_loss: 0.1274\n",
            "65:\t[0s / 22s],\t\ttrain_loss: 0.0829,\tval_loss: 0.1276\n",
            "66:\t[0s / 23s],\t\ttrain_loss: 0.0818,\tval_loss: 0.1293\n",
            "67:\t[0s / 23s],\t\ttrain_loss: 0.0811,\tval_loss: 0.1283\n",
            "68:\t[0s / 23s],\t\ttrain_loss: 0.0818,\tval_loss: 0.1273\n",
            "69:\t[0s / 24s],\t\ttrain_loss: 0.0814,\tval_loss: 0.1290\n",
            "70:\t[0s / 24s],\t\ttrain_loss: 0.0829,\tval_loss: 0.1278\n",
            "71:\t[0s / 24s],\t\ttrain_loss: 0.0795,\tval_loss: 0.1281\n",
            "72:\t[0s / 24s],\t\ttrain_loss: 0.0795,\tval_loss: 0.1283\n",
            "73:\t[0s / 25s],\t\ttrain_loss: 0.0781,\tval_loss: 0.1296\n",
            "74:\t[0s / 25s],\t\ttrain_loss: 0.0805,\tval_loss: 0.1292\n",
            "75:\t[0s / 25s],\t\ttrain_loss: 0.0783,\tval_loss: 0.1283\n",
            "76:\t[0s / 26s],\t\ttrain_loss: 0.0775,\tval_loss: 0.1305\n",
            "77:\t[0s / 26s],\t\ttrain_loss: 0.0778,\tval_loss: 0.1291\n",
            "78:\t[0s / 26s],\t\ttrain_loss: 0.0768,\tval_loss: 0.1302\n",
            "79:\t[0s / 26s],\t\ttrain_loss: 0.0758,\tval_loss: 0.1302\n",
            "80:\t[0s / 27s],\t\ttrain_loss: 0.0773,\tval_loss: 0.1290\n",
            "81:\t[0s / 27s],\t\ttrain_loss: 0.0757,\tval_loss: 0.1295\n",
            "82:\t[0s / 27s],\t\ttrain_loss: 0.0753,\tval_loss: 0.1307\n",
            "83:\t[0s / 28s],\t\ttrain_loss: 0.0724,\tval_loss: 0.1295\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 35\n",
            "{'batch_size': 64, 'batch_norm': True, 'layers': 1, 'nodes': 100, 'alpha': 0.1, 'sigma': 0.1, 'lr': 0.01, 'dropout': 0.2, 'patience': 20}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2506,\tval_loss: 0.1789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2007,\tval_loss: 0.1606\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1322\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1321,\tval_loss: 0.1225\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1183,\tval_loss: 0.1180\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1095,\tval_loss: 0.1154\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1137,\tval_loss: 0.1149\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.1065,\tval_loss: 0.1145\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1065,\tval_loss: 0.1138\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.1141,\tval_loss: 0.1252\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.1196,\tval_loss: 0.1175\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.1099,\tval_loss: 0.1155\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1078,\tval_loss: 0.1186\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.1035,\tval_loss: 0.1159\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.1049,\tval_loss: 0.1159\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.1020,\tval_loss: 0.1165\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.0980,\tval_loss: 0.1197\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.1200,\tval_loss: 0.1251\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.1258,\tval_loss: 0.1240\n",
            "19:\t[0s / 3s],\t\ttrain_loss: 0.1229,\tval_loss: 0.1294\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.1131,\tval_loss: 0.1301\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.1120,\tval_loss: 0.1249\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.1098,\tval_loss: 0.1228\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1059,\tval_loss: 0.1220\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.1037,\tval_loss: 0.1206\n",
            "25:\t[0s / 4s],\t\ttrain_loss: 0.1093,\tval_loss: 0.1191\n",
            "26:\t[0s / 4s],\t\ttrain_loss: 0.1024,\tval_loss: 0.1300\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.1023,\tval_loss: 0.1179\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.1023,\tval_loss: 0.1184\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 36\n",
            "{'batch_size': 32, 'batch_norm': True, 'layers': 2, 'nodes': 200, 'alpha': 1.0, 'sigma': 1.0, 'lr': 0.0001, 'dropout': 0.2, 'patience': 50}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 1.0033,\tval_loss: 0.9169\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.9678,\tval_loss: 0.8750\n",
            "2:\t[0s / 1s],\t\ttrain_loss: 0.9136,\tval_loss: 0.8443\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.8632,\tval_loss: 0.7839\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.7946,\tval_loss: 0.7299\n",
            "5:\t[0s / 2s],\t\ttrain_loss: 0.7320,\tval_loss: 0.6846\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.6845,\tval_loss: 0.6390\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.6527,\tval_loss: 0.6261\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.6247,\tval_loss: 0.6094\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 0.6102,\tval_loss: 0.5975\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.5827,\tval_loss: 0.5849\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.5945,\tval_loss: 0.5794\n",
            "12:\t[0s / 4s],\t\ttrain_loss: 0.5743,\tval_loss: 0.5754\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 0.5697,\tval_loss: 0.5738\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.5695,\tval_loss: 0.5657\n",
            "15:\t[0s / 5s],\t\ttrain_loss: 0.5426,\tval_loss: 0.5607\n",
            "16:\t[0s / 5s],\t\ttrain_loss: 0.5472,\tval_loss: 0.5596\n",
            "17:\t[0s / 5s],\t\ttrain_loss: 0.5437,\tval_loss: 0.5565\n",
            "18:\t[0s / 5s],\t\ttrain_loss: 0.5304,\tval_loss: 0.5608\n",
            "19:\t[0s / 6s],\t\ttrain_loss: 0.5339,\tval_loss: 0.5553\n",
            "20:\t[0s / 6s],\t\ttrain_loss: 0.5224,\tval_loss: 0.5537\n",
            "21:\t[0s / 6s],\t\ttrain_loss: 0.5208,\tval_loss: 0.5492\n",
            "22:\t[0s / 7s],\t\ttrain_loss: 0.5163,\tval_loss: 0.5508\n",
            "23:\t[0s / 7s],\t\ttrain_loss: 0.5104,\tval_loss: 0.5489\n",
            "24:\t[0s / 7s],\t\ttrain_loss: 0.5110,\tval_loss: 0.5512\n",
            "25:\t[0s / 7s],\t\ttrain_loss: 0.5081,\tval_loss: 0.5464\n",
            "26:\t[0s / 8s],\t\ttrain_loss: 0.4918,\tval_loss: 0.5534\n",
            "27:\t[0s / 8s],\t\ttrain_loss: 0.5062,\tval_loss: 0.5454\n",
            "28:\t[0s / 8s],\t\ttrain_loss: 0.4984,\tval_loss: 0.5458\n",
            "29:\t[0s / 9s],\t\ttrain_loss: 0.5000,\tval_loss: 0.5445\n",
            "30:\t[0s / 9s],\t\ttrain_loss: 0.4886,\tval_loss: 0.5466\n",
            "31:\t[0s / 9s],\t\ttrain_loss: 0.4990,\tval_loss: 0.5440\n",
            "32:\t[0s / 9s],\t\ttrain_loss: 0.4879,\tval_loss: 0.5457\n",
            "33:\t[0s / 10s],\t\ttrain_loss: 0.4744,\tval_loss: 0.5434\n",
            "34:\t[0s / 10s],\t\ttrain_loss: 0.4818,\tval_loss: 0.5471\n",
            "35:\t[0s / 10s],\t\ttrain_loss: 0.4668,\tval_loss: 0.5465\n",
            "36:\t[0s / 11s],\t\ttrain_loss: 0.4681,\tval_loss: 0.5487\n",
            "37:\t[0s / 11s],\t\ttrain_loss: 0.4682,\tval_loss: 0.5424\n",
            "38:\t[0s / 11s],\t\ttrain_loss: 0.4735,\tval_loss: 0.5442\n",
            "39:\t[0s / 12s],\t\ttrain_loss: 0.4719,\tval_loss: 0.5415\n",
            "40:\t[0s / 12s],\t\ttrain_loss: 0.4558,\tval_loss: 0.5437\n",
            "41:\t[0s / 13s],\t\ttrain_loss: 0.4606,\tval_loss: 0.5419\n",
            "42:\t[0s / 13s],\t\ttrain_loss: 0.4632,\tval_loss: 0.5436\n",
            "43:\t[0s / 13s],\t\ttrain_loss: 0.4574,\tval_loss: 0.5456\n",
            "44:\t[0s / 14s],\t\ttrain_loss: 0.4490,\tval_loss: 0.5414\n",
            "45:\t[0s / 14s],\t\ttrain_loss: 0.4612,\tval_loss: 0.5433\n",
            "46:\t[0s / 15s],\t\ttrain_loss: 0.4489,\tval_loss: 0.5388\n",
            "47:\t[0s / 15s],\t\ttrain_loss: 0.4504,\tval_loss: 0.5403\n",
            "48:\t[0s / 15s],\t\ttrain_loss: 0.4513,\tval_loss: 0.5415\n",
            "49:\t[0s / 16s],\t\ttrain_loss: 0.4445,\tval_loss: 0.5439\n",
            "50:\t[0s / 16s],\t\ttrain_loss: 0.4456,\tval_loss: 0.5424\n",
            "51:\t[0s / 16s],\t\ttrain_loss: 0.4445,\tval_loss: 0.5405\n",
            "52:\t[0s / 17s],\t\ttrain_loss: 0.4402,\tval_loss: 0.5367\n",
            "53:\t[0s / 17s],\t\ttrain_loss: 0.4359,\tval_loss: 0.5408\n",
            "54:\t[0s / 17s],\t\ttrain_loss: 0.4357,\tval_loss: 0.5407\n",
            "55:\t[0s / 17s],\t\ttrain_loss: 0.4375,\tval_loss: 0.5441\n",
            "56:\t[0s / 18s],\t\ttrain_loss: 0.4264,\tval_loss: 0.5386\n",
            "57:\t[0s / 18s],\t\ttrain_loss: 0.4390,\tval_loss: 0.5382\n",
            "58:\t[0s / 18s],\t\ttrain_loss: 0.4287,\tval_loss: 0.5391\n",
            "59:\t[0s / 19s],\t\ttrain_loss: 0.4216,\tval_loss: 0.5407\n",
            "60:\t[0s / 19s],\t\ttrain_loss: 0.4323,\tval_loss: 0.5373\n",
            "61:\t[0s / 19s],\t\ttrain_loss: 0.4259,\tval_loss: 0.5388\n",
            "62:\t[0s / 19s],\t\ttrain_loss: 0.4196,\tval_loss: 0.5356\n",
            "63:\t[0s / 20s],\t\ttrain_loss: 0.4209,\tval_loss: 0.5364\n",
            "64:\t[0s / 20s],\t\ttrain_loss: 0.4107,\tval_loss: 0.5365\n",
            "65:\t[0s / 20s],\t\ttrain_loss: 0.4148,\tval_loss: 0.5403\n",
            "66:\t[0s / 21s],\t\ttrain_loss: 0.4192,\tval_loss: 0.5362\n",
            "67:\t[0s / 21s],\t\ttrain_loss: 0.4148,\tval_loss: 0.5377\n",
            "68:\t[0s / 21s],\t\ttrain_loss: 0.4119,\tval_loss: 0.5377\n",
            "69:\t[0s / 21s],\t\ttrain_loss: 0.4024,\tval_loss: 0.5331\n",
            "70:\t[0s / 22s],\t\ttrain_loss: 0.4098,\tval_loss: 0.5424\n",
            "71:\t[0s / 22s],\t\ttrain_loss: 0.4140,\tval_loss: 0.5392\n",
            "72:\t[0s / 22s],\t\ttrain_loss: 0.4068,\tval_loss: 0.5374\n",
            "73:\t[0s / 23s],\t\ttrain_loss: 0.4109,\tval_loss: 0.5393\n",
            "74:\t[0s / 23s],\t\ttrain_loss: 0.3983,\tval_loss: 0.5394\n",
            "75:\t[0s / 23s],\t\ttrain_loss: 0.3947,\tval_loss: 0.5352\n",
            "76:\t[0s / 23s],\t\ttrain_loss: 0.4019,\tval_loss: 0.5385\n",
            "77:\t[0s / 24s],\t\ttrain_loss: 0.4050,\tval_loss: 0.5391\n",
            "78:\t[0s / 24s],\t\ttrain_loss: 0.4013,\tval_loss: 0.5382\n",
            "79:\t[0s / 24s],\t\ttrain_loss: 0.3982,\tval_loss: 0.5372\n",
            "80:\t[0s / 24s],\t\ttrain_loss: 0.4001,\tval_loss: 0.5416\n",
            "81:\t[0s / 25s],\t\ttrain_loss: 0.3977,\tval_loss: 0.5439\n",
            "82:\t[0s / 25s],\t\ttrain_loss: 0.3918,\tval_loss: 0.5373\n",
            "83:\t[0s / 25s],\t\ttrain_loss: 0.3960,\tval_loss: 0.5414\n",
            "84:\t[0s / 26s],\t\ttrain_loss: 0.3863,\tval_loss: 0.5364\n",
            "85:\t[0s / 26s],\t\ttrain_loss: 0.3865,\tval_loss: 0.5398\n",
            "86:\t[0s / 27s],\t\ttrain_loss: 0.3857,\tval_loss: 0.5403\n",
            "87:\t[0s / 27s],\t\ttrain_loss: 0.3763,\tval_loss: 0.5402\n",
            "88:\t[0s / 27s],\t\ttrain_loss: 0.3906,\tval_loss: 0.5392\n",
            "89:\t[0s / 28s],\t\ttrain_loss: 0.3788,\tval_loss: 0.5401\n",
            "90:\t[0s / 28s],\t\ttrain_loss: 0.3790,\tval_loss: 0.5432\n",
            "91:\t[0s / 29s],\t\ttrain_loss: 0.3766,\tval_loss: 0.5400\n",
            "92:\t[0s / 29s],\t\ttrain_loss: 0.3792,\tval_loss: 0.5402\n",
            "93:\t[0s / 29s],\t\ttrain_loss: 0.3796,\tval_loss: 0.5418\n",
            "94:\t[0s / 30s],\t\ttrain_loss: 0.3784,\tval_loss: 0.5449\n",
            "95:\t[0s / 30s],\t\ttrain_loss: 0.3758,\tval_loss: 0.5460\n",
            "96:\t[0s / 31s],\t\ttrain_loss: 0.3741,\tval_loss: 0.5409\n",
            "97:\t[0s / 31s],\t\ttrain_loss: 0.3741,\tval_loss: 0.5406\n",
            "98:\t[0s / 31s],\t\ttrain_loss: 0.3602,\tval_loss: 0.5453\n",
            "99:\t[0s / 32s],\t\ttrain_loss: 0.3661,\tval_loss: 0.5406\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 37\n",
            "{'batch_size': 128, 'batch_norm': False, 'layers': 3, 'nodes': 300, 'alpha': 0.5, 'sigma': 1.0, 'lr': 0.01, 'dropout': 0.4, 'patience': 20}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.4082,\tval_loss: 0.2859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.3383,\tval_loss: 0.3058\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.3246,\tval_loss: 0.3095\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.3259,\tval_loss: 0.3015\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.3086,\tval_loss: 0.3038\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.3118,\tval_loss: 0.2877\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.3090,\tval_loss: 0.2928\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.3100,\tval_loss: 0.2976\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.3126,\tval_loss: 0.2977\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.3047,\tval_loss: 0.2913\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.3053,\tval_loss: 0.2897\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.3041,\tval_loss: 0.2963\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 0.3047,\tval_loss: 0.3001\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.2911,\tval_loss: 0.3093\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.2855,\tval_loss: 0.2971\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.2870,\tval_loss: 0.2938\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.2838,\tval_loss: 0.2959\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.2863,\tval_loss: 0.2959\n",
            "18:\t[0s / 3s],\t\ttrain_loss: 0.2773,\tval_loss: 0.2904\n",
            "19:\t[0s / 3s],\t\ttrain_loss: 0.2797,\tval_loss: 0.2977\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.2907,\tval_loss: 0.2964\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 38\n",
            "{'batch_size': 128, 'batch_norm': True, 'layers': 3, 'nodes': 200, 'alpha': 1.0, 'sigma': 1.0, 'lr': 0.01, 'dropout': 0.3, 'patience': 40}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.7666,\tval_loss: 0.6737\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5935,\tval_loss: 0.6118\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5263,\tval_loss: 0.5652\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5031,\tval_loss: 0.5010\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.4638,\tval_loss: 0.5226\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4450,\tval_loss: 0.5281\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.4352,\tval_loss: 0.5508\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.4461,\tval_loss: 0.5396\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.4134,\tval_loss: 0.5321\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.4179,\tval_loss: 0.5561\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.3967,\tval_loss: 0.5356\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.3913,\tval_loss: 0.5655\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.3746,\tval_loss: 0.6071\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.3793,\tval_loss: 0.5849\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.3872,\tval_loss: 0.5816\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.3577,\tval_loss: 0.5751\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.3670,\tval_loss: 0.5953\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.3625,\tval_loss: 0.6043\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.3552,\tval_loss: 0.6128\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.3604,\tval_loss: 0.6185\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.3377,\tval_loss: 0.6249\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.3258,\tval_loss: 0.6166\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.3277,\tval_loss: 0.6289\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.3226,\tval_loss: 0.6702\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.3129,\tval_loss: 0.6489\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.3253,\tval_loss: 0.7076\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.3300,\tval_loss: 0.6614\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.3446,\tval_loss: 0.6835\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.3228,\tval_loss: 0.6814\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.3035,\tval_loss: 0.6574\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.3243,\tval_loss: 0.6757\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.2901,\tval_loss: 0.6564\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.2824,\tval_loss: 0.6917\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.2900,\tval_loss: 0.7347\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.2724,\tval_loss: 0.7081\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.2971,\tval_loss: 0.7296\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.2822,\tval_loss: 0.6973\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.3046,\tval_loss: 0.6963\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.2762,\tval_loss: 0.7505\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.2849,\tval_loss: 0.7093\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.2764,\tval_loss: 0.7387\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.2723,\tval_loss: 0.7236\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.2867,\tval_loss: 0.7146\n",
            "43:\t[0s / 6s],\t\ttrain_loss: 0.2737,\tval_loss: 0.7315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 39\n",
            "{'batch_size': 32, 'batch_norm': False, 'layers': 3, 'nodes': 100, 'alpha': 0.1, 'sigma': 0.5, 'lr': 0.0001, 'dropout': 0.1, 'patience': 40}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1705,\tval_loss: 0.1481\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1491,\tval_loss: 0.1342\n",
            "2:\t[0s / 1s],\t\ttrain_loss: 0.1379,\tval_loss: 0.1273\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1327,\tval_loss: 0.1238\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1284,\tval_loss: 0.1218\n",
            "5:\t[0s / 2s],\t\ttrain_loss: 0.1273,\tval_loss: 0.1203\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.1230,\tval_loss: 0.1191\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1240,\tval_loss: 0.1182\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 0.1211,\tval_loss: 0.1175\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 0.1211,\tval_loss: 0.1171\n",
            "10:\t[0s / 4s],\t\ttrain_loss: 0.1201,\tval_loss: 0.1167\n",
            "11:\t[0s / 4s],\t\ttrain_loss: 0.1194,\tval_loss: 0.1163\n",
            "12:\t[0s / 4s],\t\ttrain_loss: 0.1183,\tval_loss: 0.1161\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 0.1187,\tval_loss: 0.1159\n",
            "14:\t[0s / 5s],\t\ttrain_loss: 0.1169,\tval_loss: 0.1159\n",
            "15:\t[0s / 5s],\t\ttrain_loss: 0.1155,\tval_loss: 0.1159\n",
            "16:\t[0s / 5s],\t\ttrain_loss: 0.1143,\tval_loss: 0.1157\n",
            "17:\t[0s / 5s],\t\ttrain_loss: 0.1156,\tval_loss: 0.1159\n",
            "18:\t[0s / 6s],\t\ttrain_loss: 0.1144,\tval_loss: 0.1157\n",
            "19:\t[0s / 6s],\t\ttrain_loss: 0.1121,\tval_loss: 0.1157\n",
            "20:\t[0s / 6s],\t\ttrain_loss: 0.1136,\tval_loss: 0.1158\n",
            "21:\t[0s / 6s],\t\ttrain_loss: 0.1136,\tval_loss: 0.1157\n",
            "22:\t[0s / 7s],\t\ttrain_loss: 0.1114,\tval_loss: 0.1157\n",
            "23:\t[0s / 7s],\t\ttrain_loss: 0.1124,\tval_loss: 0.1156\n",
            "24:\t[0s / 7s],\t\ttrain_loss: 0.1118,\tval_loss: 0.1156\n",
            "25:\t[0s / 7s],\t\ttrain_loss: 0.1125,\tval_loss: 0.1156\n",
            "26:\t[0s / 8s],\t\ttrain_loss: 0.1101,\tval_loss: 0.1154\n",
            "27:\t[0s / 8s],\t\ttrain_loss: 0.1110,\tval_loss: 0.1156\n",
            "28:\t[0s / 8s],\t\ttrain_loss: 0.1116,\tval_loss: 0.1156\n",
            "29:\t[0s / 9s],\t\ttrain_loss: 0.1119,\tval_loss: 0.1155\n",
            "30:\t[0s / 9s],\t\ttrain_loss: 0.1111,\tval_loss: 0.1151\n",
            "31:\t[0s / 9s],\t\ttrain_loss: 0.1103,\tval_loss: 0.1153\n",
            "32:\t[0s / 9s],\t\ttrain_loss: 0.1085,\tval_loss: 0.1154\n",
            "33:\t[0s / 9s],\t\ttrain_loss: 0.1118,\tval_loss: 0.1154\n",
            "34:\t[0s / 10s],\t\ttrain_loss: 0.1109,\tval_loss: 0.1157\n",
            "35:\t[0s / 10s],\t\ttrain_loss: 0.1085,\tval_loss: 0.1157\n",
            "36:\t[0s / 10s],\t\ttrain_loss: 0.1091,\tval_loss: 0.1152\n",
            "37:\t[0s / 11s],\t\ttrain_loss: 0.1081,\tval_loss: 0.1152\n",
            "38:\t[0s / 11s],\t\ttrain_loss: 0.1068,\tval_loss: 0.1155\n",
            "39:\t[0s / 11s],\t\ttrain_loss: 0.1076,\tval_loss: 0.1160\n",
            "40:\t[0s / 11s],\t\ttrain_loss: 0.1091,\tval_loss: 0.1157\n",
            "41:\t[0s / 12s],\t\ttrain_loss: 0.1078,\tval_loss: 0.1154\n",
            "42:\t[0s / 12s],\t\ttrain_loss: 0.1082,\tval_loss: 0.1154\n",
            "43:\t[0s / 12s],\t\ttrain_loss: 0.1061,\tval_loss: 0.1153\n",
            "44:\t[0s / 12s],\t\ttrain_loss: 0.1060,\tval_loss: 0.1154\n",
            "45:\t[0s / 12s],\t\ttrain_loss: 0.1049,\tval_loss: 0.1152\n",
            "46:\t[0s / 13s],\t\ttrain_loss: 0.1045,\tval_loss: 0.1155\n",
            "47:\t[0s / 13s],\t\ttrain_loss: 0.1056,\tval_loss: 0.1155\n",
            "48:\t[0s / 13s],\t\ttrain_loss: 0.1058,\tval_loss: 0.1158\n",
            "49:\t[0s / 13s],\t\ttrain_loss: 0.1058,\tval_loss: 0.1156\n",
            "50:\t[0s / 14s],\t\ttrain_loss: 0.1067,\tval_loss: 0.1155\n",
            "51:\t[0s / 14s],\t\ttrain_loss: 0.1053,\tval_loss: 0.1159\n",
            "52:\t[0s / 14s],\t\ttrain_loss: 0.1059,\tval_loss: 0.1156\n",
            "53:\t[0s / 15s],\t\ttrain_loss: 0.1047,\tval_loss: 0.1158\n",
            "54:\t[0s / 15s],\t\ttrain_loss: 0.1038,\tval_loss: 0.1158\n",
            "55:\t[0s / 16s],\t\ttrain_loss: 0.1039,\tval_loss: 0.1156\n",
            "56:\t[0s / 16s],\t\ttrain_loss: 0.1036,\tval_loss: 0.1152\n",
            "57:\t[0s / 16s],\t\ttrain_loss: 0.1025,\tval_loss: 0.1154\n",
            "58:\t[0s / 17s],\t\ttrain_loss: 0.1042,\tval_loss: 0.1155\n",
            "59:\t[0s / 17s],\t\ttrain_loss: 0.1023,\tval_loss: 0.1154\n",
            "60:\t[0s / 17s],\t\ttrain_loss: 0.1016,\tval_loss: 0.1154\n",
            "61:\t[0s / 18s],\t\ttrain_loss: 0.1014,\tval_loss: 0.1154\n",
            "62:\t[0s / 18s],\t\ttrain_loss: 0.1026,\tval_loss: 0.1155\n",
            "63:\t[0s / 19s],\t\ttrain_loss: 0.1034,\tval_loss: 0.1152\n",
            "64:\t[0s / 19s],\t\ttrain_loss: 0.1001,\tval_loss: 0.1155\n",
            "65:\t[0s / 19s],\t\ttrain_loss: 0.1006,\tval_loss: 0.1153\n",
            "66:\t[0s / 19s],\t\ttrain_loss: 0.1019,\tval_loss: 0.1155\n",
            "67:\t[0s / 20s],\t\ttrain_loss: 0.1016,\tval_loss: 0.1154\n",
            "68:\t[0s / 20s],\t\ttrain_loss: 0.1006,\tval_loss: 0.1151\n",
            "69:\t[0s / 20s],\t\ttrain_loss: 0.1006,\tval_loss: 0.1153\n",
            "70:\t[0s / 20s],\t\ttrain_loss: 0.1000,\tval_loss: 0.1150\n",
            "71:\t[0s / 21s],\t\ttrain_loss: 0.0983,\tval_loss: 0.1151\n",
            "72:\t[0s / 21s],\t\ttrain_loss: 0.1005,\tval_loss: 0.1151\n",
            "73:\t[0s / 21s],\t\ttrain_loss: 0.0991,\tval_loss: 0.1150\n",
            "74:\t[0s / 21s],\t\ttrain_loss: 0.0986,\tval_loss: 0.1152\n",
            "75:\t[0s / 22s],\t\ttrain_loss: 0.0985,\tval_loss: 0.1152\n",
            "76:\t[0s / 22s],\t\ttrain_loss: 0.0980,\tval_loss: 0.1152\n",
            "77:\t[0s / 22s],\t\ttrain_loss: 0.0997,\tval_loss: 0.1153\n",
            "78:\t[0s / 22s],\t\ttrain_loss: 0.0977,\tval_loss: 0.1156\n",
            "79:\t[0s / 23s],\t\ttrain_loss: 0.0989,\tval_loss: 0.1157\n",
            "80:\t[0s / 23s],\t\ttrain_loss: 0.0948,\tval_loss: 0.1158\n",
            "81:\t[0s / 23s],\t\ttrain_loss: 0.0976,\tval_loss: 0.1156\n",
            "82:\t[0s / 24s],\t\ttrain_loss: 0.0965,\tval_loss: 0.1158\n",
            "83:\t[0s / 24s],\t\ttrain_loss: 0.0987,\tval_loss: 0.1160\n",
            "84:\t[0s / 24s],\t\ttrain_loss: 0.0960,\tval_loss: 0.1159\n",
            "85:\t[0s / 24s],\t\ttrain_loss: 0.0962,\tval_loss: 0.1161\n",
            "86:\t[0s / 25s],\t\ttrain_loss: 0.0962,\tval_loss: 0.1160\n",
            "87:\t[0s / 25s],\t\ttrain_loss: 0.0959,\tval_loss: 0.1163\n",
            "88:\t[0s / 25s],\t\ttrain_loss: 0.0939,\tval_loss: 0.1166\n",
            "89:\t[0s / 25s],\t\ttrain_loss: 0.0971,\tval_loss: 0.1165\n",
            "90:\t[0s / 26s],\t\ttrain_loss: 0.0971,\tval_loss: 0.1164\n",
            "91:\t[0s / 26s],\t\ttrain_loss: 0.0958,\tval_loss: 0.1163\n",
            "92:\t[0s / 26s],\t\ttrain_loss: 0.0943,\tval_loss: 0.1169\n",
            "93:\t[0s / 26s],\t\ttrain_loss: 0.0943,\tval_loss: 0.1169\n",
            "94:\t[0s / 27s],\t\ttrain_loss: 0.0935,\tval_loss: 0.1168\n",
            "95:\t[0s / 27s],\t\ttrain_loss: 0.0947,\tval_loss: 0.1167\n",
            "96:\t[0s / 27s],\t\ttrain_loss: 0.0926,\tval_loss: 0.1168\n",
            "97:\t[0s / 27s],\t\ttrain_loss: 0.0930,\tval_loss: 0.1170\n",
            "98:\t[0s / 28s],\t\ttrain_loss: 0.0972,\tval_loss: 0.1170\n",
            "99:\t[0s / 28s],\t\ttrain_loss: 0.0949,\tval_loss: 0.1175\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 40\n",
            "{'batch_size': 32, 'batch_norm': True, 'layers': 1, 'nodes': 100, 'alpha': 0.5, 'sigma': 0.1, 'lr': 0.01, 'dropout': 0.1, 'patience': 30}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.4900,\tval_loss: 0.3905\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.3371,\tval_loss: 0.2982\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.3353,\tval_loss: 0.3069\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.3044,\tval_loss: 0.3508\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.2888,\tval_loss: 0.2986\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.2761,\tval_loss: 0.2880\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.2995,\tval_loss: 0.3284\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.4717,\tval_loss: 0.3685\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.3923,\tval_loss: 0.3114\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.3292,\tval_loss: 0.2952\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.3038,\tval_loss: 0.2929\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.2807,\tval_loss: 0.2905\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.2692,\tval_loss: 0.2995\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 0.2656,\tval_loss: 0.3011\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.2537,\tval_loss: 0.2954\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.2600,\tval_loss: 0.2902\n",
            "16:\t[0s / 5s],\t\ttrain_loss: 0.2521,\tval_loss: 0.2954\n",
            "17:\t[0s / 5s],\t\ttrain_loss: 0.2461,\tval_loss: 0.3067\n",
            "18:\t[0s / 5s],\t\ttrain_loss: 0.2494,\tval_loss: 0.2958\n",
            "19:\t[0s / 5s],\t\ttrain_loss: 0.2449,\tval_loss: 0.3040\n",
            "20:\t[0s / 6s],\t\ttrain_loss: 0.2521,\tval_loss: 0.3185\n",
            "21:\t[0s / 6s],\t\ttrain_loss: 0.2358,\tval_loss: 0.3160\n",
            "22:\t[0s / 6s],\t\ttrain_loss: 0.2494,\tval_loss: 0.3071\n",
            "23:\t[0s / 6s],\t\ttrain_loss: 0.2507,\tval_loss: 0.3047\n",
            "24:\t[0s / 6s],\t\ttrain_loss: 0.2405,\tval_loss: 0.3012\n",
            "25:\t[0s / 7s],\t\ttrain_loss: 0.2259,\tval_loss: 0.3115\n",
            "26:\t[0s / 7s],\t\ttrain_loss: 0.2241,\tval_loss: 0.3041\n",
            "27:\t[0s / 7s],\t\ttrain_loss: 0.2185,\tval_loss: 0.3289\n",
            "28:\t[0s / 7s],\t\ttrain_loss: 0.2235,\tval_loss: 0.3142\n",
            "29:\t[0s / 8s],\t\ttrain_loss: 0.2288,\tval_loss: 0.3352\n",
            "30:\t[0s / 8s],\t\ttrain_loss: 0.2256,\tval_loss: 0.3284\n",
            "31:\t[0s / 8s],\t\ttrain_loss: 0.2188,\tval_loss: 0.3238\n",
            "32:\t[0s / 8s],\t\ttrain_loss: 0.2418,\tval_loss: 0.3378\n",
            "33:\t[0s / 8s],\t\ttrain_loss: 0.2438,\tval_loss: 0.3322\n",
            "34:\t[0s / 9s],\t\ttrain_loss: 0.2225,\tval_loss: 0.3550\n",
            "35:\t[0s / 9s],\t\ttrain_loss: 0.2267,\tval_loss: 0.3509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 41\n",
            "{'batch_size': 64, 'batch_norm': False, 'layers': 2, 'nodes': 200, 'alpha': 0.5, 'sigma': 0.5, 'lr': 0.001, 'dropout': 0.2, 'patience': 30}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.3538,\tval_loss: 0.2895\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2951,\tval_loss: 0.2949\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.2761,\tval_loss: 0.2851\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.2712,\tval_loss: 0.2846\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.2647,\tval_loss: 0.2861\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.2610,\tval_loss: 0.2904\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.2552,\tval_loss: 0.2874\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.2544,\tval_loss: 0.2889\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.2530,\tval_loss: 0.2940\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.2503,\tval_loss: 0.2907\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.2479,\tval_loss: 0.2926\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.2357,\tval_loss: 0.2957\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.2373,\tval_loss: 0.2938\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.2304,\tval_loss: 0.2931\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.2311,\tval_loss: 0.3010\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.2199,\tval_loss: 0.2968\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.2258,\tval_loss: 0.2985\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.2181,\tval_loss: 0.2927\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.2092,\tval_loss: 0.3002\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.2089,\tval_loss: 0.3009\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.2080,\tval_loss: 0.3006\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.2116,\tval_loss: 0.3092\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.1997,\tval_loss: 0.3108\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.1985,\tval_loss: 0.3061\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.2001,\tval_loss: 0.3063\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.1888,\tval_loss: 0.3135\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.1891,\tval_loss: 0.3144\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.1868,\tval_loss: 0.3179\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.1889,\tval_loss: 0.3192\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.1834,\tval_loss: 0.3205\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.1808,\tval_loss: 0.3261\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.1788,\tval_loss: 0.3279\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.1834,\tval_loss: 0.3273\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.1712,\tval_loss: 0.3343\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 42\n",
            "{'batch_size': 128, 'batch_norm': True, 'layers': 5, 'nodes': 300, 'alpha': 0.1, 'sigma': 0.1, 'lr': 0.0001, 'dropout': 0.2, 'patience': 30}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2485,\tval_loss: 0.1574\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.2279,\tval_loss: 0.1587\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.2356,\tval_loss: 0.1602\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.2329,\tval_loss: 0.1596\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.2150,\tval_loss: 0.1595\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.2271,\tval_loss: 0.1589\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.2100,\tval_loss: 0.1599\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1948,\tval_loss: 0.1598\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 0.1975,\tval_loss: 0.1591\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 0.2047,\tval_loss: 0.1593\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.2029,\tval_loss: 0.1598\n",
            "11:\t[0s / 4s],\t\ttrain_loss: 0.2032,\tval_loss: 0.1588\n",
            "12:\t[0s / 4s],\t\ttrain_loss: 0.2021,\tval_loss: 0.1592\n",
            "13:\t[0s / 5s],\t\ttrain_loss: 0.1999,\tval_loss: 0.1589\n",
            "14:\t[0s / 5s],\t\ttrain_loss: 0.1938,\tval_loss: 0.1593\n",
            "15:\t[0s / 5s],\t\ttrain_loss: 0.1899,\tval_loss: 0.1588\n",
            "16:\t[0s / 6s],\t\ttrain_loss: 0.1890,\tval_loss: 0.1594\n",
            "17:\t[0s / 6s],\t\ttrain_loss: 0.1948,\tval_loss: 0.1602\n",
            "18:\t[0s / 6s],\t\ttrain_loss: 0.1906,\tval_loss: 0.1599\n",
            "19:\t[0s / 7s],\t\ttrain_loss: 0.1800,\tval_loss: 0.1590\n",
            "20:\t[0s / 7s],\t\ttrain_loss: 0.1875,\tval_loss: 0.1590\n",
            "21:\t[0s / 7s],\t\ttrain_loss: 0.1785,\tval_loss: 0.1589\n",
            "22:\t[0s / 7s],\t\ttrain_loss: 0.1821,\tval_loss: 0.1592\n",
            "23:\t[0s / 8s],\t\ttrain_loss: 0.1780,\tval_loss: 0.1590\n",
            "24:\t[0s / 8s],\t\ttrain_loss: 0.1770,\tval_loss: 0.1586\n",
            "25:\t[0s / 8s],\t\ttrain_loss: 0.1789,\tval_loss: 0.1594\n",
            "26:\t[0s / 9s],\t\ttrain_loss: 0.1772,\tval_loss: 0.1575\n",
            "27:\t[0s / 9s],\t\ttrain_loss: 0.1799,\tval_loss: 0.1581\n",
            "28:\t[0s / 9s],\t\ttrain_loss: 0.1610,\tval_loss: 0.1582\n",
            "29:\t[0s / 9s],\t\ttrain_loss: 0.1700,\tval_loss: 0.1587\n",
            "30:\t[0s / 10s],\t\ttrain_loss: 0.1751,\tval_loss: 0.1588\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 43\n",
            "{'batch_size': 128, 'batch_norm': True, 'layers': 1, 'nodes': 200, 'alpha': 1.0, 'sigma': 0.1, 'lr': 0.01, 'dropout': 0.3, 'patience': 40}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.7633,\tval_loss: 0.5861\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5623,\tval_loss: 0.5428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5197,\tval_loss: 0.5527\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.4642,\tval_loss: 0.5275\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.4388,\tval_loss: 0.5403\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4297,\tval_loss: 0.5472\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.4101,\tval_loss: 0.5568\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.4154,\tval_loss: 0.5614\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.4050,\tval_loss: 0.5617\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.3853,\tval_loss: 0.5723\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.3716,\tval_loss: 0.5724\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.3759,\tval_loss: 0.5904\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.3644,\tval_loss: 0.5967\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.3755,\tval_loss: 0.6034\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.3753,\tval_loss: 0.6206\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.3418,\tval_loss: 0.6345\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.3405,\tval_loss: 0.6221\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.3468,\tval_loss: 0.6485\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.3350,\tval_loss: 0.6386\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.3330,\tval_loss: 0.6485\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.3333,\tval_loss: 0.6392\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.3377,\tval_loss: 0.6703\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.3329,\tval_loss: 0.6526\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.3210,\tval_loss: 0.6423\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.3198,\tval_loss: 0.6991\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.3212,\tval_loss: 0.6761\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.3228,\tval_loss: 0.6634\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.3235,\tval_loss: 0.6934\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.3038,\tval_loss: 0.6780\n",
            "29:\t[0s / 2s],\t\ttrain_loss: 0.3090,\tval_loss: 0.7227\n",
            "30:\t[0s / 2s],\t\ttrain_loss: 0.3066,\tval_loss: 0.7045\n",
            "31:\t[0s / 2s],\t\ttrain_loss: 0.2898,\tval_loss: 0.7159\n",
            "32:\t[0s / 2s],\t\ttrain_loss: 0.2814,\tval_loss: 0.7289\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 0.2846,\tval_loss: 0.7152\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 0.2869,\tval_loss: 0.7608\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 0.3125,\tval_loss: 0.7430\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 0.2946,\tval_loss: 0.7562\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 0.2800,\tval_loss: 0.7652\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 0.2755,\tval_loss: 0.7803\n",
            "39:\t[0s / 3s],\t\ttrain_loss: 0.2839,\tval_loss: 0.7351\n",
            "40:\t[0s / 3s],\t\ttrain_loss: 0.2738,\tval_loss: 0.7438\n",
            "41:\t[0s / 3s],\t\ttrain_loss: 0.2860,\tval_loss: 0.8129\n",
            "42:\t[0s / 3s],\t\ttrain_loss: 0.2736,\tval_loss: 0.7709\n",
            "43:\t[0s / 3s],\t\ttrain_loss: 0.2716,\tval_loss: 0.7644\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 44\n",
            "{'batch_size': 128, 'batch_norm': True, 'layers': 3, 'nodes': 100, 'alpha': 1.0, 'sigma': 0.1, 'lr': 0.001, 'dropout': 0.4, 'patience': 40}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 1.0134,\tval_loss: 0.8533\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.9459,\tval_loss: 0.7843\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.8676,\tval_loss: 0.7161\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.8038,\tval_loss: 0.6408\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.7245,\tval_loss: 0.5844\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.6766,\tval_loss: 0.5683\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.6285,\tval_loss: 0.5645\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.6230,\tval_loss: 0.5653\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.5924,\tval_loss: 0.5632\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.5893,\tval_loss: 0.5622\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.5588,\tval_loss: 0.5581\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.5647,\tval_loss: 0.5535\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.5637,\tval_loss: 0.5478\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.5540,\tval_loss: 0.5462\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.5382,\tval_loss: 0.5471\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.5425,\tval_loss: 0.5489\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.5432,\tval_loss: 0.5422\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.5314,\tval_loss: 0.5402\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.5273,\tval_loss: 0.5357\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.5330,\tval_loss: 0.5360\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.5205,\tval_loss: 0.5326\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.5243,\tval_loss: 0.5340\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.5122,\tval_loss: 0.5300\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.5029,\tval_loss: 0.5277\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.5105,\tval_loss: 0.5289\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.5031,\tval_loss: 0.5299\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.4907,\tval_loss: 0.5272\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.5039,\tval_loss: 0.5277\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.5011,\tval_loss: 0.5280\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.5007,\tval_loss: 0.5244\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.4857,\tval_loss: 0.5215\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.4910,\tval_loss: 0.5201\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.4932,\tval_loss: 0.5214\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.4758,\tval_loss: 0.5216\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.4796,\tval_loss: 0.5235\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.4833,\tval_loss: 0.5213\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.4815,\tval_loss: 0.5198\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.4856,\tval_loss: 0.5176\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.4898,\tval_loss: 0.5181\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.4761,\tval_loss: 0.5158\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.4761,\tval_loss: 0.5190\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.4878,\tval_loss: 0.5173\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.4714,\tval_loss: 0.5166\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.4789,\tval_loss: 0.5141\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.4677,\tval_loss: 0.5119\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.4756,\tval_loss: 0.5119\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.4748,\tval_loss: 0.5131\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.4805,\tval_loss: 0.5118\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.4671,\tval_loss: 0.5112\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.4558,\tval_loss: 0.5122\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.4586,\tval_loss: 0.5117\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.4680,\tval_loss: 0.5145\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.4536,\tval_loss: 0.5167\n",
            "53:\t[0s / 7s],\t\ttrain_loss: 0.4653,\tval_loss: 0.5126\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.4516,\tval_loss: 0.5155\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.4544,\tval_loss: 0.5155\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.4658,\tval_loss: 0.5136\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.4578,\tval_loss: 0.5131\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.4620,\tval_loss: 0.5119\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.4720,\tval_loss: 0.5102\n",
            "60:\t[0s / 8s],\t\ttrain_loss: 0.4537,\tval_loss: 0.5134\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.4525,\tval_loss: 0.5135\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.4575,\tval_loss: 0.5141\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.4457,\tval_loss: 0.5139\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.4450,\tval_loss: 0.5110\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.4475,\tval_loss: 0.5121\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.4496,\tval_loss: 0.5128\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.4429,\tval_loss: 0.5132\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.4371,\tval_loss: 0.5160\n",
            "69:\t[0s / 9s],\t\ttrain_loss: 0.4420,\tval_loss: 0.5155\n",
            "70:\t[0s / 9s],\t\ttrain_loss: 0.4426,\tval_loss: 0.5171\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.4566,\tval_loss: 0.5187\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.4474,\tval_loss: 0.5134\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.4362,\tval_loss: 0.5167\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.4452,\tval_loss: 0.5146\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.4380,\tval_loss: 0.5167\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.4442,\tval_loss: 0.5159\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.4494,\tval_loss: 0.5145\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.4503,\tval_loss: 0.5105\n",
            "79:\t[0s / 10s],\t\ttrain_loss: 0.4281,\tval_loss: 0.5117\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.4402,\tval_loss: 0.5144\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.4430,\tval_loss: 0.5119\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.4380,\tval_loss: 0.5111\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.4388,\tval_loss: 0.5105\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.4400,\tval_loss: 0.5135\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.4458,\tval_loss: 0.5117\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.4364,\tval_loss: 0.5134\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.4352,\tval_loss: 0.5165\n",
            "88:\t[0s / 11s],\t\ttrain_loss: 0.4305,\tval_loss: 0.5149\n",
            "89:\t[0s / 11s],\t\ttrain_loss: 0.4297,\tval_loss: 0.5138\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.4299,\tval_loss: 0.5160\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.4185,\tval_loss: 0.5180\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.4322,\tval_loss: 0.5200\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.4293,\tval_loss: 0.5211\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.4305,\tval_loss: 0.5200\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.4202,\tval_loss: 0.5206\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.4304,\tval_loss: 0.5223\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.4189,\tval_loss: 0.5225\n",
            "98:\t[0s / 12s],\t\ttrain_loss: 0.4290,\tval_loss: 0.5211\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.4205,\tval_loss: 0.5209\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 45\n",
            "{'batch_size': 256, 'batch_norm': False, 'layers': 5, 'nodes': 50, 'alpha': 0.1, 'sigma': 0.5, 'lr': 0.001, 'dropout': 0.2, 'patience': 5}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1695,\tval_loss: 0.1382\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1488,\tval_loss: 0.1270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1409,\tval_loss: 0.1184\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1314,\tval_loss: 0.1152\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1339,\tval_loss: 0.1143\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1308,\tval_loss: 0.1145\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1296,\tval_loss: 0.1148\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1295,\tval_loss: 0.1145\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1272,\tval_loss: 0.1145\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.1286,\tval_loss: 0.1138\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.1255,\tval_loss: 0.1138\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.1245,\tval_loss: 0.1140\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.1235,\tval_loss: 0.1135\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.1248,\tval_loss: 0.1136\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.1229,\tval_loss: 0.1132\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.1247,\tval_loss: 0.1134\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1229,\tval_loss: 0.1135\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.1219,\tval_loss: 0.1134\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.1240,\tval_loss: 0.1133\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.1249,\tval_loss: 0.1132\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.1219,\tval_loss: 0.1131\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.1203,\tval_loss: 0.1131\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.1227,\tval_loss: 0.1133\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.1211,\tval_loss: 0.1136\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.1174,\tval_loss: 0.1136\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.1228,\tval_loss: 0.1138\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 46\n",
            "{'batch_size': 64, 'batch_norm': False, 'layers': 5, 'nodes': 200, 'alpha': 0.5, 'sigma': 1.0, 'lr': 0.0001, 'dropout': 0.4, 'patience': 5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.5573,\tval_loss: 0.3554\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.4352,\tval_loss: 0.3379\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.4140,\tval_loss: 0.3335\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.4124,\tval_loss: 0.3401\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.3890,\tval_loss: 0.3433\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.3990,\tval_loss: 0.3460\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.4084,\tval_loss: 0.3517\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.3751,\tval_loss: 0.3540\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 47\n",
            "{'batch_size': 256, 'batch_norm': True, 'layers': 1, 'nodes': 200, 'alpha': 1.0, 'sigma': 0.1, 'lr': 0.01, 'dropout': 0.4, 'patience': 20}\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.8567,\tval_loss: 0.7641\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.6224,\tval_loss: 0.6574\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5537,\tval_loss: 0.5782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:\t[0s / 0s],\t\ttrain_loss: 0.4857,\tval_loss: 0.5457\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.4682,\tval_loss: 0.5487\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.4458,\tval_loss: 0.5351\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.4444,\tval_loss: 0.5375\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.4266,\tval_loss: 0.5350\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.4258,\tval_loss: 0.5342\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.4152,\tval_loss: 0.5565\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.4183,\tval_loss: 0.5643\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.3893,\tval_loss: 0.5405\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 0.3986,\tval_loss: 0.5603\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.3852,\tval_loss: 0.5656\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.3727,\tval_loss: 0.5589\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.3651,\tval_loss: 0.5740\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 0.3774,\tval_loss: 0.5839\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 0.3662,\tval_loss: 0.5780\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.3804,\tval_loss: 0.5802\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 0.3631,\tval_loss: 0.5897\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 0.3687,\tval_loss: 0.5861\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 0.3609,\tval_loss: 0.5897\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 0.3432,\tval_loss: 0.5882\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 0.3338,\tval_loss: 0.5963\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 0.3550,\tval_loss: 0.6003\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 0.3378,\tval_loss: 0.5990\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 0.3403,\tval_loss: 0.5980\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 0.3393,\tval_loss: 0.6036\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 0.3374,\tval_loss: 0.6075\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 48\n",
            "{'batch_size': 64, 'batch_norm': True, 'layers': 2, 'nodes': 200, 'alpha': 0.1, 'sigma': 0.5, 'lr': 0.0001, 'dropout': 0.0, 'patience': 30}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1723,\tval_loss: 0.1607\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1672,\tval_loss: 0.1579\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1610,\tval_loss: 0.1558\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1564,\tval_loss: 0.1549\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1537,\tval_loss: 0.1529\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1519,\tval_loss: 0.1509\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1463,\tval_loss: 0.1488\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.1442,\tval_loss: 0.1473\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.1411,\tval_loss: 0.1450\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1391,\tval_loss: 0.1446\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.1382,\tval_loss: 0.1434\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 0.1333,\tval_loss: 0.1418\n",
            "12:\t[0s / 2s],\t\ttrain_loss: 0.1328,\tval_loss: 0.1400\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1289,\tval_loss: 0.1380\n",
            "14:\t[0s / 3s],\t\ttrain_loss: 0.1260,\tval_loss: 0.1381\n",
            "15:\t[0s / 3s],\t\ttrain_loss: 0.1275,\tval_loss: 0.1359\n",
            "16:\t[0s / 3s],\t\ttrain_loss: 0.1258,\tval_loss: 0.1355\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.1242,\tval_loss: 0.1339\n",
            "18:\t[0s / 4s],\t\ttrain_loss: 0.1172,\tval_loss: 0.1333\n",
            "19:\t[0s / 4s],\t\ttrain_loss: 0.1203,\tval_loss: 0.1325\n",
            "20:\t[0s / 4s],\t\ttrain_loss: 0.1163,\tval_loss: 0.1323\n",
            "21:\t[0s / 5s],\t\ttrain_loss: 0.1160,\tval_loss: 0.1312\n",
            "22:\t[0s / 5s],\t\ttrain_loss: 0.1157,\tval_loss: 0.1313\n",
            "23:\t[0s / 5s],\t\ttrain_loss: 0.1118,\tval_loss: 0.1309\n",
            "24:\t[0s / 5s],\t\ttrain_loss: 0.1142,\tval_loss: 0.1293\n",
            "25:\t[0s / 5s],\t\ttrain_loss: 0.1106,\tval_loss: 0.1283\n",
            "26:\t[0s / 5s],\t\ttrain_loss: 0.1100,\tval_loss: 0.1296\n",
            "27:\t[0s / 6s],\t\ttrain_loss: 0.1127,\tval_loss: 0.1281\n",
            "28:\t[0s / 6s],\t\ttrain_loss: 0.1073,\tval_loss: 0.1287\n",
            "29:\t[0s / 6s],\t\ttrain_loss: 0.1066,\tval_loss: 0.1276\n",
            "30:\t[0s / 6s],\t\ttrain_loss: 0.1052,\tval_loss: 0.1291\n",
            "31:\t[0s / 6s],\t\ttrain_loss: 0.1040,\tval_loss: 0.1283\n",
            "32:\t[0s / 6s],\t\ttrain_loss: 0.1021,\tval_loss: 0.1275\n",
            "33:\t[0s / 7s],\t\ttrain_loss: 0.1039,\tval_loss: 0.1272\n",
            "34:\t[0s / 7s],\t\ttrain_loss: 0.1004,\tval_loss: 0.1266\n",
            "35:\t[0s / 7s],\t\ttrain_loss: 0.1016,\tval_loss: 0.1266\n",
            "36:\t[0s / 7s],\t\ttrain_loss: 0.1044,\tval_loss: 0.1260\n",
            "37:\t[0s / 7s],\t\ttrain_loss: 0.0985,\tval_loss: 0.1266\n",
            "38:\t[0s / 7s],\t\ttrain_loss: 0.0962,\tval_loss: 0.1265\n",
            "39:\t[0s / 8s],\t\ttrain_loss: 0.1015,\tval_loss: 0.1265\n",
            "40:\t[0s / 8s],\t\ttrain_loss: 0.0955,\tval_loss: 0.1264\n",
            "41:\t[0s / 8s],\t\ttrain_loss: 0.0958,\tval_loss: 0.1260\n",
            "42:\t[0s / 8s],\t\ttrain_loss: 0.0952,\tval_loss: 0.1266\n",
            "43:\t[0s / 8s],\t\ttrain_loss: 0.0943,\tval_loss: 0.1262\n",
            "44:\t[0s / 8s],\t\ttrain_loss: 0.0935,\tval_loss: 0.1264\n",
            "45:\t[0s / 8s],\t\ttrain_loss: 0.0937,\tval_loss: 0.1262\n",
            "46:\t[0s / 9s],\t\ttrain_loss: 0.0929,\tval_loss: 0.1267\n",
            "47:\t[0s / 9s],\t\ttrain_loss: 0.0920,\tval_loss: 0.1257\n",
            "48:\t[0s / 9s],\t\ttrain_loss: 0.0902,\tval_loss: 0.1266\n",
            "49:\t[0s / 9s],\t\ttrain_loss: 0.0900,\tval_loss: 0.1260\n",
            "50:\t[0s / 9s],\t\ttrain_loss: 0.0910,\tval_loss: 0.1256\n",
            "51:\t[0s / 9s],\t\ttrain_loss: 0.0898,\tval_loss: 0.1261\n",
            "52:\t[0s / 10s],\t\ttrain_loss: 0.0886,\tval_loss: 0.1252\n",
            "53:\t[0s / 10s],\t\ttrain_loss: 0.0871,\tval_loss: 0.1256\n",
            "54:\t[0s / 10s],\t\ttrain_loss: 0.0918,\tval_loss: 0.1256\n",
            "55:\t[0s / 10s],\t\ttrain_loss: 0.0863,\tval_loss: 0.1255\n",
            "56:\t[0s / 10s],\t\ttrain_loss: 0.0850,\tval_loss: 0.1267\n",
            "57:\t[0s / 10s],\t\ttrain_loss: 0.0850,\tval_loss: 0.1260\n",
            "58:\t[0s / 11s],\t\ttrain_loss: 0.0833,\tval_loss: 0.1262\n",
            "59:\t[0s / 11s],\t\ttrain_loss: 0.0821,\tval_loss: 0.1257\n",
            "60:\t[0s / 11s],\t\ttrain_loss: 0.0840,\tval_loss: 0.1263\n",
            "61:\t[0s / 11s],\t\ttrain_loss: 0.0821,\tval_loss: 0.1270\n",
            "62:\t[0s / 11s],\t\ttrain_loss: 0.0829,\tval_loss: 0.1265\n",
            "63:\t[0s / 11s],\t\ttrain_loss: 0.0801,\tval_loss: 0.1262\n",
            "64:\t[0s / 11s],\t\ttrain_loss: 0.0847,\tval_loss: 0.1260\n",
            "65:\t[0s / 12s],\t\ttrain_loss: 0.0804,\tval_loss: 0.1265\n",
            "66:\t[0s / 12s],\t\ttrain_loss: 0.0812,\tval_loss: 0.1272\n",
            "67:\t[0s / 12s],\t\ttrain_loss: 0.0835,\tval_loss: 0.1261\n",
            "68:\t[0s / 12s],\t\ttrain_loss: 0.0797,\tval_loss: 0.1273\n",
            "69:\t[0s / 12s],\t\ttrain_loss: 0.0809,\tval_loss: 0.1266\n",
            "70:\t[0s / 12s],\t\ttrain_loss: 0.0788,\tval_loss: 0.1260\n",
            "71:\t[0s / 13s],\t\ttrain_loss: 0.0772,\tval_loss: 0.1275\n",
            "72:\t[0s / 13s],\t\ttrain_loss: 0.0773,\tval_loss: 0.1277\n",
            "73:\t[0s / 13s],\t\ttrain_loss: 0.0778,\tval_loss: 0.1280\n",
            "74:\t[0s / 13s],\t\ttrain_loss: 0.0780,\tval_loss: 0.1274\n",
            "75:\t[0s / 13s],\t\ttrain_loss: 0.0787,\tval_loss: 0.1279\n",
            "76:\t[0s / 13s],\t\ttrain_loss: 0.0750,\tval_loss: 0.1283\n",
            "77:\t[0s / 13s],\t\ttrain_loss: 0.0771,\tval_loss: 0.1272\n",
            "78:\t[0s / 14s],\t\ttrain_loss: 0.0768,\tval_loss: 0.1281\n",
            "79:\t[0s / 14s],\t\ttrain_loss: 0.0753,\tval_loss: 0.1277\n",
            "80:\t[0s / 14s],\t\ttrain_loss: 0.0744,\tval_loss: 0.1284\n",
            "81:\t[0s / 14s],\t\ttrain_loss: 0.0747,\tval_loss: 0.1285\n",
            "82:\t[0s / 14s],\t\ttrain_loss: 0.0724,\tval_loss: 0.1280\n",
            "Current best c-index: 0.6309718252347897\n",
            "Random search... itr: 49\n",
            "{'batch_size': 32, 'batch_norm': False, 'layers': 5, 'nodes': 200, 'alpha': 0.1, 'sigma': 1.0, 'lr': 0.01, 'dropout': 0.1, 'patience': 10}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1343,\tval_loss: 0.1298\n",
            "1:\t[0s / 1s],\t\ttrain_loss: 0.1285,\tval_loss: 0.1139\n",
            "2:\t[0s / 1s],\t\ttrain_loss: 0.1246,\tval_loss: 0.1173\n",
            "3:\t[0s / 2s],\t\ttrain_loss: 0.1239,\tval_loss: 0.1143\n",
            "4:\t[0s / 2s],\t\ttrain_loss: 0.1228,\tval_loss: 0.1171\n",
            "5:\t[0s / 3s],\t\ttrain_loss: 0.1205,\tval_loss: 0.1176\n",
            "6:\t[0s / 3s],\t\ttrain_loss: 0.1190,\tval_loss: 0.1181\n",
            "7:\t[0s / 4s],\t\ttrain_loss: 0.1196,\tval_loss: 0.1168\n",
            "8:\t[0s / 5s],\t\ttrain_loss: 0.1157,\tval_loss: 0.1167\n",
            "9:\t[0s / 5s],\t\ttrain_loss: 0.1177,\tval_loss: 0.1137\n",
            "10:\t[0s / 5s],\t\ttrain_loss: 0.1162,\tval_loss: 0.1153\n",
            "11:\t[0s / 6s],\t\ttrain_loss: 0.1171,\tval_loss: 0.1133\n",
            "12:\t[0s / 7s],\t\ttrain_loss: 0.1155,\tval_loss: 0.1146\n",
            "13:\t[0s / 7s],\t\ttrain_loss: 0.1177,\tval_loss: 0.1176\n",
            "14:\t[0s / 8s],\t\ttrain_loss: 0.1182,\tval_loss: 0.1150\n",
            "15:\t[0s / 8s],\t\ttrain_loss: 0.1162,\tval_loss: 0.1162\n",
            "16:\t[0s / 9s],\t\ttrain_loss: 0.1179,\tval_loss: 0.1149\n",
            "17:\t[0s / 9s],\t\ttrain_loss: 0.1183,\tval_loss: 0.1193\n",
            "18:\t[0s / 10s],\t\ttrain_loss: 0.1190,\tval_loss: 0.1160\n",
            "19:\t[0s / 11s],\t\ttrain_loss: 0.1164,\tval_loss: 0.1152\n",
            "20:\t[0s / 11s],\t\ttrain_loss: 0.1162,\tval_loss: 0.1282\n",
            "21:\t[0s / 12s],\t\ttrain_loss: 0.1190,\tval_loss: 0.1138\n",
            "Current best c-index: 0.6309718252347897\n",
            "Best hyperparameters: {'batch_size': 128, 'batch_norm': True, 'layers': 3, 'nodes': 100, 'alpha': 0.5, 'sigma': 0.1, 'lr': 0.0001, 'dropout': 0.2, 'patience': 40}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        }
      ],
      "source": [
        "## Boostrapped estimates 15/8/23\n",
        "\n",
        "\n",
        "from lifelines.utils import concordance_index\n",
        "def get_random_hyperparameters():\n",
        "    SET_BATCH_SIZE = [32, 64, 128, 256]\n",
        "    SET_BATCH_NORM = [True, False]\n",
        "    SET_LAYERS = [1,2,3,5]\n",
        "    SET_NODES = [50, 100, 200, 300]\n",
        "    SET_ALPHA = [0.1, 0.5, 1.0]\n",
        "    SET_SIGMA = [0.1, 0.5, 1.0]\n",
        "    SET_LR = [1e-4, 1e-3, 1e-2]\n",
        "    SET_DROPOUT = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "    SET_PATIENCE = [5, 10, 20, 30, 40, 50]\n",
        "\n",
        "    return {\n",
        "        'batch_size': SET_BATCH_SIZE[np.random.randint(len(SET_BATCH_SIZE))],\n",
        "        'batch_norm': SET_BATCH_NORM[np.random.randint(len(SET_BATCH_NORM))],\n",
        "        'layers': SET_LAYERS[np.random.randint(len(SET_LAYERS))],\n",
        "        'nodes': SET_NODES[np.random.randint(len(SET_NODES))],\n",
        "        'alpha': SET_ALPHA[np.random.randint(len(SET_ALPHA))],\n",
        "        'sigma': SET_SIGMA[np.random.randint(len(SET_SIGMA))],\n",
        "        'lr': SET_LR[np.random.randint(len(SET_LR))],\n",
        "        'dropout': SET_DROPOUT[np.random.randint(len(SET_DROPOUT))],\n",
        "        'patience': SET_PATIENCE[np.random.randint(len(SET_PATIENCE))],\n",
        "    }\n",
        "\n",
        "\n",
        "# Main loop\n",
        "max_valid = 0.0\n",
        "best_model = None\n",
        "best_hyperparameters = None\n",
        "\n",
        "for r_itr in range(RS_ITERATION):\n",
        "    print(f'Random search... itr: {r_itr}')\n",
        "    hyperparameters = get_random_hyperparameters()\n",
        "    print(hyperparameters)\n",
        "\n",
        "    # Use chosen hyperparameters\n",
        "    num_nodes = [hyperparameters['nodes']] * hyperparameters['layers']\n",
        "    batch_norm = hyperparameters['batch_norm']\n",
        "    dropout = hyperparameters['dropout']\n",
        "\n",
        "    net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
        "\n",
        "    model = DeepHitSingle(net, tt.optim.Adam, alpha=hyperparameters['alpha'], sigma=hyperparameters['sigma'], duration_index=labtrans.cuts)\n",
        "\n",
        "    batch_size = hyperparameters['batch_size']\n",
        "    model.optimizer.set_lr(hyperparameters['lr'])\n",
        "\n",
        "    epochs = 100\n",
        "    callbacks = [tt.callbacks.EarlyStopping(patience=hyperparameters['patience'])]\n",
        "    log = model.fit(x_train, y_train, batch_size, epochs, callbacks, val_data=val)\n",
        "\n",
        "    # Validate the model\n",
        "    surv = model.predict_surv_df(x_val)\n",
        "    ev = EvalSurv(surv, durations_val, events_val, censor_surv='km')\n",
        "    c_index = ev.concordance_td('antolini')\n",
        "\n",
        "    # If this model is better, save it\n",
        "    if c_index > max_valid:\n",
        "        max_valid = c_index\n",
        "        best_model = model\n",
        "        best_hyperparameters = hyperparameters\n",
        "\n",
        "    print(f'Current best c-index: {max_valid}')\n",
        "\n",
        "print(f'Best hyperparameters: {best_hyperparameters}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKjwEPJRbZeV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "74bfef1a-c454-4086-f232-631a2d62603e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.5760,\tval_loss: 0.5125\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5717,\tval_loss: 0.5138\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5840,\tval_loss: 0.5110\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5644,\tval_loss: 0.5079\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5683,\tval_loss: 0.5010\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5597,\tval_loss: 0.4988\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.5554,\tval_loss: 0.4968\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.5471,\tval_loss: 0.4953\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.5458,\tval_loss: 0.4912\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.5295,\tval_loss: 0.4887\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.5349,\tval_loss: 0.4870\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.5381,\tval_loss: 0.4863\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.5235,\tval_loss: 0.4835\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.5240,\tval_loss: 0.4805\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.5173,\tval_loss: 0.4783\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.5136,\tval_loss: 0.4762\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.5142,\tval_loss: 0.4730\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.5056,\tval_loss: 0.4714\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.5112,\tval_loss: 0.4694\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.5057,\tval_loss: 0.4670\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.5103,\tval_loss: 0.4656\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.4986,\tval_loss: 0.4638\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.5008,\tval_loss: 0.4616\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.4973,\tval_loss: 0.4588\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.4953,\tval_loss: 0.4581\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.4879,\tval_loss: 0.4562\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.4868,\tval_loss: 0.4538\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.4858,\tval_loss: 0.4508\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.4781,\tval_loss: 0.4484\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.4784,\tval_loss: 0.4464\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.4802,\tval_loss: 0.4440\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.4638,\tval_loss: 0.4425\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.4750,\tval_loss: 0.4395\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.4644,\tval_loss: 0.4368\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.4694,\tval_loss: 0.4340\n",
            "35:\t[0s / 5s],\t\ttrain_loss: 0.4617,\tval_loss: 0.4328\n",
            "36:\t[0s / 5s],\t\ttrain_loss: 0.4549,\tval_loss: 0.4310\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.4612,\tval_loss: 0.4288\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.4532,\tval_loss: 0.4259\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.4487,\tval_loss: 0.4242\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.4590,\tval_loss: 0.4229\n",
            "41:\t[0s / 6s],\t\ttrain_loss: 0.4408,\tval_loss: 0.4203\n",
            "42:\t[0s / 6s],\t\ttrain_loss: 0.4417,\tval_loss: 0.4184\n",
            "43:\t[0s / 6s],\t\ttrain_loss: 0.4451,\tval_loss: 0.4164\n",
            "44:\t[0s / 6s],\t\ttrain_loss: 0.4380,\tval_loss: 0.4135\n",
            "45:\t[0s / 6s],\t\ttrain_loss: 0.4332,\tval_loss: 0.4112\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.4362,\tval_loss: 0.4100\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.4243,\tval_loss: 0.4065\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.4277,\tval_loss: 0.4050\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.4220,\tval_loss: 0.4038\n",
            "50:\t[0s / 7s],\t\ttrain_loss: 0.4176,\tval_loss: 0.4020\n",
            "51:\t[0s / 7s],\t\ttrain_loss: 0.4098,\tval_loss: 0.3998\n",
            "52:\t[0s / 7s],\t\ttrain_loss: 0.4145,\tval_loss: 0.3993\n",
            "53:\t[0s / 7s],\t\ttrain_loss: 0.4108,\tval_loss: 0.3970\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.4067,\tval_loss: 0.3957\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.4045,\tval_loss: 0.3946\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.4048,\tval_loss: 0.3921\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.4074,\tval_loss: 0.3894\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.3974,\tval_loss: 0.3881\n",
            "59:\t[0s / 8s],\t\ttrain_loss: 0.4038,\tval_loss: 0.3868\n",
            "60:\t[0s / 8s],\t\ttrain_loss: 0.4014,\tval_loss: 0.3847\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.3981,\tval_loss: 0.3830\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.4003,\tval_loss: 0.3827\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.3861,\tval_loss: 0.3817\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.3865,\tval_loss: 0.3791\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.3915,\tval_loss: 0.3774\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.3810,\tval_loss: 0.3781\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.3740,\tval_loss: 0.3752\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.3730,\tval_loss: 0.3738\n",
            "69:\t[0s / 9s],\t\ttrain_loss: 0.3839,\tval_loss: 0.3737\n",
            "70:\t[0s / 9s],\t\ttrain_loss: 0.3784,\tval_loss: 0.3711\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.3772,\tval_loss: 0.3697\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.3711,\tval_loss: 0.3681\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.3699,\tval_loss: 0.3676\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.3626,\tval_loss: 0.3659\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.3648,\tval_loss: 0.3643\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.3664,\tval_loss: 0.3640\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.3443,\tval_loss: 0.3625\n",
            "78:\t[0s / 10s],\t\ttrain_loss: 0.3470,\tval_loss: 0.3633\n",
            "79:\t[0s / 10s],\t\ttrain_loss: 0.3506,\tval_loss: 0.3622\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.3598,\tval_loss: 0.3612\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.3510,\tval_loss: 0.3599\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.3533,\tval_loss: 0.3599\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.3426,\tval_loss: 0.3593\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.3454,\tval_loss: 0.3587\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.3375,\tval_loss: 0.3568\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.3387,\tval_loss: 0.3599\n",
            "87:\t[0s / 11s],\t\ttrain_loss: 0.3399,\tval_loss: 0.3596\n",
            "88:\t[0s / 11s],\t\ttrain_loss: 0.3396,\tval_loss: 0.3626\n",
            "89:\t[0s / 11s],\t\ttrain_loss: 0.3421,\tval_loss: 0.3614\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.3330,\tval_loss: 0.3659\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.3359,\tval_loss: 0.3636\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.3248,\tval_loss: 0.3650\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.3251,\tval_loss: 0.3612\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.3273,\tval_loss: 0.3634\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.3269,\tval_loss: 0.3619\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.3238,\tval_loss: 0.3629\n",
            "97:\t[0s / 12s],\t\ttrain_loss: 0.3278,\tval_loss: 0.3669\n",
            "98:\t[0s / 12s],\t\ttrain_loss: 0.3353,\tval_loss: 0.3670\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.3258,\tval_loss: 0.3707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Concordance index on test set: 0.4697187262437706\n",
            "Integrated Brier Score on test set: 0.12058501611115789\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "###T#15/8/23\n",
        "num_nodes = [best_hyperparameters['nodes']] * best_hyperparameters['layers']\n",
        "batch_norm = best_hyperparameters['batch_norm']\n",
        "dropout = best_hyperparameters['dropout']\n",
        "\n",
        "best_net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
        "\n",
        "best_model = DeepHitSingle(best_net, tt.optim.Adam, alpha=best_hyperparameters['alpha'], sigma=best_hyperparameters['sigma'], duration_index=labtrans.cuts)\n",
        "\n",
        "batch_size = best_hyperparameters['batch_size']\n",
        "best_model.optimizer.set_lr(best_hyperparameters['lr'])\n",
        "\n",
        "# Train on the entire training set\n",
        "epochs = 100\n",
        "callbacks = [tt.callbacks.EarlyStopping(patience = best_hyperparameters['patience'] )]\n",
        "log = best_model.fit(x_train, y_train, batch_size, epochs, callbacks, val_data=val)\n",
        "_ = log.plot()\n",
        "\n",
        "# Evaluate on the test set\n",
        "surv = best_model.predict_surv_df(x_test)\n",
        "ev_test = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
        "c_index_test = ev_test.concordance_td('antolini')\n",
        "\n",
        "print(f'Concordance index on test set: {c_index_test}')\n",
        "\n",
        "# Calculate the integrated Brier score\n",
        "ibs = ev_test.integrated_brier_score(time_grid=np.linspace(0, durations_test.max(), 100))\n",
        "\n",
        "print(f'Integrated Brier Score on test set: {ibs}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# num_nodes = [best_hyperparameters['nodes']] * best_hyperparameters['layers']\n",
        "# batch_norm = True if best_hyperparameters['activation_fn'] == 'relu' else False\n",
        "# dropout = [best_hyperparameters['dropout']]\n",
        "\n",
        "# best_net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
        "\n",
        "# best_model = DeepHitSingle(best_net, tt.optim.Adam, alpha=best_hyperparameters['alpha'], sigma=best_hyperparameters['sigma'], duration_index=labtrans.cuts)\n",
        "\n",
        "# batch_size = best_hyperparameters['batch_size']\n",
        "# best_model.optimizer.set_lr(best_hyperparameters['lr'])\n",
        "\n",
        "# # Train on the entire training set\n",
        "# epochs = 100\n",
        "# callbacks = [tt.callbacks.EarlyStopping(patience = best_hyperparameters['patience'])]\n",
        "# log = best_model.fit(x_train, y_train, batch_size, epochs, callbacks, val_data=val)\n",
        "# _ = log.plot()\n",
        "\n",
        "# # Evaluate on the test set\n",
        "# surv = best_model.predict_surv_df(x_test)\n",
        "# ev_test = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
        "# c_index_test = ev_test.concordance_td('antolini')\n",
        "\n",
        "# print(f'Concordance index on test set: {c_index_test}')\n",
        "\n",
        "# # Calculate the integrated Brier score\n",
        "# ibs = ev_test.integrated_brier_score(time_grid=np.linspace(0, durations_test.max(), 100))\n",
        "\n",
        "# print(f'Integrated Brier Score on test set: {ibs}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "id": "IxHYuc2ityGr",
        "outputId": "5e44a365-de2a-43e9-86c7-869b90263dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1834,\tval_loss: 0.1507\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1532,\tval_loss: 0.1360\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1334,\tval_loss: 0.1297\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.1334,\tval_loss: 0.1277\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.1300,\tval_loss: 0.1598\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.1340,\tval_loss: 0.1315\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.1275,\tval_loss: 0.1273\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.1302,\tval_loss: 0.1316\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.1390,\tval_loss: 0.1310\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.1330,\tval_loss: 0.1327\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 0.1435,\tval_loss: 0.1394\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.1397,\tval_loss: 0.1356\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.1442,\tval_loss: 0.1310\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.1403,\tval_loss: 0.1325\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.1324,\tval_loss: 0.1281\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.2045,\tval_loss: 0.1473\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.1513,\tval_loss: 0.1442\n",
            "Concordance index on test set: 0.648731593321508\n",
            "Integrated Brier Score on test set: 0.0896078084305159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGhCAYAAACUFDUXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACTaElEQVR4nOzdd3iUVfbA8e87LZNMOmlAgBBK6CC9CaK4ir2gi5XFVVHRdbGs5afuYlmRXWzYC4KIomtBRUSxooAURWqoIZCQ3vvMZOb9/TGZgUhJJpnJlJzP8/ggk5n3vZeBzMm9556jqKqqIoQQQggRoDS+HoAQQgghRGtIMCOEEEKIgCbBjBBCCCECmgQzQgghhAhoEswIIYQQIqBJMCOEEEKIgCbBjBBCCCECms7XA/C2LVu2oKoqer3e10MRQgghRDNZrVYUReG0005r8rlBvzKjqireqguoqioWi8Vr1/c1mV/gC/Y5yvwCX7DPMdjnB96bozuf30G/MuNckRk4cKDHr11TU0N6ejo9e/YkLCzM49f3NZlf4Av2Ocr8Al+wzzHY5wfem+P27dub/dygX5kRQgghRHCTYEYIIYQQAU2CGSGEEEIENAlmhBBCCBHQJJgRQgghREAL+tNM7rDZbFit1mY/32w2u37VaIIvLgz2+dlsNl8PQQghhAdIMIPjLHteXh5lZWVuvc5ut6PT6cjJyQnKD/v2MD8gqOs/CCFEeyDBDLgCmYSEBMLCwlAUpVmvs9lsmM1mQkJC0Gq1Xh5l2wvm+amqSlVVFbm5uRQXF2MymXw9JCGEEC3U7oMZm83mCmQ6dOjg9msBjEZj0H3YQ/DPz2AwYLVaKS0txWazBeUchRCiPQi+vQM3OXNkgrUyozi1kJAQALdypYQQQviXdh/MODV3a0kEF3nfhRAi8EkwI4QQQoiAJsGMEEIIIQKaBDNB5JtvvmHp0qUeveb555/P448/7tFrfvzxx6SlpVFSUuLR6wohhGif5SYkmAki33zzDe+9955Hrzl//nxmzJjh0WsKIYTwjuU/7ufqh7/kYE65r4fSpiSYaWdUVcVisTT7+X369KFz585eHJEQQghP2bAzj6paK7/vLfT1UNqUBDNB4v777+eTTz5h3759pKWlkZaWxv3338/999/PBRdcwI8//shFF13EwIED+e6776ipqeHRRx/lnHPOYfDgwZx55pk88sgjVFZWNrruH7eZnNfbsGEDl1xyCUOGDGHq1Kns2LGjVeMvKyvjgQceYNSoUQwaNIhp06axadOmRs/59ddfueaaaxg2bBinnXYaF154IZ988kmzvy6EEMGurNLRhqagtMbHI2lb7b5o3smoqorZcurePTa7jTqLDTT1aDWe26MMMWjdPjJ82223UVJSQkZGBv/9738BiI2N5aWXXqKgoIDHH3+cW2+9lY4dO9KpUyfq6uqw2WzMnj2b2NhYcnNzeeWVV7jttttYsmTJKe9VWFjI448/zs0330xERATz58/n9ttvZ/Xq1ej1erfna7PZuOmmm8jKyuKee+4hLi6OJUuWMGPGDJYtW8aAAQOoqqpi5syZDBs2jKeffhqDwcD+/fupqKgAaPLrQgjRHriCmZJaH4+kbUkwcwKqqnLfCz+TnumbBNW+KbE8dft4twKarl27EhsbS05ODkOGDGn0tfLycl5//XUGDx7c6PE5c+a4/r++vp7k5GSuvvpqDh48SPfu3U96r/Lyct555x169eoFQGhoKNdffz1bt25l+PDhzR6z0w8//MC2bdt44403OP300wEYP348f/rTn3j11VdZsGABBw8epLKykrvuuou0tDQAxowZ47pGU18XQohgZ623U1XrKADa3lZmZJupHYiOjj4ukAFYvnw5l1xyCaeddhr9+/fn6quvBiAzM/OU10tISHAFMgA9e/YEID8/v0Xj27x5M+Hh4a5ABkCv13P22Wfz66+/Ao5gLTw8nH/961+sXLnyuJNQTX1dCCGCXXmV2fX/he0smJGVmRNQFIWnbh/fvG2mOjNGYwhajef6+rRkm+lU4uLijnts9erV3Hffffz5z39m9uzZREdHU1hYyKxZszCbzSe4ylGRkZGNfu/cWmrqdSdTUVFxwr5YcXFxlJc7MvKjoqJ46623eP755/nHP/6BzWZj+PDhPPTQQ6SlpTX5dSGECHbOLSaA6rp6qmutmELd3/oPRBLMnISiKBhDTv3HY7MpYK/HaND5dZPCEwVGq1atom/fvjz66KOuxzZu3NiWw3KJioqiuLj4uMeLioqIiopy/X7QoEG88cYb1NXVsWHDBp566ilmzZrFN99806yvCyFEMCutrGv0+4LSGrqHRp3k2cFFtpmCiF6vb/bqSF1d3XHJup9//rk3htWkYcOGUVVVxc8//+x6rL6+nm+++YZhw4Yd93yj0cjEiRO56qqryM7OPm7OTX1dCCGC0bErMwCFpe0nCVhWZoJIjx49+Oijj1ixYgXdunUjJibmpM8dO3Ysjz76KC+++CKnnXYaP/74I+vXr2/D0R51xhlnMGjQIO69917uvvtu12mmgoICnn/+ecCRJPzhhx8yefJkOnXqRFFREe+88w5Dhw4lJCSkya8LIUSwK6tqHMzkl7SfvBkJZoLI1KlT2bZtG4899hhlZWVceumlJ33utGnTyM7O5p133uHNN99k/PjxzJ8/nyuvvLINR+yg1Wp57bXXmDdvHv/5z3+oqamhf//+LFy4kAEDBgCOBF+NRsOzzz5LcXEx0dHRjB8/nrvuuqtZXxdCiGD3x5WZ9nSiSVGDvInD9u3bARg4cOAJv15XV+c6imw0Gt26ts1mo66uDqPR6Nc5My3VHuZXXl5Obm4uPXr0cPv9DwQ1NTWkp6fTt29fwsLCfD0cj5P5Bb5gn2Nbzu8/Szaz5vcjJMSEUlBay7hBnbh/+giv3hO8N8emPr+PJTkzQgghRBBwbjP16upIMWhPKzMSzAiPstvt1NfXn/S/IF8IFEIInylt2GZKawhmJAFYiBZ68cUXeeGFF0769SeffJLLLrusDUckhBDtgzNnpndDMFNWZcZstRGiD740gT9yO5g5cOAAjz/+OFu2bMFkMnHxxRfz97//HYPBcNLXFBQUsGjRItauXcvhw4eJiIhgxIgR3HXXXcd1ZM7Pz+fxxx/n559/dlWBfeCBBwgPD3d/dqLNXXnllZxxxhkn/XpycnLbDUYIIdqJepudyhoLAJ3jwwkN0VFrrqewtIbkhAgfj8773ApmysvLmT59OikpKSxYsID8/Hzmzp1LXV0djzzyyElft3PnTlavXs3ll1/O4MGDKS0t5eWXX+aKK65gxYoVxMbGAmC1WrnxxhsBmD9/PnV1dTz11FPcfffdvPrqq62YpmgriYmJJCYm+noYQgjRrjhbGWgUiDAZSIgJ5VBeJQUltRLM/NGyZcuorq7mhRdeIDo6GnCcCJkzZw4zZ8486YfYsGHD+PLLL9Hpjt5u6NChnHHGGSxfvpwbbrgBgK+++op9+/axcuVKUlNTAUfp/L/+9a9s27aNQYMGtWSOQgghRFBzbjFFhoeg1SjEx4Q5gpl2kgTsVgLwmjVrGDNmjCuQAZgyZQp2u521a9ee9HWRkZGNAhmApKQkYmNjKSgoaHT9tLQ0VyADMG7cOKKjo/nxxx/dGaoQQgjRbjhPMkWHO4qEJsSEAu3nRJNbwUxGRkajQAMcgUp8fDwZGRlu3fjgwYMUFxfTo0ePU15fURS6d+/u9vWFEEKI9sK5MhMd4QhmEmMd9V7ay4kmt7aZKioqjuuYDI5Ggc7uxs2hqiqPP/44CQkJnH/++Y2uHxFx/N6eu9c/0f1qak4cnZrNZux2OzabDZvt1F2yT3Rd56/uvjYQtKf51dbWYrfbfTwiz6utrW30a7CR+QW+YJ9jW82voKQKgIhQHTU1NUSFOU4w5RVXnfTzz1O8NUdVVU/YKPlEfHI0e8GCBfzyyy+88cYbbVLx0Wq1kp6eftKv63S6VjUjDPZGhsE+P5vNFvQrf5mZmb4eglfJ/AJfsM/R2/M7eLgMgHpzJenp6VSVOb5v5xRWnvLzz5O8McdTnZQ+llvBTGRkJJWVlcc9Xl5eTlRU89qMf/DBB7z44os88cQTjBkz5rjrV1VVnfD6HTt2dGeojej1enr27HnCr5nNZnJycggJCXG7nL2qqpjNZkJCQpodPQaS9jI/rVZL165dg7IhZW1tLZmZmaSkpBAaGurr4XiczC/wBfsc22p+3+zYDlSR2q0jffum0LHSzBtfF1JZa6NX7zR0Wu/VyPXWHPfv39/s57oVzKSmph73E2xlZSWFhYXH5bqcyOrVq/nXv/7F3/72N6ZOnXrC6+/du7fRY6qqcvDgQcaNG+fOUBtRFOWkK0AajQaNRoNWq3W7/5Bz60VRlKDpXbRhwwauv/56PvzwQ/r16wecen4ff/wxDzzwAOvXr3cdsQ8Ux75/oaGhQdmbySk0NDQo+944yfwCX7DP0dvzq6p1fD9LiA0nLCwMozEUvU6Dtd5OjUUhqYP3/2w9PUd3foh2K1SbMGEC69ato6KiwvXYqlWr0Gg0TQYbGzZs4K677uKKK65g1qxZJ73+7t27Gy1VrV+/nrKyMiZOnOjOUIUQQoh24+hpJscPZRqNQny0Y5WkPSQBuxXMTJs2DZPJxKxZs/j555/56KOPmDdvHtOmTWtUY2b69OmcffbZrt8fOHCAWbNmkZKSwsUXX8zvv//u+u/w4cOu551zzjn06tWLO+64g++//56VK1fy4IMPcsYZZ0iNGSGEEOIk/niaCSCh4URTezie7dY2U1RUFIsXL+axxx5j1qxZmEwmpk6dyuzZsxs9z3k6yGnr1q1UVlZSWVnJVVdd1ei5l156KXPnzgUcuS1vvPEGjz/+OHfddRc6nY6zzz6bBx98sKXzazFVVVGtp058tdtsqFYzdg0oHtxmUvTu56h8/PHHPPTQQ6xZs4a4uDjX42VlZYwfP56HHnqItLQ0Xn31VXbs2EFVVRXdunVjxowZXHLJJR4bu/OeTz31FN999x21tbX069ePu+++mxEjjrai//XXX3n66afZvXs3drud5ORkbrjhBi699NJmfV0IIYSDza5SUX2CYCbGGcwE/8qM26eZevTowaJFi075nCVLljT6/WWXXdbs5oKJiYksWLDA3WF5lKqq5Lz9f5iz9/jk/iHJfeh0/eNuBTRnn302//znP1m1ahXXXnut6/Gvv/4agHPPPZe1a9cydOhQrrrqKgwGA7/99hsPPfQQqqp6LEiw2WzcdNNNZGVlcc899xAXF8eSJUuYMWMGy5YtY8CAAVRVVTFz5kyGDRvG008/jcFgYP/+/a7ty6a+LoQQ4qiKajN2FRQFokxHT/84C+cVyspMexZYp3ciIiKYOHEiK1asaBTMrFixwlVF+diaPqqqMmLECPLz83n//fc9Fsz88MMPbNu2jTfeeIPTTz8dgPHjx/OnP/2JV199lQULFnDw4EEqKyu56667SEtLA2h0sq2prwshhDjKucUUEWZAe8yppfgY2WZq1xRFodP1jze5zWSz2VxHlz15mqkl20wA559/PrNnzyYnJ4dOnTpRUFDApk2beOqppwDHEfcFCxbw7bffkp+f79oKPLY9RWtt3ryZ8PBwVyADuLqfr1ixAoCuXbsSHh7Ov/71L6677jpGjx7d6CRUU18XQghx1InyZeCYlgYlwb/N5L2D5wFOURQ0BmOT/yn6kGY9z53/WlrTZdKkSYSGhvLFF18A8OWXXxISEsLkyZMBuP/++1mxYgU33HADb775Jh9++CGXX345FovFY39uFRUVdOjQ4bjH4+LiXFWco6KieOuttzCZTPzjH/9g3LhxXHfddezZs6dZXxdCCHHUH/syOTlzZgrLarHb1TYfV1uSYCaIGI1GJk+ezMqVKwFYuXIlkyZNIiwsDLPZzA8//MCtt97Kddddx5gxYxg4cKCrpL+nREVFUVxcfNzjRUVFjQorDho0iDfeeIPNmzfzyiuvUFxc3OjIflNfF0II4XCylZkOUUY0GoV6m53SyjpfDK3NSDATZC644AJ27drFTz/9xO+//+7Kk7FYLNjtdvR6veu5VVVVfPfddx69/7Bhw6iqquLnn392PVZfX88333zDsGHDjnu+0Whk4sSJXHXVVWRnZx/XOqGprwshRHt3smBGq9UQF+WoOxPstWYkZybIjB07lujoaB588EEiIyOZMGEC4EgQHjhwIK+//jqxsbHodDpee+01wsPDKSkp8dj9nTWB7r33Xu6++27XaaaCggKef/55wJEk/OGHHzJ58mQ6depEUVER77zzDkOHDiUkJKTJrwshhDjqZNtM4EgCLiitpaC0hj4pwZt7KMFMkNHr9Zxzzjm8//77TJ06tVGTrvnz5/PII49w//33Ex0dzXXXXUdNTQ0LFy702P21Wi2vvfYa8+bN4z//+Q81NTX079+fhQsXMmDAAMCR4KvRaHj22WcpLi4mOjqa8ePHc9dddzXr60IIIY5yrszERBwfzCTEhLKT4K81I8FMEHr00Ud59NFHj3u8W7duLF68+LjH77jjDtf/jxo1ypVoe2zhw5M5UQ2hmJgYnnzyyZO+JjU11bVK05KvCyGEOOroNtPx/eUS2snxbMmZEUIIIQJYWZUjufdk20wABSXBHczIyow4KbvdTn19PfX19Sc89aTValt8jFwIIUTr2e0qZVWO8hp/TACGY2rNyDaTaK9eeuklXnrppZN+/cknn2x2mwohhBCeV1ljcdWQiTrByoyz2WRhaQ2qqgbtD6ASzIiTuvLKKxk7diwGgwGN5vgdyeTkZB+MSgghhJPzJFN4qB697vjv0/HRjpWZOouNyhorkcf0bgomEsyIk0pISCAyMhKj0ejRdg1CCCE842Q1ZpwMei0xESGUVpopKK0J2mBGEoAbeLoSrggM8r4LIQJZU8EMHNPWIIhPNLX7YMZZEbemJnjfZHFyzorCx1ZGFkKIQHGqgnlO8Q1JwPlB3HCy3W8zabVaoqOjKSgoACAsLKzZCVLOrtnO6wSbYJ6fqqpUVVVRVFREdHR00M1PCNE+yMqMQ7sPZgCSkpIAXAFNczmPLut0uhMmyAa69jA/q9V6wi7fQggRCJoXzDiPZ0swE9QURaFjx44kJCRgtVqb/bra2loyMjLo2rUroaGhXhyhbwT7/KxWK3v37g3ao4pCiOB3dJvp+Oq/TvGxzirAss3ULmi1Wre2G+x2OwAhISEYjSf/ixSo2sv8hBAiUJVVOqr/nqgvk1NiO9hmCr69AyGEEKKdaM42kzMBuLLGSq25vk3G1dYkmBFCCCECkKoe08rgFKeZwox6wkMdJzaDNW9GghkhhBAiAFXXWqm3ObbLT7UyA8d0zw7ShpMSzAghhBABqLRhiynMqMOgP3W+Z3yQN5yUYEYIIYQIQM0pmOd0bMPJYCTBjBBCCBGAmpP865QgKzNCCCGE8DfuBTPOWjOyMiOEEEIIP+HWNlOQ15qRYEYIIYQIQEdXZpouaupMAC6pMGOx2rw6Ll+QYEYIIYQIQO5sM0WaDIQYHCeeisqCL29GghkhhBAiAJVVOVoZNGebSVGUoG44KcGMEEIIEYCcKzOn6st0rPiY4G046XYwc+DAAWbMmMGQIUMYN24c8+bNw2KxNPm6pUuXMnPmTEaPHk1aWhqrVq064fO2bNnC1VdfzaBBgxg7diyPPfYYtbXB9wcvhBBCtJSqqm5tM8HRhpPtfmWmvLyc6dOnY7VaWbBgAbNnz+aDDz5g7ty5Tb72008/pbS0lIkTJ570OUeOHOEvf/kLoaGhruuvWLGC++67z51hCiGEEEGt1lyPpb6hlUEztpngaBJwYRCuzOjcefKyZcuorq7mhRdeIDo6GgCbzcacOXOYOXMmiYmJp3ytRqMhOzub5cuXn/A5r776KpGRkbz88ssYDAYAIiMj+dvf/sauXbvo16+fO8MVQgghgpJzVcZo0GIMad5HeTDXmnFrZWbNmjWMGTPGFcgATJkyBbvdztq1a099I03Tt0pPT2fEiBGuQAZg/PjxAHz33XfuDFUIIYQIWqVubjFBcDebdGtlJiMjg8svv7zRY5GRkcTHx5ORkdHqwZjN5kaBDIBer0dRlFZdX1VVamo8/+Y5c3mCNadH5hf4gn2OMr/AF+xz9Nb8CoorAIgM0zf78y3CsctEUXkdlZVVaLWeOQPkrTmqqoqiKM16rlvBTEVFBZGRkcc9HhUVRXl5uTuXOqGUlBS2b9/eaALbtm1DVdVWXd9qtZKent7q8Z1MZmam167tD2R+gS/Y5yjzC3zBPkdPz2/3/ioANKq52Z9vdlVFowG7XWXjlp1Em9wKAZrkjffwjwscJ+PZmbTSVVddxV/+8hfmz5/PDTfcQEFBAXPmzEGrPXVr86bo9Xp69uzpoVEeVVtbS2ZmJikpKYSGhnr8+r4m8wt8wT5HmV/gC/Y5emt+23MOAGUkd+xA3759m/26+KgS8ktriY5Lpm9KjEfG4q057t+/v9nPdSuYiYyMpLKy8rjHy8vLiYqKcudSJzRmzBjuueceXnjhBV5//XU0Gg3Tpk1Dr9eTkJDQ4usqikJYWFirx3cyoaGhXr2+r8n8Al+wz1HmF/iCfY6enl+12XGSKS463K3rJnYwkV9aS0Wt3eN/3p6eY3O3mMDNYCY1NfW43JXKykoKCwtJTU1151InddNNN3HNNdeQlZVFfHw8kZGRjB49miuvvNIj1xdCCCECXVllQ/VfNxKAIXhPNLmV/TNhwgTWrVtHRUWF67FVq1ah0WgYN26cxwYVFhZGWloasbGxLF++HFVVmTJliseuL4QQQgQydwvmOblaGpQEV8K1Wysz06ZNY8mSJcyaNYuZM2eSn5/PvHnzmDZtWqMaM9OnTycnJ4fVq1e7Htu+fTtHjhyhpKQEgK1btwIQGxvLyJEjAcjKymL58uUMGjQIgF9++YW3336bf//73x7ZxhJCCCGCQVlVQzDTzIJ5TvFBujLjVjATFRXF4sWLeeyxx5g1axYmk4mpU6cye/bsRs+z2+3YbI1bjC9dupRPPvnE9fuFCxcCMHLkSJYsWQI4EnU3btzI4sWLsVqt9OnThxdeeIFJkya1aHJCCCFEMHK3L5NTQqyzCnA7DmYAevTowaJFi075HGdwcqy5c+c22fYgKSnphK8VQgghhEOduZ46i2PBoKU5M4WltW7VcfF30jVbCCGECCDOLSaDTkNoM1sZOHWICkVRwFJvd10nGEgwI4QQQgSQY5N/3V1Z0es0dIg0AsHVcFKCGSGEECKAtKQv07GCMQlYghkhhBAigBw9yWRs0euDseGkBDNCCCFEAGlpjRkn54mmAtlmEkIIIYQvtLT6r5NsMwkhhBDCp1paMM/JWQVYEoCFEEII4ROt3maSlRkhhBBC+FJrg5n4hpWZmrp6qmqtHhuXL0kwI4QQQgSQ1m4zGQ06osINQPCcaJJgRgghhAgQFquNmrp6wP2+TMcKtiRgCWaEEEKIAOHcYtJpNZhC9S2+jjMJWIIZIYQQQrSpo1tMhlY1iTy24WQwkGBGCCGECBCtTf51ipeVGSGEEEL4wtG+TC1rZeB09Hi2rMwIIYQQog2VVTVU/23hSSanxFjnNpOszAghhBCiDXlum8kRzJRXWagz17d6XL4mwYwQQggRIDwVzISH6gkz6gAoLAv8rSYJZoQQQogA0dqCeccKprYGEsy0kKqq7Mgooc5q9/VQhBBCtBOeWpmBY080ycpMu7V+ey6PvfUrq7eU+3ooQggh2glPBjNHa83Iyky7ZTQ49hoP5pl9PBIhhBDtgbXe7moM6dFtphJZmWm3eneNBqCkqp7KGotvByOEECLolTfky2g0ChFhhlZfLyE2eArnSTDTQuFhBjp2cES1+7MrfDwaIYQQwc61xRRuQKNpeSsDJ0kAFgD0TI4CYH+25M0IIYTwrqMnmVpX/dfJmQBcUlGHtT6wD7NIMNMKvbpIMCOEEKJtlFU2VP/1QPIvOPJuDDoNqgrF5YGdNyPBTCv0TI4EHNtMqqr6eDRCCCGCWakHTzIBKIoSNA0nJZhphW6JEWg1UFVrJbeo2tfDEUIIEcQ8WTDPKT5ITjRJMNMKOp2GjjGOjPK9h0t9PBohhBDBzJM1ZpyCpeGkBDOt1DnOEczskWBGCCGEF3kjmHFuM+W3t2DmwIEDzJgxgyFDhjBu3DjmzZuHxdJ0nZWlS5cyc+ZMRo8eTVpaGqtWrTrh8zZv3sx1113HiBEjGDVqFDfeeCPp6enuDrPNJHeQlRkhhBDe541tpqNVgNvRNlN5eTnTp0/HarWyYMECZs+ezQcffMDcuXObfO2nn35KaWkpEydOPOlzMjIy+Otf/0pYWBjz58/niSeeoLy8nL/85S8UFha6M9Q241yZyThSgbXe5uPRCCGECFbeWJkJllozOneevGzZMqqrq3nhhReIjo4GwGazMWfOHGbOnEliYuIpX6vRaMjOzmb58uUnfM4333yDqqo899xzGI2Oc/RpaWlMnjyZtWvXcskll7gz3DYRY9ISEaanssZKxpFy0rrF+npIQgghgozNZndVm/fGNlNRWS12u+qRYny+4NbKzJo1axgzZowrkAGYMmUKdrudtWvXnvpGmqZvZbVaMRgMhIQcfaMiIiLcGWKbUxSFXg3F8yRvRgghhDeUV1tQVdAoEGnyXDDTIdKIRqNQb1MpbahjE4jcCmYyMjJITU1t9FhkZCTx8fFkZGS0ejDnn38+NpuNZ599ltLSUvLz83nyySfp2LEjZ511Vquv7y3OSsB7D5X5diBCCCGCknOLKdIUgtaDqydarYa4KMdOSCAfz3Zrm6miooLIyMjjHo+KiqK8vPVVcFNSUli0aBG33XYbr7zyCgCdO3fmrbfeatUKjaqq1NR4fj+wttbxxndNcPxF2H2o2Cv38RXn/Jy/Bptgnx8E/xxlfoEv2OfoqfnlFTk+YyNNeo9/zsRFGSkorSUrr5Ruie63SvDWe6iqKorSvMDNrWDG2w4ePMgdd9zBuHHjuOSSSzCbzSxcuJCbbrqJZcuWERcX16LrWq1Wr56I0tY7tpfyS2rZvGUHJqPWa/fyhczMTF8PwauCfX4Q/HOU+QW+YJ9ja+eXnuEozKpTPP95plccqz679h2mg6GsxdfxxntoMDSvO7hbwUxkZCSVlZXHPV5eXk5UVJQ7lzqhZ555hri4OObNm+d6bOTIkUyaNIm3336bu+66q0XX1ev19OzZs9Xj+6Pa2loyMzPp2zuVjh3KyC2uQWtKom/vlgVd/sY5v5SUFEJDQ309HI8L9vlB8M9R5hf4gn2OnprfvuJMoJROCTH07dvXY+MD2J6zn60HD6IYIlp0bW+9h/v372/2c90KZlJTU4/LjamsrKSwsPC4XJqW2L9/P0OGDGn0mMlkomvXrhw+fLjF11UUhbCwsFaO7uRCQ0PpkxJLbnENh/JrGDfEe/fyhdDQUK/++flasM8Pgn+OMr/AF+xzbO38quscXa3jYkwe/3PqlOBYjCiptLbq2p5+D5u7xQRuJgBPmDCBdevWUVFR4Xps1apVaDQaxo0b586lTqhTp06kp6c3atpYVVXFoUOH6Ny5c6uv701pXWMAOdEkhBDC87xRMM8poeF4diC3NHBrZWbatGksWbKEWbNmMXPmTPLz85k3bx7Tpk1rVGNm+vTp5OTksHr1atdj27dv58iRI5SUlACwdetWAGJjYxk5cqTr+rNmzeKee+7h4osvxmKxsHDhQiwWC1dccUWrJ+tNvbs5gpl9h0vdSloSQgghmuKNgnlORwvn1Qbs55dbwUxUVBSLFy/mscceY9asWZhMJqZOncrs2bMbPc9ut2OzNa6Gu3TpUj755BPX7xcuXAg4cmKWLFkCwOTJk3n22Wd58803mT17Nnq9nn79+vH222+TkpLSkvm1mZSOUeh1GiprHB20O8WH+3pIQgghgoQ3g5m4aMfKjNlio6LaQpQXVn+8ze3TTD169GDRokWnfI4zODnW3Llzm9X2YMqUKUyZMsXdYfmcXqehR+codh8qZc/hUglmhBBCeIw3t5kMei2xkSGUVJgpKK0JyGBGumZ7kHOrae8hyZsRQgjhGTa7SkWV91ZmAOKP2WoKRBLMeJAkAQshhPC0ymoL9oZzMd5aNTnaPTswk4AlmPGg3g3BzMGccixW6aAthBCi9ZxbTBFhBnRa73xsO080ycqMIDE2jEiTgXqbysGc1rd3EEIIIcoaGkB6a4sJjtlmKpGVmXZPURTX6oxsNQkhhPAE50mmGC8GM0drzcjKjADSXEnAZb4diBBCiKDgzZNMTgmxjpWZfMmZEXA0b2avrMwIIYTwAG/WmHFyJgBX11qpqbN67T7eIsGMhzmDmdziasobomkhhBCipUrbIJgJDdEREaYHAjMJWIIZDwsP1dO5oWDevqwy3w5GCCFEwGuLbSY4ttZM4G01STDjBc68mT1SPE8IIUQrtcU2ExyTBByAJ5okmPECyZsRQgjhKW0XzARuFWAJZrygd9dowBHMqKrq28EIIYQIWHa76sq/jA43evVess0kGnF20K6qdXTQFkIIIVqiqtaKraGXQXSEwav3Sox1VgGWYEZwtIM2SPE8IYQQLees/msK1aPXab16r0BuNinBjJdIB20hhBCt1VYnmeBozkxZpTng+gtKMOMl0kFbCCFEa7VV8i9ARJgeo8Gx+lNYFlirMxLMeIl00BZCCNFabRnMKIoSsA0nJZjxksTYMKLCHR20M6SDthBCiBZwbjPFtME2ExytNRNoeTMSzHjJsR20JW9GCCFES7TlygwcW2tGVmZEg96SNyOEEKIV2qIv07Gc3bMlmBEuUglYCCFEa7TlaSY4pqWBbDMJJ2cwk1dcIx20hRBCuE22mZpHghkvkg7aQgghWkpV1WOCGe+2MnCKb1iZKS6vw2azt8k9PUGCGS+TDtpCCCFaorqunvqGgKKtVmZiIozotBrsdpXi8ro2uacnSDDjZZI3I4QQoiWcrQxCQ3SE6L3bysBJo1GIjw68Hk0SzHhZ2jHBjHTQFkII0VxtnS/jFB8jwYz4g5ROkRgaOmjnSAdtIYQQzdTWJ5mcEmMDr+GkBDNeptNq6JEcDUjejBBCiObz3cpM4LU0kGCmDfTqGg1I3owQQojm81UwE4i1ZiSYaQPSQVsIIYS72rovk1Mg1pqRYKYNOE80ZUoHbSGEEM3k6wTgwrJa7PbAOLjidjBz4MABZsyYwZAhQxg3bhzz5s3DYrE0+bqlS5cyc+ZMRo8eTVpaGqtWrTruOffffz9paWkn/O+1115zd6h+QzpoCyGEcJevgpm46FA0Cljr7a7VIX+nc+fJ5eXlTJ8+nZSUFBYsWEB+fj5z586lrq6ORx555JSv/fTTTwGYOHEiy5cvP+FzbrvtNqZNm9bosZUrV7J48WImTJjgzlD9irOD9qZd+ew9VEqfbrG+HpIQQgg/V+o6zdQ21X+ddFoNsZFGisrrKCitITaybe/fEm4FM8uWLaO6upoXXniB6OhoAGw2G3PmzGHmzJkkJiae8rUajYbs7OyTBjNdu3ala9eujR6bP38+PXv2pE+fPu4M1e+kNQQzkjcjhBCiKY1bGbTtygw4umcXlddRWFJLn25tfnu3ubXNtGbNGsaMGeMKZACmTJmC3W5n7dq1p76Rxv30nPz8fDZv3syFF17o9mv9jVQCFkII0Vy15npXjqVPgpkASwJ2a2UmIyODyy+/vNFjkZGRxMfHk5GR4dGBAaxYsQK73c7555/fquuoqkpNjeffkNra2ka/nkpynOMvY15xDXmFZUSaDB4fj6e5M79AFOzzg+Cfo8wv8AX7HFs6v7xix2dWiF6DarNQU9N0bqonxYTrAcgprGjy89Nb76GqqiiK0qznuhXMVFRUEBkZedzjUVFRlJd7PrF1xYoVnHbaaXTp0qVV17FaraSnp3toVMfLzMxs1vM6ROoorqjn+/U76N051Gvj8bTmzi9QBfv8IPjnKPMLfME+R3fnd7jQscUUalC8+vl1Mta6KgAOZhc1+/7eeA8Nhub94O9WMNOWDhw4wK5du3j44YdbfS29Xk/Pnj09MKrGamtryczMJCUlhdDQpoOT/rtsrPk9F7MSSd++nh+Pp7k7v0AT7POD4J+jzC/wBfscWzq/Cns+UEh8bDh9+/b13gBPwqwrYsXGLdTV65q8v7few/379zf7uW4FM5GRkVRWVh73eHl5OVFRUe5cqkmff/45Op2O8847r9XXUhSFsLAwD4zqxEJDQ5t1/X6p8az5PZeMnCqvjsfTmju/QBXs84Pgn6PML/AF+xzdnV+t1fFrbKRv/ly6JDnyPIvKawkNDW3Wdo+n38PmbjGBmwnAqampx+XGVFZWUlhYSGpqqjuXatIXX3zBmDFjiI0NnmPMrg7aWWXSQVsIIcRJ+fIkEzhOMwHUmm1UOSMrP+ZWMDNhwgTWrVtHRUWF67FVq1ah0WgYN26cxwa1detWDh8+zAUXXOCxa/oDZwftaumgLYQQ4hR8HcyE6LWubt2B0HDSrWBm2rRpmEwmZs2axc8//8xHH33EvHnzmDZtWqMaM9OnT+fss89u9Nrt27ezatUq1qxZAzgCllWrVrFx48bj7vP5559jNBqPu0agkw7aQgghmsNXfZmO5WxrUBAADSfdypmJiopi8eLFPPbYY8yaNQuTycTUqVOZPXt2o+fZ7XZstsY9iJYuXconn3zi+v3ChQsBGDlyJEuWLHE9brPZWLVqFZMmTcJkMrk9IX/Xu2sM6Zkl7D1cypnDW3dKSwghRHA6ujLju+q7CTFh7MsqozAAas24fZqpR48eLFq06JTPOTY4cZo7dy5z585t8vparZaff/7Z3WEFDOmgLYQQoim+3maCwFqZka7Zbax3N+mgLYQQ4tTKquoA3wYzgVQFWIKZNpYQE3q0g/YR6aAthBCisTpLPbXmhlYGPsyZSXCtzEgwI/7A2UEbZKtJCCHE8ZxbTHqdhjCj72rbOo9nF5TINpM4AVe9GTnRJIQQ4g+cJ5miI0LcKhznac5tpsoaC3Xmep+NozkkmPEBVwftLAlmhBBCNOZK/vXhFhOAKVSPqWFlyN+3miSY8YFeDcFMXnEN5Q0RuBBCCAH+cZLJKd6VBOzfW00SzPhAeKie5IRwAPZK3owQQohjuLaZfLwyA0e3mvy91owEMz4iScBCCCFOxJ9WZpwnmvL9vKWBBDM+ktZNkoCFEEIcz5+CmXjXyoxsM4kT6N3laAdtu106aAshhHA42pfJd60MnBJjA6NwngQzPtK4g3aVr4cjhBDCT5RV+r76r1OgtDSQYMZHju2gLUnAQgghnPxpm8mZAFxaWYe13u7j0ZycBDM+5EoClrwZIYQQgMVqo7rOUaDOH4KZqHADBr0WVYWiMv9dnZFgxodclYCzynw7ECGEEH7BmS+j0yqEh+p9PBpHC5746IatJj8+0STBjA9JB20hhBDHcm4xRYX7tpXBsQKh4aQEMz6UEBNKdHiIdNAWQggBNO7L5C9cDSf9OAlYghkfkg7aQgghjuUvfZmOlRDj/8ezJZjxsd7dogEpnieEEMK/TjI5ObeZ/LlwngQzPuYsnicrM0IIIfypL5NTvKzMiKY4O2jnl0gHbSGEaO+Orsz4vvqvk3ObqaisFpufVqyXYMbHju2gLaszQgjRvvnjNlNslBGtRsFmVykpr/P1cE5Ighk/4EwClrwZIYRo38qqHMFCjB9tM2k1Ch2i/ft4tgQzfsDVQVtWZoQQol3zx5UZgERX92wJZsRJ9O4qHbSFEKK9q7fZqayxAv4XzPh7w0kJZvxASkfpoC2EEO2d8xCIRqMQEWbw8Wga8/daMxLM+AHpoC2EEKLU2crAZECj8Y9WBk7+XmtGghk/IR20hRCiffPXfBk4ujKT76fNJiWY8ROuDtqyMiOEEO2SP7YycIqPbViZKatFVf0vt1OCGT/h7KB9MKcCs3TQFkKIdscfm0w6xTcczbZYbZRXWXw8muNJMOMnnB20bXaVjGzpoC2EEO2NP1b/ddLrtMRGOsblj0nAbgczBw4cYMaMGQwZMoRx48Yxb948LJamo7SlS5cyc+ZMRo8eTVpaGqtWrTrpc3/44QemTZvGkCFDGDFiBNdddx15eXnuDjWgSAdtIYRo3/x5mwn8OwnYrWCmvLyc6dOnY7VaWbBgAbNnz+aDDz5g7ty5Tb72008/pbS0lIkTJzb5vNtvv52RI0fyyiuvMHfuXAYMGIDZHPx9i1wdtCWYEUKIdsdZ/dcft5nAv49n69x58rJly6iuruaFF14gOjoaAJvNxpw5c5g5cyaJiYmnfK1GoyE7O5vly5ef8DllZWU8+uijPPjgg1x99dWux8866yx3hhmwJAlYCCHaL38+zQTHFs7zv2DGrZWZNWvWMGbMGFcgAzBlyhTsdjtr16499Y00Td/qyy+/xG63M3XqVHeGFTR6dYlBUaSDthBCtEfOBOAYPw1mEmIbVmZKAnybKSMjg9TU1EaPRUZGEh8fT0ZGRqsHs3XrVrp3787y5cuZNGkS/fr14+KLL+bHH39s9bUDgUk6aAshRLtks9mpqHbkn/pvzkyQbDNVVFQQGRl53ONRUVGUl7f+BE5hYSEHDx7kueee49577yU+Pp6lS5dy2223sXz5cnr16tWi66qqSk2N5//wa2trG/3qCamdIsjKr2Ln/gIGpBz/Z92WvDE/f1JdnI8+bzc13br5eiheE+zvocwv8AX7HJs7v7JKM6oKigI6pd4rn1mtFWF0VCUuKK1pND5vvYeqqqIozauE7FYw423OoOO///2vK09m5MiRnHPOObz++uvMmzevRde1Wq2kp6d7cqiNZGZmeuxa4TrHX4bf9+QwqLPVY9dtDU/Oz5+YtnxMeP5ucu31WDoN8PVwvCpY30MnmV/gC/Y5NjW/vFLHqkyoQcPevXvaYETuM1vtANTU1bNl606MhsabO954Dw2G5vWociuYiYyMpLKy8rjHy8vLiYqKcudSJ70+wOjRo12P6fV6RowYwb59+1p8Xb1eT8+ePVs9vj+qra0lMzOTlJQUQkNDPXLNkKgKvti0gbwyG2lpfXzan8Mb8/MXqqpS8OMRVCDaXESHvn19PSSvCOb3EGR+wSDY59jc+Vn2FwMFdIgKo68ffz+K+KKQyhorsYld6ZYUAXjvPdy/f3+zn+tWMJOamnpcbkxlZSWFhYXH5dK0xKkCjtYczVYUhbCwsBa/vimhoaEeu36f7kYMOg01dfWUVtvpkhjhkeu2hifn5y/qK4pRax2Bub0gI+jm90fB+B4eS+YX+IJ9jk3Nr9ZSDEBslNGv/xwSYsOorCmnslY9bpyefg+bu8UEbiYAT5gwgXXr1lFRUeF6bNWqVWg0GsaNG+fOpU5o0qRJAKxfv971mMViYdOmTfTv37/V1w8E0kG7bZhzj0b8ttI8bNVSdVkI4TtHC+b5X/XfY/lrw0m3VmamTZvGkiVLmDVrFjNnziQ/P5958+Yxbdq0RjVmpk+fTk5ODqtXr3Y9tn37do4cOUJJSQngOLkEEBsby8iRIwHo378/55xzDg8//DBlZWXEx8fz7rvvUlRUxF//+tdWTzZQpHWLIT2zhD2HSzlrRFdfDycomXMbrzDWHdmLqfcIH41GCNHe+XNfpmP5a60Zt4KZqKgoFi9ezGOPPcasWbMwmUxMnTqV2bNnN3qe3W7HZmvcLHHp0qV88sknrt8vXLgQcCT4LlmyxPX43Llzefrpp5k/fz5VVVX079+ft956i7S0NLcnF6icbQ32ycqM15hzDwCgavUoNit12bslmBFC+ExZpX9X/3Vyrsz4W0sDt08z9ejRg0WLFp3yOccGJ05z585tVtuDsLAwHnroIR566CF3hxY0nJWAnR20Q/RaH48ouKiqijnPEcxYOg0gJGsLdVm7fTwqIUR75u99mZwS/HRlRrpm+6F46aDtVbaKIuw1FaDRYu46DABL7gHUev84Ci+EaH8CZZvJX1dmJJjxQ9JB27uc+TK6DsnYwuNRQiNQbVbMea2vYi2EEC3h732ZnJwtDcqqzJittiae3XYkmPFT0kHbe5wnmfSJ3UFRMHR0VJauy/bPQlVCiOBmt6uUN7Qy8Ne+TE7hoXpCQxypD4V+tNUkwYyfSpOVGa9x5svoE1Icv3ZyBjOSNyOEaHuVNRbsdhWAKD/PmVEUhfgY/2s4KcGMn3J20C4oqXEtP4rWU1XVtc2kT+wOgKEhmDFn70FVVZ+NTQjRPjm/x0eE6dFp/f9j2R8bTvr/n1o7dWwHbdlq8pz68kLstZWg0aGL6wI0BDUaHbbqMurL8n08QiFEexMo+TJO/lhrRoIZPyZJwJ7n3GIyJHRF0ekBUHQGQjo62nHIVpMQoq2VVgVG9V8nfzzRJMGMH3PmzcjKjOdYGorlhSQ17iVmTO4DQF2WJAELIdpWoK3MJMo2k3BHr2MqATuTw0TrOPNlQjr2aPS4MdlRYVpWZoQQbS1Qqv86xcc6t5lkZUY0Q0rHSAw6DdV19RwprPL1cAKeI/m3YWXmD8FMSMPKjLUwC1tddZuPTQjRfrkK5vn5SSYn5zZTSXkt9Ta7j0fjIMGMH5MO2p5VX5aPva4KtDoM8Y0beOrCo9HFJAEq5iN7fTNAIUS7FGjbTNHhIei0GuwqFJX5x+qMBDN+Lq2bJAF7irPCb0hCN1fy77Fkq0kI4QuB0srASaNRXCea/CUJWIIZP9dbkoA9xrnFZEjqccKvu5KApRKwEKINBUqTyWP5W8NJCWb8nPNEU2ZDB23RcpaT5Ms4OVdmzEf2odrlz1oI4X2qqlIeYCszcGzhPFmZEc0QHxNKdISjg/aB7DJfDydgqap6dJupY+oJn6OP74ISEoZqrcOSf6gthyeEaKeqaq3U2xynVQNqZSbWWWtGVmZEMyiKIvVmPMCR/FuNotVjiO9ywucoigZj596A5M0IIdqGc4vJZNRh0Gt9PJrmk20m4bajeTNlvh1IAHPlyyR0Q9Een/zrdDRvRoIZIYT3BdpJJid/azYpwUwA6N01GpATTa1xsvoyf2TsIknAQoi2czSYCYxWBk6ulgZltX5R1FWCmQAgHbRbz7Uy00QwE9KpJygabBVF1FcUtcXQhBDtWGlVQ/XfAMqXAegQZUSjQL3N7jpa7ksSzAQA6aDdOqpqPyb599TBjMYQiiExBZDVGSGE9wXqNpNOqyE2ypE3U1RW5+PRSDATMKSDdsvVl+ahmmtQdAYMcclNPl+K5wkh2kqgBjMAic4TTRLMiOZynWg6JMGMuxon/+qafL500BZCtJVA68t0LGcVYH9oaSDBTIDo170DADsPFlNTZ/XxaALLyTpln4xzZcaSfxC7xfc/cQghglcgr8wcTQL2/fdJCWYCRNekCDrFmbDW29mcnu/r4QSU5p5kctJFxaON6ACqHXPOPm8OTQjRzgVaX6ZjOWvNFMrKjGguRVEYO6gTAOu25fp4NIHDneTfYx3Nm5GtJiGEd6iqGpB9mZyctWYkAVi4ZVxDMLN5dz51lnofjyYwWEtyUS21KDoD+mYk/zodrTcjScBCCO+oqavHWm8HAnxlprwOVfVtrRkJZgJIj+QoEmLDMFts/La7wNfDCQiWhnwZQ2J3FE3zS4U7k4DNR/aiqnavjE0I0b45t5hCQ7QYDU0fTvA3zpUZs8VGrcW33yclmAkgiqIwdmBHANZuy/HxaAKDOXc/4N4WEzScfNKHYK+rxlqU7Y2hCSHauaNbTIFV/dcpRK91rSiVVdt8OhYJZgKMc6tp0658LFbf/uUJBEeTf0/cKftkFK2OkE69AKjLkq0mIYTnlVY2VP8NwC0mJ+dWU7kEM8IdvbvG0CHKSK25nt/3Fvp6OH5Ntdsw5x8E3F+ZgWOSgI9IErAQwvMC+Vi2k3Orqazat3mcEswEGI1GYYxsNTWLI/m3DkUfgr5DZ7dff7R4nqzMCCE8L5BPMjl17GACCLycmQMHDjBjxgyGDBnCuHHjmDdvHhaLpcnXLV26lJkzZzJ69GjS0tJYtWrVcc/ZsGEDaWlpx/03e/Zsd4cZ1JxbTRt25rky4cXxXJV/3Uz+dQrp3BtwtEOwVZd7dGxCCBHINWacLhjfnQvHd+O0VJNPx+FW+nR5eTnTp08nJSWFBQsWkJ+fz9y5c6mrq+ORRx455Ws//fRTACZOnMjy5ctP+dwnn3yS1NSjOQ4xMTHuDLNNWAqzKPxwHobk4dC3b5veu2/3DkSHh1BWZWb7/iKG9klo0/sHipbmyzhpQ8PRx3fBWphFXfZuTGmjPDk8IUQ7FwzbTB2iQrn2nN6kp6f7dBxuBTPLli2jurqaF154gejoaABsNhtz5sxh5syZJCYmnvK1Go2G7OzsJoOZXr16MXDgQHeG1uasZfnYSnIIrf4WdeIlbXpvbcNW05frM1m7LUeCmZOwtKBY3h8ZO6c1BDN7JJgRQnhUMGwz+Qu3tpnWrFnDmDFjXIEMwJQpU7Db7axdu/bUN9IEV3pOWOpgNKYYNOZq6vZuaPP7jx3kyJv5ZUcuNptsNf2RarcdU/m3Z4uvI8XzhBDeUhoE20z+wq2VmYyMDC6//PJGj0VGRhIfH09GRobHBnXzzTdTVlZGfHw8559/PnfeeSdGY8vP4auqSk1NjcfG56TvfwbmjZ9Q+etKjH3HoSiKx+9xMqkdw4gI01NRbeHX9BwGpMZ6/B61tbWNfg0k1qJsVKsZRR+C1RhN/Qne/+bMT41LARxbVtUVZSg6g1fG6y2B/B42h8wv8AX7HE82P0crA8fRbKPOO59RbcVb76Gqqs3+XHUrmKmoqCAyMvK4x6Oioigvb32CZEREBDfeeCMjRowgJCSEX375hYULF5KRkcGrr77a4utarVav7Ocp4d2I0uiwF2Wxf91X1Md28/g9TqVnkp4tGVZW/bwbrdl7eUWZmZleu7a3GI5sxwRYwhPYvefUR6tPOT9VJcoQhsZSw76NP2KLaX5LBH8SiO+hO2R+gS/Y5/jH+ZmtdixWx6p63pGDlBYE/u6FN95Dg6F5P0D6Vf3kfv360a9fP9fvx4wZQ0JCAo8++ijbtm1j0KBBLbquXq+nZ8+WbzWcTG1tLQX7BhKStYW44t3EjDvX4/c4lTptEVsytrAv10paWh80Gs+uDNXW1pKZmUlKSgqhoaEevba3VeRtogaISulHl5MkaDd3fqX7+2I+8CudDRZMbZzs3VqB/B42h8wv8AX7HE82v7ziGiAHg17D4IH92nRl39O89R7u37+/2c91K5iJjIyksrLyuMfLy8uJiopy51LNNmXKFB599FF27NjR4mBGURTCwsI8PDKHum4jCMnagvnAb+jNFehjkrxynxMZOSAZk3E7ZVUWDhXU0T+1g1fuExoa6rU/P28pLToMgKlrnybH3tT8LN36YT7wK7b8jID7c3AKxPfQHTK/wBfsc/zj/OryHVsy0RFGTCbfHmv2FE+/h+4EeG6ta6Wmph6XG1NZWUlhYWGjo9TtiT08DkPKIEClfNPKNr23XqdhZH9H8LROCui5qHYblryGyr9Jrf97eWwSsK87wwohgoPzJFOMnGTyCLeCmQkTJrBu3ToqKipcj61atQqNRsO4ceM8PjiAL774AsCvj2qbTjsHgMqt32Kvq27Te49tKKC3blsOdrt80AJYi46g1ltQDEb0HTq1+nqGpFTQ6rDXVFBfmueBEQoh2rtgKJjnT9zaZpo2bRpLlixh1qxZzJw5k/z8fObNm8e0adMa1ZiZPn06OTk5rF692vXY9u3bOXLkCCUlJQBs3boVgNjYWEaOHAnAPffcQ7du3ejXr58rAXjRokVMnjzZr4MZQ7eB6OOSsRZlU7H1O6JHXdhm9z4tLYHQEC1F5XXsyyolrZvnTzUFGlen7KQeKErrk+o0OgMhHXtgzt5DXfZu9LEdW31NIUT7FgwF8/yJW8FMVFQUixcv5rHHHmPWrFmYTCamTp16XLsBu92Ozda4g+bSpUv55JNPXL9fuHAhACNHjmTJkiWAo1je559/zsKFC7FarXTu3JlbbrmFm2++uUWTayuKohA14nyKvnyVik0riRpxXovK57dEiF7L8L5J/PT7EdZty5VgBo6pL+O5rU9jclpDMLOHiEGTPHZdIUT7JAXzPMvt00w9evRg0aJFp3yOMzg51ty5c5k7d+4pXzdz5kxmzpzp7pD8QvjAiZT88C715QXU7N2Eqc/oNrv3uEGd+On3I6zdlsNfLgjsrHhPONrGoOWVf//ImNyHcj6T4nlCCI+QbSbPCvyD7X5Cow8h8rSzASjfuKJN7z2sTwIGvZb8khoyjrTvhoiq3YYlPxMAQ5JngxkAa2EWtjbOixJCBB/ZZvIsCWY8KHL4FNBoqctKd60OtAVjiI5hDf2Z1rbzU02WwixH8m9IGPpYzx2T15qi0DUcuzdnn7oInxBCNEW2mTxLghkP0kXEEt7PcaqrrVdnjj3V1J6PD7u2mJK6eyT591jSp0kI4SllVY5WBrIy4xkSzHhY1MgLAKjatZb6ypI2u+/IfonotBqOFFZzOO/4wobthSc6ZZ+MsXMaAHWyMiOEaIU6Sz21ZschmeiIlvcdPJHKHWvIfvMflK37uM1LhfiSBDMeFtKxB8YufcFuo+LXVW123zCjntPS4oH2XUDvaPKv59tXOFdmzDn7UG31Hr++EKJ9cG4x6bQaTEbPdRVSVZXS75diyTtAyfdLOfTCLRR/t4T6ylKP3cNfSTDjBc7VmYrfvsZuNbfZfcc1bDW117wZ1VbvSv71ROXfP9LHJaMxmlCtZiwFhzx+fSFE+3DsSSZPnj415+yjvqIIRW9EH98F1VxD+frlHH7xFgpXvoK1JNdj9/I3Esx4QVjvEeiiErDXVlK1Y02b3XdU/yS0GoVDeZVkF7S/rSZLYRaqzYomJMyVrOtJiqIhpHNvQPJmhBAt562TTFW71gJg6j2C5JueJvGK+wlJTgNbPZVbVpP1yt/I//i/bXpApa1IMOMFikZL5IjzAEcicFsl5IaHGRjcy7nVFLwR+Mk4/4EaOvbwWq0d5xFtyZsRQrSUN04yqaqd6vR1AJj6jUNRNJh6j6Dz9H/T6frHCes5DFQ71enrObLwH+S++yi1B7cFzYERCWa8JHLwmSgGI9aibGoPbm2z+44d5Ci1v257+9tqMud5vljeHxmTG5KAs2RlRgjRMs5tphgPrsyYs/dgqyxBCQkjLHVIo68Zu/Ql6c8PknzT04QPmACKhtqDW8l9dw45b91H1e71qHbbiS8cICSY8RKN0UTE4LMAKN/Qdse0Rw/oiEaBA9nl5BW3n0x2AIvrWLb3OriHdOoFigZbZTH1FUVeu48QInh5Y5upalfDqkzvkSg6/QmfY0joRsLFd9LltheJHD4FRWfAnHuAgo/+S/ard1Kx5RvUeqvHxtSWJJjxoqgR5wEKtRlbsBRlt809w0MY0CMOaF9bTarNirkhKdebKzMagxFDYndAVmeEEC3j6W0m1W5zbTGF9x3b5PP10QnEnXMjXW9/hejxU9EYw7GW5FK08mUOv3grZeuXYzfXeGRsbUWCGS/SxyQR1nsEAOUbv2iz+x5bQK+9sBRkga0ejTEcXXRi0y9oBWMXZ70ZCWaEEO7zdF+muqzd2KrL0BhNhKYOavbrtKYoYideRdc7XiF28l/QRsRiqyql5LslHF4wk5Lvl1JfVeaRMXqbBDNe5iqit/0HbDVtc8JozMCOKArsOVxKYWltm9zT147my6R6vdGmJAELIVqjrNKz1X+rG04xhfUehaI98RbTqWgMoUSPupCus14i/oJZ6Dt0xm6uoWzdx2S9eCtFX76GtTTPI2P1FglmvMzYtR+GxO6o9RYqtqxuk3vGRhrpmxILwPp2kgjsjU7ZJ+MMZiz5mdgt7SNYFEJ4jie3mVS7jard6wEI79f0FtOpKFo9EYPPJHnmsyRO/QchnXo5Prt++4qsl+8gf/kzmBtqefkbCWa8TFGUo0X0Nn/ZZpVjXVtN29tH3ow519HGwJOdsk9GF9kBbWQcqHbMOfu9fj8hRPCwWG1U1zk+BzzRyqDu0E7sNRVoQiMITRnY6uuBo6aWKW0Unf7yJB2vnUNo6mmOY907f+bIG3eT+97j1B7a6VfHuiWYaQPh/cahNUVjqyqhOn19m9xzzEDHEe1dB4sprahrk3v6ilpvdVXkbYuVGZAj2kKIlnHmy+i0CuGh7m8J/ZGrUF7aKBSt51ojgOOH8dBuA+h41UN0/ut/MfUb5zjWnbGF3HceIWfxg1Tv2YCq2j1635aQYKYNKDo9kcPOBaB84+dtEs0mxITRu2s0qgrrdwT36oyl4BDY69GEhqOLim+Te0rejBCtV1Vj4YNv97Mts8avfsr3JucWU1R4CBpN6/L7VFs91Xs2AGBq5RZTU0KSupN46V10uXUBkUPPQdHqMR/ZS/6H8yh6+wE0Vb4tVSHBTBuJHPonx5ufewBzG30Auno1bQ3uvBnzMZ2yvZ386+QMZsxH9vjFTyVCBJrf9xZw+3+/56MfDvLxuhLmLNzMobwKXw/L6zx5kqk2czv22ko0YZGEdhvQ6us1hz4mibgpN9Pl9leIHnsZmpAwbCU56At9u+UuwUwb0ZqiHJUXcbQ4aAvOvJkdGcWUV7Vdw8u25kr+bYN8GSdDYjcUvRG7uQZrYdvUEBIiGJitNl5fvp2HX11PcXkd8dFG9FqF9Mwy7pz/A4tW7KTOHLxd6T2Z/OuqLdNnDIpG2+rruUMXHk3spGvoeserxFx6L+ZuI9r0/n8kwUwbciYCV+/ZgLWswOv3S+pgIrVzFHa7yi87/PtYXWu05UkmJ0WjJaRzL0DqzQjvyS6oYuXmMvZnl/t6KB6xP6uM2c/8wGc/OVZTp4xJ4b93jGXWBYkM7xOPza7y0ff7ue0/37F+e25Qbj15qvqvarO22RbTqWhCwghJGQRtHEwdNw6f3r2dMSR0JbT7IFDtVGz+sk3uGey9muz1FiyFh4G2DWbgmCRgCWaEF1jrbcx/bysb91bxf69u5Pn3t7g+CAONzWbn/dV7uOf5NWTlVxETEcI/bxzNbVMHYzRoiTbpuPeaITx8wygSYkIpLK3l34s28tjCDUHXlsW1zdTKlZnag9uw11WjNUVj7NLXE0MLaBLMtDHXMe3fv8Fu9n6NEmfezNa9hVTVWLx+v7ZmKTgMdhuasEjHcek2JEnAwps+/mE/OUU16LSOPLDVGw9zy9xv+GzNAeptgZOnlVNYxX0v/sw7q3Zjs6uMHdSRBfdMYnjf4yt1j+yfxIv/OJMrzuqFTquwaVc+s/7zPR98sxdrfeDM+VSOrsy07li2qxdT37bfYvJHEsy0sdAep6Hv0AnVXEPltu+9fr/khAi6JkVgs6ts3BV8W02WXEfSWUhS2yX/OoV07g0o1JfmBUzJbxEY8oqr+WD1XgAuGhnDozeNoEdyFNV19bz+6Q7ufPoHtu4t9PEoT01VVb5cn8nfnv6BPYdKCTPqmH3VUO6/fgRRp1iVMBp0XH9eP56/exKDesZhsdpY8mU6f5v/PVv3+fecm8MT20xqvZXqvRsBR+kPIcFMm1MUDVEjzgegfNMXbdJ2/eippuA7on00X8Z7nbJPRms0oY/v4hiHrM4ID1FVlVc/2Y6l3s6A1FgGpoSS1jWa+XdO5PYrBhNpMnA4r5KHXl3Hk4s3UlDifw0BSyrqePTNDbz04VbMFhuDesax4J5JnDm8S7N/6OiSGMHjt4zl7quHEh0eQnZBFQ+9so75S38N6NpZZVWOsce0YpupJuN3VHMN2ohYQhq2u9s7CWZ8IHzgGWiM4dSX5lGz/zev3895qmnL3gJq6gKzvfvJOCv/tnW+jNPRrSbJmxGe8cuOXDan56PTKtxwQR/Xh79Wo3DO6BRevf8sLhjfHY1GYd22XG596lve+2o3Zqv3fzBqjrXbcrj9P9+zOT0fvU7DXy8awGMzx5IQE+b2tRRF4YxhXXj5/rM4f1x3FAV++C2bW5/6li9+zsBmD7wEYU+szDh7MZn6jkVR5GMcJJjxCY3BSMRpkwFHET1v65YUQed4E9Z6O5t25Xv9fm3FbjX7LPnX6WgSsKzMiNarNdfz2ifbAbhsUi86x5uOe054mIGZlw7iubvOYGCPOCz1dt79eg+3PfUt67bl+OwEUHWtlaff/ZW5izdRWWMhtVMUz8yeyCUTe7S6OFx4qJ5bLhvE/Dsn0LNLNNV19bzyyXbuee5H9h4u9dAMvK/eZqeyxvEDZUuDGbvVTPW+TQCE9/XdKSZ/I8GMj0QNnwKKhrpDOzHnHfTqvRRFOaZXU/CcarIUHALVjtYUhTaig0/GYOzSUDwv7wD2+uBLsBZt672v91BUXkdibBhXTu59yuemdIzkiVvH8o/rhhMXZaSgtJYnF2/ikVfXc7iNi89t31/EHfO/5/tfs9EocMVZvfjvnRPolhTp0fv06hLDf/82gVsvH4TJqGN/djn3PL+Glz7aGhAHHJz1vjQahYgwQ4uuUXtgC6qlDl1kXEPengAJZnxGFxmHqe8YAMo3eb+InjOY2ZxeEDQFqZz5MgYfJP866aIT0ZqiwVaPpWHLS4iWyMyt4NM1jr/TMy8dSIi+6RMqiqJw+pDOvHzfWfx5cm/0Og2/7yvkb/N/4I1Pd1Bd691tZYvVxpuf7eDBl9dSWFpLUocw5s46nevP64de552PF61G4byx3Xn5/rM4Y1gyqgpfrsvk1qe+47vNWX5dm6bU2crAZGjxalVVuvMU01iffd/zRxLM+JDzmHbVzp+pr/LuUmmPzlEkxIZhsdr4dY/3C/a1haP5Mm2f/OukKIorAU/yZkRL2e0qL324FbtdZczAjozol+TW640hOq6d0peX/nEmo/onYbOrfLrmALfM/ZZvNh7C7oXckgPZZcx+9keW/+gIwM4Z3Y3n755E3+6xHr/XicREGLn76mH8+9ZxdEkMp6zKzDPv/caDL69t85Wp5mptvozdUkfNvs0AjqaPwkWCGR8ydu5NSOc0sNVT8etXXr2XoiiuU03rgqRXkyWv4Vh2x54+HYcrCVg6aIsW+m7zYdIzSzAatNx08cAWXyepg4mHbhjFv24aTed4xwf8c+//zr0L1ngst8RmV/nft3u55/k1HM6rJDoihIf/OorbrxhCaIhnuzY3x8CecTx31ySuP68vBr2WHQeK+dv8H1j8xS7qLP61Ct3aVgY1B35DtZrRRSf4LE/QX0kw42NRIx3HtCt++8rrORfOasCb0vOw+MnJh5ZyJP86eiKFJPluZQaOSQI+ssevl7iFf6qotrDw810AXPWnPsTHhLb6msP6JLLgnknMuKA/oSFa9h4u4+7n1vD8+1sorWz5sebcomoeePFn3l6ZTr3NsYr0wj2TGOnmSpKn6XUarjird6OVqQ+/28esed+xYYf/lKRobZPJxqeYZIvpWG4HMwcOHGDGjBkMGTKEcePGMW/ePCyWpj+Ely5dysyZMxk9ejRpaWmsWrXqlM+32+1cdtllzXpuIDP1GY02Mg57TQVVO37y6r16d4khLspIrdnGlgDfarLkZzYk/0ajjWibZe2TCUlKRdHqsddUYC3xn2+cIjAs/mIXlTUWuiVFcNEEzwXmep2Gyyb15JX7J3PmcEc9JEcV4W/51M0qwqqq8tUvmfxt/vekZ5YQGqLj79NO44Hppy6A19YSY8N46IZRPDRjJPExoRSU1vL4Wxt5fOEG8v2gHk9rqv/aLbWuUh5SKO94bgUz5eXlTJ8+HavVyoIFC5g9ezYffPABc+fObfK1n376KaWlpUycOLFZ91q2bBn5+cFzjPhkFI3WcbIJqNi0wqs/2Ws0CmNcp5oC+0P32OaSvv4JRdHpMTQs+Zolb0a4If1gCV9vOATArZcPRqf1/GJ5bKSR2VcNZd7tp9MjOYqaunre+HQHf5vfvCrCpZV1PLZwAy/8byt1Fhv9Uzuw4J5JnDWiq8//7Z3MqAEdeeneM5l6Zi+0GoUNO/O4bd53/O9b37ZFaM02U82+zaj1FnQxSRgSu3t6aAHPrX85y5Yto7q6mhdeeIHTTz+dqVOncu+99zYr8Fi2bBkffPABd9xxR5P3KSkp4bnnnuOuu+5yZ3gBK2LIZBS9EUvBYeoyt3v1Xs68mQ07cgO614k5r+Ekk5/sGzuPaEu9GdFcNpudlz7aCsDkEV3pn+rd8gJ9u8c2qiKclX+0ivDJVi3Wb8/l9v98z6Zd+ei0GmZc0J8nbh1HYqz7BfDamjFEx/Tz+/H83Q31eKw23l6Zzp1Pf8/OjGKfjMlZ/bcl20xVDVtM4f3G+W0Q6UtuBTNr1qxhzJgxREdHux6bMmUKdrudtWvXnvpGmubf6umnn2bUqFGMGjXKneEFLG1oOBGDzgCgfKN3j2n3SYklOiKE6rp6tu0P3D4nx67M+ANjZznRJNzz+c8ZZOZWEBGm5y8X9GuTe56sivBtf6giXFNn5dllv/HvRRupqLaQ0jGSZ2ZP5LJJPdG2sgBeW+ua5KjHc1dDW4SsfEdbhF0H2z6gaelpJru5hpoDWwBHvow4nlup5xkZGVx++eWNHouMjCQ+Pp6MDM/U2Ni2bRsrVqxgxQrPfairqkpNjef3S2traxv92hqGgWfBr6uo2f8rFUcOoIvp2OprnsyIvvGs3pjNmt+y6Ns14qTP8+T8PMlurcNa5Ej+tUd1avF768n5qR26AmAtyqaqpACNMbzV1/QEf30PPSVQ51dcXsfSVY7A96qze6LX2E7499hb89MA153Tk4mDE3lr5R52HSzl3a/3sHrjIaaM6cqX6w9TWFaHosBF41O44swe6HUav/8+eiqj+nZgQMoYXvxoB7/uKeKJtzbw71tGER/d+oTrUzl2fs7ka6POvc+k2l0/g60ebWwn6sPjsXnhfWgNb72Hqqo2exXKrWCmoqKCyMjjKzpGRUVRXl7uzqVOyG63M2fOHGbMmEFycjLZ2dmtviaA1WolPT3dI9c6kczMTI9cxxTfE0PhfrK/e5/afud45Jon0jHc8Q9q/Y5cxvWiyZ+0PDU/T9GWZhGpqthDwtmblQu0Lv/HU/OLDItFW1PCgY3fUx/v2+Pif+Rv76GnBdr8PvipmDqLjeQ4A0lhFU1+f/Lm/K4YHcbOTgpfbymnsKyOt790dOuONmm5dEws3RLq2b/P+9unbfUenjPYwJECPXmlVh57cwM3nB1PiN77B3sPZBykotpRxLAg9xC1ZU0XRXQy/fYtBqAqJpWi3f67+uuN99BgaF6l5LYvCnAK//vf/ygqKuLmm2/26HX1ej09e3r+w6W2tpbMzExSUlIIDW19dG82TaX0o7mE5myn6/k3oTEe35fFE3r3tvPJL2scPUJCk+ibeuLTQJ6en6dUbzlMJRDauRed+vZt8XU8Pb/yw/2p3fUTSdo6IloxLk/y1/fQUwJxfr/vK2JXVjYajcIdVw4lpePJV0cr92+hdOMXRA/9E5F9RnptTP36wYVn2vh0zUG+3pjNyH4JXHdub8KM3v+I8MV7+HDXOh58ZQP5ZRa+2WHlrmmDW90/6mSc8+uQ0Bk4gqLAsMH90DYz2dteV03B146WN8ljz0cfl+yVcbaGt97D/fv3N/u5bv1NjYyMpLKy8rjHy8vLiYqKcudSx6murubpp59m9uzZWK1WrFYrVVVVANTV1VFVVUV4eMuW7hVFISzMewlroaGhHrl+aNpwqhO6YSk4RP2etUSPuaT1gzuJ0QM6snrjYTbvKWbkgFP/4/DU/DylqjgLgLDk3p75c/fQ/OpTBlC76ydseQf86s8L/O899LRAmZ/ZauOtLxyrHBeOT6Vfj8STPrc2czvVKxdgsFmp+XIP7B9Oh7NnoI/xTk2XsDCYcdEgZlw0yCvXb0pbvoddwxxHuB98aS2b0gv5eM0hrj/Pu3lL5npH8BJpMhAR0fzPssp9v4Ddhj6+C1Fd/bsXk6ffQ3cSnd1aW0tNTT0uN6ayspLCwkJSU1tXH6G0tJSysjL++c9/MmLECEaMGMHFF18MwH333cc553hv28VfKIrianFQvvlLVLv3CtuNG+w41fTL9lxsXih17k2u5N8k/0j+dXIWzzPn7EO1+Vfl0WCkqipLv9rHx+tKqPJyDyJP+d+3e8krrqFDlJGrz0k76fPqsnaT98FcsFmpj0gAjZaafZvJfvXvlKx5H7vV3IajDk59usVyx5VDAPjft/v44TfPpDWcTHm1ox6bu8eyq3Y5ejGF95XaMqfiVjAzYcIE1q1bR0XF0b4Xq1atQqPRMG5c6/6g4+Pjefvttxv99/TTTwNwxx13sGDBglZdP1CY+o9Ha4rCVlFE9e5fvHafQT3jMRl1lFaa2Z1Z4rX7eJrdUou16AgABh/2ZDoRfVxnNMZw1HoL5vxMXw8n6H32Uwaf/ZzJtswa5ry5mdKKlle2bQtHCqv46DvHsvlNFw8kzKg/4fPMOfvJff8JVGsdhm4DqRzzF+KufYLQlIGoNitlP31A9qt/p3rPRqk43UqThnVh6pm9AHj+/S0ea/lwIuUtqP5rq6mkNnMbAKZ+corpVNwKZqZNm4bJZGLWrFn8/PPPfPTRR8ybN49p06aRmHh0uXT69OmcffbZjV67fft2Vq1axZo1awDYunUrq1atYuPGjQCEhIS4jmM7/xs8eDAAPXv2ZOjQoa2aaKDQ6AxEDHWsQpVv/MJr99HrNIwa4DgxtW5b4PRqMucdBFS0EbHowmN8PZxGFEVDSGfHMrAUz/Ou/VllLFqxEwC9TuFwfhX3vfAzecXVPh7ZiamqyisfbaPeZmdonwRXa5E/MudnkvveY6jmGozd+hNz4Z2g0aHr0Jmkq/9JwmX3oI2Mo768gPwPnyLv/SewlgTOv19/dN2Uvozsl4S13s7jCzdQVOadU1XlVc6VmeZX/63eswHsNgwJKRg6dPbKuIKFW8FMVFQUixcvRqvVMmvWLObPn8/UqVO5//77Gz3PbrdjszXeIlm6dCl33nknc+bMAWDhwoXceeed7WbFxR2RQ88BrQ7zkT3UHdnrtfuMHXg0mPFGV11vsOQ5O2X71xaT09HieRLMeEtNnZV5SzZTb1MZ2S+BW6ckkhATSm5xNfe98BOH/LBj8k+/H+H3fYXodRpmXjrwhLkAlqJsct+dg72uipDOaSRd8QCK/uhP8YqiEN53DF1mPkf02MtAq6P2wBayXptNyfdLsVv8e2XKX2k0CndfM5SUjpGUVpp5/K0NXmlQ6Qpm3FiZqU53bDFJh+ymuX0erUePHixatIitW7eybt067rvvvuOOTi1ZsoTvvvuu0WNz585lz549x/23ZMmSk94rOTmZPXv2cO6557o7zICmC48mvP/pgHeL6J2WlkBoiJai8jr2ZXlvedWTjhbL86+jz06uppNZ0nTSG1RV5cUPt5JbXE1CTCgzL+lHbISOOTcOp1tSBCUVZh548Wf2HPKfrdPqWitvfLoDgCvO6k2nuOOTP60lueQu/Rf2mgoMSakkTfs/NCEnPhWiMRiJnXQNXW5+htDU08BWT9m6j8l69U6q0tfL37sWCDPqeeiGUUSaDBzILufZZVs8/udY5mYwY6sup7ahIny4bDE1Sbpm+ylnInB1+nrqK4q8cg+DXsuIvo6TEWu3BUavpqPJv/6VL+MU0qkXaLTYqkqorwjcCsv+6puNh1mz5QgajcK91w4nPNSRdxIbaeTJWeNJ6xZDZY2Vh15Zx+97/aOZ6jur0imtNNMpzsTUM48Pwq3lBeQu/Re2qlL08V3peNUjaJtRlkEf24mkaf9H4tT70EUlYKsoouDj/5L33qNYirybzBqMEmPDePAvI9FpFdZuzWHZas+uirubAFy9+xdQ7RiSenjtBFswkWDGT4UkpmDsNgBUO+Wbv/TafcY2nGpaty3H73+is5trsRY78gP8dZtJow8hpKEJnFn6NHlUVn4lr3zi+En12nP70CelcX2kiDADj80cy5De8dRZbMx5Y4PP88H2Z5excq2jRsitlw9Cr2tcKK2+soTcpXOoryhC36ETHa/+J9qwk9ed+SNFUTCljSR55rNEn34lilZP7cFtZL9+F8XfLsZuDqzKyL7WP7UDt13uyNV896vd/Lz1iMeu7W4CcFXDFpOsyjSPBDN+zLk6U7nlG6/thw9LS8Cg15JfUsOBI62v4uxN5vwMQEUbGYfW1Lq6Rt4U4tpqkrwZTzFbbTz19iYsVhtDesdz+aReJ3xeaIiOR/46inGDOlFvs/PU25tY3dCVuq3Z7CovfbgVuwoThnRmSO+Exl+vLid36b+oL81DF51Ix6v/hS48ukX30uhDiJ3wZ5JnPktYrxFgt1H+y2dkvXIHVTt+8vsfVPzJ2aO6cclExw9Lz7y3hf3ZZR65rjs5M/VVpdQd3gVIL6bmkmDGj4X1GoYuJgl7XRVV23/wyj2MITqG93V8k/X1T7FN8bfmkicjHbQ9781Pd3Aor5LoiBDuunroKau16nVa7r1uOGeP7Ipdhec/+J2Pv29+JVFP+fqXTPZllREaouOGi/o3+pqttpLcd+dgLT6CNjKOjtf8C11k67tm62OSSLryfpL+/CC6mCRsVaUUfPosue88gqXAN0FdIPrLBf0Z2icBi9XGEws3UNLKY/92VaWixlELKaYZwYxziymkUy/00QlNPl9IMOPXFEVD1IjzAccxbVW1e+U+YwcGxlaTv+fLODk7aFsKDskyvwes3ZrDl+szURS4++qhxEQ0fbRVq1G448ohXD7JkaPy1oqdvL1yV5v9/S6trGPxSke/pWun9KFD1NFkXntdNXnvPYal4BBaUzSdrvmnxz+wwnoOI/nmZ4iZeBWKzkDd4V1kv3EPRV8vxF7nn8fX/YlWo/CPa4fTJTGcovI6/v3WRizWlhcxrTXbXSdGo5qRM1O9ay0gtWXcIcGMn4sYPAlNSBjWkhxqG1rAe9qIfonodRqOFFZzOO/4dhX+wpLr38eynXSRHdBFxYNqpy7He0fr24O84moWfOD4ez/1zF7HbdWciqIo/OWC/kw/31Gm/n/f7uOlj7a1ScXrtz7fSXWtldTOUZw/trvrcbulltz3n8CcewBNWCQdr/kX+thOXhmDRmcgZvxUutzyPKY+o0G1U7HpC7JeuYPKbd977YejYGEKdZxwigjTs+dwKQs++L3FwXBVnePPOiJMj66Jnkz1FcWuLepw2WJqNglm/JzGEErEkMmA945phxn1nNbwIbHWT7ea7HXVruJg/h7MwNG8GUkCbrl6m53/vvMr1XX19OkWw9Xn9GnRdaae2YtZUwejKLBqfSbzl/6Ktd57H+Tb9xfx/a/ZKArMmjrY1VDQbjWT98FczNl70BhNdLzqEQzxXbw2DiddVDyJl99L0lWPoO/QCVt1OYWfv0DO2w9hzsto+gLtWKe4cO6fPgKtRuGH37L58Lt9LbpOdZ1jVac5+TLVu9cDKiHJaegi41p0v/ZIgpkAEDliCigaag9uw1Jw2Cv3GDfYv6sBm/MdJ0J0UfFowyJ9PJqmGZOleF5rvfNlOnsOl2IK1XPvtcOb/In2VM4dk9JwDYWffj/iKIxm9nxhNGu9nZc/3uq45+gUend1VKlW663kf/gf6g7tQDGEkjTtYUKSup/qUh4XljqY5JueJvbM61D0RszZeziy8D6KVr2OrdZ/V2R9bVDPeGZeOhCAJV+m88sO98tYOFdmmlP99+gpJimU5w4JZgKAPioBU9ooAErXfeSVff+R/ZLQahQO5VWSXeB/39gCJfnXyVU878g+rzYMDVa/7S7go4ak3b9dOYSE2NZ34j19SGcevmE0IQYtv+0u4JHX1lNVY2n1dY+1/Mf9ZOVXERVu4Prz+gKg2urJ/+RpajO2oOhD6Djt/zB2PvFpLG9TtHqix1zi2HrqN86x9fTrKrJe+RsVW76RraeTmDK2O+eP646qwvylv3Iwx72Tn81dmamvKGpYzVUw9RnT0uG2SxLMBIio0RcBUL3zZ0q+WeTxgCY8zMDg3vEArPPDAnrOYMbgZ52yT8aQ0A3FYEQ112ApzPL1cAJKSUUdT7/3KwDnj+vO2EGeyykZ2ieBx24eiylUT3pmCQ+8tNZjDSrzS2pchdZuuLA/4WEGVLuNgs+ep2bvRhStnqQr7sfYpa9H7tcausgOJF56Fx2vnYM+vgv2mgqKVr5MzlsPUJfT9ie/AsFNFw9gSC9HDaPHF26grLL5nctdKzNNBDPOVRlj177oImJP+VzRmAQzAcLYuTdx594EOHJnir9+0+MBzbiGDw1/zJsJtJUZRaPF6Go6KXkzzWWzq8xf+ivlVRa6d4rkhgv7N/0iN/XtHsuTt40jJiKEzNwKjzWofO2T7VisNgb06MCkYV1QVTuFX7zsOJmi0ZE49V5Cuw/ywAw8J7TbAJL/+l9iJ/8FxRCKOXc/OW/dT9FXb2K3Nv/Duj3QajXcd/1wOsWZKCit5cnFG7HWN2/V1bUy08RJpupdDb2YJPHXbRLMBJDIYecSd96tgELF5i8p+vI1jy4Lj+qfhEajkHGk3K+6D9vqqqkvzQP8/1j2sUIajmhL3kzzffjdXrbtL8Jo0PKP64Zj0GubflELdO8UxVO3n05ibJhHGlT+siOXjbvy0GoUbr3MEbAUr3qDqm3fg6Ih8dLZhPUc5qnhe5Si1RE96kK63LqA8IFnACoVm1dyZOE/MOdKgvCxwsMMPHTDKExGHbsOlvDSh9ua9UNlVW3TKzPWsnzMOftA0ThOnwm3SDATYCJPm0z8hbMAhcotX1P0xcsey8mICg9hYA9H4S5/SgR2dsrWRSe4Verd16SDtnt2ZhTz7leOVaxbLhtEcoJ33+uOcSaeun08XVvZoLLOXM9ryx1tFi49oyddEiMo+XYxFb99BSgkXPS3gPhw0oXHkHDRHSRNewitKRprUTZHFj1A2bqPJe/rGF0SI/jH9SPQKPDNpsN8uuZAk69pTs5Mdfp6AIxd+6ELj/HMYNsRCWYCUMSgScRf/DdQNFRu/Y7CFS967JuNMz/Bn/JmAm2LycnYqRegUF9WQH1lYHQl95XKGgv/XfordrvKpGHJnDWia5vct0NUKHNb2aBy2eo9FJbWkhATyp8n96b0x2WUb/gcgLjzbyV8wOneGLrXhPU4jeSbnyEsbRTY6yn5fim57/wTa5l/NO70B0PTEvjrxQMAR02hzen5p3z+0dNMJw9mqhoK5ckpppaRYCZARQyYQMIlfwdFQ9X2Hyn47HmPBDRjBnREUWDP4VKKyr3TD8pdRyv/BlYwozGaMCQ4PpTrjsjqzMmoqspzy7ZQVFZLpzgTt1zWtnklrWlQeSivguU/Ov5+3nzJQGo3f0rZ2g8B6HDOjUQOOctr4/YmbVgkiZffS/wFs1AMRuqy0sl+/S4qt/3g11XC29KF41M5Z3Q37Cr8553NHD7JNqWqqlSbT70yYy3JdaxAKxrXyVXhHglmAlh4v3EkXnY3aLRU7/yZgk+eQbW1rnZGTKSRft0dW00bd/nHT2KBujIDUjyvOb5Ye5ANO/PQaTX847rhhBn1bT4GZ4PKsYM6NrtBpaqqvNxQUXhU/yTSqjdT+sO7AMSeNZ2o4VPaYuheoygKEYPPJPnG+YQk90G11FL4+QIKPp6Prcb/yje0NUVRmHnpIAb06EBNXT2PLdxARfXxR/2ra+uxN6Q2nmxlxnmKKTRloF830fVnEswEOFOf0SRefi9odVTvXk/+x/NRbdZWXXPsIEcBvQ07T7102hZstVXUlznGYQig5F8nV/G8hvLkbVFKP5AcyC7jzc92Ao7jzD2So302Fr1Oyz+uG9HsBpXfbc5iZ0YxIQYtM3oVUPLNIgBiJkwjuqGUQjDQxyTR6bpHiTnjascPTrvXk/36bGoyfvf10HxOr9Nw//UjSIwNI6+4hrmLN1Fva3woo6zKcSoszKg7aUK7nGJqPQlmgoCp9wiSpt6HotVTs3cj+R/+B3t9y4uBORtP7jlcRmWtbxP/zHmOVRldTBLa0HCfjqUlnMXzzHkZvPDeRq54YAXvfrVbluqBmjor85Zspt5mZ1T/JC4Y37YVcU/E2aDysjNO3aCyssbCws8dQdhtg6swr1kEQPTYy4geP7VNx9wWFI2WmHGX0/kvTzpaIlSVkvfeYxR9LUe4o8JDePivowgN0bH9QBGvfrK90d+X8obVmiiT4YSvtxQfwVKQCRotpj6yxdRSEswEibCeQ0m88gEUnYGa/b+S/7+nWvxNJi46lLRuMagqpGf5tuuzq7lkAK7KAGijEqg3RIDdxr7ff8dab+e9r/ewVAIaXvl4GzlF1cRFh3LntNNQFMXXQwIc2wczLjx1g8q3V6ZTUW1hcnweKRmOHJnIEecTc8bVfjMPbwjp2IPOf/0vkcPOBaBiU8MR7nbe46lbUiT3XjvM1f/ri7UHXV8rr2oIZsJPHMw4V2VCuw9CGxo4pzX9jc7XAxCeE5Y6mKQ/P0jeB09Sm/E7+R88SeKVD6DRN93c7I/GDuzEnkOlbNxbhWH1PvT6o3kMf/wMbu6H8nGvO8FzYiON/GlUV1feRCDnyxzKq+Dlj7YxsiqGIYZKhsZUMKjfWJb/eID3V+9Foygtbp4Y6L7bfJjvf81Go1G455phRISd+Bu9L009sxfhoXpe+mgrq9ZnUl1rZfZVQ8k4UsZXv2QyUH+YC+xrQFWJOO1PdDh7RlAHMk4afQhx595EWM9hFK540XGE+60HiJ04jajRF6FovFMbyN+N6JfEX87vz1srdvL6pzvoHB/OaWkJTQYzVekNp5hki6lVJJgJMqEpA0ma9hB57z9BbeZ28pY9QdKfH0BjCHXrOmMHdeStFTspqqhn+ZpM7wz2JD74Zi9XTu7FeWO7B2QwU2ep54Nv9vLx9/ux2VU6mhIZwmH+1N1Cx4sG0CHKyJuf7eS9r/egAFe1s4Amu6CSlz/aBsDV56TRP7WDj0d0cueOScEUqufpd3/lp9+PUF1npazCTJruCDMifkJR7YQPPIO4KTe1i0DmWGE9h5J88zMUrnyFmj0bKPn+HWoO/Eb8RXegj0rw9fB84tIzenAor4LvNmfx1JLNzL9zgiuYOVHyr6XwMNbCLNDoHEfhRYtJMBOEQrv2o+NVD5O77AnqDu8k973H6Tjt/9CENL9ZX1IHE3+7YiAbtx0kNjYWnf7oXxWF479pN+f7+Im+2R/7iAps3JnHkcIq3vxsJ1//uJN7tI4TVYGS/Ls5PZ+XP95GQUkN4KiqfOXY7tR+tAnzkb2oqsolE3uiqrDw8528+/UeFI3CtLPTfDzytmGx2pi3ZDN1FhuDesYx9czevh5Sk04f0hmTUc+/F2/kt90F9NTlcWPED2ixYeo7lvgLbkNR2ueOvfMId9W27yn6+k3qDu8i+/W7iTvnr4QPmNjuAjxFUbj9isHkFlWTnlnCY2/+QnK8CThxzkxVwxZTWOpgtEZTm4412EgwE6SMyX3oeNUj5C17DHP2bnLfe8xR2dONfzDjBiURqy+lb980wsJa37W4Oaaf15fvNmfx7le7CavOgEgoIYrcPeWMHRTmt98ci8treX35Dldfq7joUGZeOpDRAzqi2qxk6gzYayuxluRg6NCZS8/oiaqqvLViF0tX7UZR4M+Tgz+gWfj5Tg7mVBAVbuDua4ah1fjn+/lHQ/sk8NhfBrP83U+4RL8WvWIjrNcIEi6+s91uqzg5j3Abu/aj4LPnMWfvofCzBdTs20zclJntLg9Er9PywF9GcPdzazhSWM2RQkdrmD9uM6mqSnXDFpNJCuW1mgQzQczYuRcdr/4Xue/NwXxkL3nvziHpqof9+puLVqvh7FHdmDg0mU3vL4RDcNAcw9tvb6Jnl2iun9KXIb3j/SaosdnsfLH2IO+sSqfWbEOjUbh4Qg+u+lMaoSGOf16KVk9Ixx7UZaVTl7UbQ4fOAFw2qRd2FRZ/sYt3vtyNgsKVk/1/paKl1m/PcSVGzr5qKLGRRh+P6NTUeit12bupPbiN2oPbCMnL4M8Gx7Hb0O6DSbzsbhStfAt1chzhfoyydZ9Q+tMHVKevpy5rD/EX3U5Y98E+HZutrhpz9m7qsnZTd2QPush4Yiddiy7CO20DYiKMPHzDKO5d8BNmi+NE6B+DGUvBIazFOShaPabeI7wyjvZE/iUGuZCOqXS8Zg65787BnHuA3KVz6Hj1I2jDIn09tFMy6LX0MJZSA8T16EvoHi37s8p45LX1DOoZx/Xn9SWtW6xPx7j3cCkvfbSVA9nlAKR1i2HW1MF073R80auQ5DTqstIdxfOOqQo79cxeqKrK2yvTWfJlOooCV5wVfAFNQUkNz73/OwCXndGTYX0SfTugE1BVFUvBIVfwUpe1C/UPJwL1ccmE9RpOzOlXoujavrifv1M0WmLGTyUsdQgFnz2HtTiHvHcfJXLE+cROuqZFhxFaor6iyPXDQ13WLiwFWfzxyEHN/s3EnXuz19oHdO8Uxd1XD+XfizYBEBvZeO7VDe0LQnuc5lYKgDgxCWbagZDEFDpdM4fcd/+FJf8guUv/Scer/+X3lSadDSZHnzGaoZf34oNv97JybSbb9hdxz/M/MXpAEtdO6Uu3pLYNzKprrSz5Mp2V6w6iqmAK1fOX8/vxp1Hd0Jxk28SY3IdyTtx08oqzeqOqsOTLdN5emY5GUbj8zF5enkXbqbfZ+c87m6mutZLWNYbrzuvr6yG51FcUU3twqyOAydyGrbq80de1pmhCuw9y/JcyCF2k/yYr+5OQTj3p/Nf/UvLt21T8uoqKTV9Qm7mNhIv/Tkhiikfvpap2rIXZ1GXtaghe0qmvKDruefrYjoQk98XYqQcVv3+LJS+Dgk+epnrPBuLOvckrK9ZjBnbizisH8tvOTFI7Hf0+paqqq+pveD85xeQJEsy0E4aErnS89lFyl/4LS8Fhct55hI7X/Mtvu7PaaiqoLy8EHDVmQkNCuOnigVw8oQfLvt7Dt5sO88uOPDbuzOOMYV24+pw+JMZ696cbVVX5+fccXv90O6WVjp/YzxiWzA0X9icm4tRbJs7iedbiI9hqKo/r/n3l5N6oqso7q3az6ItdKIpjGyoYvPvVbnYfKsVk1HHPtcPQaX2XLGs311B7aGfD6stWrMVHGn1d0Ydg7NqP0O6DCes+CH18V7/Z0gw0R49wD6VwxUtYC7M4svA+Ys+4iqhRF7Y418heb8GSe+Doykv2bux11Y2fpGgISUrF2KUPxi59CUnugy482vXliCGTKf35Q8rWfkT1rrXUHd5F/Pm3EdZzaCtmfGJjByYRoytt9PfIkneQ+tI8FJ2BsF7DPX7P9kiCmXbEEJdMp+seJeedf2Ityib3nUfoeM0cdBG+3a45EeeRbH1sp0ZLsAkxYfztz6dx6Rk9eWdVOuu25fLd5izWbMlmytjuXHlW75M2c2uNnKIqXvloG1v2OgKszvEmbr18MIN7xTfr9dqwSPQdOmEtzqHuyB5MJ/gG9uez01CBpat289aKXSiKwqUNlWgDgaUom5LvlmCrLkcbHoMuIpaCOgOHNxaRpgtj6pQRxJscQWFbBQiqrR5zzn5qGlZfzEf2gnpMuXlFQ0jHHg2rL4MxJvdG0cr2kSeF9RxG8k1PO45w791IyXdLqNn/G/EX3d6sI9y22irM2Xuoy24IXnL2wR960Cl6I8bk3hiT+2Ls0oeQzr1OWY5C0eqInTjNUSvn8+cd22HvP0HEaWfTYfJ0t0tZuMtZWyas51Cv36u9kGCmndHHdqLTdY+R+84/sRbnkLPkYTpdOwddZJyvh9ZIU/VluiRG8MD0kew9XMqSlen8vq+Qz3/KYPWGQ1w8sQeXTuyJKbT1H0rWehsff7+f97/Zi7Xejl6n4YqzejP1zJ7ode79ZGlM7oO1OIfSH5aii4g9YVXjaWenodpV3v16Dws/34miKFwy0b9r7Kh2G+UbPqf0x2XH9QUzAlc7D9D9+A2HfgRFZ0AbEYsuIrYh6OmANqLh14YgSBse06L8ClVVsRYfca281B7aiWppXMVaF5NEWPfBjuClW/+AbJMRaLSmKBKn/oPKrd9S/PVb1B3e2XCE+0Y0qY0D+/ryQmqz0l0rL9bCwye4XrRr1cXYpS+GxJQWrfQYO/dybId9v5SKTV9QuWU1tQe3En/hHYR27dfi+Z6KqqpHezHJKSaPkWCmHdLHJNHxusfIXfpP6kvzyFnyMB2vmYM+2n8KXTmDGUMTxfJ6d43hsVvGsnVvIYtX7mJfVhnvr97LyrUHmXpmb84f352QkzR3a8q2/YW89OE2jhRWATCkVzy3Xj6ITvEt+/CLHH4e1Xs2Yik4zJGF9xE95mKix19x3If2Vef0wa7CstV7ePOzHSgKXDzBPwMaS1E2hZ+/gDlnH+BIZowYchb1lWV8/9N26sqKSDRa6NkB7FWl2OuqUOst1JfmUV+ad8pra0LD0YbHoouIQRveAV2EM9BpCIQiYlEVA4q5itr0tVTlOE4e2SpL/nCdCFfOS2j3QX7197w9URSFyCGTCe02gIJPn8d8ZA+Fnz2PsfcoQnTRlB38nsLcfdhOlO/SoZNr1cXYpS+6mCSPre5p9CHE/ekGTL1HUPj5C9SXFZC75BGiRl9IzMSr0Og8W53anHuA+vICFH0IYT2HefTa7ZnbwcyBAwd4/PHH2bJlCyaTiYsvvpi///3vGAynfsOXLl3KmjVr2Lp1K6WlpTz33HOce+65jZ6zbds2nnnmGfbu3Ut5eTlxcXGMHTuWO++8k8RE/zv9EMj00Ql0uu4xct5xBDS5Sx6m47Vz0Mck+XpoAK5eLyEdm1csb3DveOb3msAvO3JZ8mU6WflVvLViJ5/9dICr/pTG5BFd0TYzV6Os0sxbK3by3eYsAKIjQrjxogFMOK1zq76BhiR1J3nmsxR//SbV6espW/cJ1bs3EHf+rcf9FHj1OWmoqLy/ei9vfOoIaC463X8Cmj+uxighYcSdPYPwQZNQFIUPv9vH4iMWDPp+PHPbBLo2JGnbrWZsVaXUV5Zgqyyhvqrh18qSRo+r9RbstVXYa6tO+JO5i6IQraocm7araPUYu/YltPtgQlMGYUhKabdF7fyRPiaJTtc3HOFe8z51ezcQBtQ5n6DRHs13aQhg2uKwQmjKQJJvepqi1Yuo2vYd5b98Rs2BLSRc+Ldmfx9qDucpprBew9vsdFd74FYwU15ezvTp00lJSWHBggXk5+czd+5c6urqeOSRR0752k8//RSAiRMnsnz58hM+p6KigtTUVK644go6dOhAVlYWL730Etu3b+ejjz5qMmAS7tFFxtGpISnYWnJ0y0kf28mn47JVlzf8dKYQktj8byKKojBmYCdG9u/I95uzePfr3RSW1vLC/7byyQ/7uebcvowb1OmkJ47sdpXVGw+xaMUuqmqtKIqjnP315/Uj3ANbVgC68BgSL7uH6j0bKFr1OtaSHHKXPEzk0HOIPfNaV36Qoihcc04fVNXR3uH15TtQULjwdN9XQj5uNSb1NOLPv9V10md3ZglLvkwHYOalA12BDDh+CtbEJJ0yaFZVFXtdNbaqEuorS7FVFlNfVfqHoKcYW1UZqHZUQJ+QgqnHEEK7D8KY3Ec+JPyc8wh3aOoQir5dQnV1NTG9hxKROpCQTr3QGHxTg0hjNJFw4SxMaSMpWvmyI2l50f3EjL+C6HGXtbpAoqraj55i6itbTJ7kVjCzbNkyqqureeGFF4iOjgbAZrMxZ84cZs6cecrVk2XLlqHRaMjOzj5pMDN+/HjGjx/v+v2oUaPo2LEjN9xwAzt27GDoUM9nmrd3usgOdLyuIaApyiZnieOUkyEu2WdjciX/duiEJsT95DitRmHyyK5MHNqZL9dl8sG3ezlSWM28JZvpkRzF9VP6cVpa48TdzNwKXvpwK+mZji2K1E5R3DZ1kNdq2ZjSRmHsNoCSb9+m8vdvqPjtK6r3bSZ+ykzCejmWnhVF4dpz+6CqKv/7dh+vLd+ORoHzx/smoGlqNQagqsbCf97ZjN2uMuG0zpw9sqvb91EUBW1oONrQcAzxJ3+9ardRVZTPvgMZ9Bk8tM2qVAvPMXbqSezl95Gfnk6Xvn0J9ZP30NR7BMbOvSla9RrVu3+hdM0yavZtJv6iO1r1vdF8xLGNphiMhPYY4rkBC9xae12zZg1jxoxxBTIAU6ZMwW63s3bt2lPfSNOyZV7nvaxW66mfKFpMFx5Dp2sfxZDQFVtVKbnvPIKl4BRL+17mqeaSep2Wiyb04LUHJnP1OX0IDdFxILucf76+nv97eR17s8qw1Nt556u93Pn0D6RnlmA0aPnrRQN4+u8TvF6UT2s0EX/+rY4j8jFJ2CqLyfvg3+Qvf8ZV70RRFK6b0pepDXVnXvlku6uKbluyFGWTs/j/KPluCarNSmjqaXS5+VkiBp/pCmTKq8w8894WCkpr6djBxKypg716aknRaNGGR6PKaRDhBVpTFAmX3UP8xXeiCQnDnLufI2/eS/mmL1CPPRHnhqqGLSZT75Gyeuhhbq3MZGRkcPnllzd6LDIykvj4eDIyMjw2KJvNhs1mIysri//85z/079+fYcNaniilqio1NTUeG59TbW1to18DmqIn+rL7KfnoKeoLD3HknUcwnf93oO3nV3Nkr2NIHbp47H27eHwXJp2WyKc/ZfLVhiy2Hyhi+4EijAaFOoujMujIfglMPy+NuCgjZnNdE1f0oIQedLjmcSrXf0zNb19SvfNnag78TuQZ12LsMxZFUZh6RjcsFiuf/ZzJKx9vo95q4eyRXZq8dGv/jqp2OzW/fUnluo/AZkUxhBIx8RpC+0/AoihYamrYn13Oql+yWL8jj3qbilarcMcV/cFupabGuz+EBNW/wRMI9vmB/89RmzqcDtelUv7161gO76D464VUpq8n6k83o23GKVDnvGpqql2NJXWpw7zymeQr3noP3Snj4FYwU1FRQWTk8dVWo6KiKC8vP8ErWubaa6/lt99+A2DAgAG89tpr6HQtP3hltVpJT0/31PCOk5mZ6bVrtzVl4GWEb16GriKXik//i3b4n2nr6UVl70MDHKnTYPPw+za8G/SKS+DHHZVsyaimzqISZdJy3vBo0jobKMw5SGGOR2/ZfPFD0I5OJGzHF+gqCyhf9QpFm1dT3f9c1NAoTuuiUtQ3nHXpVbzx+W7y8vIY3qt5J6ta8ndUU1WEafsX6ModheWscalU9z+PEm0k1p3p7DxUw8a9VeSUHA1YOsXqmTQoCktFDukVbfcHGUz/Bk8k2OcHATDHvhdiCO9M2J7vsGSlU7DoPmr6no2l8yBoxgfukS0/E1FdiqoL4WCdHrz4meQr3ngPm5sr65dHs5944gkqKys5dOgQr7/+OjNmzOC9994jPLxlR2L1ej09e3q++FhtbS2ZmZmkpKQQGho8S932tDRKP/kP1rwDRK5fhCauC2E9hxPSYxg6L1dEtVWXUWiuBEWh5/AJXksEHD0cMrKL2bD1IFPG9yE6yl9qjfRFHTGB6s1fULVhOfqiA8Sse5Pw8VcSNvgs+vZViP1qHyvWHmLFpjI6derIWcNPvoffkr+jrtWY9cevxhSV17F6Yzbf/XqEyoZVF51WYezAJM4Z1YWeyW3bIiNY/w06Bfv8IMDm2K8f9aPOpnzVq1hz92Ha8QWxNblETr7hpCeunPPrUHMECxDaawQd+w9s23F7mbfew/379zf7uW4FM5GRkVRWVh73eHl5OVFRnvsmlprqSHAcPHgwY8eOZdKkSbz//vv89a9/bdH1FEXxanJgaGhocCUfhoURdu2/yP3kGeoO/Ia9KIuqoiyqfvkEXWQcYb1HENZ7BKFd+3u8a3DNEcdPK/oOnQmP9m7OSmoymCsLiI4K97v3zzTpKqIHnk7hFy9jzt5N5fdvY92/ibjzbuHmSwej1er4dM0BXvs0HYMhhHNGdzvl9Zr7d9RSlE3hihcdlXKB0NQhxJ13CzvzVVa8v4NNu/KwN/Tri48JZcqYFP40qhtR4b7d/w+6f4N/EOzzgwCaY1h3Iv7yBOW/fEbJj8swZ/xG8Tv7iZtyM+F9xpz4Naqd+gzHbkP0oAmBMc8W8PR76M4Pzm59EqWmph6XG1NZWUlhYaErAPG0uLg4kpKSOHTokFeuL05MExJGzEWz2b11M111NdRn/k5txlbqK4qo2PwlFZu/RBMSRmjPoZh6jyQsdQgao6npCzfhaPJv4JTx9xZDXDKdrn+Mil+/ouT7d6jLSif7jbuJOf1Kbjj/IlRUPluTwQv/+x2NAmePOnVAcyonOqkUMfFa1tf25IuXjxYOBEfxwPPGdWdkv8Rm1+4RIpgoGi3RYy8ltMdpFH72PJaCQxR89F9qBkygwzk3ov3D90JdSRb2mnI0xnBCuw/y0aiDm1vBzIQJE3jllVca5c6sWrUKjUbDuHHeOTOfm5tLTk4OXbo0newoPE81mAjrO5ywEedit5qpPbiNmr0bqd63GXtNBdU7f6Z658+g0RHarT9hvUdg6j2ixe0RzHnOYMb39VT8gaJoiBo+BVOv4RR++Sq1B7ZQ+sO7VO9ax3Xn34KqpvL5Txks+N/vKApMHul+QPPH1Rg6D+B741l8+XEFdZYdAISG6DhreBfOG9edLome7y4sRCAKSUyh8w1PUbrmA8rWL6dqxxpqD+0g/oJZhKUOcT3PkLcLAFPaSOn95SVuBTPTpk1jyZIlzJo1i5kzZ5Kfn8+8efOYNm1aoxoz06dPJycnh9WrV7se2759O0eOHKGkxFHHY+vWrQDExsYycuRIAB555BFiYmIYOHAg4eHhHDx4kLfeeosOHTowderUVk9WtI5GH4KpIViJs9sw5+yjeu8mavZuxFqc4+iFc3ArxV+9gSEpFVPvEYT1HokhoVuzlws9dSw72Oii4kn68/9RtWMNxavfwlKQSc6iB7l81IUoY/vz2bpsnv/gdxRF4awRzavtotptlG9cQekP76HarNh1RtaGnM6H25OAUgC6JIZz/rhUJg1LJswo34SF+CNFqyd20jWE9RpO4ecLsJbkkvfeY0QOO5fYM69DtdvQ5+8BpBeTN7kVzERFRbF48WIee+wxZs2ahclkYurUqcyePbvR8+x2OzabrdFjS5cu5ZNPPnH9fuHChQCMHDmSJUuWADBo0CA++OAD3n33XSwWCx07dmTChAnccsstxMTEtGiCwjsUjRZjch+MyX3ocOZ1WIqPULN3E9V7N2HO3oMlLwNLXgala95HFxVPWC9HEGTs2u+keTbO6q4oGgyJ3dt4Rv5PURQiBk4kLHUIRV+/SfWutZT/8innxGwgcsifeOd3eO79LSgKnDn81AHNH1dj9qvJLCkaRZndhEajMKp/EheM787AHnFt1uFaiEBmTE5raFr5jmMr/tdV1GT8jrHf6WgsNSjGcEK7DfD1MIOW29mbPXr0YNGiRad8jjM4OdbcuXOZO3fuKV83depUWYEJUIYOnTGM6Uz0mEuwVZdTvW8zNXs3UXtwK/XlhVRsXknF5pVojCbCegx1JBH3OM1Vvh+OqfwblywFpU5Ba4oi8dK7qB4wgaIvX6W+NI8RpW+T1H0oL2b25tllW1AUhUnDjt+adebGFP/wHoq9nlpVz/Lq4fxi6UlUeAhXjk7h3NEpxMf4+akSIfyQxmAk7pwbCes9gsLPX6S+NI+qtf8DwNhrhMcPTIij5E9WeJzWFEXkkLOIHHKWI88mYys1+za58myqdv5E1c6fHHk2Kf0J6zUSU+8RbjeXbO9MvYYT2rUfJd+9Q8VvX9Gl/Df+Fb+PJaXDePY9UICRfTu4nl+Vl8XhD5/FWJ6JAqRbO7KseiyJXZK5e1x3xg3uhF7Xut4zQggI6z6Y5JufofjrhVRt/wEAY9pon44p2EkwI7xKow/BlDYSU9pIR57NkX1U791Izd5NWEtyqM3YSm3GVoq/eh1F5yiOFJIk+TLNpQkJI27KzZj6j6Poi5ehJJebIn7gN3M3Xl9Wi+WyEWjMFta8u5jued9jVGzUqXo+qxuBsf8ZPDI+lV5dZAtXCE/TGk0kXHQH+l6jyNq/m6Qu/Xw9pKAmwYxoM4pGi7FLH4xd+tDhrOuxFGU78mz2bcKcvRe13gI49p6Fe0K79qfzjfMp+/l/lK3/lKEhh0jT5/LVikxO02fSW18IChwgmdph13Lr6YN8XhtGiPYgpNsArDWy4ultEswInzHEJWOISyZ67KXUV5VRs/9XFK1OTjK1kEYfQuykazH1HUvhipcg/yCXhW0CwIIB85CpTDr3UnRSG0YIEWQkmBF+QRceTeSQs3w9jKAQkpRK5xlzKfvlM4p/+pDaiE6kXP43IpKad2RbCCECjQQzQgQhRasjZtxlGIb8id279zSru68QQgQqWW8WIogpivwTF0IEP/lOJ4QQQoiAJsGMEEIIIQKaBDNCCCGECGgSzAghhBAioEkwI4QQQoiAJsGMEEIIIQKaBDNCCCGECGgSzAghhBAioEkwI4QQQoiAJsGMEEIIIQKaBDNCCCGECGgSzAghhBAioEkwI4QQQoiApqiqqvp6EN7022+/oaoqBoPB49dWVRWr1Yper0dRFI9f39dkfoEv2Oco8wt8wT7HYJ8feG+OFosFRVEYOnRok8/Veeyufsqbf3kURfFKkOQvZH6BL9jnKPMLfME+x2CfH3hvjoqiNPszPOhXZoQQQggR3CRnRgghhBABTYIZIYQQQgQ0CWaEEEIIEdAkmBFCCCFEQJNgRgghhBABTYIZIYQQQgQ0CWaEEEIIEdAkmBFCCCFEQJNgRgghhBABTYIZIYQQQgQ0CWaEEEIIEdAkmBFCCCFEQJNgpgUOHDjAjBkzGDJkCOPGjWPevHlYLBZfD8sjvvzyS2699VYmTJjAkCFDuPjii/nwww8J1n6k1dXVTJgwgbS0NLZv3+7r4XjUJ598wiWXXMLAgQMZNWoUN954I3V1db4elkd8++23XHHFFZx22mmMHz+eO++8k6ysLF8Pq0UOHTrEI488wsUXX0y/fv244IILTvi8//3vf5xzzjkMHDiQiy66iO+//76NR9pyTc2xqqqKBQsWMHXqVIYPH87YsWO55ZZb2LNnj49G7J7mvodO33zzDWlpaU0+z580d44VFRU8/vjjjB8/noEDBzJ58mQWLlzo9fHpvH6HIFNeXs706dNJSUlhwYIF5OfnM3fuXOrq6njkkUd8PbxWW7RoEZ07d+b+++8nJiaGdevW8fDDD5OXl8ftt9/u6+F53EsvvYTNZvP1MDzu5Zdf5vXXX+eWW25hyJAhlJaWsn79+qCY64YNG7j99tu55JJLmD17NmVlZTz33HPccMMNfP755xiNRl8P0S379u3jxx9/ZPDgwdjt9hP+4PDFF1/w8MMPc8sttzB69GhWrlzJ7bffztKlSxkyZEjbD9pNTc0xJyeH999/n8svv5y///3vmM1mFi5cyJ///Gc++ugjevTo4aORN09z3kOnuro6/v3vfxMXF9eGI2y95syxpqaG6667Dq1Wy4MPPkiHDh3IzMykqqrK+wNUhVteeeUVdciQIWppaanrsWXLlql9+/ZV8/LyfDcwDykuLj7usYceekgdOnSoarPZfDAi79m/f786ZMgQ9b333lN79+6tbtu2zddD8ogDBw6o/fr1U3/44QdfD8UrHn74YfXMM89U7Xa767H169ervXv3Vjdt2uTDkbXMsf+u7rvvPvX8888/7jl/+tOf1LvuuqvRY3/+85/VG2+80evj84Sm5lhdXa3W1NQ0eqyqqkodOXKk+uijj7bJGFujOe+h07PPPqtec801TT7P3zRnjs8884x61llnqdXV1W05NFVVVVW2mdy0Zs0axowZQ3R0tOuxKVOmYLfbWbt2re8G5iGxsbHHPda3b1+qqqqoqanxwYi85/HHH2fatGl0797d10PxqI8//pjk5GQmTpzo66F4RX19PSaTCUVRXI9FREQABOR2qEZz6m/DWVlZZGZmMmXKlEaPn3feeaxfvz4gtribmmNYWBihoaGNHjOZTHTt2pWCggJvDs0jmpqf0+HDh3nrrbd46KGHvDwiz2vOHD/88EMuv/xywsLC2mBEjUkw46aMjAxSU1MbPRYZGUl8fDwZGRk+GpV3/frrryQmJhIeHu7roXjMqlWr2Lt3L7NmzfL1UDxu69at9O7dm5deeokxY8YwYMAApk2bxtatW309NI+47LLLOHDgAEuXLqWyspKsrCyefvpp+vXrx9ChQ309PI9zfl/5Y9Ddo0cPrFZrwOYKNaWiooJ9+/Yd9/02kD3xxBNcfPHF9OnTx9dD8bjs7GwKCwuJiYnhlltuYcCAAYwcOZKHHnqI6upqr99fghk3VVRUEBkZedzjUVFRlJeX+2BE3rV582ZWrlzJDTfc4OuheExtbS1z585l9uzZQRWgORUWFvLzzz/z6aef8s9//pMXX3wRRVG44YYbKC4u9vXwWm348OG88MILzJ8/n+HDhzN58mSKi4t5/fXX0Wq1vh6exzm/r/zx+47z98H4fQfgP//5D4qicNVVV/l6KB7x3XffsWXLFu68805fD8UrioqKAHjqqaeIiori9ddfZ/bs2axatYqHH37Y6/eXYEacVF5eHrNnz2bUqFFcf/31vh6Ox7z88st06NCByy+/3NdD8QpVVampqeG5557j3HPPZeLEibz88suoqso777zj6+G12m+//cY//vEPrrzyShYvXsxzzz2H3W7n5ptvDprTWu3dRx99xAcffMAjjzxCUlKSr4fTamazmX//+9/ccccdJ9zKDwZ2ux1wrCA+9dRTjBkzhquuuor77ruPL774wusriHKayU2RkZFUVlb+fzv3F9JkF8cB/PsO3ILJnIEY1URzN5uMvCidDKKZdyLmVcOLGcQc+KdcdrFuopE0iLqKIAyCFNFSiiDGbmLsxuGVI1YDmRP/LBhB5rbKWLT3IjbeNXtdr898fPZ+P5fnMPY9PPOcn885z1PQvrW1haqqKhESlUYikYDNZoNarcb9+/eL3hM+6GKxGB4/fowHDx7krmP2LNCXL1/w+fNnKJVKMSPumUqlglqtzruVrVarodfrEYlEREwmjLGxMRiNRjidzlxbc3Mzzp49i5cvX+LChQsiphNedl5JJpOoqanJtScSibz+cuH3+3Hjxg0MDAygp6dH7DiCePLkCWQyGTo7O3PXLZ1O48ePH0gkEjh06BDkcrnIKfcm+ztsbW3NazcajQB+Pg2l0WhK9v0sZv7QiRMnCs7GJJNJfPjwoWz2dre3t2G325FMJvH06dPc4cpysLGxgXQ6jf7+/oI+q9WKkydP4tmzZyIkE45Wq8Xa2tqOfd++fdvnNMJbXl7GuXPn8tqOHDmC6urq345byrLzyq/n9aLRKCoqKkq6QOy3YDCIK1eu4Pz582W1HRONRrG6uoq2traCvtOnT+PmzZuS307TaDT/WpCVeu5hMfOHzpw5g4cPH+adnfF6vZDJZDCZTCKn27vv379jZGQE0WgUU1NTqK2tFTuSoHQ6HSYmJvLawuEw3G43XC4XDAaDSMmEYzab8fz5c4TDYeh0OgDA5uYm3r59i4sXL4obTgBHjx7Fu3fv8tpisRg2Nzdx7NgxkVKVjkajQX19PbxeLzo6OnLtHo8HbW1tkv+PPisSicBut8NoNMLlcokdR1A2m63gLtP4+DhWVlbgdrtRX18vTjAByeVymEwmBAKBvPb5+XkAQFNTU0m/n8XMH7JYLJicnMTg4CDsdjvi8Tju3LkDi8VSFgu/y+WCz+eD0+lEKpVCMBjM9en1eslPnCqVquA2aFZTU1PJ/+D2Q0dHBwwGAy5fvgyHwwGFQoHx8XHI5XL09vaKHW/PLBYLbt++jbGxMbS3t+PTp0+5c1C/Pr4sBV+/foXf7wfwsyhLpVLwer0AgJaWFhw+fBjDw8O4du0a6urq0NraCo/Hgzdv3kjmDNRuY8xkMrh06RIUCgX6+voQCoVyn62srIRWqxUld7F2G19jY2PBi/9evHiBeDz+2/nooCnmdzo0NASLxYLR0VH09PRgdXUV9+7dQ1dXF+rq6kqa76+MFF/MILLl5WXcunULi4uLUCqV6O7uhsPhkPxCDwDt7e2IxWI79r1+/RrHjx/f50Slt7CwAKvVirm5ubK4MwMAHz9+hNvths/nQzqdxqlTp3D9+vUDvygUI5PJYGZmBtPT01hfX4dSqURzczMcDseBf1PsTjY2Ngq2zbImJiZyi93s7CwePXqE9+/fo6GhAVevXoXZbN7PqP/ZbmME8NuHDFpaWjA5OVmybEIo9hr+k9PpRCgUwqtXr0odTxDFjjEQCODu3btYWlpCVVUVurq69mV9ZDFDREREklYej6gQERHR/xaLGSIiIpI0FjNEREQkaSxmiIiISNJYzBAREZGksZghIiIiSWMxQ0RERJLGYoaIiIgkjcUMERERSRqLGSIiIpI0FjNEREQkaX8Dio83jcveOdUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TBa6lvRtXIdM",
        "outputId": "7f40aaf5-89f2-4470-8489-9c67355ce7f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.5899,\tval_loss: 0.5017\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5818,\tval_loss: 0.5022\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5709,\tval_loss: 0.4996\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.5632,\tval_loss: 0.4966\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.5624,\tval_loss: 0.4936\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.5479,\tval_loss: 0.4911\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.5418,\tval_loss: 0.4898\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.5295,\tval_loss: 0.4862\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.5223,\tval_loss: 0.4836\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 0.5318,\tval_loss: 0.4820\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.5329,\tval_loss: 0.4783\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.5200,\tval_loss: 0.4782\n",
            "12:\t[0s / 4s],\t\ttrain_loss: 0.5115,\tval_loss: 0.4746\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 0.5129,\tval_loss: 0.4735\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.5058,\tval_loss: 0.4690\n",
            "15:\t[0s / 5s],\t\ttrain_loss: 0.4980,\tval_loss: 0.4661\n",
            "16:\t[0s / 5s],\t\ttrain_loss: 0.5035,\tval_loss: 0.4655\n",
            "17:\t[0s / 5s],\t\ttrain_loss: 0.4946,\tval_loss: 0.4643\n",
            "18:\t[0s / 5s],\t\ttrain_loss: 0.5042,\tval_loss: 0.4630\n",
            "19:\t[0s / 5s],\t\ttrain_loss: 0.4900,\tval_loss: 0.4611\n",
            "20:\t[0s / 5s],\t\ttrain_loss: 0.4951,\tval_loss: 0.4584\n",
            "21:\t[0s / 5s],\t\ttrain_loss: 0.4814,\tval_loss: 0.4581\n",
            "22:\t[0s / 5s],\t\ttrain_loss: 0.4885,\tval_loss: 0.4553\n",
            "23:\t[0s / 6s],\t\ttrain_loss: 0.4733,\tval_loss: 0.4537\n",
            "24:\t[0s / 6s],\t\ttrain_loss: 0.4722,\tval_loss: 0.4512\n",
            "25:\t[0s / 6s],\t\ttrain_loss: 0.4744,\tval_loss: 0.4509\n",
            "26:\t[0s / 6s],\t\ttrain_loss: 0.4711,\tval_loss: 0.4486\n",
            "27:\t[0s / 6s],\t\ttrain_loss: 0.4713,\tval_loss: 0.4458\n",
            "28:\t[0s / 6s],\t\ttrain_loss: 0.4657,\tval_loss: 0.4435\n",
            "29:\t[0s / 6s],\t\ttrain_loss: 0.4728,\tval_loss: 0.4407\n",
            "30:\t[0s / 6s],\t\ttrain_loss: 0.4521,\tval_loss: 0.4412\n",
            "31:\t[0s / 6s],\t\ttrain_loss: 0.4531,\tval_loss: 0.4377\n",
            "32:\t[0s / 6s],\t\ttrain_loss: 0.4521,\tval_loss: 0.4363\n",
            "33:\t[0s / 7s],\t\ttrain_loss: 0.4443,\tval_loss: 0.4323\n",
            "34:\t[0s / 7s],\t\ttrain_loss: 0.4535,\tval_loss: 0.4296\n",
            "35:\t[0s / 7s],\t\ttrain_loss: 0.4428,\tval_loss: 0.4296\n",
            "36:\t[0s / 7s],\t\ttrain_loss: 0.4459,\tval_loss: 0.4261\n",
            "37:\t[0s / 7s],\t\ttrain_loss: 0.4346,\tval_loss: 0.4248\n",
            "38:\t[0s / 7s],\t\ttrain_loss: 0.4301,\tval_loss: 0.4209\n",
            "39:\t[0s / 7s],\t\ttrain_loss: 0.4283,\tval_loss: 0.4180\n",
            "40:\t[0s / 7s],\t\ttrain_loss: 0.4296,\tval_loss: 0.4158\n",
            "41:\t[0s / 7s],\t\ttrain_loss: 0.4274,\tval_loss: 0.4154\n",
            "42:\t[0s / 8s],\t\ttrain_loss: 0.4268,\tval_loss: 0.4119\n",
            "43:\t[0s / 8s],\t\ttrain_loss: 0.4228,\tval_loss: 0.4093\n",
            "44:\t[0s / 8s],\t\ttrain_loss: 0.4108,\tval_loss: 0.4086\n",
            "45:\t[0s / 8s],\t\ttrain_loss: 0.4138,\tval_loss: 0.4064\n",
            "46:\t[0s / 8s],\t\ttrain_loss: 0.4063,\tval_loss: 0.4036\n",
            "47:\t[0s / 8s],\t\ttrain_loss: 0.3999,\tval_loss: 0.4020\n",
            "48:\t[0s / 8s],\t\ttrain_loss: 0.4029,\tval_loss: 0.3993\n",
            "49:\t[0s / 8s],\t\ttrain_loss: 0.4041,\tval_loss: 0.3972\n",
            "50:\t[0s / 8s],\t\ttrain_loss: 0.3939,\tval_loss: 0.3953\n",
            "51:\t[0s / 8s],\t\ttrain_loss: 0.3985,\tval_loss: 0.3925\n",
            "52:\t[0s / 9s],\t\ttrain_loss: 0.3963,\tval_loss: 0.3917\n",
            "53:\t[0s / 9s],\t\ttrain_loss: 0.3884,\tval_loss: 0.3889\n",
            "54:\t[0s / 9s],\t\ttrain_loss: 0.3786,\tval_loss: 0.3875\n",
            "55:\t[0s / 9s],\t\ttrain_loss: 0.3884,\tval_loss: 0.3839\n",
            "56:\t[0s / 9s],\t\ttrain_loss: 0.3783,\tval_loss: 0.3837\n",
            "57:\t[0s / 9s],\t\ttrain_loss: 0.3686,\tval_loss: 0.3817\n",
            "58:\t[0s / 9s],\t\ttrain_loss: 0.3693,\tval_loss: 0.3821\n",
            "59:\t[0s / 9s],\t\ttrain_loss: 0.3690,\tval_loss: 0.3795\n",
            "60:\t[0s / 9s],\t\ttrain_loss: 0.3736,\tval_loss: 0.3759\n",
            "61:\t[0s / 9s],\t\ttrain_loss: 0.3640,\tval_loss: 0.3733\n",
            "62:\t[0s / 10s],\t\ttrain_loss: 0.3713,\tval_loss: 0.3722\n",
            "63:\t[0s / 10s],\t\ttrain_loss: 0.3612,\tval_loss: 0.3723\n",
            "64:\t[0s / 10s],\t\ttrain_loss: 0.3650,\tval_loss: 0.3697\n",
            "65:\t[0s / 10s],\t\ttrain_loss: 0.3576,\tval_loss: 0.3672\n",
            "66:\t[0s / 10s],\t\ttrain_loss: 0.3534,\tval_loss: 0.3660\n",
            "67:\t[0s / 10s],\t\ttrain_loss: 0.3555,\tval_loss: 0.3658\n",
            "68:\t[0s / 10s],\t\ttrain_loss: 0.3468,\tval_loss: 0.3638\n",
            "69:\t[0s / 10s],\t\ttrain_loss: 0.3399,\tval_loss: 0.3618\n",
            "70:\t[0s / 10s],\t\ttrain_loss: 0.3437,\tval_loss: 0.3608\n",
            "71:\t[0s / 10s],\t\ttrain_loss: 0.3444,\tval_loss: 0.3598\n",
            "72:\t[0s / 11s],\t\ttrain_loss: 0.3468,\tval_loss: 0.3587\n",
            "73:\t[0s / 11s],\t\ttrain_loss: 0.3419,\tval_loss: 0.3580\n",
            "74:\t[0s / 11s],\t\ttrain_loss: 0.3377,\tval_loss: 0.3561\n",
            "75:\t[0s / 11s],\t\ttrain_loss: 0.3321,\tval_loss: 0.3550\n",
            "76:\t[0s / 11s],\t\ttrain_loss: 0.3398,\tval_loss: 0.3521\n",
            "77:\t[0s / 11s],\t\ttrain_loss: 0.3320,\tval_loss: 0.3524\n",
            "78:\t[0s / 11s],\t\ttrain_loss: 0.3391,\tval_loss: 0.3507\n",
            "79:\t[0s / 11s],\t\ttrain_loss: 0.3273,\tval_loss: 0.3504\n",
            "80:\t[0s / 11s],\t\ttrain_loss: 0.3221,\tval_loss: 0.3482\n",
            "81:\t[0s / 12s],\t\ttrain_loss: 0.3215,\tval_loss: 0.3469\n",
            "82:\t[0s / 12s],\t\ttrain_loss: 0.3252,\tval_loss: 0.3472\n",
            "83:\t[0s / 12s],\t\ttrain_loss: 0.3302,\tval_loss: 0.3449\n",
            "84:\t[0s / 12s],\t\ttrain_loss: 0.3214,\tval_loss: 0.3442\n",
            "85:\t[0s / 12s],\t\ttrain_loss: 0.3240,\tval_loss: 0.3431\n",
            "86:\t[0s / 12s],\t\ttrain_loss: 0.3089,\tval_loss: 0.3419\n",
            "87:\t[0s / 12s],\t\ttrain_loss: 0.3121,\tval_loss: 0.3408\n",
            "88:\t[0s / 12s],\t\ttrain_loss: 0.3212,\tval_loss: 0.3387\n",
            "89:\t[0s / 12s],\t\ttrain_loss: 0.3067,\tval_loss: 0.3400\n",
            "90:\t[0s / 12s],\t\ttrain_loss: 0.3050,\tval_loss: 0.3385\n",
            "91:\t[0s / 13s],\t\ttrain_loss: 0.3180,\tval_loss: 0.3364\n",
            "92:\t[0s / 13s],\t\ttrain_loss: 0.3030,\tval_loss: 0.3354\n",
            "93:\t[0s / 13s],\t\ttrain_loss: 0.3061,\tval_loss: 0.3343\n",
            "94:\t[0s / 13s],\t\ttrain_loss: 0.3070,\tval_loss: 0.3339\n",
            "95:\t[0s / 13s],\t\ttrain_loss: 0.3072,\tval_loss: 0.3325\n",
            "96:\t[0s / 13s],\t\ttrain_loss: 0.3006,\tval_loss: 0.3322\n",
            "97:\t[0s / 13s],\t\ttrain_loss: 0.3043,\tval_loss: 0.3314\n",
            "98:\t[0s / 13s],\t\ttrain_loss: 0.3111,\tval_loss: 0.3305\n",
            "99:\t[0s / 13s],\t\ttrain_loss: 0.2909,\tval_loss: 0.3302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6384,\tval_loss: 0.5462\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.6103,\tval_loss: 0.5490\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.6091,\tval_loss: 0.5435\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5909,\tval_loss: 0.5387\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5785,\tval_loss: 0.5328\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5818,\tval_loss: 0.5294\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.5808,\tval_loss: 0.5244\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.5551,\tval_loss: 0.5188\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.5684,\tval_loss: 0.5164\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.5454,\tval_loss: 0.5142\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.5425,\tval_loss: 0.5105\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.5452,\tval_loss: 0.5056\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.5384,\tval_loss: 0.5031\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.5478,\tval_loss: 0.4999\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.5309,\tval_loss: 0.4982\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.5193,\tval_loss: 0.4954\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.5304,\tval_loss: 0.4938\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.5187,\tval_loss: 0.4915\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.5077,\tval_loss: 0.4890\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.5201,\tval_loss: 0.4859\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.5068,\tval_loss: 0.4846\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.4987,\tval_loss: 0.4825\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.5013,\tval_loss: 0.4816\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.4941,\tval_loss: 0.4776\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.5025,\tval_loss: 0.4751\n",
            "25:\t[0s / 4s],\t\ttrain_loss: 0.4987,\tval_loss: 0.4719\n",
            "26:\t[0s / 4s],\t\ttrain_loss: 0.4907,\tval_loss: 0.4717\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.4901,\tval_loss: 0.4684\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.4880,\tval_loss: 0.4663\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.4853,\tval_loss: 0.4627\n",
            "30:\t[0s / 5s],\t\ttrain_loss: 0.4734,\tval_loss: 0.4589\n",
            "31:\t[0s / 5s],\t\ttrain_loss: 0.4800,\tval_loss: 0.4584\n",
            "32:\t[0s / 5s],\t\ttrain_loss: 0.4770,\tval_loss: 0.4556\n",
            "33:\t[0s / 5s],\t\ttrain_loss: 0.4688,\tval_loss: 0.4529\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.4730,\tval_loss: 0.4514\n",
            "35:\t[0s / 6s],\t\ttrain_loss: 0.4607,\tval_loss: 0.4484\n",
            "36:\t[0s / 6s],\t\ttrain_loss: 0.4729,\tval_loss: 0.4460\n",
            "37:\t[0s / 6s],\t\ttrain_loss: 0.4641,\tval_loss: 0.4444\n",
            "38:\t[0s / 6s],\t\ttrain_loss: 0.4526,\tval_loss: 0.4418\n",
            "39:\t[0s / 6s],\t\ttrain_loss: 0.4596,\tval_loss: 0.4405\n",
            "40:\t[0s / 6s],\t\ttrain_loss: 0.4501,\tval_loss: 0.4373\n",
            "41:\t[0s / 7s],\t\ttrain_loss: 0.4544,\tval_loss: 0.4363\n",
            "42:\t[0s / 7s],\t\ttrain_loss: 0.4467,\tval_loss: 0.4324\n",
            "43:\t[0s / 7s],\t\ttrain_loss: 0.4401,\tval_loss: 0.4298\n",
            "44:\t[0s / 7s],\t\ttrain_loss: 0.4331,\tval_loss: 0.4288\n",
            "45:\t[0s / 7s],\t\ttrain_loss: 0.4448,\tval_loss: 0.4276\n",
            "46:\t[0s / 8s],\t\ttrain_loss: 0.4328,\tval_loss: 0.4252\n",
            "47:\t[0s / 8s],\t\ttrain_loss: 0.4398,\tval_loss: 0.4220\n",
            "48:\t[0s / 8s],\t\ttrain_loss: 0.4294,\tval_loss: 0.4195\n",
            "49:\t[0s / 8s],\t\ttrain_loss: 0.4225,\tval_loss: 0.4173\n",
            "50:\t[0s / 8s],\t\ttrain_loss: 0.4205,\tval_loss: 0.4150\n",
            "51:\t[0s / 9s],\t\ttrain_loss: 0.4193,\tval_loss: 0.4135\n",
            "52:\t[0s / 9s],\t\ttrain_loss: 0.4144,\tval_loss: 0.4123\n",
            "53:\t[0s / 9s],\t\ttrain_loss: 0.4059,\tval_loss: 0.4094\n",
            "54:\t[0s / 9s],\t\ttrain_loss: 0.4136,\tval_loss: 0.4085\n",
            "55:\t[0s / 9s],\t\ttrain_loss: 0.4026,\tval_loss: 0.4063\n",
            "56:\t[0s / 9s],\t\ttrain_loss: 0.4066,\tval_loss: 0.4052\n",
            "57:\t[0s / 9s],\t\ttrain_loss: 0.3999,\tval_loss: 0.4036\n",
            "58:\t[0s / 10s],\t\ttrain_loss: 0.4031,\tval_loss: 0.4018\n",
            "59:\t[0s / 10s],\t\ttrain_loss: 0.4007,\tval_loss: 0.4014\n",
            "60:\t[0s / 10s],\t\ttrain_loss: 0.3983,\tval_loss: 0.4004\n",
            "61:\t[0s / 10s],\t\ttrain_loss: 0.3964,\tval_loss: 0.3991\n",
            "62:\t[0s / 10s],\t\ttrain_loss: 0.3846,\tval_loss: 0.3968\n",
            "63:\t[0s / 10s],\t\ttrain_loss: 0.3877,\tval_loss: 0.3954\n",
            "64:\t[0s / 10s],\t\ttrain_loss: 0.3854,\tval_loss: 0.3932\n",
            "65:\t[0s / 10s],\t\ttrain_loss: 0.3711,\tval_loss: 0.3917\n",
            "66:\t[0s / 10s],\t\ttrain_loss: 0.3821,\tval_loss: 0.3907\n",
            "67:\t[0s / 11s],\t\ttrain_loss: 0.3768,\tval_loss: 0.3897\n",
            "68:\t[0s / 11s],\t\ttrain_loss: 0.3756,\tval_loss: 0.3857\n",
            "69:\t[0s / 11s],\t\ttrain_loss: 0.3757,\tval_loss: 0.3860\n",
            "70:\t[0s / 11s],\t\ttrain_loss: 0.3767,\tval_loss: 0.3849\n",
            "71:\t[0s / 11s],\t\ttrain_loss: 0.3732,\tval_loss: 0.3838\n",
            "72:\t[0s / 11s],\t\ttrain_loss: 0.3742,\tval_loss: 0.3815\n",
            "73:\t[0s / 11s],\t\ttrain_loss: 0.3662,\tval_loss: 0.3814\n",
            "74:\t[0s / 11s],\t\ttrain_loss: 0.3704,\tval_loss: 0.3789\n",
            "75:\t[0s / 11s],\t\ttrain_loss: 0.3659,\tval_loss: 0.3781\n",
            "76:\t[0s / 12s],\t\ttrain_loss: 0.3556,\tval_loss: 0.3769\n",
            "77:\t[0s / 12s],\t\ttrain_loss: 0.3507,\tval_loss: 0.3764\n",
            "78:\t[0s / 12s],\t\ttrain_loss: 0.3573,\tval_loss: 0.3761\n",
            "79:\t[0s / 12s],\t\ttrain_loss: 0.3578,\tval_loss: 0.3744\n",
            "80:\t[0s / 12s],\t\ttrain_loss: 0.3506,\tval_loss: 0.3729\n",
            "81:\t[0s / 12s],\t\ttrain_loss: 0.3436,\tval_loss: 0.3729\n",
            "82:\t[0s / 12s],\t\ttrain_loss: 0.3581,\tval_loss: 0.3727\n",
            "83:\t[0s / 12s],\t\ttrain_loss: 0.3439,\tval_loss: 0.3718\n",
            "84:\t[0s / 12s],\t\ttrain_loss: 0.3449,\tval_loss: 0.3709\n",
            "85:\t[0s / 12s],\t\ttrain_loss: 0.3368,\tval_loss: 0.3694\n",
            "86:\t[0s / 13s],\t\ttrain_loss: 0.3376,\tval_loss: 0.3684\n",
            "87:\t[0s / 13s],\t\ttrain_loss: 0.3433,\tval_loss: 0.3669\n",
            "88:\t[0s / 13s],\t\ttrain_loss: 0.3323,\tval_loss: 0.3676\n",
            "89:\t[0s / 13s],\t\ttrain_loss: 0.3446,\tval_loss: 0.3691\n",
            "90:\t[0s / 13s],\t\ttrain_loss: 0.3312,\tval_loss: 0.3660\n",
            "91:\t[0s / 13s],\t\ttrain_loss: 0.3444,\tval_loss: 0.3652\n",
            "92:\t[0s / 13s],\t\ttrain_loss: 0.3286,\tval_loss: 0.3646\n",
            "93:\t[0s / 13s],\t\ttrain_loss: 0.3405,\tval_loss: 0.3643\n",
            "94:\t[0s / 13s],\t\ttrain_loss: 0.3283,\tval_loss: 0.3633\n",
            "95:\t[0s / 14s],\t\ttrain_loss: 0.3247,\tval_loss: 0.3627\n",
            "96:\t[0s / 14s],\t\ttrain_loss: 0.3292,\tval_loss: 0.3628\n",
            "97:\t[0s / 14s],\t\ttrain_loss: 0.3271,\tval_loss: 0.3627\n",
            "98:\t[0s / 14s],\t\ttrain_loss: 0.3240,\tval_loss: 0.3620\n",
            "99:\t[0s / 14s],\t\ttrain_loss: 0.3208,\tval_loss: 0.3609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6197,\tval_loss: 0.5445\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.6012,\tval_loss: 0.5452\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5862,\tval_loss: 0.5443\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5794,\tval_loss: 0.5405\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5859,\tval_loss: 0.5366\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5653,\tval_loss: 0.5309\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.5704,\tval_loss: 0.5283\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.5700,\tval_loss: 0.5254\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.5637,\tval_loss: 0.5211\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.5433,\tval_loss: 0.5185\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.5569,\tval_loss: 0.5162\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.5437,\tval_loss: 0.5128\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.5413,\tval_loss: 0.5094\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.5433,\tval_loss: 0.5061\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.5303,\tval_loss: 0.5038\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.5337,\tval_loss: 0.5023\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.5243,\tval_loss: 0.4996\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.5204,\tval_loss: 0.4982\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.5250,\tval_loss: 0.4947\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.5250,\tval_loss: 0.4916\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.5215,\tval_loss: 0.4881\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.5114,\tval_loss: 0.4867\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.5076,\tval_loss: 0.4839\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.5020,\tval_loss: 0.4814\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.4971,\tval_loss: 0.4794\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.5024,\tval_loss: 0.4768\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.4967,\tval_loss: 0.4733\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.4881,\tval_loss: 0.4709\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.4881,\tval_loss: 0.4670\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.4885,\tval_loss: 0.4657\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.4739,\tval_loss: 0.4631\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.4815,\tval_loss: 0.4595\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.4756,\tval_loss: 0.4572\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.4685,\tval_loss: 0.4539\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.4709,\tval_loss: 0.4509\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.4606,\tval_loss: 0.4497\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.4584,\tval_loss: 0.4461\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.4545,\tval_loss: 0.4444\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.4545,\tval_loss: 0.4412\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.4432,\tval_loss: 0.4382\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.4465,\tval_loss: 0.4359\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.4415,\tval_loss: 0.4320\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.4389,\tval_loss: 0.4297\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.4356,\tval_loss: 0.4284\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.4342,\tval_loss: 0.4262\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.4270,\tval_loss: 0.4222\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.4372,\tval_loss: 0.4203\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.4279,\tval_loss: 0.4159\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.4185,\tval_loss: 0.4125\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.4186,\tval_loss: 0.4114\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.4287,\tval_loss: 0.4091\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.4089,\tval_loss: 0.4087\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.4118,\tval_loss: 0.4054\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.4035,\tval_loss: 0.4022\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.4051,\tval_loss: 0.3998\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.3906,\tval_loss: 0.3973\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.3921,\tval_loss: 0.3932\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.3923,\tval_loss: 0.3951\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.3941,\tval_loss: 0.3932\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.3858,\tval_loss: 0.3906\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.3860,\tval_loss: 0.3884\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.3739,\tval_loss: 0.3880\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.3818,\tval_loss: 0.3853\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.3740,\tval_loss: 0.3816\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.3695,\tval_loss: 0.3810\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.3656,\tval_loss: 0.3787\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.3706,\tval_loss: 0.3767\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.3541,\tval_loss: 0.3758\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.3658,\tval_loss: 0.3726\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.3590,\tval_loss: 0.3729\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.3625,\tval_loss: 0.3721\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.3538,\tval_loss: 0.3703\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.3472,\tval_loss: 0.3669\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.3655,\tval_loss: 0.3680\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.3437,\tval_loss: 0.3686\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.3579,\tval_loss: 0.3656\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.3443,\tval_loss: 0.3635\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.3403,\tval_loss: 0.3634\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.3385,\tval_loss: 0.3622\n",
            "79:\t[0s / 10s],\t\ttrain_loss: 0.3365,\tval_loss: 0.3598\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.3413,\tval_loss: 0.3597\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.3352,\tval_loss: 0.3588\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.3379,\tval_loss: 0.3586\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.3304,\tval_loss: 0.3560\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.3342,\tval_loss: 0.3542\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.3170,\tval_loss: 0.3562\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.3334,\tval_loss: 0.3536\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.3316,\tval_loss: 0.3527\n",
            "88:\t[0s / 11s],\t\ttrain_loss: 0.3226,\tval_loss: 0.3516\n",
            "89:\t[0s / 11s],\t\ttrain_loss: 0.3231,\tval_loss: 0.3502\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.3212,\tval_loss: 0.3509\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.3327,\tval_loss: 0.3504\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.3101,\tval_loss: 0.3484\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.3102,\tval_loss: 0.3480\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.3089,\tval_loss: 0.3476\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.3130,\tval_loss: 0.3473\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.3193,\tval_loss: 0.3465\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.3002,\tval_loss: 0.3474\n",
            "98:\t[0s / 12s],\t\ttrain_loss: 0.3086,\tval_loss: 0.3469\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.3046,\tval_loss: 0.3487\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6220,\tval_loss: 0.5283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5999,\tval_loss: 0.5114\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.6071,\tval_loss: 0.5065\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5823,\tval_loss: 0.5018\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5587,\tval_loss: 0.4971\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5585,\tval_loss: 0.4962\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.5508,\tval_loss: 0.4956\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.5470,\tval_loss: 0.4919\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.5255,\tval_loss: 0.4891\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.5372,\tval_loss: 0.4883\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.5220,\tval_loss: 0.4846\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.5190,\tval_loss: 0.4838\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.5175,\tval_loss: 0.4824\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.5188,\tval_loss: 0.4785\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.5221,\tval_loss: 0.4774\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.5081,\tval_loss: 0.4760\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.4978,\tval_loss: 0.4744\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.5021,\tval_loss: 0.4732\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.4979,\tval_loss: 0.4701\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.4931,\tval_loss: 0.4700\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.4906,\tval_loss: 0.4686\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.4880,\tval_loss: 0.4662\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.4803,\tval_loss: 0.4635\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.4785,\tval_loss: 0.4614\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.4811,\tval_loss: 0.4603\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.4658,\tval_loss: 0.4578\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.4718,\tval_loss: 0.4558\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.4700,\tval_loss: 0.4543\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.4677,\tval_loss: 0.4532\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.4685,\tval_loss: 0.4506\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.4552,\tval_loss: 0.4502\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.4497,\tval_loss: 0.4483\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.4484,\tval_loss: 0.4471\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.4521,\tval_loss: 0.4455\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.4528,\tval_loss: 0.4440\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.4418,\tval_loss: 0.4408\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.4388,\tval_loss: 0.4418\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.4371,\tval_loss: 0.4380\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.4336,\tval_loss: 0.4367\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.4305,\tval_loss: 0.4371\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.4262,\tval_loss: 0.4347\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.4228,\tval_loss: 0.4328\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.4149,\tval_loss: 0.4321\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.4183,\tval_loss: 0.4313\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.4089,\tval_loss: 0.4298\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.4093,\tval_loss: 0.4292\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.4018,\tval_loss: 0.4262\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.4108,\tval_loss: 0.4257\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.3987,\tval_loss: 0.4257\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.3985,\tval_loss: 0.4215\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.3934,\tval_loss: 0.4198\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.3854,\tval_loss: 0.4207\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.3918,\tval_loss: 0.4191\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.3870,\tval_loss: 0.4158\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.3880,\tval_loss: 0.4158\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.3944,\tval_loss: 0.4148\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.3836,\tval_loss: 0.4139\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.3781,\tval_loss: 0.4111\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.3664,\tval_loss: 0.4118\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.3704,\tval_loss: 0.4097\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.3723,\tval_loss: 0.4125\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.3615,\tval_loss: 0.4114\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.3578,\tval_loss: 0.4071\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.3608,\tval_loss: 0.4083\n",
            "64:\t[0s / 9s],\t\ttrain_loss: 0.3579,\tval_loss: 0.4052\n",
            "65:\t[0s / 9s],\t\ttrain_loss: 0.3567,\tval_loss: 0.4047\n",
            "66:\t[0s / 9s],\t\ttrain_loss: 0.3518,\tval_loss: 0.4072\n",
            "67:\t[0s / 10s],\t\ttrain_loss: 0.3420,\tval_loss: 0.4050\n",
            "68:\t[0s / 10s],\t\ttrain_loss: 0.3509,\tval_loss: 0.4060\n",
            "69:\t[0s / 10s],\t\ttrain_loss: 0.3411,\tval_loss: 0.4035\n",
            "70:\t[0s / 11s],\t\ttrain_loss: 0.3425,\tval_loss: 0.4055\n",
            "71:\t[0s / 11s],\t\ttrain_loss: 0.3321,\tval_loss: 0.4062\n",
            "72:\t[0s / 11s],\t\ttrain_loss: 0.3388,\tval_loss: 0.4051\n",
            "73:\t[0s / 11s],\t\ttrain_loss: 0.3382,\tval_loss: 0.4023\n",
            "74:\t[0s / 12s],\t\ttrain_loss: 0.3297,\tval_loss: 0.4015\n",
            "75:\t[0s / 12s],\t\ttrain_loss: 0.3245,\tval_loss: 0.4056\n",
            "76:\t[0s / 12s],\t\ttrain_loss: 0.3252,\tval_loss: 0.4007\n",
            "77:\t[0s / 12s],\t\ttrain_loss: 0.3254,\tval_loss: 0.4029\n",
            "78:\t[0s / 12s],\t\ttrain_loss: 0.3228,\tval_loss: 0.4034\n",
            "79:\t[0s / 12s],\t\ttrain_loss: 0.3224,\tval_loss: 0.4037\n",
            "80:\t[0s / 13s],\t\ttrain_loss: 0.3391,\tval_loss: 0.4037\n",
            "81:\t[0s / 13s],\t\ttrain_loss: 0.3140,\tval_loss: 0.4023\n",
            "82:\t[0s / 13s],\t\ttrain_loss: 0.3031,\tval_loss: 0.4064\n",
            "83:\t[0s / 13s],\t\ttrain_loss: 0.3092,\tval_loss: 0.4074\n",
            "84:\t[0s / 13s],\t\ttrain_loss: 0.3097,\tval_loss: 0.4049\n",
            "85:\t[0s / 13s],\t\ttrain_loss: 0.3068,\tval_loss: 0.4036\n",
            "86:\t[0s / 13s],\t\ttrain_loss: 0.3031,\tval_loss: 0.4052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6107,\tval_loss: 0.4960\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5792,\tval_loss: 0.4947\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5758,\tval_loss: 0.4923\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5534,\tval_loss: 0.4902\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5471,\tval_loss: 0.4840\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5452,\tval_loss: 0.4809\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.5444,\tval_loss: 0.4767\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.5295,\tval_loss: 0.4763\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.5341,\tval_loss: 0.4734\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.5435,\tval_loss: 0.4700\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.5281,\tval_loss: 0.4676\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.5246,\tval_loss: 0.4664\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.5225,\tval_loss: 0.4630\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.5172,\tval_loss: 0.4611\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.5100,\tval_loss: 0.4582\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.5147,\tval_loss: 0.4572\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.5039,\tval_loss: 0.4544\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.5047,\tval_loss: 0.4525\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.5033,\tval_loss: 0.4501\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.4919,\tval_loss: 0.4480\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.4836,\tval_loss: 0.4455\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.4947,\tval_loss: 0.4446\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.4881,\tval_loss: 0.4426\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.4795,\tval_loss: 0.4420\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.4797,\tval_loss: 0.4384\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.4787,\tval_loss: 0.4379\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.4708,\tval_loss: 0.4354\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.4723,\tval_loss: 0.4307\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.4702,\tval_loss: 0.4305\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.4597,\tval_loss: 0.4276\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.4605,\tval_loss: 0.4250\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.4558,\tval_loss: 0.4242\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.4620,\tval_loss: 0.4228\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.4596,\tval_loss: 0.4198\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.4529,\tval_loss: 0.4184\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.4495,\tval_loss: 0.4169\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.4394,\tval_loss: 0.4131\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.4511,\tval_loss: 0.4114\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.4357,\tval_loss: 0.4092\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.4393,\tval_loss: 0.4073\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.4373,\tval_loss: 0.4043\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.4278,\tval_loss: 0.4019\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.4217,\tval_loss: 0.4013\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.4236,\tval_loss: 0.3991\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.4144,\tval_loss: 0.3971\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.4094,\tval_loss: 0.3930\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.4214,\tval_loss: 0.3915\n",
            "47:\t[0s / 4s],\t\ttrain_loss: 0.4066,\tval_loss: 0.3890\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.4094,\tval_loss: 0.3876\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.4072,\tval_loss: 0.3852\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.4027,\tval_loss: 0.3826\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.4006,\tval_loss: 0.3795\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.3971,\tval_loss: 0.3790\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.3909,\tval_loss: 0.3747\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.3858,\tval_loss: 0.3739\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.3784,\tval_loss: 0.3719\n",
            "56:\t[0s / 5s],\t\ttrain_loss: 0.3854,\tval_loss: 0.3696\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.3851,\tval_loss: 0.3657\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.3777,\tval_loss: 0.3639\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.3708,\tval_loss: 0.3631\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.3718,\tval_loss: 0.3594\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.3700,\tval_loss: 0.3576\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.3719,\tval_loss: 0.3540\n",
            "63:\t[0s / 6s],\t\ttrain_loss: 0.3705,\tval_loss: 0.3541\n",
            "64:\t[0s / 6s],\t\ttrain_loss: 0.3758,\tval_loss: 0.3505\n",
            "65:\t[0s / 6s],\t\ttrain_loss: 0.3526,\tval_loss: 0.3494\n",
            "66:\t[0s / 6s],\t\ttrain_loss: 0.3623,\tval_loss: 0.3481\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.3578,\tval_loss: 0.3456\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.3496,\tval_loss: 0.3447\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.3482,\tval_loss: 0.3433\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.3479,\tval_loss: 0.3411\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.3502,\tval_loss: 0.3392\n",
            "72:\t[0s / 7s],\t\ttrain_loss: 0.3393,\tval_loss: 0.3367\n",
            "73:\t[0s / 7s],\t\ttrain_loss: 0.3394,\tval_loss: 0.3372\n",
            "74:\t[0s / 7s],\t\ttrain_loss: 0.3358,\tval_loss: 0.3347\n",
            "75:\t[0s / 7s],\t\ttrain_loss: 0.3426,\tval_loss: 0.3324\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.3283,\tval_loss: 0.3320\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.3280,\tval_loss: 0.3322\n",
            "78:\t[0s / 8s],\t\ttrain_loss: 0.3291,\tval_loss: 0.3301\n",
            "79:\t[0s / 8s],\t\ttrain_loss: 0.3312,\tval_loss: 0.3291\n",
            "80:\t[0s / 8s],\t\ttrain_loss: 0.3295,\tval_loss: 0.3276\n",
            "81:\t[0s / 8s],\t\ttrain_loss: 0.3218,\tval_loss: 0.3272\n",
            "82:\t[0s / 8s],\t\ttrain_loss: 0.3181,\tval_loss: 0.3270\n",
            "83:\t[0s / 8s],\t\ttrain_loss: 0.3218,\tval_loss: 0.3254\n",
            "84:\t[0s / 8s],\t\ttrain_loss: 0.3227,\tval_loss: 0.3238\n",
            "85:\t[0s / 8s],\t\ttrain_loss: 0.3127,\tval_loss: 0.3229\n",
            "86:\t[0s / 9s],\t\ttrain_loss: 0.3170,\tval_loss: 0.3215\n",
            "87:\t[0s / 9s],\t\ttrain_loss: 0.3080,\tval_loss: 0.3244\n",
            "88:\t[0s / 9s],\t\ttrain_loss: 0.3144,\tval_loss: 0.3223\n",
            "89:\t[0s / 9s],\t\ttrain_loss: 0.3068,\tval_loss: 0.3212\n",
            "90:\t[0s / 9s],\t\ttrain_loss: 0.3126,\tval_loss: 0.3197\n",
            "91:\t[0s / 9s],\t\ttrain_loss: 0.3071,\tval_loss: 0.3194\n",
            "92:\t[0s / 9s],\t\ttrain_loss: 0.3041,\tval_loss: 0.3178\n",
            "93:\t[0s / 10s],\t\ttrain_loss: 0.2972,\tval_loss: 0.3171\n",
            "94:\t[0s / 10s],\t\ttrain_loss: 0.2994,\tval_loss: 0.3164\n",
            "95:\t[0s / 10s],\t\ttrain_loss: 0.3031,\tval_loss: 0.3167\n",
            "96:\t[0s / 10s],\t\ttrain_loss: 0.2967,\tval_loss: 0.3149\n",
            "97:\t[0s / 10s],\t\ttrain_loss: 0.2925,\tval_loss: 0.3145\n",
            "98:\t[0s / 10s],\t\ttrain_loss: 0.3033,\tval_loss: 0.3147\n",
            "99:\t[0s / 10s],\t\ttrain_loss: 0.2980,\tval_loss: 0.3145\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6025,\tval_loss: 0.5034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5954,\tval_loss: 0.5000\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5805,\tval_loss: 0.4996\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5751,\tval_loss: 0.4957\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5607,\tval_loss: 0.4945\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5622,\tval_loss: 0.4932\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.5531,\tval_loss: 0.4914\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.5563,\tval_loss: 0.4892\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.5450,\tval_loss: 0.4870\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.5538,\tval_loss: 0.4851\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.5380,\tval_loss: 0.4830\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.5287,\tval_loss: 0.4822\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.5314,\tval_loss: 0.4796\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 0.5264,\tval_loss: 0.4786\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.5210,\tval_loss: 0.4757\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.5207,\tval_loss: 0.4757\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.5180,\tval_loss: 0.4734\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.5168,\tval_loss: 0.4715\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.5101,\tval_loss: 0.4692\n",
            "19:\t[0s / 3s],\t\ttrain_loss: 0.5072,\tval_loss: 0.4680\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.5116,\tval_loss: 0.4668\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.5061,\tval_loss: 0.4644\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.4993,\tval_loss: 0.4634\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.4938,\tval_loss: 0.4606\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.4923,\tval_loss: 0.4577\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.4913,\tval_loss: 0.4575\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.4869,\tval_loss: 0.4557\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.4860,\tval_loss: 0.4537\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.4786,\tval_loss: 0.4529\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.4755,\tval_loss: 0.4509\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.4721,\tval_loss: 0.4491\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.4720,\tval_loss: 0.4468\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.4669,\tval_loss: 0.4442\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.4622,\tval_loss: 0.4437\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.4706,\tval_loss: 0.4413\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.4593,\tval_loss: 0.4405\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.4558,\tval_loss: 0.4386\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.4528,\tval_loss: 0.4372\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.4450,\tval_loss: 0.4351\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.4445,\tval_loss: 0.4340\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.4432,\tval_loss: 0.4322\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.4358,\tval_loss: 0.4304\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.4323,\tval_loss: 0.4293\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.4398,\tval_loss: 0.4273\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.4262,\tval_loss: 0.4255\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.4325,\tval_loss: 0.4241\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.4283,\tval_loss: 0.4223\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.4202,\tval_loss: 0.4209\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.4143,\tval_loss: 0.4191\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.4085,\tval_loss: 0.4172\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.4093,\tval_loss: 0.4171\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.4040,\tval_loss: 0.4143\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.4065,\tval_loss: 0.4139\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.4021,\tval_loss: 0.4119\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.3997,\tval_loss: 0.4091\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.3947,\tval_loss: 0.4093\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.3950,\tval_loss: 0.4075\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.3820,\tval_loss: 0.4061\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.3845,\tval_loss: 0.4039\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.3849,\tval_loss: 0.4036\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.3753,\tval_loss: 0.4001\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.3905,\tval_loss: 0.4012\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.3784,\tval_loss: 0.3998\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.3705,\tval_loss: 0.3992\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.3666,\tval_loss: 0.3987\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.3664,\tval_loss: 0.3969\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.3619,\tval_loss: 0.3961\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.3636,\tval_loss: 0.3956\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.3581,\tval_loss: 0.3952\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.3463,\tval_loss: 0.3939\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.3557,\tval_loss: 0.3911\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.3550,\tval_loss: 0.3913\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.3487,\tval_loss: 0.3888\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.3494,\tval_loss: 0.3900\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.3403,\tval_loss: 0.3894\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.3436,\tval_loss: 0.3875\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.3440,\tval_loss: 0.3887\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.3414,\tval_loss: 0.3867\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.3440,\tval_loss: 0.3854\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.3333,\tval_loss: 0.3838\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.3357,\tval_loss: 0.3829\n",
            "81:\t[0s / 9s],\t\ttrain_loss: 0.3337,\tval_loss: 0.3811\n",
            "82:\t[0s / 9s],\t\ttrain_loss: 0.3347,\tval_loss: 0.3852\n",
            "83:\t[0s / 9s],\t\ttrain_loss: 0.3287,\tval_loss: 0.3838\n",
            "84:\t[0s / 9s],\t\ttrain_loss: 0.3298,\tval_loss: 0.3824\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.3272,\tval_loss: 0.3799\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.3221,\tval_loss: 0.3827\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.3237,\tval_loss: 0.3823\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.3152,\tval_loss: 0.3799\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.3206,\tval_loss: 0.3840\n",
            "90:\t[0s / 10s],\t\ttrain_loss: 0.3182,\tval_loss: 0.3843\n",
            "91:\t[0s / 10s],\t\ttrain_loss: 0.3169,\tval_loss: 0.3838\n",
            "92:\t[0s / 10s],\t\ttrain_loss: 0.3190,\tval_loss: 0.3878\n",
            "93:\t[0s / 10s],\t\ttrain_loss: 0.3084,\tval_loss: 0.3828\n",
            "94:\t[0s / 10s],\t\ttrain_loss: 0.3137,\tval_loss: 0.3833\n",
            "95:\t[0s / 10s],\t\ttrain_loss: 0.3161,\tval_loss: 0.3860\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6226,\tval_loss: 0.5178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.6108,\tval_loss: 0.5148\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5833,\tval_loss: 0.5121\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5704,\tval_loss: 0.5085\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5744,\tval_loss: 0.5037\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5639,\tval_loss: 0.5001\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.5490,\tval_loss: 0.4974\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.5457,\tval_loss: 0.4950\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.5449,\tval_loss: 0.4919\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.5392,\tval_loss: 0.4906\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.5313,\tval_loss: 0.4883\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.5331,\tval_loss: 0.4857\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.5209,\tval_loss: 0.4831\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.5233,\tval_loss: 0.4806\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.5239,\tval_loss: 0.4794\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.5254,\tval_loss: 0.4774\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.5167,\tval_loss: 0.4755\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.5073,\tval_loss: 0.4726\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.5053,\tval_loss: 0.4703\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.5100,\tval_loss: 0.4685\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.5105,\tval_loss: 0.4666\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.5018,\tval_loss: 0.4649\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.5005,\tval_loss: 0.4643\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.4970,\tval_loss: 0.4619\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.4889,\tval_loss: 0.4593\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.4834,\tval_loss: 0.4578\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.4868,\tval_loss: 0.4558\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.4886,\tval_loss: 0.4529\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.4768,\tval_loss: 0.4513\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.4760,\tval_loss: 0.4492\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.4727,\tval_loss: 0.4491\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.4701,\tval_loss: 0.4456\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.4748,\tval_loss: 0.4451\n",
            "33:\t[0s / 4s],\t\ttrain_loss: 0.4695,\tval_loss: 0.4412\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.4575,\tval_loss: 0.4395\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.4655,\tval_loss: 0.4391\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.4602,\tval_loss: 0.4359\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.4659,\tval_loss: 0.4341\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.4535,\tval_loss: 0.4323\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.4462,\tval_loss: 0.4302\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.4500,\tval_loss: 0.4286\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.4445,\tval_loss: 0.4273\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.4462,\tval_loss: 0.4249\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.4453,\tval_loss: 0.4226\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.4427,\tval_loss: 0.4207\n",
            "45:\t[0s / 6s],\t\ttrain_loss: 0.4386,\tval_loss: 0.4168\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.4448,\tval_loss: 0.4158\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.4304,\tval_loss: 0.4137\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.4291,\tval_loss: 0.4124\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.4212,\tval_loss: 0.4103\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.4270,\tval_loss: 0.4092\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.4263,\tval_loss: 0.4065\n",
            "52:\t[0s / 7s],\t\ttrain_loss: 0.4132,\tval_loss: 0.4053\n",
            "53:\t[0s / 7s],\t\ttrain_loss: 0.4225,\tval_loss: 0.4031\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.4146,\tval_loss: 0.4021\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.4137,\tval_loss: 0.3998\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.4045,\tval_loss: 0.3990\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.4097,\tval_loss: 0.3970\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.4022,\tval_loss: 0.3953\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.3989,\tval_loss: 0.3939\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.3975,\tval_loss: 0.3914\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.3980,\tval_loss: 0.3899\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.3884,\tval_loss: 0.3882\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.3872,\tval_loss: 0.3873\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.3930,\tval_loss: 0.3858\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.3906,\tval_loss: 0.3853\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.3917,\tval_loss: 0.3840\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.3832,\tval_loss: 0.3842\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.3840,\tval_loss: 0.3821\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.3847,\tval_loss: 0.3802\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.3821,\tval_loss: 0.3784\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.3747,\tval_loss: 0.3775\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.3822,\tval_loss: 0.3784\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.3676,\tval_loss: 0.3774\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.3732,\tval_loss: 0.3753\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.3663,\tval_loss: 0.3724\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.3737,\tval_loss: 0.3716\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.3701,\tval_loss: 0.3713\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.3573,\tval_loss: 0.3704\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.3590,\tval_loss: 0.3701\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.3590,\tval_loss: 0.3698\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.3544,\tval_loss: 0.3685\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.3551,\tval_loss: 0.3680\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.3553,\tval_loss: 0.3670\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.3545,\tval_loss: 0.3665\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.3556,\tval_loss: 0.3652\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.3608,\tval_loss: 0.3644\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.3458,\tval_loss: 0.3630\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.3410,\tval_loss: 0.3623\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.3400,\tval_loss: 0.3619\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.3453,\tval_loss: 0.3611\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.3383,\tval_loss: 0.3591\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.3437,\tval_loss: 0.3588\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.3368,\tval_loss: 0.3579\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.3352,\tval_loss: 0.3576\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.3398,\tval_loss: 0.3574\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.3313,\tval_loss: 0.3548\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.3318,\tval_loss: 0.3566\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.3316,\tval_loss: 0.3551\n",
            "99:\t[0s / 11s],\t\ttrain_loss: 0.3196,\tval_loss: 0.3541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6006,\tval_loss: 0.5148\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5825,\tval_loss: 0.5218\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5766,\tval_loss: 0.5216\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5682,\tval_loss: 0.5181\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5454,\tval_loss: 0.5150\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5543,\tval_loss: 0.5118\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.5482,\tval_loss: 0.5060\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.5505,\tval_loss: 0.5029\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.5385,\tval_loss: 0.5000\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.5309,\tval_loss: 0.4993\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.5279,\tval_loss: 0.4952\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.5309,\tval_loss: 0.4896\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.5205,\tval_loss: 0.4856\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.5217,\tval_loss: 0.4827\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.5023,\tval_loss: 0.4805\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.5145,\tval_loss: 0.4772\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.5094,\tval_loss: 0.4739\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.5052,\tval_loss: 0.4717\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.5048,\tval_loss: 0.4687\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.4971,\tval_loss: 0.4681\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.4870,\tval_loss: 0.4634\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.4897,\tval_loss: 0.4614\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.4858,\tval_loss: 0.4582\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.4854,\tval_loss: 0.4549\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.4891,\tval_loss: 0.4515\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.4880,\tval_loss: 0.4511\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.4707,\tval_loss: 0.4474\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.4721,\tval_loss: 0.4426\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.4688,\tval_loss: 0.4425\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.4666,\tval_loss: 0.4394\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.4587,\tval_loss: 0.4374\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.4605,\tval_loss: 0.4343\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.4584,\tval_loss: 0.4313\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.4506,\tval_loss: 0.4291\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.4468,\tval_loss: 0.4266\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.4411,\tval_loss: 0.4243\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.4423,\tval_loss: 0.4225\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.4371,\tval_loss: 0.4185\n",
            "38:\t[0s / 3s],\t\ttrain_loss: 0.4386,\tval_loss: 0.4158\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.4338,\tval_loss: 0.4122\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.4308,\tval_loss: 0.4093\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.4267,\tval_loss: 0.4067\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.4337,\tval_loss: 0.4047\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.4146,\tval_loss: 0.4023\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.4191,\tval_loss: 0.4008\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.4093,\tval_loss: 0.3968\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.4038,\tval_loss: 0.3942\n",
            "47:\t[0s / 4s],\t\ttrain_loss: 0.3984,\tval_loss: 0.3912\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.4005,\tval_loss: 0.3880\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.3976,\tval_loss: 0.3865\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.4021,\tval_loss: 0.3841\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.3999,\tval_loss: 0.3835\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.3911,\tval_loss: 0.3809\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.3907,\tval_loss: 0.3779\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.3746,\tval_loss: 0.3754\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.3781,\tval_loss: 0.3742\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.3857,\tval_loss: 0.3709\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.3871,\tval_loss: 0.3685\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.3695,\tval_loss: 0.3666\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.3686,\tval_loss: 0.3643\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.3646,\tval_loss: 0.3628\n",
            "61:\t[0s / 7s],\t\ttrain_loss: 0.3633,\tval_loss: 0.3610\n",
            "62:\t[0s / 7s],\t\ttrain_loss: 0.3672,\tval_loss: 0.3591\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.3627,\tval_loss: 0.3575\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.3547,\tval_loss: 0.3553\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.3495,\tval_loss: 0.3529\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.3424,\tval_loss: 0.3503\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.3448,\tval_loss: 0.3479\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.3537,\tval_loss: 0.3463\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.3536,\tval_loss: 0.3458\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.3373,\tval_loss: 0.3442\n",
            "71:\t[0s / 8s],\t\ttrain_loss: 0.3342,\tval_loss: 0.3423\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.3379,\tval_loss: 0.3389\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.3313,\tval_loss: 0.3391\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.3317,\tval_loss: 0.3379\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.3233,\tval_loss: 0.3351\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.3191,\tval_loss: 0.3342\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.3255,\tval_loss: 0.3318\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.3194,\tval_loss: 0.3309\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.3114,\tval_loss: 0.3292\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.3240,\tval_loss: 0.3277\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.3166,\tval_loss: 0.3273\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.3122,\tval_loss: 0.3266\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.3115,\tval_loss: 0.3249\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.3128,\tval_loss: 0.3240\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.3087,\tval_loss: 0.3239\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.2984,\tval_loss: 0.3217\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.2964,\tval_loss: 0.3208\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.3004,\tval_loss: 0.3204\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.2988,\tval_loss: 0.3202\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.2936,\tval_loss: 0.3197\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.2892,\tval_loss: 0.3186\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.2956,\tval_loss: 0.3175\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.2933,\tval_loss: 0.3175\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.2918,\tval_loss: 0.3166\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.2948,\tval_loss: 0.3158\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.2929,\tval_loss: 0.3153\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.2933,\tval_loss: 0.3139\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.2906,\tval_loss: 0.3134\n",
            "99:\t[0s / 11s],\t\ttrain_loss: 0.2820,\tval_loss: 0.3139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6117,\tval_loss: 0.5131\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5896,\tval_loss: 0.5137\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5751,\tval_loss: 0.5112\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5966,\tval_loss: 0.5087\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5588,\tval_loss: 0.5071\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5654,\tval_loss: 0.5052\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.5677,\tval_loss: 0.5012\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.5505,\tval_loss: 0.4985\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.5544,\tval_loss: 0.4979\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.5523,\tval_loss: 0.4964\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.5437,\tval_loss: 0.4929\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.5269,\tval_loss: 0.4925\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.5443,\tval_loss: 0.4895\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.5473,\tval_loss: 0.4883\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.5312,\tval_loss: 0.4876\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.5276,\tval_loss: 0.4867\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.5244,\tval_loss: 0.4850\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.5185,\tval_loss: 0.4820\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.5090,\tval_loss: 0.4805\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.5163,\tval_loss: 0.4784\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.5114,\tval_loss: 0.4766\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.5181,\tval_loss: 0.4761\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.5038,\tval_loss: 0.4757\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.5007,\tval_loss: 0.4734\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.5051,\tval_loss: 0.4722\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.4887,\tval_loss: 0.4701\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.4921,\tval_loss: 0.4685\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.4967,\tval_loss: 0.4665\n",
            "28:\t[0s / 2s],\t\ttrain_loss: 0.4805,\tval_loss: 0.4637\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.4822,\tval_loss: 0.4635\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.4851,\tval_loss: 0.4612\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.4833,\tval_loss: 0.4590\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.4780,\tval_loss: 0.4579\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.4772,\tval_loss: 0.4551\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.4771,\tval_loss: 0.4537\n",
            "35:\t[0s / 3s],\t\ttrain_loss: 0.4822,\tval_loss: 0.4509\n",
            "36:\t[0s / 3s],\t\ttrain_loss: 0.4591,\tval_loss: 0.4497\n",
            "37:\t[0s / 3s],\t\ttrain_loss: 0.4567,\tval_loss: 0.4478\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.4700,\tval_loss: 0.4465\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.4602,\tval_loss: 0.4457\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.4500,\tval_loss: 0.4431\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.4514,\tval_loss: 0.4407\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.4486,\tval_loss: 0.4391\n",
            "43:\t[0s / 4s],\t\ttrain_loss: 0.4387,\tval_loss: 0.4372\n",
            "44:\t[0s / 4s],\t\ttrain_loss: 0.4398,\tval_loss: 0.4343\n",
            "45:\t[0s / 4s],\t\ttrain_loss: 0.4376,\tval_loss: 0.4322\n",
            "46:\t[0s / 4s],\t\ttrain_loss: 0.4487,\tval_loss: 0.4305\n",
            "47:\t[0s / 4s],\t\ttrain_loss: 0.4326,\tval_loss: 0.4279\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.4408,\tval_loss: 0.4254\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.4322,\tval_loss: 0.4241\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.4206,\tval_loss: 0.4209\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.4289,\tval_loss: 0.4174\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.4205,\tval_loss: 0.4150\n",
            "53:\t[0s / 5s],\t\ttrain_loss: 0.4147,\tval_loss: 0.4138\n",
            "54:\t[0s / 5s],\t\ttrain_loss: 0.4126,\tval_loss: 0.4106\n",
            "55:\t[0s / 5s],\t\ttrain_loss: 0.4131,\tval_loss: 0.4092\n",
            "56:\t[0s / 5s],\t\ttrain_loss: 0.4020,\tval_loss: 0.4069\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.3995,\tval_loss: 0.4051\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.4036,\tval_loss: 0.4030\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.3984,\tval_loss: 0.4007\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.3948,\tval_loss: 0.3974\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.3924,\tval_loss: 0.3969\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.3857,\tval_loss: 0.3928\n",
            "63:\t[0s / 6s],\t\ttrain_loss: 0.3855,\tval_loss: 0.3926\n",
            "64:\t[0s / 6s],\t\ttrain_loss: 0.3884,\tval_loss: 0.3905\n",
            "65:\t[0s / 6s],\t\ttrain_loss: 0.3789,\tval_loss: 0.3876\n",
            "66:\t[0s / 6s],\t\ttrain_loss: 0.3777,\tval_loss: 0.3870\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.3810,\tval_loss: 0.3844\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.3673,\tval_loss: 0.3826\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.3679,\tval_loss: 0.3808\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.3690,\tval_loss: 0.3792\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.3651,\tval_loss: 0.3770\n",
            "72:\t[0s / 7s],\t\ttrain_loss: 0.3664,\tval_loss: 0.3776\n",
            "73:\t[0s / 7s],\t\ttrain_loss: 0.3566,\tval_loss: 0.3767\n",
            "74:\t[0s / 7s],\t\ttrain_loss: 0.3581,\tval_loss: 0.3738\n",
            "75:\t[0s / 7s],\t\ttrain_loss: 0.3490,\tval_loss: 0.3719\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.3526,\tval_loss: 0.3695\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.3543,\tval_loss: 0.3693\n",
            "78:\t[0s / 8s],\t\ttrain_loss: 0.3434,\tval_loss: 0.3689\n",
            "79:\t[0s / 8s],\t\ttrain_loss: 0.3483,\tval_loss: 0.3671\n",
            "80:\t[0s / 8s],\t\ttrain_loss: 0.3470,\tval_loss: 0.3654\n",
            "81:\t[0s / 8s],\t\ttrain_loss: 0.3429,\tval_loss: 0.3635\n",
            "82:\t[0s / 9s],\t\ttrain_loss: 0.3420,\tval_loss: 0.3609\n",
            "83:\t[0s / 9s],\t\ttrain_loss: 0.3378,\tval_loss: 0.3600\n",
            "84:\t[0s / 9s],\t\ttrain_loss: 0.3343,\tval_loss: 0.3591\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.3334,\tval_loss: 0.3572\n",
            "86:\t[0s / 9s],\t\ttrain_loss: 0.3335,\tval_loss: 0.3570\n",
            "87:\t[0s / 9s],\t\ttrain_loss: 0.3165,\tval_loss: 0.3546\n",
            "88:\t[0s / 9s],\t\ttrain_loss: 0.3292,\tval_loss: 0.3546\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.3250,\tval_loss: 0.3535\n",
            "90:\t[0s / 10s],\t\ttrain_loss: 0.3247,\tval_loss: 0.3530\n",
            "91:\t[0s / 10s],\t\ttrain_loss: 0.3243,\tval_loss: 0.3529\n",
            "92:\t[0s / 10s],\t\ttrain_loss: 0.3228,\tval_loss: 0.3523\n",
            "93:\t[0s / 10s],\t\ttrain_loss: 0.3171,\tval_loss: 0.3478\n",
            "94:\t[0s / 10s],\t\ttrain_loss: 0.3205,\tval_loss: 0.3483\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.3133,\tval_loss: 0.3488\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.3155,\tval_loss: 0.3488\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.3101,\tval_loss: 0.3470\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.3109,\tval_loss: 0.3442\n",
            "99:\t[0s / 11s],\t\ttrain_loss: 0.3093,\tval_loss: 0.3434\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6168,\tval_loss: 0.5208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5910,\tval_loss: 0.5279\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5905,\tval_loss: 0.5256\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5927,\tval_loss: 0.5199\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5618,\tval_loss: 0.5143\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5753,\tval_loss: 0.5119\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.5689,\tval_loss: 0.5088\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.5466,\tval_loss: 0.5064\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.5376,\tval_loss: 0.5032\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.5449,\tval_loss: 0.5024\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.5421,\tval_loss: 0.4988\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.5340,\tval_loss: 0.4974\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.5411,\tval_loss: 0.4932\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.5415,\tval_loss: 0.4921\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.5277,\tval_loss: 0.4914\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.5298,\tval_loss: 0.4877\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.5300,\tval_loss: 0.4843\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.5105,\tval_loss: 0.4845\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.5156,\tval_loss: 0.4817\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.5106,\tval_loss: 0.4810\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.5103,\tval_loss: 0.4780\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.5029,\tval_loss: 0.4764\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.5057,\tval_loss: 0.4730\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.5015,\tval_loss: 0.4706\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.4929,\tval_loss: 0.4696\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.4926,\tval_loss: 0.4673\n",
            "26:\t[0s / 3s],\t\ttrain_loss: 0.4877,\tval_loss: 0.4653\n",
            "27:\t[0s / 3s],\t\ttrain_loss: 0.4850,\tval_loss: 0.4631\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.4880,\tval_loss: 0.4630\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.4767,\tval_loss: 0.4608\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.4896,\tval_loss: 0.4583\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.4817,\tval_loss: 0.4565\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.4753,\tval_loss: 0.4549\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.4804,\tval_loss: 0.4528\n",
            "34:\t[0s / 4s],\t\ttrain_loss: 0.4628,\tval_loss: 0.4504\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.4596,\tval_loss: 0.4496\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.4666,\tval_loss: 0.4481\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.4612,\tval_loss: 0.4464\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.4512,\tval_loss: 0.4438\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.4557,\tval_loss: 0.4411\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.4451,\tval_loss: 0.4397\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.4503,\tval_loss: 0.4365\n",
            "42:\t[0s / 4s],\t\ttrain_loss: 0.4443,\tval_loss: 0.4352\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.4466,\tval_loss: 0.4327\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.4454,\tval_loss: 0.4315\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.4429,\tval_loss: 0.4298\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.4398,\tval_loss: 0.4285\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.4296,\tval_loss: 0.4259\n",
            "48:\t[0s / 5s],\t\ttrain_loss: 0.4384,\tval_loss: 0.4241\n",
            "49:\t[0s / 5s],\t\ttrain_loss: 0.4289,\tval_loss: 0.4216\n",
            "50:\t[0s / 5s],\t\ttrain_loss: 0.4256,\tval_loss: 0.4192\n",
            "51:\t[0s / 5s],\t\ttrain_loss: 0.4259,\tval_loss: 0.4170\n",
            "52:\t[0s / 5s],\t\ttrain_loss: 0.4207,\tval_loss: 0.4158\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.4178,\tval_loss: 0.4137\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.4182,\tval_loss: 0.4110\n",
            "55:\t[0s / 6s],\t\ttrain_loss: 0.4040,\tval_loss: 0.4092\n",
            "56:\t[0s / 6s],\t\ttrain_loss: 0.4055,\tval_loss: 0.4071\n",
            "57:\t[0s / 6s],\t\ttrain_loss: 0.4040,\tval_loss: 0.4055\n",
            "58:\t[0s / 6s],\t\ttrain_loss: 0.4075,\tval_loss: 0.4033\n",
            "59:\t[0s / 6s],\t\ttrain_loss: 0.3934,\tval_loss: 0.4003\n",
            "60:\t[0s / 6s],\t\ttrain_loss: 0.4007,\tval_loss: 0.4005\n",
            "61:\t[0s / 6s],\t\ttrain_loss: 0.4013,\tval_loss: 0.3971\n",
            "62:\t[0s / 6s],\t\ttrain_loss: 0.3964,\tval_loss: 0.3942\n",
            "63:\t[0s / 7s],\t\ttrain_loss: 0.3932,\tval_loss: 0.3933\n",
            "64:\t[0s / 7s],\t\ttrain_loss: 0.3865,\tval_loss: 0.3892\n",
            "65:\t[0s / 7s],\t\ttrain_loss: 0.3901,\tval_loss: 0.3887\n",
            "66:\t[0s / 7s],\t\ttrain_loss: 0.3771,\tval_loss: 0.3864\n",
            "67:\t[0s / 7s],\t\ttrain_loss: 0.3791,\tval_loss: 0.3874\n",
            "68:\t[0s / 7s],\t\ttrain_loss: 0.3785,\tval_loss: 0.3846\n",
            "69:\t[0s / 7s],\t\ttrain_loss: 0.3755,\tval_loss: 0.3815\n",
            "70:\t[0s / 7s],\t\ttrain_loss: 0.3671,\tval_loss: 0.3807\n",
            "71:\t[0s / 7s],\t\ttrain_loss: 0.3780,\tval_loss: 0.3798\n",
            "72:\t[0s / 8s],\t\ttrain_loss: 0.3683,\tval_loss: 0.3789\n",
            "73:\t[0s / 8s],\t\ttrain_loss: 0.3739,\tval_loss: 0.3759\n",
            "74:\t[0s / 8s],\t\ttrain_loss: 0.3744,\tval_loss: 0.3752\n",
            "75:\t[0s / 8s],\t\ttrain_loss: 0.3632,\tval_loss: 0.3744\n",
            "76:\t[0s / 8s],\t\ttrain_loss: 0.3572,\tval_loss: 0.3717\n",
            "77:\t[0s / 8s],\t\ttrain_loss: 0.3618,\tval_loss: 0.3718\n",
            "78:\t[0s / 8s],\t\ttrain_loss: 0.3507,\tval_loss: 0.3694\n",
            "79:\t[0s / 8s],\t\ttrain_loss: 0.3564,\tval_loss: 0.3694\n",
            "80:\t[0s / 8s],\t\ttrain_loss: 0.3564,\tval_loss: 0.3690\n",
            "81:\t[0s / 8s],\t\ttrain_loss: 0.3511,\tval_loss: 0.3673\n",
            "82:\t[0s / 9s],\t\ttrain_loss: 0.3428,\tval_loss: 0.3658\n",
            "83:\t[0s / 9s],\t\ttrain_loss: 0.3392,\tval_loss: 0.3637\n",
            "84:\t[0s / 9s],\t\ttrain_loss: 0.3545,\tval_loss: 0.3650\n",
            "85:\t[0s / 9s],\t\ttrain_loss: 0.3474,\tval_loss: 0.3620\n",
            "86:\t[0s / 9s],\t\ttrain_loss: 0.3371,\tval_loss: 0.3604\n",
            "87:\t[0s / 9s],\t\ttrain_loss: 0.3393,\tval_loss: 0.3593\n",
            "88:\t[0s / 9s],\t\ttrain_loss: 0.3334,\tval_loss: 0.3561\n",
            "89:\t[0s / 9s],\t\ttrain_loss: 0.3410,\tval_loss: 0.3564\n",
            "90:\t[0s / 9s],\t\ttrain_loss: 0.3326,\tval_loss: 0.3543\n",
            "91:\t[0s / 10s],\t\ttrain_loss: 0.3334,\tval_loss: 0.3548\n",
            "92:\t[0s / 10s],\t\ttrain_loss: 0.3143,\tval_loss: 0.3535\n",
            "93:\t[0s / 10s],\t\ttrain_loss: 0.3306,\tval_loss: 0.3531\n",
            "94:\t[0s / 10s],\t\ttrain_loss: 0.3228,\tval_loss: 0.3548\n",
            "95:\t[0s / 10s],\t\ttrain_loss: 0.3221,\tval_loss: 0.3536\n",
            "96:\t[0s / 10s],\t\ttrain_loss: 0.3281,\tval_loss: 0.3517\n",
            "97:\t[0s / 10s],\t\ttrain_loss: 0.3212,\tval_loss: 0.3513\n",
            "98:\t[0s / 10s],\t\ttrain_loss: 0.3261,\tval_loss: 0.3507\n",
            "99:\t[0s / 10s],\t\ttrain_loss: 0.3267,\tval_loss: 0.3486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6431,\tval_loss: 0.5232\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.6264,\tval_loss: 0.5214\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.6235,\tval_loss: 0.5190\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.6031,\tval_loss: 0.5152\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5964,\tval_loss: 0.5135\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5887,\tval_loss: 0.5090\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.6071,\tval_loss: 0.5062\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 0.5872,\tval_loss: 0.5033\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 0.5922,\tval_loss: 0.5024\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.5737,\tval_loss: 0.5001\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.5739,\tval_loss: 0.4976\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.5693,\tval_loss: 0.4943\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.5776,\tval_loss: 0.4934\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.5666,\tval_loss: 0.4924\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 0.5569,\tval_loss: 0.4904\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 0.5625,\tval_loss: 0.4891\n",
            "16:\t[0s / 2s],\t\ttrain_loss: 0.5533,\tval_loss: 0.4869\n",
            "17:\t[0s / 2s],\t\ttrain_loss: 0.5445,\tval_loss: 0.4857\n",
            "18:\t[0s / 2s],\t\ttrain_loss: 0.5393,\tval_loss: 0.4827\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.5434,\tval_loss: 0.4806\n",
            "20:\t[0s / 3s],\t\ttrain_loss: 0.5379,\tval_loss: 0.4801\n",
            "21:\t[0s / 3s],\t\ttrain_loss: 0.5298,\tval_loss: 0.4784\n",
            "22:\t[0s / 3s],\t\ttrain_loss: 0.5291,\tval_loss: 0.4770\n",
            "23:\t[0s / 3s],\t\ttrain_loss: 0.5264,\tval_loss: 0.4753\n",
            "24:\t[0s / 3s],\t\ttrain_loss: 0.5173,\tval_loss: 0.4746\n",
            "25:\t[0s / 3s],\t\ttrain_loss: 0.5204,\tval_loss: 0.4732\n",
            "26:\t[0s / 4s],\t\ttrain_loss: 0.5190,\tval_loss: 0.4707\n",
            "27:\t[0s / 4s],\t\ttrain_loss: 0.5168,\tval_loss: 0.4688\n",
            "28:\t[0s / 4s],\t\ttrain_loss: 0.5074,\tval_loss: 0.4674\n",
            "29:\t[0s / 4s],\t\ttrain_loss: 0.5155,\tval_loss: 0.4646\n",
            "30:\t[0s / 4s],\t\ttrain_loss: 0.5069,\tval_loss: 0.4639\n",
            "31:\t[0s / 4s],\t\ttrain_loss: 0.5131,\tval_loss: 0.4614\n",
            "32:\t[0s / 4s],\t\ttrain_loss: 0.5121,\tval_loss: 0.4598\n",
            "33:\t[0s / 5s],\t\ttrain_loss: 0.5050,\tval_loss: 0.4579\n",
            "34:\t[0s / 5s],\t\ttrain_loss: 0.4966,\tval_loss: 0.4563\n",
            "35:\t[0s / 5s],\t\ttrain_loss: 0.5024,\tval_loss: 0.4563\n",
            "36:\t[0s / 5s],\t\ttrain_loss: 0.4939,\tval_loss: 0.4529\n",
            "37:\t[0s / 5s],\t\ttrain_loss: 0.4941,\tval_loss: 0.4528\n",
            "38:\t[0s / 5s],\t\ttrain_loss: 0.4802,\tval_loss: 0.4515\n",
            "39:\t[0s / 5s],\t\ttrain_loss: 0.4894,\tval_loss: 0.4489\n",
            "40:\t[0s / 5s],\t\ttrain_loss: 0.4917,\tval_loss: 0.4472\n",
            "41:\t[0s / 5s],\t\ttrain_loss: 0.4822,\tval_loss: 0.4464\n",
            "42:\t[0s / 6s],\t\ttrain_loss: 0.4753,\tval_loss: 0.4447\n",
            "43:\t[0s / 6s],\t\ttrain_loss: 0.4802,\tval_loss: 0.4424\n",
            "44:\t[0s / 6s],\t\ttrain_loss: 0.4806,\tval_loss: 0.4403\n",
            "45:\t[0s / 6s],\t\ttrain_loss: 0.4794,\tval_loss: 0.4364\n",
            "46:\t[0s / 6s],\t\ttrain_loss: 0.4675,\tval_loss: 0.4357\n",
            "47:\t[0s / 6s],\t\ttrain_loss: 0.4710,\tval_loss: 0.4331\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.4678,\tval_loss: 0.4326\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.4588,\tval_loss: 0.4316\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.4643,\tval_loss: 0.4299\n",
            "51:\t[0s / 7s],\t\ttrain_loss: 0.4543,\tval_loss: 0.4284\n",
            "52:\t[0s / 7s],\t\ttrain_loss: 0.4552,\tval_loss: 0.4255\n",
            "53:\t[0s / 7s],\t\ttrain_loss: 0.4535,\tval_loss: 0.4251\n",
            "54:\t[0s / 7s],\t\ttrain_loss: 0.4520,\tval_loss: 0.4232\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.4454,\tval_loss: 0.4209\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.4499,\tval_loss: 0.4192\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.4392,\tval_loss: 0.4178\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.4357,\tval_loss: 0.4163\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.4295,\tval_loss: 0.4148\n",
            "60:\t[0s / 8s],\t\ttrain_loss: 0.4368,\tval_loss: 0.4124\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.4323,\tval_loss: 0.4117\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.4310,\tval_loss: 0.4097\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.4245,\tval_loss: 0.4080\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.4176,\tval_loss: 0.4069\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.4227,\tval_loss: 0.4052\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.4265,\tval_loss: 0.4029\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.4182,\tval_loss: 0.4008\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.4168,\tval_loss: 0.3996\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.4130,\tval_loss: 0.3988\n",
            "70:\t[0s / 9s],\t\ttrain_loss: 0.4146,\tval_loss: 0.3953\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.4143,\tval_loss: 0.3942\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.4046,\tval_loss: 0.3929\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.4011,\tval_loss: 0.3901\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.3988,\tval_loss: 0.3889\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.4044,\tval_loss: 0.3876\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.3919,\tval_loss: 0.3866\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.3958,\tval_loss: 0.3868\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.3972,\tval_loss: 0.3837\n",
            "79:\t[0s / 10s],\t\ttrain_loss: 0.3878,\tval_loss: 0.3826\n",
            "80:\t[0s / 10s],\t\ttrain_loss: 0.3868,\tval_loss: 0.3812\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.3824,\tval_loss: 0.3794\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.3771,\tval_loss: 0.3796\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.3740,\tval_loss: 0.3768\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.3786,\tval_loss: 0.3754\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.3772,\tval_loss: 0.3752\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.3688,\tval_loss: 0.3727\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.3628,\tval_loss: 0.3714\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.3651,\tval_loss: 0.3703\n",
            "89:\t[0s / 11s],\t\ttrain_loss: 0.3624,\tval_loss: 0.3682\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.3702,\tval_loss: 0.3683\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.3583,\tval_loss: 0.3664\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.3596,\tval_loss: 0.3643\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.3618,\tval_loss: 0.3624\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.3569,\tval_loss: 0.3619\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.3563,\tval_loss: 0.3606\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.3487,\tval_loss: 0.3590\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.3409,\tval_loss: 0.3583\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.3506,\tval_loss: 0.3579\n",
            "99:\t[0s / 12s],\t\ttrain_loss: 0.3421,\tval_loss: 0.3575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6222,\tval_loss: 0.5165\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.6235,\tval_loss: 0.5192\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.5834,\tval_loss: 0.5200\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.5837,\tval_loss: 0.5169\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5815,\tval_loss: 0.5164\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5683,\tval_loss: 0.5128\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.5670,\tval_loss: 0.5100\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.5590,\tval_loss: 0.5063\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.5643,\tval_loss: 0.5041\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.5537,\tval_loss: 0.5036\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.5553,\tval_loss: 0.5001\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.5411,\tval_loss: 0.4982\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.5271,\tval_loss: 0.4953\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.5522,\tval_loss: 0.4932\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.5340,\tval_loss: 0.4902\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.5231,\tval_loss: 0.4876\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.5159,\tval_loss: 0.4859\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.5221,\tval_loss: 0.4866\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.5194,\tval_loss: 0.4846\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.5245,\tval_loss: 0.4808\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.5012,\tval_loss: 0.4772\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.5075,\tval_loss: 0.4766\n",
            "22:\t[0s / 2s],\t\ttrain_loss: 0.5028,\tval_loss: 0.4739\n",
            "23:\t[0s / 2s],\t\ttrain_loss: 0.5032,\tval_loss: 0.4726\n",
            "24:\t[0s / 2s],\t\ttrain_loss: 0.4986,\tval_loss: 0.4720\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 0.4917,\tval_loss: 0.4699\n",
            "26:\t[0s / 2s],\t\ttrain_loss: 0.4908,\tval_loss: 0.4667\n",
            "27:\t[0s / 2s],\t\ttrain_loss: 0.4952,\tval_loss: 0.4654\n",
            "28:\t[0s / 3s],\t\ttrain_loss: 0.4907,\tval_loss: 0.4640\n",
            "29:\t[0s / 3s],\t\ttrain_loss: 0.4919,\tval_loss: 0.4617\n",
            "30:\t[0s / 3s],\t\ttrain_loss: 0.4821,\tval_loss: 0.4602\n",
            "31:\t[0s / 3s],\t\ttrain_loss: 0.4784,\tval_loss: 0.4583\n",
            "32:\t[0s / 3s],\t\ttrain_loss: 0.4735,\tval_loss: 0.4579\n",
            "33:\t[0s / 3s],\t\ttrain_loss: 0.4733,\tval_loss: 0.4560\n",
            "34:\t[0s / 3s],\t\ttrain_loss: 0.4668,\tval_loss: 0.4529\n",
            "35:\t[0s / 4s],\t\ttrain_loss: 0.4737,\tval_loss: 0.4528\n",
            "36:\t[0s / 4s],\t\ttrain_loss: 0.4721,\tval_loss: 0.4498\n",
            "37:\t[0s / 4s],\t\ttrain_loss: 0.4567,\tval_loss: 0.4471\n",
            "38:\t[0s / 4s],\t\ttrain_loss: 0.4618,\tval_loss: 0.4454\n",
            "39:\t[0s / 4s],\t\ttrain_loss: 0.4591,\tval_loss: 0.4433\n",
            "40:\t[0s / 4s],\t\ttrain_loss: 0.4576,\tval_loss: 0.4428\n",
            "41:\t[0s / 4s],\t\ttrain_loss: 0.4587,\tval_loss: 0.4402\n",
            "42:\t[0s / 5s],\t\ttrain_loss: 0.4497,\tval_loss: 0.4379\n",
            "43:\t[0s / 5s],\t\ttrain_loss: 0.4384,\tval_loss: 0.4364\n",
            "44:\t[0s / 5s],\t\ttrain_loss: 0.4507,\tval_loss: 0.4343\n",
            "45:\t[0s / 5s],\t\ttrain_loss: 0.4447,\tval_loss: 0.4322\n",
            "46:\t[0s / 5s],\t\ttrain_loss: 0.4313,\tval_loss: 0.4294\n",
            "47:\t[0s / 5s],\t\ttrain_loss: 0.4293,\tval_loss: 0.4285\n",
            "48:\t[0s / 6s],\t\ttrain_loss: 0.4335,\tval_loss: 0.4251\n",
            "49:\t[0s / 6s],\t\ttrain_loss: 0.4300,\tval_loss: 0.4232\n",
            "50:\t[0s / 6s],\t\ttrain_loss: 0.4293,\tval_loss: 0.4211\n",
            "51:\t[0s / 6s],\t\ttrain_loss: 0.4287,\tval_loss: 0.4196\n",
            "52:\t[0s / 6s],\t\ttrain_loss: 0.4199,\tval_loss: 0.4168\n",
            "53:\t[0s / 6s],\t\ttrain_loss: 0.4179,\tval_loss: 0.4142\n",
            "54:\t[0s / 6s],\t\ttrain_loss: 0.4134,\tval_loss: 0.4123\n",
            "55:\t[0s / 7s],\t\ttrain_loss: 0.4073,\tval_loss: 0.4114\n",
            "56:\t[0s / 7s],\t\ttrain_loss: 0.4069,\tval_loss: 0.4080\n",
            "57:\t[0s / 7s],\t\ttrain_loss: 0.4061,\tval_loss: 0.4066\n",
            "58:\t[0s / 7s],\t\ttrain_loss: 0.4023,\tval_loss: 0.4044\n",
            "59:\t[0s / 7s],\t\ttrain_loss: 0.4014,\tval_loss: 0.4017\n",
            "60:\t[0s / 7s],\t\ttrain_loss: 0.3952,\tval_loss: 0.4016\n",
            "61:\t[0s / 8s],\t\ttrain_loss: 0.3903,\tval_loss: 0.3979\n",
            "62:\t[0s / 8s],\t\ttrain_loss: 0.3949,\tval_loss: 0.3968\n",
            "63:\t[0s / 8s],\t\ttrain_loss: 0.3860,\tval_loss: 0.3958\n",
            "64:\t[0s / 8s],\t\ttrain_loss: 0.3818,\tval_loss: 0.3921\n",
            "65:\t[0s / 8s],\t\ttrain_loss: 0.3816,\tval_loss: 0.3905\n",
            "66:\t[0s / 8s],\t\ttrain_loss: 0.3836,\tval_loss: 0.3890\n",
            "67:\t[0s / 8s],\t\ttrain_loss: 0.3787,\tval_loss: 0.3876\n",
            "68:\t[0s / 8s],\t\ttrain_loss: 0.3717,\tval_loss: 0.3840\n",
            "69:\t[0s / 8s],\t\ttrain_loss: 0.3719,\tval_loss: 0.3814\n",
            "70:\t[0s / 8s],\t\ttrain_loss: 0.3744,\tval_loss: 0.3826\n",
            "71:\t[0s / 9s],\t\ttrain_loss: 0.3636,\tval_loss: 0.3801\n",
            "72:\t[0s / 9s],\t\ttrain_loss: 0.3647,\tval_loss: 0.3787\n",
            "73:\t[0s / 9s],\t\ttrain_loss: 0.3587,\tval_loss: 0.3775\n",
            "74:\t[0s / 9s],\t\ttrain_loss: 0.3604,\tval_loss: 0.3745\n",
            "75:\t[0s / 9s],\t\ttrain_loss: 0.3546,\tval_loss: 0.3736\n",
            "76:\t[0s / 9s],\t\ttrain_loss: 0.3466,\tval_loss: 0.3718\n",
            "77:\t[0s / 9s],\t\ttrain_loss: 0.3530,\tval_loss: 0.3709\n",
            "78:\t[0s / 9s],\t\ttrain_loss: 0.3445,\tval_loss: 0.3694\n",
            "79:\t[0s / 9s],\t\ttrain_loss: 0.3388,\tval_loss: 0.3685\n",
            "80:\t[0s / 9s],\t\ttrain_loss: 0.3385,\tval_loss: 0.3678\n",
            "81:\t[0s / 10s],\t\ttrain_loss: 0.3407,\tval_loss: 0.3671\n",
            "82:\t[0s / 10s],\t\ttrain_loss: 0.3452,\tval_loss: 0.3665\n",
            "83:\t[0s / 10s],\t\ttrain_loss: 0.3356,\tval_loss: 0.3647\n",
            "84:\t[0s / 10s],\t\ttrain_loss: 0.3335,\tval_loss: 0.3626\n",
            "85:\t[0s / 10s],\t\ttrain_loss: 0.3287,\tval_loss: 0.3619\n",
            "86:\t[0s / 10s],\t\ttrain_loss: 0.3380,\tval_loss: 0.3614\n",
            "87:\t[0s / 10s],\t\ttrain_loss: 0.3256,\tval_loss: 0.3601\n",
            "88:\t[0s / 10s],\t\ttrain_loss: 0.3288,\tval_loss: 0.3589\n",
            "89:\t[0s / 10s],\t\ttrain_loss: 0.3248,\tval_loss: 0.3577\n",
            "90:\t[0s / 11s],\t\ttrain_loss: 0.3223,\tval_loss: 0.3555\n",
            "91:\t[0s / 11s],\t\ttrain_loss: 0.3189,\tval_loss: 0.3562\n",
            "92:\t[0s / 11s],\t\ttrain_loss: 0.3171,\tval_loss: 0.3555\n",
            "93:\t[0s / 11s],\t\ttrain_loss: 0.3127,\tval_loss: 0.3557\n",
            "94:\t[0s / 11s],\t\ttrain_loss: 0.3145,\tval_loss: 0.3548\n",
            "95:\t[0s / 11s],\t\ttrain_loss: 0.3149,\tval_loss: 0.3548\n",
            "96:\t[0s / 11s],\t\ttrain_loss: 0.3138,\tval_loss: 0.3586\n",
            "97:\t[0s / 11s],\t\ttrain_loss: 0.3099,\tval_loss: 0.3557\n",
            "98:\t[0s / 11s],\t\ttrain_loss: 0.3070,\tval_loss: 0.3550\n",
            "99:\t[0s / 11s],\t\ttrain_loss: 0.3038,\tval_loss: 0.3547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.6272,\tval_loss: 0.5113\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.6475,\tval_loss: 0.5094\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.6131,\tval_loss: 0.5057\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.6302,\tval_loss: 0.5023\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 0.5864,\tval_loss: 0.5002\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.5820,\tval_loss: 0.4976\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.5729,\tval_loss: 0.4930\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.5715,\tval_loss: 0.4891\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.5634,\tval_loss: 0.4863\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 0.5689,\tval_loss: 0.4840\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 0.5622,\tval_loss: 0.4810\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 0.5639,\tval_loss: 0.4802\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 0.5718,\tval_loss: 0.4768\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 0.5419,\tval_loss: 0.4765\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 0.5518,\tval_loss: 0.4749\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 0.5543,\tval_loss: 0.4726\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 0.5392,\tval_loss: 0.4704\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 0.5460,\tval_loss: 0.4702\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 0.5314,\tval_loss: 0.4689\n",
            "19:\t[0s / 2s],\t\ttrain_loss: 0.5240,\tval_loss: 0.4662\n",
            "20:\t[0s / 2s],\t\ttrain_loss: 0.5224,\tval_loss: 0.4662\n",
            "21:\t[0s / 2s],\t\ttrain_loss: 0.5264,\tval_loss: 0.4647\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-7dcc026d9d57>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbootstrap_train_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbootstrap_train_y_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootstrap_train_y_events\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Evaluate on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0msurv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_surv_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtuples/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, input, target, batch_size, epochs, callbacks, verbose, num_workers, shuffle, metrics, val_data, val_batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtuples/base.py\u001b[0m in \u001b[0;36mfit_dataloader\u001b[0;34m(self, dataloader, epochs, callbacks, verbose, metrics, val_dataloader)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m                 \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtuples/optim.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m                                                f\"but got {result}.\")\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 state_steps)\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    282\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mstep_t\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#15/8/23\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Number of bootstrap iterations\n",
        "n_bootstrap_iterations = 50\n",
        "\n",
        "# Arrays to store bootstrap C-indices and IBS scores\n",
        "bootstrap_c_indices_deephit = np.zeros(n_bootstrap_iterations)\n",
        "bootstrap_ibs_scores_deep_hit = np.zeros(n_bootstrap_iterations)\n",
        "\n",
        "for i in range(n_bootstrap_iterations):\n",
        "    # Generate a bootstrap sample of indices\n",
        "    bootstrap_indices = resample(np.arange(len(x_train)), replace=True)\n",
        "\n",
        "    # Use these indices to create bootstrap samples\n",
        "    bootstrap_train_x = x_train[bootstrap_indices]\n",
        "    bootstrap_train_y_times = y_train[0][bootstrap_indices]\n",
        "    bootstrap_train_y_events = y_train[1][bootstrap_indices]\n",
        "\n",
        "    #\n",
        "    # Fit the model using the resampled training data with the best hyperparameters\n",
        "    num_nodes = [best_hyperparameters['nodes']] * best_hyperparameters['layers']\n",
        "    batch_norm = best_hyperparameters['batch_norm']\n",
        "    dropout = best_hyperparameters['dropout']\n",
        "\n",
        "\n",
        "    bootstrap_net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
        "\n",
        "    bootstrap_model = DeepHitSingle(bootstrap_net, tt.optim.Adam, alpha=best_hyperparameters['alpha'], sigma=best_hyperparameters['sigma'], duration_index=labtrans.cuts)\n",
        "\n",
        "    batch_size = best_hyperparameters['batch_size']\n",
        "    bootstrap_model.optimizer.set_lr(best_hyperparameters['lr'])\n",
        "\n",
        "    epochs = 100\n",
        "    callbacks = [tt.callbacks.EarlyStopping()]\n",
        "    log = bootstrap_model.fit(bootstrap_train_x, (bootstrap_train_y_times, bootstrap_train_y_events), batch_size, epochs, callbacks, val_data=val)\n",
        "    # Evaluate on the test set\n",
        "    surv = bootstrap_model.predict_surv_df(x_test)\n",
        "    ev_test = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
        "    c_index_test = ev_test.concordance_td('antolini')\n",
        "    bootstrap_c_indices_deephit[i] = c_index_test\n",
        "\n",
        "    # Calculate the integrated Brier score\n",
        "    ibs = ev_test.integrated_brier_score(time_grid=np.linspace(0, durations_test.max(), 100))\n",
        "    bootstrap_ibs_scores_deep_hit[i] = ibs\n",
        "\n",
        "# Compute the lower and upper percentiles for C-index\n",
        "lower_percentile_c_index = np.percentile(bootstrap_c_indices_deephit, 2.5)\n",
        "upper_percentile_c_index = np.percentile(bootstrap_c_indices_deephit, 97.5)\n",
        "\n",
        "# Compute the lower and upper percentiles for IBS\n",
        "lower_percentile_ibs = np.percentile(bootstrap_ibs_scores_deep_hit, 2.5)\n",
        "upper_percentile_ibs = np.percentile(bootstrap_ibs_scores_deep_hit, 97.5)\n",
        "\n",
        "print('Bootstrap 95% confidence interval for the C-index: ({:.2f}, {:.2f})'.format(lower_percentile_c_index, upper_percentile_c_index))\n",
        "print('Bootstrap 95% confidence interval for the IBS: ({:.2f}, {:.2f})'.format(lower_percentile_ibs, upper_percentile_ibs))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "g6qba1SwYZNq",
        "outputId": "182a964d-d657-4fee-afe5-5fd0c74ca308"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Boostrapped estimates 15/8/23\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the style for seaborn\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create a figure\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Subplot for C-index\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot(y=bootstrap_c_indices_deephit)\n",
        "plt.title(\"Boxplot of Bootstrap C-Indices\")\n",
        "plt.ylabel(\"C-Index\")\n",
        "\n",
        "# Subplot for IBS\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(y=bootstrap_ibs_scores_deep_hit)\n",
        "plt.title(\"Boxplot of Bootstrap IBS Scores\")\n",
        "plt.ylabel(\"IBS Score\")\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# save the numpy arrays to the specified directory\n",
        "np.save('/content/drive/MyDrive/MSc_summer_project/Clinical_trial_data/Breast/Confidence_intervals_breast_IBS_cindex/bootstrap_c_indices_deephit.npy', bootstrap_c_indices_deephit)\n",
        "np.save('/content/drive/MyDrive/MSc_summer_project/Clinical_trial_data/Breast/Confidence_intervals_breast_IBS_cindex/bootstrap_ibs_scores_deep_hit.npy', bootstrap_ibs_scores_deep_hit)\n"
      ],
      "metadata": {
        "id": "DcvGioNNserb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNZWC5g6fUfV"
      },
      "outputs": [],
      "source": [
        "## This gives;\n",
        "## - Bootstrap 95% confidence interval for the C-index: (0.50, 0.63)\n",
        "## - Bootstrap 95% confidence interval for the IBS: (0.09, 0.13)\n",
        "best_hyperparameters = {'batch_size': 32, 'layers': 5, 'nodes': 300, 'activation_fn': 'elu', 'alpha': 0.1, 'sigma': 0.5, 'lr': 0.001, 'dropout': 0.3, 'patience': 30}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9RVUvBBnCvA"
      },
      "outputs": [],
      "source": [
        "best_hyperparameters = {'batch_size': 32, 'layers': 5, 'nodes': 50, 'activation_fn': 'elu', 'alpha': 0.1, 'sigma': 0.1, 'lr': 0.01}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQvs0MF8fTHg",
        "outputId": "5732f5e6-ce65-48ff-8915-1bcde0b4ea92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2157,\tval_loss: 0.1499\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1603,\tval_loss: 0.1417\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1450,\tval_loss: 0.1308\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1420,\tval_loss: 0.1255\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1310,\tval_loss: 0.1212\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1230,\tval_loss: 0.1172\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1197,\tval_loss: 0.1159\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1191,\tval_loss: 0.1150\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1177,\tval_loss: 0.1159\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1161,\tval_loss: 0.1155\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.1150,\tval_loss: 0.1143\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1158,\tval_loss: 0.1157\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1142,\tval_loss: 0.1149\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1152,\tval_loss: 0.1151\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1147,\tval_loss: 0.1157\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1143,\tval_loss: 0.1155\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1134,\tval_loss: 0.1154\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.1110,\tval_loss: 0.1193\n",
            "18:\t[0s / 5s],\t\ttrain_loss: 0.1119,\tval_loss: 0.1173\n",
            "19:\t[0s / 5s],\t\ttrain_loss: 0.1127,\tval_loss: 0.1191\n",
            "20:\t[0s / 5s],\t\ttrain_loss: 0.1100,\tval_loss: 0.1216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2198,\tval_loss: 0.1195\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1205\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1526,\tval_loss: 0.1150\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1467,\tval_loss: 0.1141\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1400,\tval_loss: 0.1143\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1336,\tval_loss: 0.1130\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.1328,\tval_loss: 0.1164\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1355,\tval_loss: 0.1153\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 0.1300,\tval_loss: 0.1172\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 0.1277,\tval_loss: 0.1162\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1256,\tval_loss: 0.1181\n",
            "11:\t[0s / 4s],\t\ttrain_loss: 0.1281,\tval_loss: 0.1186\n",
            "12:\t[0s / 4s],\t\ttrain_loss: 0.1318,\tval_loss: 0.1180\n",
            "13:\t[0s / 5s],\t\ttrain_loss: 0.1259,\tval_loss: 0.1194\n",
            "14:\t[0s / 5s],\t\ttrain_loss: 0.1261,\tval_loss: 0.1219\n",
            "15:\t[0s / 5s],\t\ttrain_loss: 0.1243,\tval_loss: 0.1239\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2476,\tval_loss: 0.1233\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1555,\tval_loss: 0.1172\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1340,\tval_loss: 0.1163\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1295,\tval_loss: 0.1154\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1279,\tval_loss: 0.1144\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1257,\tval_loss: 0.1147\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1254,\tval_loss: 0.1138\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1223,\tval_loss: 0.1148\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1216,\tval_loss: 0.1137\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1163,\tval_loss: 0.1158\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.1156,\tval_loss: 0.1141\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1139,\tval_loss: 0.1209\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1187,\tval_loss: 0.1187\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1214,\tval_loss: 0.1231\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1192,\tval_loss: 0.1161\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1143,\tval_loss: 0.1159\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1126,\tval_loss: 0.1298\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.1117,\tval_loss: 0.1204\n",
            "18:\t[0s / 5s],\t\ttrain_loss: 0.1315,\tval_loss: 0.1199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1798,\tval_loss: 0.1195\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1473,\tval_loss: 0.1155\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1351,\tval_loss: 0.1155\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1301,\tval_loss: 0.1149\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1291,\tval_loss: 0.1164\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1275,\tval_loss: 0.1149\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1252,\tval_loss: 0.1149\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1226,\tval_loss: 0.1139\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1198,\tval_loss: 0.1183\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1189,\tval_loss: 0.1199\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1589,\tval_loss: 0.1141\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1265,\tval_loss: 0.1147\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1226,\tval_loss: 0.1150\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1231,\tval_loss: 0.1147\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1229,\tval_loss: 0.1176\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1226,\tval_loss: 0.1160\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1194\n",
            "17:\t[0s / 5s],\t\ttrain_loss: 0.1205,\tval_loss: 0.1163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2888,\tval_loss: 0.1209\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1691,\tval_loss: 0.1223\n",
            "2:\t[0s / 1s],\t\ttrain_loss: 0.1578,\tval_loss: 0.1151\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1491,\tval_loss: 0.1176\n",
            "4:\t[0s / 2s],\t\ttrain_loss: 0.1440,\tval_loss: 0.1159\n",
            "5:\t[0s / 2s],\t\ttrain_loss: 0.1620,\tval_loss: 0.1183\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.1402,\tval_loss: 0.1160\n",
            "7:\t[0s / 3s],\t\ttrain_loss: 0.1370,\tval_loss: 0.1142\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 0.1280,\tval_loss: 0.1141\n",
            "9:\t[0s / 4s],\t\ttrain_loss: 0.1363,\tval_loss: 0.1146\n",
            "10:\t[0s / 4s],\t\ttrain_loss: 0.1292,\tval_loss: 0.1131\n",
            "11:\t[0s / 4s],\t\ttrain_loss: 0.1300,\tval_loss: 0.1138\n",
            "12:\t[0s / 4s],\t\ttrain_loss: 0.1290,\tval_loss: 0.1134\n",
            "13:\t[0s / 5s],\t\ttrain_loss: 0.1283,\tval_loss: 0.1138\n",
            "14:\t[0s / 5s],\t\ttrain_loss: 0.1249,\tval_loss: 0.1147\n",
            "15:\t[0s / 5s],\t\ttrain_loss: 0.1264,\tval_loss: 0.1130\n",
            "16:\t[0s / 6s],\t\ttrain_loss: 0.1268,\tval_loss: 0.1122\n",
            "17:\t[0s / 6s],\t\ttrain_loss: 0.1229,\tval_loss: 0.1133\n",
            "18:\t[0s / 6s],\t\ttrain_loss: 0.1208,\tval_loss: 0.1137\n",
            "19:\t[0s / 6s],\t\ttrain_loss: 0.1211,\tval_loss: 0.1142\n",
            "20:\t[0s / 7s],\t\ttrain_loss: 0.1187,\tval_loss: 0.1122\n",
            "21:\t[0s / 7s],\t\ttrain_loss: 0.1210,\tval_loss: 0.1137\n",
            "22:\t[0s / 7s],\t\ttrain_loss: 0.1225,\tval_loss: 0.1145\n",
            "23:\t[0s / 8s],\t\ttrain_loss: 0.1187,\tval_loss: 0.1152\n",
            "24:\t[0s / 8s],\t\ttrain_loss: 0.1207,\tval_loss: 0.1150\n",
            "25:\t[0s / 8s],\t\ttrain_loss: 0.1172,\tval_loss: 0.1139\n",
            "26:\t[0s / 8s],\t\ttrain_loss: 0.1161,\tval_loss: 0.1189\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2236,\tval_loss: 0.1246\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1527,\tval_loss: 0.1207\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1504,\tval_loss: 0.1187\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1371,\tval_loss: 0.1182\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1315,\tval_loss: 0.1145\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1329,\tval_loss: 0.1172\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1302,\tval_loss: 0.1161\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1287,\tval_loss: 0.1150\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1289,\tval_loss: 0.1153\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1254,\tval_loss: 0.1135\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1242,\tval_loss: 0.1166\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1220,\tval_loss: 0.1227\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1222,\tval_loss: 0.1173\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1195,\tval_loss: 0.1204\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1200\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1206,\tval_loss: 0.1176\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.2071,\tval_loss: 0.1181\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.1672,\tval_loss: 0.1182\n",
            "18:\t[0s / 5s],\t\ttrain_loss: 0.1380,\tval_loss: 0.1175\n",
            "19:\t[0s / 5s],\t\ttrain_loss: 0.1314,\tval_loss: 0.1157\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2125,\tval_loss: 0.1168\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1626,\tval_loss: 0.1151\n",
            "2:\t[0s / 1s],\t\ttrain_loss: 0.1477,\tval_loss: 0.1142\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1380,\tval_loss: 0.1158\n",
            "4:\t[0s / 2s],\t\ttrain_loss: 0.1355,\tval_loss: 0.1146\n",
            "5:\t[0s / 2s],\t\ttrain_loss: 0.1373,\tval_loss: 0.1140\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.1333,\tval_loss: 0.1141\n",
            "7:\t[0s / 3s],\t\ttrain_loss: 0.1302,\tval_loss: 0.1131\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 0.1292,\tval_loss: 0.1123\n",
            "9:\t[0s / 4s],\t\ttrain_loss: 0.1283,\tval_loss: 0.1135\n",
            "10:\t[0s / 4s],\t\ttrain_loss: 0.1271,\tval_loss: 0.1128\n",
            "11:\t[0s / 4s],\t\ttrain_loss: 0.1289,\tval_loss: 0.1141\n",
            "12:\t[0s / 5s],\t\ttrain_loss: 0.1252,\tval_loss: 0.1170\n",
            "13:\t[0s / 5s],\t\ttrain_loss: 0.1338,\tval_loss: 0.1161\n",
            "14:\t[0s / 5s],\t\ttrain_loss: 0.1287,\tval_loss: 0.1144\n",
            "15:\t[0s / 5s],\t\ttrain_loss: 0.1276,\tval_loss: 0.1186\n",
            "16:\t[0s / 6s],\t\ttrain_loss: 0.1296,\tval_loss: 0.1163\n",
            "17:\t[0s / 6s],\t\ttrain_loss: 0.1276,\tval_loss: 0.1142\n",
            "18:\t[0s / 6s],\t\ttrain_loss: 0.1356,\tval_loss: 0.1146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1908,\tval_loss: 0.1182\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1542,\tval_loss: 0.1158\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1423,\tval_loss: 0.1157\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1316,\tval_loss: 0.1142\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1340,\tval_loss: 0.1144\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1309,\tval_loss: 0.1130\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1258,\tval_loss: 0.1138\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1247,\tval_loss: 0.1128\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1293,\tval_loss: 0.1133\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1280,\tval_loss: 0.1121\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1286,\tval_loss: 0.1127\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1221,\tval_loss: 0.1134\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1206,\tval_loss: 0.1141\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1270,\tval_loss: 0.1158\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1302,\tval_loss: 0.1168\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1258,\tval_loss: 0.1223\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1230,\tval_loss: 0.1184\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.1199,\tval_loss: 0.1173\n",
            "18:\t[0s / 5s],\t\ttrain_loss: 0.1288,\tval_loss: 0.1175\n",
            "19:\t[0s / 5s],\t\ttrain_loss: 0.1230,\tval_loss: 0.1155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1811,\tval_loss: 0.1205\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1349,\tval_loss: 0.1190\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1351,\tval_loss: 0.1147\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1365,\tval_loss: 0.1154\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1268,\tval_loss: 0.1153\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1279,\tval_loss: 0.1140\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1266,\tval_loss: 0.1135\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1228,\tval_loss: 0.1127\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1250,\tval_loss: 0.1123\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1207,\tval_loss: 0.1119\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1175,\tval_loss: 0.1153\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1195,\tval_loss: 0.1170\n",
            "12:\t[0s / 4s],\t\ttrain_loss: 0.1177,\tval_loss: 0.1117\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 0.1166,\tval_loss: 0.1150\n",
            "14:\t[0s / 5s],\t\ttrain_loss: 0.1166,\tval_loss: 0.1122\n",
            "15:\t[1s / 6s],\t\ttrain_loss: 0.1158,\tval_loss: 0.1129\n",
            "16:\t[0s / 6s],\t\ttrain_loss: 0.1187,\tval_loss: 0.1153\n",
            "17:\t[0s / 7s],\t\ttrain_loss: 0.1207,\tval_loss: 0.1174\n",
            "18:\t[0s / 7s],\t\ttrain_loss: 0.1141,\tval_loss: 0.1142\n",
            "19:\t[0s / 7s],\t\ttrain_loss: 0.1917,\tval_loss: 0.1225\n",
            "20:\t[0s / 8s],\t\ttrain_loss: 0.1307,\tval_loss: 0.1167\n",
            "21:\t[0s / 8s],\t\ttrain_loss: 0.1253,\tval_loss: 0.1162\n",
            "22:\t[0s / 8s],\t\ttrain_loss: 0.1213,\tval_loss: 0.1149\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1721,\tval_loss: 0.1259\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1463,\tval_loss: 0.1195\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1417,\tval_loss: 0.1149\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1332,\tval_loss: 0.1155\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1258,\tval_loss: 0.1150\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1307,\tval_loss: 0.1161\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1281,\tval_loss: 0.1152\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1224,\tval_loss: 0.1153\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1243,\tval_loss: 0.1162\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1218,\tval_loss: 0.1149\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.1240,\tval_loss: 0.1153\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1209,\tval_loss: 0.1161\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1155,\tval_loss: 0.1237\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1202,\tval_loss: 0.1177\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1159,\tval_loss: 0.1209\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1159,\tval_loss: 0.1240\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1153,\tval_loss: 0.1239\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.1128,\tval_loss: 0.1260\n",
            "18:\t[0s / 5s],\t\ttrain_loss: 0.1154,\tval_loss: 0.1203\n",
            "19:\t[0s / 5s],\t\ttrain_loss: 0.1156,\tval_loss: 0.1273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2403,\tval_loss: 0.1465\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1671,\tval_loss: 0.1314\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1204\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1309,\tval_loss: 0.1180\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1323,\tval_loss: 0.1180\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1209,\tval_loss: 0.1169\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1235,\tval_loss: 0.1155\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1140\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1196,\tval_loss: 0.1172\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1215,\tval_loss: 0.1148\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1147,\tval_loss: 0.1181\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1193,\tval_loss: 0.1169\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1136,\tval_loss: 0.1203\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 0.1120,\tval_loss: 0.1210\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1134,\tval_loss: 0.1238\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1121,\tval_loss: 0.1192\n",
            "16:\t[0s / 5s],\t\ttrain_loss: 0.1137,\tval_loss: 0.1258\n",
            "17:\t[0s / 5s],\t\ttrain_loss: 0.1136,\tval_loss: 0.1251\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1948,\tval_loss: 0.1192\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1606,\tval_loss: 0.1151\n",
            "2:\t[0s / 1s],\t\ttrain_loss: 0.1388,\tval_loss: 0.1160\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1354,\tval_loss: 0.1142\n",
            "4:\t[0s / 2s],\t\ttrain_loss: 0.1312,\tval_loss: 0.1148\n",
            "5:\t[0s / 2s],\t\ttrain_loss: 0.1282,\tval_loss: 0.1158\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.1253,\tval_loss: 0.1155\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1257,\tval_loss: 0.1171\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 0.1229,\tval_loss: 0.1174\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 0.1243,\tval_loss: 0.1208\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1246,\tval_loss: 0.1156\n",
            "11:\t[0s / 4s],\t\ttrain_loss: 0.1203,\tval_loss: 0.1159\n",
            "12:\t[0s / 4s],\t\ttrain_loss: 0.1209,\tval_loss: 0.1210\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 0.1194,\tval_loss: 0.1173\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1652,\tval_loss: 0.1165\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1466,\tval_loss: 0.1161\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1401,\tval_loss: 0.1141\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1387,\tval_loss: 0.1132\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1351,\tval_loss: 0.1147\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1322,\tval_loss: 0.1136\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1294,\tval_loss: 0.1141\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1285,\tval_loss: 0.1128\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1243,\tval_loss: 0.1131\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1272,\tval_loss: 0.1161\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.1210,\tval_loss: 0.1147\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1223,\tval_loss: 0.1152\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1240,\tval_loss: 0.1175\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1260,\tval_loss: 0.1179\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1330,\tval_loss: 0.1236\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1263,\tval_loss: 0.1171\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1254,\tval_loss: 0.1167\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.1280,\tval_loss: 0.1149\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2080,\tval_loss: 0.1264\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1573,\tval_loss: 0.1173\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1397,\tval_loss: 0.1160\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1391,\tval_loss: 0.1171\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1335,\tval_loss: 0.1168\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1304,\tval_loss: 0.1152\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1270,\tval_loss: 0.1159\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1273,\tval_loss: 0.1158\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1247,\tval_loss: 0.1222\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1232,\tval_loss: 0.1157\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1248,\tval_loss: 0.1152\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1238,\tval_loss: 0.1174\n",
            "12:\t[0s / 4s],\t\ttrain_loss: 0.1225,\tval_loss: 0.1204\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 0.1216,\tval_loss: 0.1197\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1174,\tval_loss: 0.1243\n",
            "15:\t[0s / 5s],\t\ttrain_loss: 0.1159,\tval_loss: 0.1193\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2136,\tval_loss: 0.1341\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1499,\tval_loss: 0.1208\n",
            "2:\t[0s / 1s],\t\ttrain_loss: 0.1425,\tval_loss: 0.1158\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1309,\tval_loss: 0.1167\n",
            "4:\t[0s / 2s],\t\ttrain_loss: 0.1239,\tval_loss: 0.1161\n",
            "5:\t[0s / 2s],\t\ttrain_loss: 0.1238,\tval_loss: 0.1141\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.1256,\tval_loss: 0.1131\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1206,\tval_loss: 0.1136\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 0.1204,\tval_loss: 0.1139\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 0.1213,\tval_loss: 0.1155\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1176,\tval_loss: 0.1197\n",
            "11:\t[0s / 4s],\t\ttrain_loss: 0.1175,\tval_loss: 0.1157\n",
            "12:\t[0s / 4s],\t\ttrain_loss: 0.1174,\tval_loss: 0.1170\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 0.1141,\tval_loss: 0.1146\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1150,\tval_loss: 0.1173\n",
            "15:\t[0s / 5s],\t\ttrain_loss: 0.1137,\tval_loss: 0.1152\n",
            "16:\t[0s / 5s],\t\ttrain_loss: 0.1128,\tval_loss: 0.1207\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2342,\tval_loss: 0.1243\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1541,\tval_loss: 0.1250\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1425,\tval_loss: 0.1165\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1381,\tval_loss: 0.1163\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1301,\tval_loss: 0.1180\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1288,\tval_loss: 0.1161\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1214,\tval_loss: 0.1146\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1197,\tval_loss: 0.1181\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1213,\tval_loss: 0.1158\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1201,\tval_loss: 0.1171\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1164,\tval_loss: 0.1165\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1159,\tval_loss: 0.1161\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1151,\tval_loss: 0.1183\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1128,\tval_loss: 0.1230\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1134,\tval_loss: 0.1224\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1125,\tval_loss: 0.1210\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1123,\tval_loss: 0.1213\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1878,\tval_loss: 0.1186\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1487,\tval_loss: 0.1186\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1372,\tval_loss: 0.1182\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1282,\tval_loss: 0.1174\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1222,\tval_loss: 0.1151\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1238,\tval_loss: 0.1153\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1205,\tval_loss: 0.1161\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1165,\tval_loss: 0.1148\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1127,\tval_loss: 0.1157\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 0.1125,\tval_loss: 0.1167\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1125,\tval_loss: 0.1184\n",
            "11:\t[0s / 4s],\t\ttrain_loss: 0.1107,\tval_loss: 0.1235\n",
            "12:\t[1s / 5s],\t\ttrain_loss: 0.1127,\tval_loss: 0.1184\n",
            "13:\t[1s / 6s],\t\ttrain_loss: 0.1115,\tval_loss: 0.1224\n",
            "14:\t[0s / 7s],\t\ttrain_loss: 0.1085,\tval_loss: 0.1219\n",
            "15:\t[0s / 7s],\t\ttrain_loss: 0.1144,\tval_loss: 0.1194\n",
            "16:\t[0s / 7s],\t\ttrain_loss: 0.1098,\tval_loss: 0.1203\n",
            "17:\t[0s / 8s],\t\ttrain_loss: 0.1048,\tval_loss: 0.1255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1644,\tval_loss: 0.1199\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1513,\tval_loss: 0.1196\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1337,\tval_loss: 0.1155\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1295,\tval_loss: 0.1178\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1242,\tval_loss: 0.1162\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1177,\tval_loss: 0.1158\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1197,\tval_loss: 0.1149\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1246,\tval_loss: 0.1150\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1198,\tval_loss: 0.1151\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1251,\tval_loss: 0.1152\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1197,\tval_loss: 0.1152\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1133,\tval_loss: 0.1161\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1221,\tval_loss: 0.1163\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1171,\tval_loss: 0.1153\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1158,\tval_loss: 0.1156\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1167,\tval_loss: 0.1151\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1142,\tval_loss: 0.1154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2661,\tval_loss: 0.1298\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1787,\tval_loss: 0.1186\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1572,\tval_loss: 0.1178\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1471,\tval_loss: 0.1184\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1432,\tval_loss: 0.1149\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1406,\tval_loss: 0.1155\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1407,\tval_loss: 0.1163\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1416,\tval_loss: 0.1152\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1347,\tval_loss: 0.1143\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1321,\tval_loss: 0.1159\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1277,\tval_loss: 0.1148\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1242,\tval_loss: 0.1164\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1294,\tval_loss: 0.1144\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1299,\tval_loss: 0.1154\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1227,\tval_loss: 0.1135\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1222,\tval_loss: 0.1125\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1248,\tval_loss: 0.1153\n",
            "17:\t[0s / 5s],\t\ttrain_loss: 0.1234,\tval_loss: 0.1169\n",
            "18:\t[0s / 6s],\t\ttrain_loss: 0.1226,\tval_loss: 0.1161\n",
            "19:\t[0s / 6s],\t\ttrain_loss: 0.1282,\tval_loss: 0.1165\n",
            "20:\t[0s / 6s],\t\ttrain_loss: 0.1224,\tval_loss: 0.1179\n",
            "21:\t[0s / 7s],\t\ttrain_loss: 0.1208,\tval_loss: 0.1143\n",
            "22:\t[0s / 7s],\t\ttrain_loss: 0.1213,\tval_loss: 0.1186\n",
            "23:\t[0s / 8s],\t\ttrain_loss: 0.1189,\tval_loss: 0.1194\n",
            "24:\t[0s / 8s],\t\ttrain_loss: 0.1235,\tval_loss: 0.1193\n",
            "25:\t[0s / 8s],\t\ttrain_loss: 0.1235,\tval_loss: 0.1211\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2750,\tval_loss: 0.1213\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1420,\tval_loss: 0.1213\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1444,\tval_loss: 0.1187\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1386,\tval_loss: 0.1174\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1288,\tval_loss: 0.1178\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1348,\tval_loss: 0.1199\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1289,\tval_loss: 0.1165\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1280,\tval_loss: 0.1158\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1238,\tval_loss: 0.1147\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1214,\tval_loss: 0.1155\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1209,\tval_loss: 0.1142\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1206,\tval_loss: 0.1159\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1207,\tval_loss: 0.1145\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1162,\tval_loss: 0.1163\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1172,\tval_loss: 0.1177\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1159,\tval_loss: 0.1187\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1179,\tval_loss: 0.1168\n",
            "17:\t[0s / 5s],\t\ttrain_loss: 0.1484,\tval_loss: 0.1250\n",
            "18:\t[0s / 5s],\t\ttrain_loss: 0.1227,\tval_loss: 0.1181\n",
            "19:\t[0s / 5s],\t\ttrain_loss: 0.1205,\tval_loss: 0.1244\n",
            "20:\t[0s / 5s],\t\ttrain_loss: 0.1168,\tval_loss: 0.1185\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1722,\tval_loss: 0.1210\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1380,\tval_loss: 0.1157\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1289,\tval_loss: 0.1168\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1223,\tval_loss: 0.1141\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1232,\tval_loss: 0.1152\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1200,\tval_loss: 0.1157\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1177,\tval_loss: 0.1157\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1198,\tval_loss: 0.1142\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1145,\tval_loss: 0.1145\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1141,\tval_loss: 0.1155\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1116,\tval_loss: 0.1154\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1093,\tval_loss: 0.1156\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1133,\tval_loss: 0.1172\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1073,\tval_loss: 0.1259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2020,\tval_loss: 0.1189\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1453,\tval_loss: 0.1201\n",
            "2:\t[0s / 1s],\t\ttrain_loss: 0.1385,\tval_loss: 0.1182\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1325,\tval_loss: 0.1162\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1276,\tval_loss: 0.1170\n",
            "5:\t[0s / 2s],\t\ttrain_loss: 0.1265,\tval_loss: 0.1155\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.1206,\tval_loss: 0.1168\n",
            "7:\t[0s / 3s],\t\ttrain_loss: 0.1208,\tval_loss: 0.1152\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 0.1204,\tval_loss: 0.1147\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 0.1172,\tval_loss: 0.1156\n",
            "10:\t[0s / 4s],\t\ttrain_loss: 0.1135,\tval_loss: 0.1190\n",
            "11:\t[0s / 4s],\t\ttrain_loss: 0.1123,\tval_loss: 0.1218\n",
            "12:\t[0s / 5s],\t\ttrain_loss: 0.1168,\tval_loss: 0.1233\n",
            "13:\t[0s / 5s],\t\ttrain_loss: 0.1152,\tval_loss: 0.1207\n",
            "14:\t[0s / 5s],\t\ttrain_loss: 0.1146,\tval_loss: 0.1188\n",
            "15:\t[0s / 5s],\t\ttrain_loss: 0.1137,\tval_loss: 0.1248\n",
            "16:\t[0s / 6s],\t\ttrain_loss: 0.1103,\tval_loss: 0.1304\n",
            "17:\t[0s / 6s],\t\ttrain_loss: 0.1072,\tval_loss: 0.1291\n",
            "18:\t[0s / 6s],\t\ttrain_loss: 0.1081,\tval_loss: 0.1329\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1838,\tval_loss: 0.1189\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1456,\tval_loss: 0.1188\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1360,\tval_loss: 0.1133\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1255,\tval_loss: 0.1134\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1236,\tval_loss: 0.1142\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1130\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1185,\tval_loss: 0.1129\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1196,\tval_loss: 0.1128\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1168,\tval_loss: 0.1148\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1204,\tval_loss: 0.1128\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1159,\tval_loss: 0.1133\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1151,\tval_loss: 0.1113\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1160,\tval_loss: 0.1120\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1131,\tval_loss: 0.1111\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1170,\tval_loss: 0.1121\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1116,\tval_loss: 0.1152\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1122,\tval_loss: 0.1135\n",
            "17:\t[0s / 5s],\t\ttrain_loss: 0.1155,\tval_loss: 0.1115\n",
            "18:\t[0s / 5s],\t\ttrain_loss: 0.1140,\tval_loss: 0.1149\n",
            "19:\t[0s / 5s],\t\ttrain_loss: 0.1134,\tval_loss: 0.1172\n",
            "20:\t[0s / 5s],\t\ttrain_loss: 0.1157,\tval_loss: 0.1131\n",
            "21:\t[0s / 6s],\t\ttrain_loss: 0.1093,\tval_loss: 0.1184\n",
            "22:\t[0s / 6s],\t\ttrain_loss: 0.1112,\tval_loss: 0.1148\n",
            "23:\t[0s / 6s],\t\ttrain_loss: 0.1100,\tval_loss: 0.1206\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1636,\tval_loss: 0.1219\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1386,\tval_loss: 0.1152\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1276,\tval_loss: 0.1128\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1193,\tval_loss: 0.1122\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1221,\tval_loss: 0.1147\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1139,\tval_loss: 0.1156\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1149,\tval_loss: 0.1135\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1141,\tval_loss: 0.1139\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1166,\tval_loss: 0.1151\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 0.1155,\tval_loss: 0.1134\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1149,\tval_loss: 0.1128\n",
            "11:\t[0s / 4s],\t\ttrain_loss: 0.1135,\tval_loss: 0.1140\n",
            "12:\t[0s / 4s],\t\ttrain_loss: 0.1148,\tval_loss: 0.1139\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 0.1139,\tval_loss: 0.1148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2277,\tval_loss: 0.1252\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1432,\tval_loss: 0.1182\n",
            "2:\t[0s / 1s],\t\ttrain_loss: 0.1404,\tval_loss: 0.1175\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1265,\tval_loss: 0.1159\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1277,\tval_loss: 0.1151\n",
            "5:\t[0s / 2s],\t\ttrain_loss: 0.1265,\tval_loss: 0.1146\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.1197,\tval_loss: 0.1152\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1165,\tval_loss: 0.1155\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1144\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 0.1137,\tval_loss: 0.1157\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1148,\tval_loss: 0.1151\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1119,\tval_loss: 0.1142\n",
            "12:\t[0s / 4s],\t\ttrain_loss: 0.1139,\tval_loss: 0.1157\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 0.1106,\tval_loss: 0.1188\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1103,\tval_loss: 0.1169\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1085,\tval_loss: 0.1178\n",
            "16:\t[0s / 5s],\t\ttrain_loss: 0.1098,\tval_loss: 0.1221\n",
            "17:\t[0s / 5s],\t\ttrain_loss: 0.1118,\tval_loss: 0.1219\n",
            "18:\t[0s / 5s],\t\ttrain_loss: 0.1150,\tval_loss: 0.1181\n",
            "19:\t[0s / 6s],\t\ttrain_loss: 0.1075,\tval_loss: 0.1216\n",
            "20:\t[0s / 6s],\t\ttrain_loss: 0.1102,\tval_loss: 0.1226\n",
            "21:\t[0s / 6s],\t\ttrain_loss: 0.1054,\tval_loss: 0.1281\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2087,\tval_loss: 0.1215\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1523,\tval_loss: 0.1215\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1506,\tval_loss: 0.1163\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1501,\tval_loss: 0.1150\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1359,\tval_loss: 0.1121\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1302,\tval_loss: 0.1143\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1281,\tval_loss: 0.1146\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1285,\tval_loss: 0.1127\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1299,\tval_loss: 0.1152\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1241,\tval_loss: 0.1146\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.1247,\tval_loss: 0.1141\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1250,\tval_loss: 0.1109\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1219,\tval_loss: 0.1131\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1237,\tval_loss: 0.1103\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1224,\tval_loss: 0.1123\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1211,\tval_loss: 0.1107\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1241,\tval_loss: 0.1128\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.1231,\tval_loss: 0.1123\n",
            "18:\t[0s / 5s],\t\ttrain_loss: 0.1225,\tval_loss: 0.1121\n",
            "19:\t[0s / 5s],\t\ttrain_loss: 0.1234,\tval_loss: 0.1133\n",
            "20:\t[0s / 6s],\t\ttrain_loss: 0.1212,\tval_loss: 0.1120\n",
            "21:\t[0s / 6s],\t\ttrain_loss: 0.1218,\tval_loss: 0.1123\n",
            "22:\t[0s / 6s],\t\ttrain_loss: 0.1203,\tval_loss: 0.1112\n",
            "23:\t[0s / 7s],\t\ttrain_loss: 0.1257,\tval_loss: 0.1133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2283,\tval_loss: 0.1474\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1672,\tval_loss: 0.1477\n",
            "2:\t[0s / 1s],\t\ttrain_loss: 0.1560,\tval_loss: 0.1421\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1475,\tval_loss: 0.1365\n",
            "4:\t[0s / 2s],\t\ttrain_loss: 0.1374,\tval_loss: 0.1279\n",
            "5:\t[0s / 2s],\t\ttrain_loss: 0.1350,\tval_loss: 0.1231\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.1318,\tval_loss: 0.1185\n",
            "7:\t[0s / 3s],\t\ttrain_loss: 0.1238,\tval_loss: 0.1177\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 0.1262,\tval_loss: 0.1142\n",
            "9:\t[0s / 4s],\t\ttrain_loss: 0.1232,\tval_loss: 0.1156\n",
            "10:\t[0s / 4s],\t\ttrain_loss: 0.1212,\tval_loss: 0.1139\n",
            "11:\t[0s / 4s],\t\ttrain_loss: 0.1222,\tval_loss: 0.1152\n",
            "12:\t[0s / 5s],\t\ttrain_loss: 0.1216,\tval_loss: 0.1145\n",
            "13:\t[0s / 5s],\t\ttrain_loss: 0.1188,\tval_loss: 0.1144\n",
            "14:\t[0s / 5s],\t\ttrain_loss: 0.1168,\tval_loss: 0.1123\n",
            "15:\t[0s / 5s],\t\ttrain_loss: 0.1178,\tval_loss: 0.1133\n",
            "16:\t[0s / 6s],\t\ttrain_loss: 0.1202,\tval_loss: 0.1127\n",
            "17:\t[0s / 6s],\t\ttrain_loss: 0.1166,\tval_loss: 0.1135\n",
            "18:\t[0s / 6s],\t\ttrain_loss: 0.1139,\tval_loss: 0.1131\n",
            "19:\t[0s / 7s],\t\ttrain_loss: 0.1143,\tval_loss: 0.1133\n",
            "20:\t[0s / 7s],\t\ttrain_loss: 0.1168,\tval_loss: 0.1118\n",
            "21:\t[0s / 7s],\t\ttrain_loss: 0.1195,\tval_loss: 0.1247\n",
            "22:\t[0s / 7s],\t\ttrain_loss: 0.1167,\tval_loss: 0.1145\n",
            "23:\t[0s / 8s],\t\ttrain_loss: 0.1125,\tval_loss: 0.1132\n",
            "24:\t[0s / 8s],\t\ttrain_loss: 0.1144,\tval_loss: 0.1128\n",
            "25:\t[0s / 8s],\t\ttrain_loss: 0.1211,\tval_loss: 0.1128\n",
            "26:\t[0s / 8s],\t\ttrain_loss: 0.1162,\tval_loss: 0.1220\n",
            "27:\t[0s / 9s],\t\ttrain_loss: 0.1130,\tval_loss: 0.1097\n",
            "28:\t[0s / 9s],\t\ttrain_loss: 0.1124,\tval_loss: 0.1129\n",
            "29:\t[0s / 9s],\t\ttrain_loss: 0.1122,\tval_loss: 0.1173\n",
            "30:\t[0s / 10s],\t\ttrain_loss: 0.2736,\tval_loss: 0.1226\n",
            "31:\t[0s / 10s],\t\ttrain_loss: 0.1312,\tval_loss: 0.1178\n",
            "32:\t[0s / 10s],\t\ttrain_loss: 0.1206,\tval_loss: 0.1174\n",
            "33:\t[0s / 10s],\t\ttrain_loss: 0.1358,\tval_loss: 0.1206\n",
            "34:\t[0s / 11s],\t\ttrain_loss: 0.1225,\tval_loss: 0.1192\n",
            "35:\t[0s / 11s],\t\ttrain_loss: 0.1172,\tval_loss: 0.1231\n",
            "36:\t[0s / 11s],\t\ttrain_loss: 0.1168,\tval_loss: 0.1224\n",
            "37:\t[0s / 11s],\t\ttrain_loss: 0.1224,\tval_loss: 0.1212\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.3021,\tval_loss: 0.1221\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1637,\tval_loss: 0.1216\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1623,\tval_loss: 0.1205\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1509,\tval_loss: 0.1181\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1379,\tval_loss: 0.1197\n",
            "5:\t[0s / 2s],\t\ttrain_loss: 0.1336,\tval_loss: 0.1182\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.1367,\tval_loss: 0.1174\n",
            "7:\t[0s / 3s],\t\ttrain_loss: 0.1269,\tval_loss: 0.1172\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 0.1252,\tval_loss: 0.1170\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 0.1238,\tval_loss: 0.1159\n",
            "10:\t[0s / 4s],\t\ttrain_loss: 0.1237,\tval_loss: 0.1171\n",
            "11:\t[0s / 4s],\t\ttrain_loss: 0.1192,\tval_loss: 0.1160\n",
            "12:\t[0s / 5s],\t\ttrain_loss: 0.1193,\tval_loss: 0.1190\n",
            "13:\t[0s / 5s],\t\ttrain_loss: 0.1196,\tval_loss: 0.1158\n",
            "14:\t[0s / 5s],\t\ttrain_loss: 0.1223,\tval_loss: 0.1168\n",
            "15:\t[0s / 5s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1152\n",
            "16:\t[0s / 6s],\t\ttrain_loss: 0.1206,\tval_loss: 0.1153\n",
            "17:\t[0s / 6s],\t\ttrain_loss: 0.1114,\tval_loss: 0.1168\n",
            "18:\t[0s / 6s],\t\ttrain_loss: 0.1187,\tval_loss: 0.1178\n",
            "19:\t[0s / 7s],\t\ttrain_loss: 0.1108,\tval_loss: 0.1176\n",
            "20:\t[0s / 7s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1155\n",
            "21:\t[0s / 7s],\t\ttrain_loss: 0.1116,\tval_loss: 0.1172\n",
            "22:\t[0s / 7s],\t\ttrain_loss: 0.1086,\tval_loss: 0.1184\n",
            "23:\t[0s / 8s],\t\ttrain_loss: 0.1135,\tval_loss: 0.1180\n",
            "24:\t[0s / 8s],\t\ttrain_loss: 0.1127,\tval_loss: 0.1167\n",
            "25:\t[0s / 8s],\t\ttrain_loss: 0.1085,\tval_loss: 0.1259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2257,\tval_loss: 0.1244\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1129\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1176\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1400,\tval_loss: 0.1139\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1312,\tval_loss: 0.1154\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1243,\tval_loss: 0.1137\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1241,\tval_loss: 0.1151\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1237,\tval_loss: 0.1143\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1210,\tval_loss: 0.1144\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1190,\tval_loss: 0.1155\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.1156,\tval_loss: 0.1162\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1155,\tval_loss: 0.1148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1832,\tval_loss: 0.1192\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1453,\tval_loss: 0.1160\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1466,\tval_loss: 0.1134\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1331,\tval_loss: 0.1142\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1266,\tval_loss: 0.1151\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1260,\tval_loss: 0.1151\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1244,\tval_loss: 0.1150\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1242,\tval_loss: 0.1144\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1199,\tval_loss: 0.1137\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1210,\tval_loss: 0.1126\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1209,\tval_loss: 0.1133\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1177,\tval_loss: 0.1148\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1176,\tval_loss: 0.1199\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 0.1150,\tval_loss: 0.1192\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1151,\tval_loss: 0.1234\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1153,\tval_loss: 0.1218\n",
            "16:\t[0s / 5s],\t\ttrain_loss: 0.1138,\tval_loss: 0.1222\n",
            "17:\t[0s / 5s],\t\ttrain_loss: 0.1160,\tval_loss: 0.1230\n",
            "18:\t[0s / 6s],\t\ttrain_loss: 0.1114,\tval_loss: 0.1252\n",
            "19:\t[0s / 6s],\t\ttrain_loss: 0.1095,\tval_loss: 0.1284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2321,\tval_loss: 0.1210\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1528,\tval_loss: 0.1179\n",
            "2:\t[0s / 1s],\t\ttrain_loss: 0.1524,\tval_loss: 0.1180\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1435,\tval_loss: 0.1137\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1387,\tval_loss: 0.1150\n",
            "5:\t[0s / 2s],\t\ttrain_loss: 0.1363,\tval_loss: 0.1149\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.1346,\tval_loss: 0.1145\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1305,\tval_loss: 0.1138\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1275,\tval_loss: 0.1138\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 0.1258,\tval_loss: 0.1150\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1244,\tval_loss: 0.1141\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1239,\tval_loss: 0.1125\n",
            "12:\t[0s / 4s],\t\ttrain_loss: 0.1224,\tval_loss: 0.1132\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 0.1244,\tval_loss: 0.1123\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1233,\tval_loss: 0.1116\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1247,\tval_loss: 0.1124\n",
            "16:\t[0s / 5s],\t\ttrain_loss: 0.1198,\tval_loss: 0.1154\n",
            "17:\t[0s / 5s],\t\ttrain_loss: 0.1208,\tval_loss: 0.1128\n",
            "18:\t[0s / 5s],\t\ttrain_loss: 0.1176,\tval_loss: 0.1154\n",
            "19:\t[0s / 5s],\t\ttrain_loss: 0.1183,\tval_loss: 0.1127\n",
            "20:\t[0s / 6s],\t\ttrain_loss: 0.1174,\tval_loss: 0.1150\n",
            "21:\t[0s / 6s],\t\ttrain_loss: 0.1167,\tval_loss: 0.1188\n",
            "22:\t[0s / 6s],\t\ttrain_loss: 0.1149,\tval_loss: 0.1136\n",
            "23:\t[0s / 7s],\t\ttrain_loss: 0.5302,\tval_loss: 0.1305\n",
            "24:\t[0s / 7s],\t\ttrain_loss: 0.2121,\tval_loss: 0.1262\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2246,\tval_loss: 0.1234\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1865,\tval_loss: 0.1158\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1484,\tval_loss: 0.1140\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1453,\tval_loss: 0.1154\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1430,\tval_loss: 0.1152\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1415,\tval_loss: 0.1157\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1382,\tval_loss: 0.1131\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1366,\tval_loss: 0.1123\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1372,\tval_loss: 0.1146\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1357,\tval_loss: 0.1163\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1329,\tval_loss: 0.1138\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1361,\tval_loss: 0.1148\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1351,\tval_loss: 0.1150\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1313,\tval_loss: 0.1129\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1318,\tval_loss: 0.1155\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1328,\tval_loss: 0.1152\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1305,\tval_loss: 0.1139\n",
            "17:\t[0s / 5s],\t\ttrain_loss: 0.1275,\tval_loss: 0.1140\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2679,\tval_loss: 0.1312\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1552,\tval_loss: 0.1178\n",
            "2:\t[0s / 1s],\t\ttrain_loss: 0.1410,\tval_loss: 0.1173\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1470,\tval_loss: 0.1145\n",
            "4:\t[0s / 2s],\t\ttrain_loss: 0.1345,\tval_loss: 0.1189\n",
            "5:\t[0s / 2s],\t\ttrain_loss: 0.1346,\tval_loss: 0.1153\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.1318,\tval_loss: 0.1168\n",
            "7:\t[0s / 3s],\t\ttrain_loss: 0.1315,\tval_loss: 0.1136\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 0.1254,\tval_loss: 0.1139\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 0.1245,\tval_loss: 0.1147\n",
            "10:\t[0s / 4s],\t\ttrain_loss: 0.1256,\tval_loss: 0.1129\n",
            "11:\t[0s / 4s],\t\ttrain_loss: 0.1224,\tval_loss: 0.1128\n",
            "12:\t[0s / 4s],\t\ttrain_loss: 0.1230,\tval_loss: 0.1139\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 0.1188,\tval_loss: 0.1118\n",
            "14:\t[0s / 5s],\t\ttrain_loss: 0.1207,\tval_loss: 0.1169\n",
            "15:\t[0s / 5s],\t\ttrain_loss: 0.1202,\tval_loss: 0.1141\n",
            "16:\t[0s / 5s],\t\ttrain_loss: 0.1192,\tval_loss: 0.1156\n",
            "17:\t[0s / 6s],\t\ttrain_loss: 0.1154,\tval_loss: 0.1158\n",
            "18:\t[0s / 6s],\t\ttrain_loss: 0.1192,\tval_loss: 0.1182\n",
            "19:\t[0s / 6s],\t\ttrain_loss: 0.1158,\tval_loss: 0.1189\n",
            "20:\t[0s / 6s],\t\ttrain_loss: 0.1147,\tval_loss: 0.1219\n",
            "21:\t[0s / 7s],\t\ttrain_loss: 0.1130,\tval_loss: 0.1176\n",
            "22:\t[0s / 7s],\t\ttrain_loss: 0.1135,\tval_loss: 0.1237\n",
            "23:\t[0s / 7s],\t\ttrain_loss: 0.1142,\tval_loss: 0.1213\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2168,\tval_loss: 0.1234\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1538,\tval_loss: 0.1182\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1441,\tval_loss: 0.1167\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1325,\tval_loss: 0.1198\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1358,\tval_loss: 0.1173\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1283,\tval_loss: 0.1151\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1303,\tval_loss: 0.1156\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1273,\tval_loss: 0.1157\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1221,\tval_loss: 0.1158\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1256,\tval_loss: 0.1162\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1230,\tval_loss: 0.1163\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1216,\tval_loss: 0.1171\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1246,\tval_loss: 0.1178\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1182,\tval_loss: 0.1185\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1199,\tval_loss: 0.1206\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1198,\tval_loss: 0.1224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1776,\tval_loss: 0.1236\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1535,\tval_loss: 0.1196\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1317,\tval_loss: 0.1190\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1210,\tval_loss: 0.1155\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1210,\tval_loss: 0.1210\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1209,\tval_loss: 0.1152\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.1151,\tval_loss: 0.1178\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1165,\tval_loss: 0.1148\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 0.1133,\tval_loss: 0.1150\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 0.1155,\tval_loss: 0.1158\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1119,\tval_loss: 0.1143\n",
            "11:\t[0s / 4s],\t\ttrain_loss: 0.1125,\tval_loss: 0.1149\n",
            "12:\t[0s / 4s],\t\ttrain_loss: 0.1085,\tval_loss: 0.1164\n",
            "13:\t[0s / 5s],\t\ttrain_loss: 0.1076,\tval_loss: 0.1210\n",
            "14:\t[0s / 5s],\t\ttrain_loss: 0.1084,\tval_loss: 0.1157\n",
            "15:\t[0s / 5s],\t\ttrain_loss: 0.1109,\tval_loss: 0.1175\n",
            "16:\t[0s / 6s],\t\ttrain_loss: 0.1095,\tval_loss: 0.1204\n",
            "17:\t[0s / 6s],\t\ttrain_loss: 0.1084,\tval_loss: 0.1175\n",
            "18:\t[0s / 6s],\t\ttrain_loss: 0.1068,\tval_loss: 0.1189\n",
            "19:\t[0s / 7s],\t\ttrain_loss: 0.1051,\tval_loss: 0.1213\n",
            "20:\t[0s / 7s],\t\ttrain_loss: 0.1017,\tval_loss: 0.1190\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1861,\tval_loss: 0.1364\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1554,\tval_loss: 0.1186\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1451,\tval_loss: 0.1190\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1425,\tval_loss: 0.1211\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1259,\tval_loss: 0.1191\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1255,\tval_loss: 0.1167\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1211,\tval_loss: 0.1158\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1187,\tval_loss: 0.1203\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1205,\tval_loss: 0.1199\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1193,\tval_loss: 0.1163\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1197,\tval_loss: 0.1181\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1289,\tval_loss: 0.1162\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1122,\tval_loss: 0.1141\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1165,\tval_loss: 0.1153\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1124,\tval_loss: 0.1134\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1147,\tval_loss: 0.1153\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1159,\tval_loss: 0.1146\n",
            "17:\t[0s / 5s],\t\ttrain_loss: 0.1265,\tval_loss: 0.1181\n",
            "18:\t[0s / 5s],\t\ttrain_loss: 0.1155,\tval_loss: 0.1143\n",
            "19:\t[0s / 5s],\t\ttrain_loss: 0.1114,\tval_loss: 0.1164\n",
            "20:\t[0s / 5s],\t\ttrain_loss: 0.1117,\tval_loss: 0.1155\n",
            "21:\t[0s / 6s],\t\ttrain_loss: 0.1119,\tval_loss: 0.1151\n",
            "22:\t[0s / 6s],\t\ttrain_loss: 0.1193,\tval_loss: 0.1188\n",
            "23:\t[0s / 7s],\t\ttrain_loss: 0.1172,\tval_loss: 0.1174\n",
            "24:\t[0s / 7s],\t\ttrain_loss: 0.1131,\tval_loss: 0.1177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1966,\tval_loss: 0.1227\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1500,\tval_loss: 0.1168\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1384,\tval_loss: 0.1168\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1318,\tval_loss: 0.1181\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1279,\tval_loss: 0.1156\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1257,\tval_loss: 0.1157\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.1207,\tval_loss: 0.1172\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1203,\tval_loss: 0.1184\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 0.1230,\tval_loss: 0.1163\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 0.1187,\tval_loss: 0.1166\n",
            "10:\t[0s / 4s],\t\ttrain_loss: 0.1163,\tval_loss: 0.1157\n",
            "11:\t[0s / 4s],\t\ttrain_loss: 0.1176,\tval_loss: 0.1160\n",
            "12:\t[0s / 4s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1169\n",
            "13:\t[0s / 5s],\t\ttrain_loss: 0.1145,\tval_loss: 0.1198\n",
            "14:\t[0s / 5s],\t\ttrain_loss: 0.1136,\tval_loss: 0.1173\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.3817,\tval_loss: 0.1262\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1733,\tval_loss: 0.1224\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1536,\tval_loss: 0.1182\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1463,\tval_loss: 0.1161\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1403,\tval_loss: 0.1170\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1363,\tval_loss: 0.1199\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1387,\tval_loss: 0.1172\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1342,\tval_loss: 0.1176\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1288,\tval_loss: 0.1157\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1288,\tval_loss: 0.1169\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1312,\tval_loss: 0.1161\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1274,\tval_loss: 0.1158\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1265,\tval_loss: 0.1169\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1270,\tval_loss: 0.1168\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1257,\tval_loss: 0.1167\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1356,\tval_loss: 0.1146\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1251,\tval_loss: 0.1143\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.1240,\tval_loss: 0.1145\n",
            "18:\t[0s / 5s],\t\ttrain_loss: 0.1232,\tval_loss: 0.1170\n",
            "19:\t[0s / 5s],\t\ttrain_loss: 0.1233,\tval_loss: 0.1173\n",
            "20:\t[0s / 5s],\t\ttrain_loss: 0.1197,\tval_loss: 0.1199\n",
            "21:\t[0s / 5s],\t\ttrain_loss: 0.1202,\tval_loss: 0.1218\n",
            "22:\t[0s / 6s],\t\ttrain_loss: 0.1201,\tval_loss: 0.1250\n",
            "23:\t[0s / 6s],\t\ttrain_loss: 0.1213,\tval_loss: 0.1203\n",
            "24:\t[0s / 6s],\t\ttrain_loss: 0.1186,\tval_loss: 0.1212\n",
            "25:\t[0s / 7s],\t\ttrain_loss: 0.1230,\tval_loss: 0.1191\n",
            "26:\t[0s / 7s],\t\ttrain_loss: 0.1197,\tval_loss: 0.1241\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1982,\tval_loss: 0.1289\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1482,\tval_loss: 0.1172\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1479,\tval_loss: 0.1180\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1345,\tval_loss: 0.1183\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1330,\tval_loss: 0.1164\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1335,\tval_loss: 0.1161\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1286,\tval_loss: 0.1155\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1259,\tval_loss: 0.1166\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1257,\tval_loss: 0.1175\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1213,\tval_loss: 0.1203\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1211,\tval_loss: 0.1167\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1204,\tval_loss: 0.1173\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1201,\tval_loss: 0.1161\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 0.1185,\tval_loss: 0.1153\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1191,\tval_loss: 0.1175\n",
            "15:\t[0s / 5s],\t\ttrain_loss: 0.1109,\tval_loss: 0.1200\n",
            "16:\t[0s / 5s],\t\ttrain_loss: 0.1187,\tval_loss: 0.1247\n",
            "17:\t[0s / 5s],\t\ttrain_loss: 0.1147,\tval_loss: 0.1198\n",
            "18:\t[0s / 6s],\t\ttrain_loss: 0.1198,\tval_loss: 0.1198\n",
            "19:\t[0s / 6s],\t\ttrain_loss: 0.1155,\tval_loss: 0.1314\n",
            "20:\t[0s / 7s],\t\ttrain_loss: 0.1197,\tval_loss: 0.1250\n",
            "21:\t[0s / 7s],\t\ttrain_loss: 0.1168,\tval_loss: 0.1239\n",
            "22:\t[0s / 7s],\t\ttrain_loss: 0.1202,\tval_loss: 0.1186\n",
            "23:\t[0s / 8s],\t\ttrain_loss: 0.1183,\tval_loss: 0.1159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1815,\tval_loss: 0.1214\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1458,\tval_loss: 0.1170\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1441,\tval_loss: 0.1176\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1307,\tval_loss: 0.1182\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1268,\tval_loss: 0.1145\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1252,\tval_loss: 0.1159\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1205,\tval_loss: 0.1161\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1165,\tval_loss: 0.1170\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1202,\tval_loss: 0.1136\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1152,\tval_loss: 0.1151\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.1114,\tval_loss: 0.1142\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1122,\tval_loss: 0.1148\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1161,\tval_loss: 0.1164\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1158,\tval_loss: 0.1147\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1110,\tval_loss: 0.1204\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1148,\tval_loss: 0.1160\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1115,\tval_loss: 0.1155\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.1128,\tval_loss: 0.1206\n",
            "18:\t[0s / 5s],\t\ttrain_loss: 0.1118,\tval_loss: 0.1159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2171,\tval_loss: 0.1189\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1526,\tval_loss: 0.1175\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1468,\tval_loss: 0.1178\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1390,\tval_loss: 0.1168\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1361,\tval_loss: 0.1200\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1316,\tval_loss: 0.1161\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1293,\tval_loss: 0.1177\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1286,\tval_loss: 0.1164\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1273,\tval_loss: 0.1187\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1277,\tval_loss: 0.1180\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1255,\tval_loss: 0.1170\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1254,\tval_loss: 0.1155\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1232,\tval_loss: 0.1157\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1227,\tval_loss: 0.1175\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1218,\tval_loss: 0.1160\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1200,\tval_loss: 0.1203\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1233,\tval_loss: 0.1189\n",
            "17:\t[0s / 5s],\t\ttrain_loss: 0.1209,\tval_loss: 0.1172\n",
            "18:\t[0s / 5s],\t\ttrain_loss: 0.1199,\tval_loss: 0.1206\n",
            "19:\t[0s / 6s],\t\ttrain_loss: 0.1206,\tval_loss: 0.1148\n",
            "20:\t[0s / 6s],\t\ttrain_loss: 0.1178,\tval_loss: 0.1191\n",
            "21:\t[0s / 6s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1209\n",
            "22:\t[0s / 7s],\t\ttrain_loss: 0.1196,\tval_loss: 0.1233\n",
            "23:\t[0s / 7s],\t\ttrain_loss: 0.1156,\tval_loss: 0.1251\n",
            "24:\t[0s / 8s],\t\ttrain_loss: 0.1166,\tval_loss: 0.1219\n",
            "25:\t[0s / 8s],\t\ttrain_loss: 0.1150,\tval_loss: 0.1229\n",
            "26:\t[0s / 9s],\t\ttrain_loss: 0.1132,\tval_loss: 0.1205\n",
            "27:\t[0s / 9s],\t\ttrain_loss: 0.1143,\tval_loss: 0.1210\n",
            "28:\t[0s / 9s],\t\ttrain_loss: 0.1112,\tval_loss: 0.1379\n",
            "29:\t[0s / 9s],\t\ttrain_loss: 0.1172,\tval_loss: 0.1282\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2241,\tval_loss: 0.1196\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1424,\tval_loss: 0.1193\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1419,\tval_loss: 0.1159\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1390,\tval_loss: 0.1146\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1328,\tval_loss: 0.1164\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1273,\tval_loss: 0.1159\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1260,\tval_loss: 0.1152\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1263,\tval_loss: 0.1166\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1205,\tval_loss: 0.1143\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1220,\tval_loss: 0.1146\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.1217,\tval_loss: 0.1195\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1202,\tval_loss: 0.1162\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1199,\tval_loss: 0.1147\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1137,\tval_loss: 0.1168\n",
            "14:\t[0s / 3s],\t\ttrain_loss: 0.1140,\tval_loss: 0.1154\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1185,\tval_loss: 0.1138\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1102,\tval_loss: 0.1169\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.1090,\tval_loss: 0.1211\n",
            "18:\t[0s / 5s],\t\ttrain_loss: 0.1083,\tval_loss: 0.1237\n",
            "19:\t[0s / 5s],\t\ttrain_loss: 0.1143,\tval_loss: 0.1166\n",
            "20:\t[0s / 5s],\t\ttrain_loss: 0.1059,\tval_loss: 0.1182\n",
            "21:\t[0s / 5s],\t\ttrain_loss: 0.1115,\tval_loss: 0.1197\n",
            "22:\t[0s / 6s],\t\ttrain_loss: 0.1098,\tval_loss: 0.1196\n",
            "23:\t[0s / 6s],\t\ttrain_loss: 0.1058,\tval_loss: 0.1284\n",
            "24:\t[0s / 6s],\t\ttrain_loss: 0.1074,\tval_loss: 0.1269\n",
            "25:\t[0s / 6s],\t\ttrain_loss: 0.1072,\tval_loss: 0.1403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1841,\tval_loss: 0.1184\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1412,\tval_loss: 0.1146\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1334,\tval_loss: 0.1177\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1287,\tval_loss: 0.1146\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1261,\tval_loss: 0.1143\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1221,\tval_loss: 0.1134\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1250,\tval_loss: 0.1147\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1185,\tval_loss: 0.1157\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1194,\tval_loss: 0.1132\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1215,\tval_loss: 0.1139\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1185,\tval_loss: 0.1164\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1188,\tval_loss: 0.1189\n",
            "12:\t[0s / 4s],\t\ttrain_loss: 0.1191,\tval_loss: 0.1162\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 0.1190,\tval_loss: 0.1143\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1179\n",
            "15:\t[0s / 5s],\t\ttrain_loss: 0.1167,\tval_loss: 0.1131\n",
            "16:\t[0s / 5s],\t\ttrain_loss: 0.1157,\tval_loss: 0.1187\n",
            "17:\t[0s / 6s],\t\ttrain_loss: 0.1175,\tval_loss: 0.1130\n",
            "18:\t[0s / 6s],\t\ttrain_loss: 0.1248,\tval_loss: 0.1193\n",
            "19:\t[0s / 6s],\t\ttrain_loss: 0.1156,\tval_loss: 0.1191\n",
            "20:\t[0s / 7s],\t\ttrain_loss: 0.1174,\tval_loss: 0.1209\n",
            "21:\t[0s / 7s],\t\ttrain_loss: 0.1171,\tval_loss: 0.1180\n",
            "22:\t[0s / 7s],\t\ttrain_loss: 0.1162,\tval_loss: 0.1159\n",
            "23:\t[0s / 7s],\t\ttrain_loss: 0.1135,\tval_loss: 0.1185\n",
            "24:\t[0s / 8s],\t\ttrain_loss: 0.1111,\tval_loss: 0.1193\n",
            "25:\t[0s / 8s],\t\ttrain_loss: 0.1147,\tval_loss: 0.1157\n",
            "26:\t[0s / 8s],\t\ttrain_loss: 0.1151,\tval_loss: 0.1127\n",
            "27:\t[0s / 9s],\t\ttrain_loss: 0.1136,\tval_loss: 0.1144\n",
            "28:\t[0s / 9s],\t\ttrain_loss: 0.1170,\tval_loss: 0.1190\n",
            "29:\t[0s / 9s],\t\ttrain_loss: 0.1138,\tval_loss: 0.1161\n",
            "30:\t[0s / 9s],\t\ttrain_loss: 0.1898,\tval_loss: 0.1362\n",
            "31:\t[0s / 10s],\t\ttrain_loss: 0.5130,\tval_loss: 0.1256\n",
            "32:\t[0s / 10s],\t\ttrain_loss: 0.1550,\tval_loss: 0.1210\n",
            "33:\t[0s / 10s],\t\ttrain_loss: 0.1368,\tval_loss: 0.1223\n",
            "34:\t[0s / 10s],\t\ttrain_loss: 0.1282,\tval_loss: 0.1150\n",
            "35:\t[0s / 11s],\t\ttrain_loss: 0.1259,\tval_loss: 0.1145\n",
            "36:\t[0s / 11s],\t\ttrain_loss: 0.1215,\tval_loss: 0.1150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1949,\tval_loss: 0.1234\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1406,\tval_loss: 0.1180\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1293,\tval_loss: 0.1151\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1233,\tval_loss: 0.1131\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1156,\tval_loss: 0.1197\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1132,\tval_loss: 0.1120\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1103,\tval_loss: 0.1136\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1156,\tval_loss: 0.1102\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1074,\tval_loss: 0.1124\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1067,\tval_loss: 0.1126\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1060,\tval_loss: 0.1162\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1074,\tval_loss: 0.1160\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1038,\tval_loss: 0.1162\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1016,\tval_loss: 0.1170\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1016,\tval_loss: 0.1237\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1008,\tval_loss: 0.1217\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.0972,\tval_loss: 0.1222\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 0.0972,\tval_loss: 0.1235\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.3141,\tval_loss: 0.1203\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1559,\tval_loss: 0.1148\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1384,\tval_loss: 0.1156\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1399,\tval_loss: 0.1163\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1371,\tval_loss: 0.1144\n",
            "5:\t[0s / 2s],\t\ttrain_loss: 0.1283,\tval_loss: 0.1144\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.1294,\tval_loss: 0.1154\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1264,\tval_loss: 0.1160\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 0.1249,\tval_loss: 0.1152\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 0.1197,\tval_loss: 0.1190\n",
            "10:\t[0s / 4s],\t\ttrain_loss: 0.1195,\tval_loss: 0.1159\n",
            "11:\t[0s / 4s],\t\ttrain_loss: 0.1212,\tval_loss: 0.1141\n",
            "12:\t[0s / 5s],\t\ttrain_loss: 0.1183,\tval_loss: 0.1144\n",
            "13:\t[0s / 5s],\t\ttrain_loss: 0.1203,\tval_loss: 0.1147\n",
            "14:\t[0s / 5s],\t\ttrain_loss: 0.1205,\tval_loss: 0.1183\n",
            "15:\t[0s / 5s],\t\ttrain_loss: 0.1135,\tval_loss: 0.1149\n",
            "16:\t[0s / 6s],\t\ttrain_loss: 0.1170,\tval_loss: 0.1154\n",
            "17:\t[0s / 6s],\t\ttrain_loss: 0.1132,\tval_loss: 0.1172\n",
            "18:\t[0s / 6s],\t\ttrain_loss: 0.1126,\tval_loss: 0.1174\n",
            "19:\t[0s / 6s],\t\ttrain_loss: 0.1092,\tval_loss: 0.1201\n",
            "20:\t[0s / 7s],\t\ttrain_loss: 0.1143,\tval_loss: 0.1196\n",
            "21:\t[0s / 7s],\t\ttrain_loss: 0.1139,\tval_loss: 0.1232\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1868,\tval_loss: 0.1182\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1523,\tval_loss: 0.1162\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1384,\tval_loss: 0.1144\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1305,\tval_loss: 0.1161\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1227,\tval_loss: 0.1128\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1186,\tval_loss: 0.1151\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1173,\tval_loss: 0.1106\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1158,\tval_loss: 0.1125\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1178,\tval_loss: 0.1139\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1149,\tval_loss: 0.1143\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 0.1140,\tval_loss: 0.1136\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1132,\tval_loss: 0.1114\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1088,\tval_loss: 0.1153\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 0.1076,\tval_loss: 0.1140\n",
            "14:\t[0s / 3s],\t\ttrain_loss: 0.1127,\tval_loss: 0.1168\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1119,\tval_loss: 0.1191\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1082,\tval_loss: 0.1164\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2889,\tval_loss: 0.1201\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1613,\tval_loss: 0.1226\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1493,\tval_loss: 0.1200\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1350,\tval_loss: 0.1208\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1345,\tval_loss: 0.1179\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1324,\tval_loss: 0.1175\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 0.1306,\tval_loss: 0.1163\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1239,\tval_loss: 0.1173\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1215,\tval_loss: 0.1177\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1223,\tval_loss: 0.1181\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1204,\tval_loss: 0.1188\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1200,\tval_loss: 0.1198\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1203,\tval_loss: 0.1176\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 0.1180,\tval_loss: 0.1257\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1165,\tval_loss: 0.1282\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1196,\tval_loss: 0.1223\n",
            "16:\t[0s / 5s],\t\ttrain_loss: 0.1168,\tval_loss: 0.1193\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1974,\tval_loss: 0.1229\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1429,\tval_loss: 0.1181\n",
            "2:\t[0s / 1s],\t\ttrain_loss: 0.1305,\tval_loss: 0.1188\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1287,\tval_loss: 0.1156\n",
            "4:\t[0s / 2s],\t\ttrain_loss: 0.1251,\tval_loss: 0.1155\n",
            "5:\t[0s / 2s],\t\ttrain_loss: 0.1235,\tval_loss: 0.1129\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.1208,\tval_loss: 0.1139\n",
            "7:\t[0s / 3s],\t\ttrain_loss: 0.1217,\tval_loss: 0.1129\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 0.1173,\tval_loss: 0.1132\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 0.1181,\tval_loss: 0.1127\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1178,\tval_loss: 0.1124\n",
            "11:\t[0s / 4s],\t\ttrain_loss: 0.1139,\tval_loss: 0.1116\n",
            "12:\t[0s / 4s],\t\ttrain_loss: 0.1135,\tval_loss: 0.1112\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 0.1156,\tval_loss: 0.1152\n",
            "14:\t[0s / 5s],\t\ttrain_loss: 0.1143,\tval_loss: 0.1144\n",
            "15:\t[0s / 5s],\t\ttrain_loss: 0.1109,\tval_loss: 0.1135\n",
            "16:\t[0s / 5s],\t\ttrain_loss: 0.1131,\tval_loss: 0.1151\n",
            "17:\t[0s / 5s],\t\ttrain_loss: 0.1137,\tval_loss: 0.1153\n",
            "18:\t[0s / 6s],\t\ttrain_loss: 0.1099,\tval_loss: 0.1170\n",
            "19:\t[0s / 6s],\t\ttrain_loss: 0.1148,\tval_loss: 0.1156\n",
            "20:\t[0s / 6s],\t\ttrain_loss: 0.1089,\tval_loss: 0.1191\n",
            "21:\t[0s / 6s],\t\ttrain_loss: 0.1113,\tval_loss: 0.1148\n",
            "22:\t[0s / 7s],\t\ttrain_loss: 0.1090,\tval_loss: 0.1196\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.2296,\tval_loss: 0.1179\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1647,\tval_loss: 0.1169\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.1561,\tval_loss: 0.1170\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1427,\tval_loss: 0.1147\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1323,\tval_loss: 0.1148\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 0.1312,\tval_loss: 0.1136\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.1317,\tval_loss: 0.1136\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1244,\tval_loss: 0.1133\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1221,\tval_loss: 0.1130\n",
            "9:\t[0s / 2s],\t\ttrain_loss: 0.1240,\tval_loss: 0.1132\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1238,\tval_loss: 0.1131\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1169,\tval_loss: 0.1108\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1191,\tval_loss: 0.1130\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 0.1138,\tval_loss: 0.1111\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 0.1129,\tval_loss: 0.1123\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 0.1154,\tval_loss: 0.1101\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 0.1139,\tval_loss: 0.1105\n",
            "17:\t[0s / 5s],\t\ttrain_loss: 0.1094,\tval_loss: 0.1089\n",
            "18:\t[0s / 5s],\t\ttrain_loss: 0.1123,\tval_loss: 0.1123\n",
            "19:\t[0s / 5s],\t\ttrain_loss: 0.1085,\tval_loss: 0.1134\n",
            "20:\t[0s / 6s],\t\ttrain_loss: 0.1088,\tval_loss: 0.1100\n",
            "21:\t[0s / 6s],\t\ttrain_loss: 0.1090,\tval_loss: 0.1121\n",
            "22:\t[0s / 7s],\t\ttrain_loss: 0.1054,\tval_loss: 0.1191\n",
            "23:\t[0s / 7s],\t\ttrain_loss: 0.1129,\tval_loss: 0.1142\n",
            "24:\t[0s / 8s],\t\ttrain_loss: 0.1071,\tval_loss: 0.1152\n",
            "25:\t[0s / 8s],\t\ttrain_loss: 0.1030,\tval_loss: 0.1189\n",
            "26:\t[0s / 8s],\t\ttrain_loss: 0.1078,\tval_loss: 0.1150\n",
            "27:\t[0s / 9s],\t\ttrain_loss: 0.1045,\tval_loss: 0.1184\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 0.1679,\tval_loss: 0.1168\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.1593,\tval_loss: 0.1155\n",
            "2:\t[0s / 1s],\t\ttrain_loss: 0.1318,\tval_loss: 0.1126\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 0.1223,\tval_loss: 0.1148\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 0.1205,\tval_loss: 0.1135\n",
            "5:\t[0s / 2s],\t\ttrain_loss: 0.1129,\tval_loss: 0.1180\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 0.1094,\tval_loss: 0.1163\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 0.1109,\tval_loss: 0.1171\n",
            "8:\t[0s / 2s],\t\ttrain_loss: 0.1094,\tval_loss: 0.1141\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 0.1076,\tval_loss: 0.1142\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 0.1066,\tval_loss: 0.1139\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 0.1060,\tval_loss: 0.1155\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 0.1068,\tval_loss: 0.1155\n",
            "Bootstrap 95% confidence interval for the C-index: (0.52, 0.65)\n",
            "Bootstrap 95% confidence interval for the IBS: (0.08, 0.09)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pycox/evaluation/eval_surv.py:36: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  assert pd.Series(self.index_surv).is_monotonic\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# Number of bootstrap iterations\n",
        "n_bootstrap_iterations = 50\n",
        "\n",
        "# Arrays to store bootstrap C-indices and IBS scores\n",
        "bootstrap_c_indices_deephit = np.zeros(n_bootstrap_iterations)\n",
        "bootstrap_ibs_scores_deep_hit = np.zeros(n_bootstrap_iterations)\n",
        "\n",
        "best_hyperparameters = {\n",
        "    'batch_size': 32,\n",
        "    'layers': 5,\n",
        "    'nodes': 50,\n",
        "    'activation_fn': 'elu',\n",
        "    'alpha': 0.1,\n",
        "    'sigma': 0.1,\n",
        "    'lr': 0.01\n",
        "}\n",
        "\n",
        "for i in range(n_bootstrap_iterations):\n",
        "    # Generate a bootstrap sample of indices\n",
        "    bootstrap_indices = resample(np.arange(len(x_train)), replace=True)\n",
        "\n",
        "    # Use these indices to create bootstrap samples\n",
        "    bootstrap_train_x = x_train[bootstrap_indices]\n",
        "    bootstrap_train_y_times = y_train[0][bootstrap_indices]\n",
        "    bootstrap_train_y_events = y_train[1][bootstrap_indices]\n",
        "\n",
        "    # Fit the model using the resampled training data with the best hyperparameters\n",
        "    num_nodes = [best_hyperparameters['nodes']] * best_hyperparameters['layers']\n",
        "    batch_norm = False\n",
        "    dropout = 0.4\n",
        "\n",
        "    bootstrap_net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
        "\n",
        "    bootstrap_model = DeepHitSingle(bootstrap_net, tt.optim.Adam, alpha=best_hyperparameters['alpha'], sigma=best_hyperparameters['sigma'], duration_index=labtrans.cuts)\n",
        "\n",
        "    batch_size = best_hyperparameters['batch_size']\n",
        "    bootstrap_model.optimizer.set_lr(best_hyperparameters['lr'])\n",
        "\n",
        "    epochs = 100\n",
        "    callbacks = [tt.callbacks.EarlyStopping()]\n",
        "    log = bootstrap_model.fit(bootstrap_train_x, (bootstrap_train_y_times, bootstrap_train_y_events), batch_size, epochs, callbacks, val_data=val)\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    surv = bootstrap_model.predict_surv_df(x_test)\n",
        "    ev_test = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
        "    c_index_test = ev_test.concordance_td('antolini')\n",
        "    bootstrap_c_indices_deephit[i] = c_index_test\n",
        "\n",
        "    # Calculate the integrated Brier score\n",
        "    ibs = ev_test.integrated_brier_score(time_grid=np.linspace(0, durations_test.max(), 100))\n",
        "    bootstrap_ibs_scores_deep_hit[i] = ibs\n",
        "\n",
        "# Compute the lower and upper percentiles for C-index\n",
        "lower_percentile_c_index = np.percentile(bootstrap_c_indices_deephit, 2.5)\n",
        "upper_percentile_c_index = np.percentile(bootstrap_c_indices_deephit, 97.5)\n",
        "\n",
        "# Compute the lower and upper percentiles for IBS\n",
        "lower_percentile_ibs = np.percentile(bootstrap_ibs_scores_deep_hit, 2.5)\n",
        "upper_percentile_ibs = np.percentile(bootstrap_ibs_scores_deep_hit, 97.5)\n",
        "\n",
        "print('Bootstrap 95% confidence interval for the C-index: ({:.2f}, {:.2f})'.format(lower_percentile_c_index, upper_percentile_c_index))\n",
        "print('Bootstrap 95% confidence interval for the IBS: ({:.2f}, {:.2f})'.format(lower_percentile_ibs, upper_percentile_ibs))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3g3iHsBkYtyB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# save the numpy arrays to the specified directory\n",
        "np.save('/content/drive/MyDrive/MSc_summer_project/Clinical_trial_data/Breast/Confidence_intervals_breast_IBS_cindex/bootstrap_c_indices_deephit.npy', bootstrap_c_indices_deephit)\n",
        "np.save('/content/drive/MyDrive/MSc_summer_project/Clinical_trial_data/Breast/Confidence_intervals_breast_IBS_cindex/bootstrap_ibs_scores_deep_hit.npy', bootstrap_ibs_scores_deep_hit)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yAAsHYHM6Ce0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1JZCZf3vTk0yx1AMoDYV46Rkosjo4XCUe",
      "authorship_tag": "ABX9TyMwv4kPM9qqs6OA9/hVD3X9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
